rpm update complaining on plugin changes sudo yum install logstash loaded plugins fastestmirror priorities logstash 951 00 00 00 logstash primary kb 00 00 00 loading mirror speeds from cached hostfile logstash resolving dependencies running transaction check package logstash noarch will be updated package logstash noarch will be an update finished dependency resolution dependencies resolved package arch version repository size updating logstash noarch logstash 72 transaction summary upgrade package total download size 72 is this ok downloading packages delta rpms disabled because usr bin applydeltarpm not installed logstash noarch rpm 72 mb 00 00 03 running transaction check running transaction test transaction test succeeded running transaction updating logstash noarch warning etc init logstash created as etc init logstash rpmnew cleanup logstash noarch warning file opt logstash vendor bundle jruby specifications logstash output kafka gemspec remove failed no such file or directory warning file opt logstash vendor bundle jruby specifications logstash input kafka gemspec remove failed no such file or directory warning file opt logstash vendor bundle jruby specifications jruby openssl 12 java gemspec remove failed no such file or directory warning file opt logstash vendor bundle jruby specifications jruby kafka java gemspec remove failed no such file or directory warning file opt logstash vendor bundle jruby specifications jrjackson gemspec remove failed no such file or directory warning file opt logstash vendor bundle jruby specifications jar dependencies gemspec remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash output kafka logstash output kafka gemspec remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash output kafka lib logstash outputs kafka rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash output kafka readme md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash output kafka notice txt remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash output kafka license remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash output kafka gemfile remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash output kafka developer md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash output kafka contributors remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash output kafka changelog md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash input kafka logstash input kafka gemspec remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash input kafka lib logstash inputs kafka rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash input kafka readme md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash input kafka notice txt remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash input kafka license remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash input kafka gemfile remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash input kafka developer md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash input kafka contributors remove failed no such file or directory warning file opt logstash vendor bundle jruby gems logstash input kafka changelog md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib org bouncycastle bcprov jdk15on 50 bcprov jdk15on 50 jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib org bouncycastle bcpkix jdk15on 50 bcpkix jdk15on 50 jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl x509 rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl x509 internal rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl ssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl ssl internal rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl pkcs7 rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl pkcs12 rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl digest rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl config rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl cipher rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl buffering rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl bn rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib openssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jruby openssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl22 openssl x509 rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl22 openssl ssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl22 openssl digest rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl22 openssl config rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl22 openssl cipher rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl22 openssl buffering rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl22 openssl bn rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl22 openssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl21 openssl x509 rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl21 openssl ssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl21 openssl digest rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl21 openssl config rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl21 openssl cipher rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl21 openssl buffering rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl21 openssl bn rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl21 openssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl19 openssl x509 rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl19 openssl x509 internal rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl19 openssl ssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl19 openssl ssl internal rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl19 openssl digest rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl19 openssl config rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl19 openssl cipher rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl19 openssl buffering rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl19 openssl bn rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl19 openssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl x509 rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl x509 internal rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl ssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl ssl internal rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl pkcs7 rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl digest rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl config rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl cipher rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl buffering rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl bn rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl18 openssl rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl version rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl load rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java rakefile remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java readme md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java license txt remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby openssl 12 java history md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems virtus maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems thread safe maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems ruby maven maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems ruby maven libs maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems rake maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems maven tools maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems jar dependencies maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems ice nine maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems equalizer maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems descendants tracker maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems coercible maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib rubygems axiom types maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org xerial snappy snappy java maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org xerial snappy snappy java snappy java jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org slf4j slf4j log4j12 maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org slf4j slf4j log4j12 10 slf4j log4j12 10 jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org slf4j slf4j api maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org slf4j slf4j api 10 slf4j api 10 jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org scala lang scala library maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org scala lang scala library 10 scala library 10 jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org apache zookeeper zookeeper maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org apache zookeeper zookeeper zookeeper jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org apache kafka kafka 10 maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org apache kafka kafka 10 kafka 10 jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org apache kafka kafka clients maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib org apache kafka kafka clients kafka clients jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib net sf jopt simple jopt simple maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib net sf jopt simple jopt simple jopt simple jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib net jpountz lz4 lz4 maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib net jpountz lz4 lz4 lz4 jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib log4j log4j maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib log4j log4j 17 log4j 17 jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib junit junit maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib junit junit junit jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib jruby kafka jars rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib jruby kafka producer rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib jruby kafka namespace rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib jruby kafka kafka producer rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib jruby kafka group rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib jruby kafka error rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib jruby kafka consumer rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib jruby kafka rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib jline jline maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib jline jline 94 jline 94 jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib io netty netty maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib io netty netty final netty final jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib com yammer metrics metrics core maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib com yammer metrics metrics core metrics core jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib com 101tec zkclient maven metadata local xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jruby kafka java lib com 101tec zkclient zkclient jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson test jrjackson test rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson streamparse java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson schparse java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson sajparse java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubyutils java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubysymbolnameconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubysymbolkeyconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubystringnameconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubystringkeyconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubystringconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubyobjectdeserializer java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubynameconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubykeyconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubyjacksonmodule java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubyintvalueconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubyhandler java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubyfloatvalueconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubydateformat java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubyconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubybigintvalueconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubybigdecimalvalueconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson rubyanyserializer java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson parseerror java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson jrparse java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson jrjacksonservice java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson jrjacksonsch java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson jrjacksonsaj java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson jrjacksonruby java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson jrjacksonraw java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson jrjacksonjava java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson jrjacksonbase java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson jjparse java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson javalongvalueconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson javahandler java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson javafloatvalueconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson javaconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson javabigintvalueconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson javabigdecimalvalueconverter java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson src main java com jrjackson iparsehandler java remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson run mri individual bench sh remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson run jruby individual bench sh remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson run all individual bench sh remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson profiling profiled rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson pom xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson lib require relative patch rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson lib jrjackson jrjackson rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson lib jrjackson jars jrjackson 17 jar remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson lib jrjackson build info rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson lib jrjackson rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson jrjackson gemspec remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson dependency reduced pom xml remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson changelog md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson alt bench rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson rakefile remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson readme md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jrjackson gemfile remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib rubygems plugin rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars version rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars setup rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars post install hook rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars output jars pom rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars maven factory rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars maven exec rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars lock down pom rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars lock down rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars lock rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars installer rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars gemspec pom rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars gemspec artifacts rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars classpath rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jars attach jars pom rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jar installer rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jar install post install hook rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jar dependencies rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies lib jar dependencies rb remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies jar dependencies gemspec remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies bin lock jars remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies readme md remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies rakefile remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies mavenfile remove failed no such file or directory warning file opt logstash vendor bundle jruby gems jar dependencies mit license remove failed no such file or directory verifying logstash noarch verifying logstash noarch updated logstash noarch complete >>>discuss enhancement packaging
fix errors in documentation about filebeat the documentation about filebeat in the logstash reference is incorrect and it causing users some confusion https www elastic co guide en logstash deploying and scaling html deploying filebeat filebeat does not use logstash forwarder or the lumberjack plugin the diagram needs to be updated it should say filebeat instead of logstash forwarder and it should say beats input plugin instead of lumberjack plugin https www elastic co guide en logstash advanced pipeline html configuring lsf the information about configuring filebeat is incorrect we wondered why so many people on the forums were using an old pre ga configuration this is the problem with duplicating content rather than duplicating the content we should point to the getting started in the filebeat reference for the configuration details delete the configuration details beginning with create configuration file for filebeat similar to the following example then add something like the following for information about installing and configuring filebeat see the https www elastic co guide en beats filebeat current filebeat getting started html getting started topic in the filebeat reference if you don want to deep link add link to the filebeat reference instead >>>bug docs
fix an issue with the expectation on the agent uptime fixes https github com elastic logstash issues 4686>>>blocker metrics v3.0.0-alpha1
test failing in the feature metrics jvm stats logstash api hotthreadscommand schema return hot threads information failure error expect report to not to be empty double agent received unexpected message uptime with no args logstash core lib logstash api lib app command rb 22 in `uptime logstash core lib logstash api lib app commands stats hotthreads command rb 112 in `cpu time as percent logstash core lib logstash api lib app commands stats hotthreads command rb 54 in `to hash logstash core lib logstash api lib app commands stats hotthreads command rb 78 in `each logstash core lib logstash api lib app commands stats hotthreads command rb 73 in `each logstash core lib logstash api lib app commands stats hotthreads command rb 52 in `to hash logstash core lib logstash api lib app commands stats hotthreads command rb 35 in `to logstash core spec api lib commands jvm spec rb 21 in root vendor bundle jruby gems rspec wait lib rspec wait rb 46 in root rakelib test rake 42 in root vendor bundle jruby gems rake 10 lib rake task rb 240 in `execute vendor bundle jruby gems rake 10 lib rake task rb 235 in `execute vendor bundle jruby gems rake 10 lib rake task rb 179 in `invoke with call chain vendor bundle jruby gems rake 10 lib rake task rb 172 in `invoke with call chain vendor bundle jruby gems rake 10 lib rake task rb 165 in `invoke vendor bundle jruby gems rake 10 lib rake application rb 150 in `invoke task vendor bundle jruby gems rake 10 lib rake application rb 106 in `top level vendor bundle jruby gems rake 10 lib rake application rb 106 in `top level vendor bundle jruby gems rake 10 lib rake application rb 115 in `run with threads vendor bundle jruby gems rake 10 lib rake application rb 100 in `top level vendor bundle jruby gems rake 10 lib rake application rb 78 in `run vendor bundle jruby gems rake 10 lib rake application rb 176 in `standard exception handling vendor bundle jruby gems rake 10 lib rake application rb 75 in `run >>>blocker bug metrics v3.0.0-alpha1
fix the metrics api when used from artifacts and small changes in webserver class fixes 4679 cc jsvd ph thoughts >>>bug metrics v3.0.0-alpha1
cleanup non used expectation inside the jvm specs fixes 4682 cc ph>>>bug metrics tests
test for `jvm stats logstash api hotthreadscommand` failling randomly jvm stats logstash api hotthreadscommand schema return hot threads information failure error expect subject to receive uptime and return 10 at least once uptime any args expected at least time with any arguments received times with any arguments logstash core spec api lib commands jvm spec rb 15 in root vendor bundle jruby gems rspec wait lib rspec wait rb 46 in root rakelib test rake 42 in root vendor bundle jruby gems rake 10 lib rake task rb 240 in `execute vendor bundle jruby gems rake 10 lib rake task rb 235 in `execute vendor bundle jruby gems rake 10 lib rake task rb 179 in `invoke with call chain vendor bundle jruby gems rake 10 lib rake task rb 172 in `invoke with call chain vendor bundle jruby gems rake 10 lib rake task rb 165 in `invoke vendor bundle jruby gems rake 10 lib rake application rb 150 in `invoke task vendor bundle jruby gems rake 10 lib rake application rb 106 in `top level vendor bundle jruby gems rake 10 lib rake application rb 106 in `top level vendor bundle jruby gems rake 10 lib rake application rb 115 in `run with threads vendor bundle jruby gems rake 10 lib rake application rb 100 in `top level vendor bundle jruby gems rake 10 lib rake application rb 78 in `run vendor bundle jruby gems rake 10 lib rake application rb 176 in `standard exception handling vendor bundle jruby gems rake 10 lib rake application rb 75 in `run finished in 19 81 seconds files took 44 seconds to load 1727 examples failure>>>metrics tests v3.0.0-alpha1
feature metrics cleanups cleanups debug variable used inside the pipeline fixed small typo in the memory command >>>metrics v3.0.0-alpha1
feature metrics is not working with latest commits suyog machine ws elastic logstash feature metrics bin logstash input stdin output stdout settings default pipeline workers logstash startup completed debug nil http host nil http port nil no application configured nothing to run level error suyog machine ws elastic logstash feature metrics ruby jruby 19 3p551 2015 01 29 20786bd on java hotspot tm 64 bit server vm 65 b17 jit darwin x86 64 suyog machine ws elastic logstash feature metrics java version java version 65 java tm se runtime environment build 65 b17 java hotspot tm 64 bit server vm build 25 65 b01 mixed mode settings default pipeline workers starting pipeline id main pipeline workers batch size 125 batch delay max inflight 1000 level info file logstash pipeline rb line 222 method start workers pipeline started level info file logstash pipeline rb line 170 method run logstash startup completed debug true http host nil http port nil puma start 2016 02 11 23 38 06 0800 level debug file logstash webserver rb line 47 method log puma starting in single mode level debug file logstash webserver rb line 47 method log version 16 jruby codename midwinter nights trance level debug file logstash webserver rb line 47 method log min threads max threads 16 level debug file logstash webserver rb line 47 method log environment development level debug file logstash webserver rb line 47 method log no application configured nothing to run level error file logstash webserver rb line 51 method error >>>blocker bug metrics
reviews from the metric collection and api pr >>>metrics v3.0.0-alpha1
collection of fixes from last round if reviews in the feature metrics pr hi this actually makes sure to fix few of the concerns coming out of the last round of reviews in the metrics api in detail make sure puma version 16 same as in the http input add http host option to the web server fix typos and wrongly removed lines ph what do you think cc jsvd >>>metrics v3.0.0-alpha1
make proper test integration for the metrics api make usage of proper test integration with the main core pipeline for the logstash web api this basically means this pr is cleaning up all unnecessary mocks and going through real agent and pipeline for testing purposes still room to improve the test this this is first pass next steps are to actually improve the api endpoint test for expected behaviour small set of test improvements like cleanup non used fixture improve node stats tests by adding more context and format checks add new node specs endpoint test that checks the expected data is returned for the hot threads resource ph what do you think cc jsvd >>>metrics tests v3.0.0-alpha1
bad file descriptor errno ebadf error when shutting down the web api webserver sometimes when shutting down logstash puma shows this error is not something causing problem in runtime but should be investigated and avoided >>>bug metrics v3.0.0-alpha2
this brings back filter workers for the series this will be go ne in the next major version>>>blocker v2.2.1
from json should not generate new event on blank empty json input `event from json` was previously generating empty `event` on blank empty json input but it should just ignore it and not generate empty event this complements logstash plugins logstash codec json lines pull 22>>>java_event v2.3.0
metrics more tests add more test for the filterdelegator we did not have any before fix an issue when the plugin buffer events to keep the accurate count fix an issue with the naming of the metrics at the plugin level>>>metrics v3.0.0-alpha1
removal of filterworkers considered harmful just learned the hard way that filterworkers` was removed in logstash specifically commit https github com elastic logstash commit 028576ba6f141f57c180c8f3dbffa14cb24967c0 there are three problems with this this was not mentioned in the changelog https github com elastic logstash blob changelog md there was no backwards compatible deprecation period which arguably would ve made sense to match people expectations for non major update like the command line docs for https github com elastic logstash blob docs static command line flags asciidoc haven been updated and still list filterworkers` as available this change broke logstash filter verifier https github com magnusbaeck logstash filter verifier issues suggestions reinstate filterworkers` in as possibly undocumented alias of w` pipeline workers` to avoid additional breakage and schedule the flag for permanent removal in update the changelog update the command line documentation can supply pr for the latter two if you like do you want it to the branch >>>blocker bug v2.2.1
installing all plugins pack offline is failing in logstash installing the all plugins pack offline is failing downloaded pack used https download elastic co logstash logstash logstash all plugins tar gz the command used bin plugin unpack tgz users samirbennacer testing logstash all plugins tar gz the error >>>v2.2.0
improve current test suites for the webapi integration we need to improve bit the coverage and resiliency of the web api tests this will include being sure that mocks are done where it makes sense integration with the pipeline and collector interface should not be mocked all resources are tested for presence this should be done with an easy and simple test test parameters are properly checked error and misbehave conditions are checked >>>metrics tests
threadsafety problem when creating the initial metric instance this pr fix an issue where we were incorrectly creating the first instance of the metric this was causing missing increments>>>v3.0.0-alpha1
improve performance of the metrics collection the current metrics system add 15 slowdown in the events processing of the pipeline we should improve that situation believe we have some room to grow to improve the situation think is reasonable to improve the performance by lets try the following we have some allocation required for the lookup cache which believe could be removed we are using the atomicfixnum type in the metric store since we have multiples threads updating the same values we should look at `longadder` to see if we can some performance improvements 4508 profile the code to see the bottlenecks followup of 4572>>>metrics
set of small fixes proposed with merge to master review from https github com elastic logstash pull 4653 issuecomment 181961527 about idle threads we are actually ignoring at my understanding the idle threads es id ignoring do you propose to ignore all waiting threads about versions yeah we can add both this should not be complicated to archive about 404 agree we should return empty body with status 404 thanks lot for your time basically adds this pr default content for 404 errors bring back the threads param to select the number of threads to be shown in the web api default the hot threads number to ignore all threads that fall under one of the next criteria an internal jvm thread an internal jruby thread pool thread or an internal jruby jit thread this will obviously be shown if the right flag is passed >>>metrics v3.0.0-alpha1
use the right keys in locale to describe cli flags fixes pipeline workers count translation missing en logstash runner flag pipeline workers default `>>>bug v2.2.1
add unit test for the embedded webserver behaviour should add proper unit test this component and check expected behaviour >>>metrics tests v3.0.0-alpha2
pass back the metrics into the pipeline during registration time fixes https github com elastic logstash pull 4653 issuecomment 181888195>>>bug metrics
add pretty print option to the metrics web api fixes 4645>>>metrics v3.0.0-alpha1
logstash output plugin aws firehose hi guys recently implemented amazon kinesis firehose output plugin for logstash so thinking it might be useful for the community still improving it but current version has already basic functionality please check if you think it worth it repository https github com chupakabr logstash output firehose ps while implementing this plugin found out one critical bug in aws sdk ruby library by amazon see related pull request https github com aws aws sdk ruby pull 1086 with best valera>>>needs_review new-plugin
logstash service not running hi have some problems with running logstash service on ubuntu 14 04 installed logstash from apt repositories when start the logstash service it is running for moment and after few seconds it stops running no logs are written to logstash log file below is screenshot http snag gy uczfg jpg>>>bug
fix web api http to be 9600 as default fixes 4648>>>metrics v3.0.0-alpha1
fix web api http to be 9600 as default fixes 4648 >>>metrics v3.0.0-alpha1
add metrics collection and api for logstash core and plugins this pr add initial support for metrics collection within the core logstash pipeline including plugins being used with it and rest api to query them for monitoring purposes the webapi defines an initial collection of resources as discussed in 4446 that are node hot threads node stats node stats events node stats jvm stats jvm for more context on the metrics collection and api efforts you can check https github com elastic logstash issues 3908 after the merge of 4655 the default port is 9600 as discussed in 4648 you can operate this through cli flag after the merge of 4658 now all resources returning json can do pretty print if they have the key pretty in the url see 4645 for more details cc ph>>>metrics v3.0.0-alpha1
metrics api resources definition follows the initial sketches created in 4446 as discussed in this adds node hot threads node stats node stats events node stats jvm stats jvm introduces also small refactors and cleanup necessary to improve the webapi code quality adds also way to handle references from the webapi to the internals of logstash by passing the agent references to the collector this is not perfect but for now it solve the communication situation until further refactor supersede 4641 as this one is directed to the right branch after we made all available again under the feature metrics branch >>>metrics v3.0.0-alpha1
clarify offline plugin instructions from plugin command to reproduce create separate ls directories one for the logstash source with internet access to prepare the offline package the other logstash target to unpack the offline package first prepare the offline package in logstash source in the logstash target location see how it tells you to use the `install local plugin name` option for the plugin command if you try this now with internet access disabled you will see that the plugin install using the local cache will fail same thing if you use the update command the following seems to work as workaround by using the `update` action and just local` to update all packages there are improvements here we can make to the plugins command `the unpacked plugins can now be installed in local only mode using bin plugin install local plugin name is misleading message since it doesn actually work if you look at the output of the workaround plugin update local` you will see that it only provides an indication that it updated the es output but for some reason no indication that it updated the kafka input the plugin list command later on confirms it though >>>plugin_manager
http server default port change the default port of the http server the current default is 9292 this port conflict with es range suyograo suggested we move to 9600 quick google search doesnt show any popular application using that port also we should be able to change it when starting logstash with `cli` command http port` this can be moved to the settings file later to `http port` setting >>>metrics v3.0.0-alpha1
add json preatty print option to the web api it would be nice to have an option like pretty when appending pretty to any request made the json returned will be pretty formatted >>>metrics v3.0.0-alpha2
offline installation plugins installed locally can not be packaged for offline installation plugins installed locally see don get packaged for offline installations the only possible workaround here is to set up custom plugin server for examples using geminabox and do the installation through it >>>bug known_issue plugin_manager
clone metadata when event clone is called this partially fixes 4640 only for ruby implementation we need to make similar change to java implementation>>>bug
metrics api resources definition this make all designed resources for the metrics api available this follows the initial sketches created in 4446 as discussed in 4446 this adds node hot threads node stats node stats events node stats jvm stats jvm you can find all resource definitions within the app directory of the api sinatra app resources>>>metrics v3.0.0-alpha1
`logstash event clone` should also clone the metadata` the ruby event implements custom clone` method the code return newly created object using the data` instance variable as the initial hash this has the side effect of not cloning the metadata` some filter use the clone and will drop any associated metadata` when the event goes through the filter chain original issue https github com logstash plugins logstash filter dns issues 17 https github com logstash plugins logstash filter dns blob master lib logstash filters dns rb l68>>>bug v2.3.0
remove the secondary pipeline>>>metrics v3.0.0-alpha1
bin plugin can not install plugins on centos am unable to get `bin plugin` to do anything useful other than `list` tried this on freshly created centos x64 vm the commands listed below are literally my entire interaction with this vm steps needed to reproduce install logstash on centos yum makecache yum update yum install bash completion vim java openjdk headless reboot rpm import https packages elastic co gpg key elasticsearch vim etc yum repos logstash repo yum makecache yum install logstash reboot cd opt logstash the file etc yum repos logstash repo` has the following content logstash name logstash repository for packages baseurl http packages elastic co logstash centos gpgcheck gpgkey https packages elastic co gpg key elasticsearch enabled the version of logstash that was installed is `2 0` attempt to install plugins using `bin plugin` with without verification and install from local file root testd logstash date `date` debug bin plugin install logstash filter de dot echo date date debug exec opt logstash vendor jruby bin jruby xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xx heapdumponoutofmemoryerror xmx1g xx heapdumppath opt logstash heapdump hprof opt logstash lib pluginmanager main rb install logstash filter de dot validating logstash filter de dot cfre feb 09 17 49 est 2016 fre feb 09 19 45 est 2016 root testd logstash date `date` debug bin plugin install logstash output tcp echo date date debug exec opt logstash vendor jruby bin jruby xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xx heapdumponoutofmemoryerror xmx1g xx heapdumppath opt logstash heapdump hprof opt logstash lib pluginmanager main rb install logstash output tcp validating logstash output tcp cfre feb 09 20 05 est 2016 fre feb 09 22 40 est 2016 root testd logstash date `date` debug bin plugin install logstash output csv echo date date debug exec opt logstash vendor jruby bin jruby xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xx heapdumponoutofmemoryerror xmx1g xx heapdumppath opt logstash heapdump hprof opt logstash lib pluginmanager main rb install logstash output csv validating logstash output csv cfre feb 09 22 49 est 2016 fre feb 09 25 34 est 2016 root testd logstash date `date` debug bin plugin install no verify logstash filter de dot echo date date debug exec opt logstash vendor jruby bin jruby xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xx heapdumponoutofmemoryerror xmx1g xx heapdumppath opt logstash heapdump hprof opt logstash lib pluginmanager main rb install no verify logstash filter de dot installing logstash filter de dot cfre feb 09 25 51 est 2016 fre feb 09 28 23 est 2016 root testd logstash date `date` debug bin plugin install no verify logstash output tcp echo date date debug exec opt logstash vendor jruby bin jruby xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xx heapdumponoutofmemoryerror xmx1g xx heapdumppath opt logstash heapdump hprof opt logstash lib pluginmanager main rb install no verify logstash output tcp installing logstash output tcp cfre feb 09 28 41 est 2016 fre feb 09 31 05 est 2016 root testd logstash date `date` debug bin plugin install local root logstash filter de dot gem echo date date debug exec opt logstash vendor jruby bin jruby xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xx heapdumponoutofmemoryerror xmx1g xx heapdumppath opt logstash heapdump hprof opt logstash lib pluginmanager main rb install local root logstash filter de dot gem validating root logstash filter de dot gem cfre feb 09 32 39 est 2016 fre feb 09 34 56 est 2016 root testd logstash date `date` debug bin plugin install local root logstash output tcp gem echo date date debug exec opt logstash vendor jruby bin jruby xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xx heapdumponoutofmemoryerror xmx1g xx heapdumppath opt logstash heapdump hprof opt logstash lib pluginmanager main rb install local root logstash output tcp gem validating root logstash output tcp gem cfre feb 09 35 09 est 2016 fre feb 09 37 18 est 2016 expected outcome each of the executions of `bin plugin` shown above should install plugin if it not installed already actual outcome `plugin` hangs until it is killed for all tried invocations picked the plugin names at random the plugins used are just examples>>>plugin_manager
date filter year guessing problem noticed that some logs where getting the wrong timestamp in elastic via logstash we run logstash our setup includes logstash fwd logstash input lumberjack logstash output redis redis logstash input redis grok date filter logstash output elastic elastic syslog messages are in the format month day hh mm ss and don include the year because of logstash fwd that will send events on startup since it was last active and also because of our queue some events of dec 2015 arrive on the logstash date filter on jan 2016 but since the message has no year in it logstash decides to timestamp it as dec 2016 expect that if events come in without year that logstash could check if the month day is in the future or not to add the current year or previous year to it >>>needs_details
introduces basic logging back introduce basic logging including basic access logging this pr introduces basic access and error logging booths serve the purpose of knowing when something goes wrong why it going wrong aka exception and error handling know usage of resources including status code monitoring fixes 4575 and supersede 4617 by poiting it to the new metrics branch >>>enhancement metrics
master build failure on java there is build failure in 4631 which does not seems to be related to the pr in fact just finished checking on bare master and it also reproduces the failure happens only in java and can be reproduced with the error is >>>blocker bug tests-infra
add event from json method will fix 4595 this introduces `event from json` which takes as argument json string and returns new `event` object the idea here is to update the json lines codec to use this method to avoid double type conversion by first parsing the json to ruby structure then passing that structure to the java event and go through unnecessary type conversions the poc has shown 50 performance increase using this note that this pr adds specs for the input corner cases behaviour of the current deserialization behaviour to make sure `from json` behaves the same way >>>enhancement java_event performance-improvements v2.3.0
force ruby maven version as of feb 3rd 2016 the ruby maven gem is resolved to version and that version has an rdoc problem that causes bundler exception is the current latest version which does not have this problem cc purbon ph >>>bug java_event v2.3.0
metrictype decoration to be consumed by the web api hi in the current branch for the metrics feature there is mechanism to provide only the relevant data to the webapi while delivering all the metrics fields to the store this is archived by something like and then using json serialization to provide all necessary fields for the web api this is doing it work but is an obscure method to select only relevant data propose we introduce decorator that transform this class by only providing the relevant data aka minimal data this will allow us remove the usage of `to json data` method only required by jrjackson and allow us to have more clever code to understand in the long run >>>enhancement internal-cleanup metrics v3.0.0-alpha2
rebased the feature metrics branch from master manually this has been done into this new branch this branch include code for the metrics delivery instrumentalization and the web api to be presented to the user it also include test for each component implemented ph can you make sure everything is reasonable >>>metrics
bundler could not find compatible versions for gem jdbc sqlite3 offline installation of third party plugin am new to elk am running it on windows machine the logstash version is have to load data from mongodb to es since there is no official plugin am trying to install third party plugin logstash input mongodb https github com phutchins logstash input mongodb when try to install it from the offline location using the following command logstash bin plugin install local no verify logstash input mongodb master logstash input mongodb gem get the following error message installing logstash input mongodb plugin version conflict aborting error installation aborted message bundler could not find compatible versions for gem jdbc sqlite3 in snapshot gemfile lock jdbc sqlite3 11 in gemfile jdbc sqlite3 java logstash input mongodb java depends on jdbc sqlite3 10 java running bundle update will rebuild your snapshot from scratch using only the gems in your gemfile which may resolve the conflict the reason am installing with no verify and local is because without it get the following error `validating logstash input mongodb gem installing logstash input mongodb error bundler httperror retrying 10 could not fetch specs from https rubygems org error bundler httperror retrying 10 could not fetch specs from https rubygems org error bundler httperror retrying 10 could not fetch specs from https rubygems org error bundler httperror retrying 10 could not fetch specs from https rubygems org error bundler httperror retrying 10 could not fetch specs from https rubygems org error bundler httperror retrying 10 could not fetch specs from https rubygems org error bundler httperror retrying 10 could not fetch specs from https rubygems org error bundler httperror retrying 10 could not fetch specs from https rubygems org error bundler httperror retrying 10 could not fetch specs from https rubygems org error bundler httperror retrying 10 10 could not fetch specs from https rubygems org too many retries aborting caused by bundler httperror error installation aborted message could not fetch specs from https rubygems org how do solve this issue >>>question
make java as minimum required oracle marked the eol of java in april 2015 and as of july 2015 they no longer provide downloads for java fixes 3877>>>v3.0.0
make logstash complain if attempting to use batch count redis input plugin with single threaded filter plugin tried to use configuration today by accident that included the redis input plugin batch count setting as well as zeromq filter in the same configuration zeromq requires that it be single threaded and know that logstash can detect that but for some reason after setting the batch count in the redis input plugin it starts up and doesn complain at all finally found it when went into the configuration file and noticed the setting after determined it wasn ingesting from it input think it would be helpful if logstash complained about this setting either through configtest or otherwise >>>bug
fix flusher initialization to prevent race breaking flushing if start flusher is called before running is set to true it may shut itself down before it truly starts this fixes that bug >>>blocker bug v2.2.1
travis ci pr testing fails marking pr as failed see screen shot 2016 02 03 at 16 51 53 https cloud githubusercontent com assets 68540 12787673 bf1ecdb6 ca96 11e5 8fc0 f63c61d1d852 png while the internal jenkins pass this should be fixed or the travis ci test disabled until they work as expected otherwise the information given for testing is contradictory to pr creators >>>bug tests-infra
improving the logstash logging subsystem aka making it more precise common pain point of logstash monitoring is processing its logs they could become very big and verbose propose set of actions that will help improve the overall logging system revisit logging with in logstash and their plugins to make it as accurate as possible removing unnecessary log enable trace logs they should be turn on by default and only available when debugging this will help getting accurate logs only for parts under investigation let users decide to get only logs generated by selected groups of components the intention of this issue is to discuss and generate ideas to have clever logging infra there related issues focused on implementation details relates to 4548>>>discuss logging_improvements
metrics to stdout not working with logstash hello today updated logstash from to on my test server and metrics output stopped working have the following setup it test benchmark server file input plugins reads file metrics plugins counts the number of events and adds tag metric if there is metric tag in the event print it out to stdout else send event to dev null somehow don get any text on stdout is it connected with the new pipeline is metrics plugin even useful now with the new pipeline design my config the same config is working on matej>>>bug v2.2.1
is the merging of and still desirable behaviour currently when giving logstash both and the config string and contents of the config files will be merged into single pipeline don see use case for this behaviour and only makes logic more complex so propose that and become incompatible flags in the next major release of logstash >>>breaking-compatibility discuss
logstash nomethoderror undefined method for nil nilclass logstash codec json lines logstash input tcp firstly os windows server 2012 r2 jvm java version 71 logstash all plugins zip using simple tcp json lines input then for each data document received this continuously is being logged no data reaches elasticsearch so total data loss json documents can be sent via another logstash instance or different application sending up same document format what gives >>>bug
introduces basic logging back introduce basic logging including basic access logging this pr introduces basic access and error logging booths serve the purpose of knowing when something goes wrong why it going wrong aka exception and error handling know usage of resources including status code monitoring fixes 4575>>>enhancement metrics
pass log file make logstash quit without notice if running logstash in master with bin logstash dummy conf log foo bar debug or bin logstash dummy metrics conf log foo bar `` it created the file foo bar but logstash quits without any notice config is easy as this means no logs could be generated for debug >>>bug v2.3.0
relocate logstash core api into logstash core lib logstash api fixes 4574>>>metrics
manticore errors in the feature metrics branch test hi when running test in the metrics feature branch you get this manticore errors understand this happen because it trying to contact with es and es is not there we should definitely mock this calls >>>bug metrics tests
next steps on plugin management for logstash hi during the implementation of 4535 many good ideas flowed to improve the way we handle plugins inside logstash this issue is created with the intention to have common place to discuss our vision for next steps >>>design discuss
logstash master default plugins job failure file input break the master default plugins test see for an error description at http build eu 00 elastic co view ls 20master job logstash master default plugins 1029 console guyboertje know you re working on this something fixed what do you think >>>bug tests
logstash fails to run by exception gemnotfound about ci reporter rspec gem trying to create new plugin but after installing it by `bin plugin install path of logstash output treasure data gem` logstash become to fail to start `ci reporter rspec` seems gem for development but it included in `gemfile jruby lock` but it not included in logstash release package using tar gz it seems weird for me that this exception doesn occur without my new plugin reading bootstrapping code but cannot find root cause for now does someone have any idea about this problem >>>needs_details
initial travis yml wip not ready for review yet >>>tests-infra work_in_progress
full encryption of events passing through logstash currently individual plugins can have their own encryption support such as the upcoming kafka client and producer that supports the new ssl features in kafka for the in flight events we have request from the field to provide encryption capabilities for them as well esp when we start persisting these in the future >>>enhancement
make sure that sprintf return new clone in some cases `event sprintf` was returning reference to the value and not new instance this would lead in some weird behavior when using `add fields` with the sprintf syntax fixes 4592>>>v2.3.0
label individual instances of logstash through cmdline params is there way to label individual instances of logstash run multiple logstash instances on host and it works fine but when run topbeat on the host it identifies that same proc name for all the instances if there was way to label individual instances by passing in identifiers in command line params can atleast grok the instance name and aggregate metrics per each individual logstash instance>>>enhancement
hide milestone confusing message to the user this pr change the log level when user load plugin with milestone option to debug instead of warn fixes 4562>>>v2.3.0
metrics flexibility refactoring of the metric conform to the metric defined in follow 4492 better filtering of the metrics from the metric store fixes 4461 hide the implementation details of the metric store it return an hash fixes 4529 metricstore each now support path to only fetch subset on the metrics >>>metrics
unable to find non world writable directory for dir tmpdir consider setting env tmpdir env tmp or env temp to non world writable directory hi all am using logstash es on windows every time start logstash agent it outputting this tried downgrading to it works fine regards zul >>>bug needs_details windows
new java event interfere the plugin manager uninstall command with cached gems the introduction and enablement of the new java event in master broke the way the offline installation works mostly affecting the uninstall command when there are plugins cached due to the fact that we empty the internal bundler caches aka app cache during package time we introduced hack that forced this caches to be rebuild see https github com elastic logstash blob master lib bootstrap bundler rb l35 l40 this basically pulls all requested specs from rubygems in case they are not actually installed inside the internal cache but as the new logstash core event java is not at rubygems this process fails uninstallation still works but users see set of nasty messages that can be misleading if no cache is present if there are plugins cached after that uninstalled plugin is gone but the set of error and warnings looks bad smiley colinsurprenant what do you think about releasing event java to rubygems is this an option >>>bug java_event plugin_manager
introduce event from json to avoid type conversions in java event as described in 4481 suggest we add `event from json` for json deserialization to avoid double type conversions when used in the context of the java event the best example is the json lines codec which uses the `logstash json load` method to deserialize json https github com logstash plugins logstash codec json lines blob 1eb838d12321a05f291c3836dce51c230605f915 lib logstash codecs json lines rb l55 which produces ruby object tree that is in turn passed to the java event which has to convert back into native java objects by introducing `event from json` we would be able to short circuit this double type conversion and improve significantly the deserialization speed to keep backward compatibility the codec could just first check for `event method defined from json and choose the best strategy >>>enhancement java_event performance-improvements v3.0.0-alpha1
use static jackson mapper this improves the event json serialization speed by 10x>>>enhancement java_event performance-improvements v2.3.0
undocumented behaviour with add field recognized that after calling the add field method to get copy of field both fields point to the same content so changes to the new field also cause the same change to the old field let us assume have created field mapping with the uppercase string foobar and do the following steps mutate add field mappingout mapping mutate lowercase mappingout now both fields contain the lowercase string foobar the following workaround is applicable mutate add field mappingout tt mapping mutate lowercase mappingout using the workaround mapping contains the original uppercase string foobar and mappingout the lowercase ttfoobar am not sure wether this behaviour is accidently or not if not the documentation of add field should be adapted and highlight this >>>bug v2.3.0
please add this output plugin to the logstash plugins project logstash output rados the plugin can be found here https github com endticket logstash output rados the plugin makes possible to store logs in ceph >>>new-plugin
logstash lumberjack input unhandled exception hello am getting the following error about once ever seconds eventually the server crashes had this error on upgraded to and it still remains timestamp 2016 01 28t15 33 12 173000 0000 message lumberjack input unhandled exception exception backtrace opt logstash vendor bundle jruby gems logstash core java lib logstash util charset rb 14 in `convert opt logstash vendor bundle jruby gems logstash codec plain lib logstash codecs plain rb 35 in `decode opt logstash vendor bundle jruby gems logstash codec multiline lib logstash codecs identity map codec rb 143 in `decode opt logstash vendor bundle jruby gems logstash input lumberjack lib logstash inputs lumberjack rb 110 in `create event opt logstash vendor bundle jruby gems logstash input lumberjack lib logstash inputs lumberjack rb 145 in `invoke org jruby rubyproc java 281 in `call opt logstash vendor bundle jruby gems jls lumberjack 26 lib lumberjack server rb 372 in `data opt logstash vendor bundle jruby gems jls lumberjack 26 lib lumberjack server rb 351 in `read socket org jruby rubyproc java 281 in `call opt logstash vendor bundle jruby gems jls lumberjack 26 lib lumberjack server rb 363 in `ack if needed opt logstash vendor bundle jruby gems jls lumberjack 26 lib lumberjack server rb 347 in `read socket opt logstash vendor bundle jruby gems jls lumberjack 26 lib lumberjack server rb 246 in `json data payload opt logstash vendor bundle jruby gems jls lumberjack 26 lib lumberjack server rb 163 in `feed opt logstash vendor bundle jruby gems jls lumberjack 26 lib lumberjack server rb 296 in `compressed payload opt logstash vendor bundle jruby gems jls lumberjack 26 lib lumberjack server rb 163 in `feed opt logstash vendor bundle jruby gems jls lumberjack 26 lib lumberjack server rb 332 in `read socket opt logstash vendor bundle jruby gems jls lumberjack 26 lib lumberjack server rb 315 in `run opt logstash vendor bundle jruby gems logstash input lumberjack lib logstash inputs lumberjack rb 144 in `invoke org jruby rubyproc java 281 in `call opt logstash vendor bundle jruby gems concurrent ruby java lib concurrent executor executor service rb 515 in `run concurrent javaexecutorservice job 1733552057 gen 13 in `run level error >>>unconfirmed
auto plugin installation at runtime it would be great to have the option for online environments to automatically install missing plugins needed by config at runtime especially with the dynamic pipeline reload feature >>>enhancement plugin_manager
fix coverage helper for use with java event the coverage helper uses directory pattern for its skip list implementation this glob mecanism https github com elastic logstash blob 40b0685468b953cc8288ddac5c111443684ccf08 spec coverage helper rb l18 is not compatible with the new event implementations it actually goes into the logstash core event directory and require all files event though this is not the right gem that is activated we probably need to rethink this skip list thing this is the cause of the current jenkins `logstash master default plugins` build errors >>>bug java_event v2.3.0
implement proper event inspect the java event does not have an `inspect` method it actually defaults to `to s` which is not sufficient for debugging or error logging purposes should output more information that just the `to s` representation of the event the good news is that we get to correct the previous behaviour which actually ended in dumping the event data multiple times because of the inner accessors class referencing back into the event relates to 4428 >>>bug java_event v3.0.0-alpha1
plugin manager extend functionality to installation plugin packs plugin packs are collection of multiple plugins which contain gems and their dependencies this is mainly an upper layer on top of current install command that will basically pull all plugins and install them from the package also compliments the current offline installation features some characteristics about packages are they could be installed either from web url or from the local file system are compressed in zip file and have the zip extension they can have one or multiple plugins including their dependencies tasks enhance the current install command to handle packages handle plugins from web url handle plugins from the file system handle plugins by name introduce version checks to be sure plugins works with expected logstash versions add user agent identification when fetching plugins from web url make the base url configurable add all necessary unit add all necessary integration tests >>>enhancement plugin_manager v3.0.0-alpha1
work in progress extended installation of packaged plugins this pr adds the idea of packaged plugins to the plugin manager basically collection of plugins that are going to be installed from given zip file this file could life either in local file system or in remote installation this set of changes also need to make available the logstash version constant at the plugin manager level this requires to finally move the logstash version file from logstash core where it was before updating all dependencies etc now logstash core only have it own version and the main logstash version is under lib fixes 4585>>>enhancement plugin_manager v3.0.0-alpha2 work_in_progress
build filter to map geo points hi there now that geo point is one of the native elasticsearch types as far as can tell it seems as though logstash should have filter for this data type out of the box yes am aware that we can manually map these types but that an extra step that logstash is already handling gracefully for all of the other types ve noticed that the twitter input plugin maps correctly to geo points so it should be possible in filter as well there are geo point fields in the geoip section of properties in the default logstash template as well there is an existing issue opened about such feature https github com elastic logstash issues 3291 but no one has replied to it is there something holding this development back thanks for the help james>>>adoptme new-plugin
fix warning in the tests when running the test for the `shutdownwatcher` in the full suite the logger of the class was incorrectly setup this pr make sure we use silent logger instead fixes 4581>>>v2.3.0
remove warning when running the core branch from the master branch when you run the core test in the master branch you get few warnings they are unnecessary noise and should be remove >>>internal-cleanup v2.3.0
fix jar generation for artifact packaging attach jar copy hook to the jar generation and not build change location of jar into `lib logstash core event java simplify jar `require` fixes 4578 >>>blocker bug java_event v2.3.0
cpu usage 100 logstash we updated for logstash and it consuming all of our cpu logstash works perfectly my configuration file >>>needs_details
assess packaging tasks work correctly with core event java test and verify if ls packaging works correctly when defaulting to java event implementation >>>java_event v2.3.0
sync jackson dependencies between java event and jrjackson we have to make sure our jackson dependency works well across the java event code and the jrjackson gem should jrjackson move to jar dependencies usage similar to https github com elastic logstash blob 5a522a00370fb7bd7275d4ae7d7ab996a5fd329e logstash core event java logstash core event java gemspec l22 l25 guyboertje >>>java_event v3.0.0-alpha1
add an option to turn on request logging for metrics api rack support request response logging like http should we support that feature is there any value in providing that >>>discuss metrics
implement basic logging in the api the current implementation of the logging inside the api is not linked with the default cabin logger and it basically does is own thing we need to fix that to use the default configured log output and log level there is no reason to have separate logger for this part of the application and this will make things lot easier to tests what should be logged all errors generated from system calls should be catch errors shouldn bring down logstash sinatra errors should show up in the logs what should not be logged access logs apache like log shouldnt not be saved >>>metrics v3.0.0-alpha1
move the `logstash core lib api` to `logstash core lib logstash api` to be more consistent with the current architecture of logstash it should be move to `logstash core lib logstash api`>>>metrics v3.0.0-alpha1
add integration test for the metrics collection since we are using pipeline under the hood and this part of the code react to the back pressure we need to tests theses scenarios and maybe adapt how the metrics are send to the pipeline pipeline is slow pipeline is not responding >>>metrics tests v3.0.0-alpha2
benchmark the new metrics benchmark the new metrics system to see that is the performance affecting the events in real situation think the best scenario is to use the getting started workshop to get good set of common used plugins >>>metrics v3.0.0-alpha1
plugin index doc generation is very whitespace intolerant when generating the index of for plugin type such as input the lack of final blank line single plugin documentation can cause the whole process to fail example bug introducing pr https github com elastic logstash docs commit 2fdc8685be8911b5cea9e11fbdbb2c2b71df7a7a diff 42452c263ebd72b9268e3f747dda5c77l417 resulting doc building fail http build us 00 elastic co view doc job docs 4284 console fix https github com elastic logstash docs commit 10e02d9d9b65093a6895da09b2ffd76af8880acf it would be nice if the loop over the plugin collection didn require this subtlety to work thoughts suyograo >>>bug docs enhancement
failing plugin tests and picking wrong logstash core version as we could see at logstash output elasticsearch http build eu 00 elastic co view ls 20plugins view ls 20outputs job logstash plugin output elasticsearch unit jdk jdk7 nodes metal pool 89 console jenkins job picks one version of logstash core while logstash plugin output csv http build eu 00 elastic co view ls 20plugins view ls 20outputs job logstash plugin output csv unit jdk jdk7 nodes metal pool 16 console jenkins job picks another some are picking as like the logstash plugin filter multiline http build eu 00 elastic co view ls 20plugins view ls 20filters job logstash plugin filter multiline unit jdk jdk7 nodes metal pool 12 console job we should make sure jenkins jobs pick all the same version this might be the reason why some plugins are failing see http build eu 00 elastic co view ls 20plugins for details >>>bug tests-infra v2.3.0 v3.0.0
default plugins test fail for and other branches see http build eu 00 elastic co view ls 202 job logstash default plugins 22 for suspects are ogstash input rabbitmq logstash input s3 and logstash input file see http build eu 00 elastic co view ls 20master job logstash master default plugins 998 console for master colinsurprenant andrewvc ph untergeek any idea what might be happening here >>>bug tests v2.3.0 v3.0.0
file input multiline codec will never fully process last line hi if you are using file input with multiline codec and files and you stop writing to the file when file is rotated over then last line from that file won be ever processed as logstash will be always stuck on multiline codec waiting for continuation of that message could you please check if it is possible to implement timeout for this so logstash won wait longer than defined amount of time >>>bug v2.1.2 v2.2.0
file input re using inodes leads to missing corrupted data please implement periodic cleanup of sincedb entries hi sincedb for file input infinitely keeps reference to all files inodes that were ever tracked under some frequent conditions this will lead to missing or corrupted data for example if there is any kind of log rotation mechanism that actually deletes any even single source file and new files are created afterwards then you will certainly see this issue occurring at some point as file will be eventually created using an inode that was already tracked in past issue is even more visible if start position is set to beginning as likely first parsed message will be incomplete the more input files you create the more chances to observe this issue in my repro case ve created and rotated deleted around 1k files per day and ve seen this issue re occurring few times day currently my sincedb files are having over 100k lines if possible please implement dropping references from sincedb to files that do not exist anymore >>>bug
timestamp loses precision when parsed from json was trying to figure out why the gelf input wasn showing milliseconds in kibana turns out to be mainly jruby bug which opened here https github com jruby jruby issues 3616 basically the gelf input plugin parses the json using `logstash json load` here https github com logstash plugins logstash input gelf blob master lib logstash inputs gelf rb l107 and later it creates the timestamp value with `logstash timestamp at event timestamp the real problem happens here https github com elastic logstash blob v2 lib logstash timestamp rb l26 l28 basically when `time at` is called with bigdecimal which logstash json load provides the milliseconds are stripped could it be worth to handle the case when it bigdecimal and call `to f` on it if so can work on pr since you stil bundle an older jruby version and maybe it easier to handle the problem with patch instead of waiting for new jruby release that you should also globally upgrade >>>bug
installed gem is not recognized during configtest made new version of the opentsdb output plugin and built installed it locally with `jgem build gemspec` and `logstash plugin install gem` all of which succeeded `logstash plugin list` includes the plugin in the output and can see it in logstash `gemfile` and at usr local cellar logstash libexec vendor local gems logstash output and it has gemspec` file at that path however when try and do configtest on an config file using my output plugin get the error `the error reported is couldn find any output plugin named opentsdb are you sure this is correct trying to load the opentsdb output plugin resulted in this error no such file to load opentsdb` ve read both of https github com elastic logstash issues 3971 and https github com elastic logstash issues 4171 but not depending on jar with the name of my gem so the solution that worked there doesn apply to me my plugin code is at https github com camjn logstash output opentsdb tree elasticsearch inspired other details jruby and logstash were installed by homebrew on os and java is oracle jdk 72>>>needs_details
default to java event replaces 4494 which got wrongfully merged and unmerged into shared branch but now github won believe it not merged for real default to logstash core event java removed dependency on guava cleaned unused dependencies cleaned unused imports cleaned build gradle removed java code so it compiles on java use jar dependencies to handle jackson dependency use json unit for json related tests added gem jar creation and cleanup in build gradle fix array fields nil values handling to comply with 4561 for merging into feature core event java shared branch guyboertje please review relates to 4480 >>>java_event
milestone warning is displayed when pluginpath is used pluginpath can be used with ls to load plugins which are not converted into rubygems yet ls will output warning when used with this option message abc plugin is using the milestone method to declare the version of the plugin this method is deprecated in favor of declaring the version inside the gemspec level warn this is benign message and can be ignored but we need to remove this warning so it does not confuse users >>>plugin_manager v2.3.0
add specs for nil values in array fields specs for nil values in `event` array fields this relates to discussion in java event implementation 4494 >>>tests
elasticsearch output is not creating the index with the defined template hi im working on local envrionment with two vms one is running elasticserach and the other is running logstash for some reason when logstash creates the index in elasticsearch the template provided in the logstash config is not being used any idea what may be causing this this are the config and log outputs logstash conf twitter template json elasticserach log at index creation you can see the template is missing thanks >>>bug needs_details unconfirmed
logstash output elasticsearch installation is wrong for logstash `2 1` the documentation points that to install the shield output for elasticsearch you need to however the correct way to install this plugin is to do the following command which is correct for the documentation version for logstash `2 0` >>>bug docs
service provider is not loading at startup time in the webapi the service provide code within the webapi is not loading at startup time so data is not received until one resource is used this causes unnecessary delay on getting information service provider should be loaded at startup time serviceprovider class https github com elastic logstash blob feature metrics logstash core api lib app service rb>>>bug metrics
fixed small bugs that pervented the metrics collection to work as expected this is collection of small fixes that make the metric collection work again it also introduces test to make sure the metrics input can fetch data from the metric store when receiving an update call this bug was introduced when changing the behaviour of metricstore each method used during the previous procedure it also fixes an important issue that made the api service gathering code to load after resource was loaded now the service provider is loaded as soon as the webapi is started fixed 4553 and 4555 ph thoughts >>>bug metrics
missing method when the metric store gets flushed error when running metrics branch this happen when the metric store gets flushed >>>bug metrics
add default pipeline batch size to docs>>>docs v2.2.0
set ls heap size correctly to 1g previously we had set heap size to 1g in few places but not everywhere>>>bug v2.2.0
add hidden flag to pipeline currently we have pipelines running in parallels `main` logstash config the other one for dealing with metrics right now when we access the web api we get the metrics for both pipeline but in this case the metrics pipeline is just noise since it doesn record any metrics for itself suggest we add flag when we initialize new pipeline `hide` which will be set to false by default since we don have good control over the logger in logstash this flag will allow us to suppressing the double message concerning the workers this flag is not exposed to the end user but only for developers interacting with the pipeline >>>metrics v3.0.0-alpha3
explore use of slf4j in logstash and default to log4j the current logging library in logstash is cabin https github com jordansissel ruby cabin created by jordansissel to primarily overcome the lack of structured logging capabilities in ruby logger more information on cabin features can be found in its readme https github com jordansissel ruby cabin there are some additional requirements for logging in ls that needs to be addressed finer logging configuration per plugin cabin log levels are controlled at the instance level it would be really useful in ls for example enable trace messages only for grok filter see https github com elastic logstash issues 2040 https github com elastic logstash issues 3692 log rotation by size and age criteria currently logstash writes to single log file if logging is enabled this can result in complete usage of disk space causing system to freeze see https github com elastic logstash issues 3658 https github com elastic logstash issues 2520 dynamic update of log level introduce an api to control log levels dynamically just like elasticsearch allows users to we could add all these features to cabin but most of these requirements are already solved by libraries like log4j2 which can be run on jruby better yet we can introduce slf4j which is an abstraction layer over logging libraries and we can ship default log4j implementation slf4j and log4j both support structured logging http www slf4j org api org slf4j mdc html so this migration should be easy >>>discuss enhancement logging_improvements
fix hanging runner test by actually mocking out the agent execute call so test execution are only testing the runner and not the following methods fixes 4546>>>bug metrics
runner spec hangs when executing see this might be probably due to the way the webserver starts >>>bug metrics
live partial pipeline updates following the nice new feature to allow dynamic configuration reloading as described in 4513 and pr 4520 suggest the next step is to provide and api for dynamic partial updates to live pipeline this would allow for example to dynamically update the filter and or output stages without altering stopping the input stage providing the ability to change configuration without loosing any input when paired with variable length persistent queue this is an idea discussion issue if this idea has leg we can followup with design issue and or poc >>>discuss enhancement
docs generation does not handle codec defined in plugin looks like the doc generation only looks at base input for type of codec used if plugin overrides it that info is not generated see https github com logstash plugins logstash input rabbitmq issues 26>>>docs
unhandled data from input gives no complaints hi just had an issue where had an input file type foo and output if type foo but type was in file source already and file was of type json so logstash didn override type set in file hence the output didn match and data just disappeared much to my dismay after quite some debugging figured that out it would be nice if logstash logged when some input didn match any outputs at all like are you sure this isn an error >>>discuss
delete metrics in the metric store when pipeline reloaded currently the `metricstore` will keep all the collected metrics since logstash starts the only way to clean the store is to physically restart logstash this is problem with the introduction of config reloading which could result in unwanted or inaccurate metric collection we collect metrics at two different level application and the pipeline at the application level we are gathering information about the jvm cpu os and events in outs at the pipeline levels we also gather in out and in out of the different plugins so this generate few questions at how we will handle the lifecycle of the metrics what should happen when new config is reloaded inside logstash do we think that bringing new config into logstash is similar to restart and we clear all the metrics collected before starting the new pipeline or we clean only the information gathered at the pipeline level in the first version of the metrics we only show that we gather information at the system level it might make more sense to clear the whole collected metrics since it will be the only way for people to know on their graph that something restarted logstash the spike if we consider clearing only the pipeline level we need to make change to the way the id of the pipeline are dealt with when we start logstash the default pipeline is called `main` when logstash reload new config the pipeline created from that config is also named `main` we need to introduce uuid to make sure no pipeline can have the same id in the metric store >>>metrics v3.0.0-alpha2
upgrade to jruby 24 this release fix the following problems we have file stat on 32 bits jvm on windows https github com logstash plugins logstash input file issues 82 annoying io console warning on windows https github com elastic logstash issues 3087 full changelog http jruby org 2016 01 20 jruby 24 html>>>v2.3.0
how to pass codecs to plugins hi during my work on 4533 noticed that we have actually two kind of behaviours for passing codec instances during plugin creation time basically for config like you will receive in the logstash plugin initialize method hash like codec plain but for something like we get the actual instance see codec charset utf looks like the actual approach is to pass an instance if the plugin gets parameters or to pass string if not leaving the instance creation for later steps good improvement here would be to pass always the same thing so later steps don have to create the codec if an string is passed would it be good option in your opinion to pass here hash that include the class the parameters necessary to build it and let the plugin decide when to create new instance create clone etc other options are also to pass always an instance but at my understanding passing letting plugin manage their codec instance could be the best approach what do you think >>>design discuss enhancement
encoding decoding issues in file path with require relative on windows unable to run logstash on windows using swedish characters like in the path it probably minor issue since having the above characters in the path is generally not recommended but might be the reality for some users it perhaps more of jruby issue really >>>bug windows
search through nested directory structure for jars in vendor directory it is not always the case that jars will be located in one level within the `runtime jars` and `test jars` directory for example when project jar dependencies is vendored using jar dependencies https github com mkristian jar dependencies the jars are nested >>>enhancement
persistence reboot this is design issue about the reboot of the persistence in the context of the new pipeline and the java event implementations as been previously discussed pluggable persistence architecture would allow different persistence implementations from using fast local persistence to the use of external storage or messaging systems like kafka to move forward with pluggable persistence we first need to properly define and and agree on the persistence interface the tricky part here is that it will have to accommodate future resiliency output acking architecture that will be factored in the pipeline for this think we could start by providing drop in replacement of the current wrapped synchronous queue implementation with persisting one this will provide base implementation to play with and assess performance impact believe we could easily provide variable length persistent queuing at this point to at the same time we should move forward with the design of output acking to move toward at least once semantic of the pipeline with persistence here what propose we divide the work on this persisting wrapped synchronous queue implementation variable length persisting wrapped synchronous queue output acking and at least once pipeline semantic design pluggable persistence interface design with support for at least once semantic refactor persistence implementation for pluggable persistence interface background reference issues 4254 3693 2609 2606 2605 >>>design enhancement resiliency
allow the plugins to retrieve the `nodename` currently the logstash node name is only available in the context of the agent it would be great to make that value available in the pipeline or the events so we can decorate events with the current `node name` in the metadata` this will allow user to have more traceability into which instances the work has been done this is related to 4465 >>>metrics v3.0.0-alpha2
common plugin registry to be reused around logstash introducing common plugin registry class this class will let us load current plugins loaded from our configurations load any other kind of plugins we want to introduce for logstash this new module is more or less feature pare with the current plugin loading behaviour the list of features are load plugins if installed as gems load plugins defined in code base mostly used for test could we remove this raise error if not andrewvc jsvd ph your thoughts are much appreciate it >>>enhancement v3.0.0-alpha2
filter delegator need more unit test to cover all the logic the filter delegator is used to track metric at the filter level this class need more unit test >>>metrics v3.0.0-alpha1
hide the implementations details of the metricstore when retrieving metrics hi as user of the metric store don expect to interact with implementation details today when asking the metric store for data it returns an instance of concurrent map this makes the consumer of this api aware of an implementation detail that might change in the feature we should return plain ruby hash or similar the way the metric store is implemented also make the values of this concurrent map be metrictype instance this is problematic as to retrieve value out of it user must call it value method the returned value object for the metric store should be plain ruby object or similar >>>enhancement metrics v3.0.0-alpha1
rename default pipeline to main today it is named as `base` `main` is more meaningful >>>bug
change in the default of the metric feature metric will be on by default for the pipelines and the plugins its not possible to turn it off for the pipeline but you can turn off metrics collection for specific plugin fixes 4502>>>metrics
add `plugin id` that return an id for plugin this method return an id for the plugins and be configured by the users in the configuration like this this information will be used when collecting metrics for specific plugin allowing the user to change it allow to stick between restart fixes 3892>>>metrics
plugin list doesn show deps installed logstash centos6 when doing an offline plugin install deps will be missing if there are any as such doing pack will get the dependencies at least on to the offline box is there way to install dependencies through the plugin utility if so how can validate all the deps are there offline example of installing plugin dep offline with the pack unpacked it does install but errors out after 10 tries heres what happens when plugin is missing dep verbose only shows plugin versions no deps >>>adoptme enhancement plugin_manager
plugin pack missing pack plugins logstash centos6 when creating pack some plugins are not included the ones have found to be missing are logstash output webhdfs and logstash output mongo these both have java in common list of plugins from host that was used to create the pack the plugins on this host were installed via the typical plugin install list of gems from pack file in opt logstash vendor cache after unpack not sure if this is just plugin problem or pack problem two plugins that we use are experiencing this and seem to install fine in traditional ways plugin install tarball pack this might be related when packing plugins 3735>>>bug needs_details plugin_manager
plugin uninstall broken for offline uninstall logstash centos6 typically offline installs are installed with local this is fine but when uninstalling its trying to verify to the internet again no verify doesnt exist >>>bug plugin_manager
plugin install local no verify still connects to the internet during offline install logstash centos created pack on another host that had the plugins installed via the typical plugin install method to the internet on the second host did plugin unpack tar gz plugin does install but the retries and final error will cause issues when packaging >>>bug needs_details plugin_manager
agent config reloading implements configuration reloading through sighup and the flag this pr is based off of the pluggable agents pr https github com elastic logstash pull 4194 sans the agentregistry mechanism fixes https github com elastic logstash issues 4513 this needs to be backported to branch for >>>config_management enhancement v2.3.0 v3.0.0-alpha1
init remove overwrite of java opts fixes 4517>>>v2.2.0
init script java opts are getting overwritten by ls java opts https github com elastic logstash blob master pkg logstash sysv l144 intended behavior see https github com elastic logstash blob master bin logstash l11 ls java opts xxx to append extra options to the defaults java opts provided by logstash java opts xxx to completely override the defauls set of java opts provided by logstash >>>bug packaging v2.2.0
define config directories for rpm deb install there no mention of where various config files live la elasticsearch paths https www elastic co guide en elasticsearch reference setup dir layout html it be awesome to have this somewhere >>>docs v2.3.0
features for v2 enable java event https github com elastic logstash issues 4191 as default https github com elastic logstash issues 4480 apply configuration changes from file without restarting https github com elastic logstash issues 4513>>>meta release_plan
test failling feature metrics not sure why we are using different channel for the web api changes introduced in master break the tests >>>bug metrics
apply changes from configuration file without restarting today any config changes made to ls pipeline requires process restart which is not ideal plan is to implement feature which would track config file for changes and restart the pipeline same process with updated changes this feature can be enabled by passing cli option auto reload` with reload interval` which controls how often ls should check the config files for changes >>>config_management enhancement v2.3.0 v3.0.0-alpha1
work in progress nodes api work in progress nodes api example as will be defined and requested during in 4446 as work in progress pr this will change to adapt it to the final decision on api design >>>metrics work_in_progress
new lookup filter new lookup plugin for dynamic lookup enrichment from multiple types of sources there are few different filters out there today that conduct different types of lookups which may make sense being encapsulated within one `lookup` filter list of lookup filters translate filter https www elastic co guide en logstash current plugins filters translate html elasticsearch filter https www elastic co guide en logstash current plugins filters elasticsearch html jdbc filter https github com wiibaa logstash filter jdbc http filter https github com elastic logstash issues 3489 use cases https github com elastic logstash issues 3446>>>design discuss new-plugin
logstash environment variable workaround blog post environment variable injection https github com elastic logstash issues 3944 has been common ask in logstash we should have blog post outlining how sed awk can be used as workaround >>>developer-support v2.3.0
experiment with longadder the current implementation of the `counter` in the metrics use the `concurrent ruby` `atomicfixnum` class for managing the counter docs https github com ruby concurrency concurrent ruby blob master lib concurrent atomic atomic fixnum rb the java implementation of this code uses java `atomiclong` this class gives ok performance but since multiples thread can change the counter it might be good idea to investigate if replacing the code with `longadder` would actually yield benefits see http blog palominolabs com 2014 02 10 java performance improvements longadder vs atomiclong https minddotout wordpress com 2013 05 11 java concurrency longadder java comes but java doesnt but an implementation exist for java es actually use it and its also present in `concurrent ruby` code https github com ruby concurrency concurrent ruby blob master ext com concurrent ruby ext jsr166e longadder java >>>metrics v3.0.0-alpha3
upgraded to ls and now getting json filter errors just upgraded my install from to am now seeing the following messages in my logstash logs the events that are throwing this error are all running through this filter the output for these events is es and when look in kibana the events get there but none of the json is parsed like it was previous to the upgrade the events are also tagged with jsonparsefailure any ideas >>>bug
add guards for the `metricstore` the metric store would benefit from some guards to protect the data the current implementation of the `metricstore` can grow unbounded we should add guards on the size of it to make sure its stays under control and log that information we can create namspace in unknown location we might want to secure or protect them this is from discussion from this pr https github com elastic logstash pull 4602 discussion r51735098>>>metrics v3.0.0-alpha2
collect plugin metrics by default we should also collect metric defined in the plugins by default currently to collect metric from specific plugins we have to set the `enable flag` to true >>>metrics v3.0.0-alpha1
enable metrics collection by default currently the metrics are not enabled by default and users need to tell logstash to collect metrics by using the metric` option we should change that to make sure the metrics are always on by default and we cannot turn them off the reasoning behind this is to make sure we always have visibility inside logstash for debugging or monitoring >>>metrics
configuration of the metric the current way for logstash to send metrics to an external services is by using an internal pipeline this pipeline need to be configured the appropriate way for the branch https github com elastic logstash tree feature metrics to correctly work this pipeline has the current format possible solutions solution settings yml my initial idea was to use the newly introduced `settings yml` https github com elastic logstash pull 4499 file to configure the pipeline and also hide the implementation details of real pipeline doing the work if we decide to go with something else than pipeline we can change the implementation solution adding `metric conf` another solution is to add `metric conf` as template and use the same syntax as normal configuration files this configuration will contains the `metrics` in the input solution metric bock add metric block inside the current logstash syntax this was the original idea at the beginning of the development so normal logstash configuration would look like this dont really like the 3rd solution because it require changes in the ast but it might be better in the context of clustering note when we are configuring the metrics its more than just defining shipper we can configure the web api too ssl port and the snapshot resolution all of theses options can be easily defined in the yml files jsvd andrewvc purbon and colinsurprenant what are your thoughts on this >>>discuss metrics v3.0.0-alpha2
truncated messages in logstash debian package just upgraded logstash to version using the elastic debian repository and am seeing grokparsefailures in logstash stdout that did not occur with version reverting back to fixed the issue essentially it appears that logstash is truncating some of the messages from my nginx access log this is resulting in grokparsefailures in logstash stdout have tested my grok patterns against the lines that are being truncated and they match perfectly again reverting back to version fixed the issue here my stack note these are virtual machines running on vmware here an example of line from our nginx access log that is being truncated here are our logstash filters they work with the earlier version and are verified to match the line above using https grokdebug herokuapp com here is logstash stdout showing the truncated message again rolling back to the prior version fixed this thanks >>>bug needs_details unconfirmed
wip implementation of the settings yml file this settings yml located at logstash home will override the defaults settings but can still be overridden itself by command line arguments todo configurable location for settings yml documentation this pr targets the currently empty to master feature branch https github com elastic logstash tree feature settings file>>>breaking-compatibility config_management enhancement needs_review v3.0.0-alpha2
metrictype gauge add gauge type for the metric collector this is useful for values like size of queue actual memory fixes 4488>>>metrics
metric type for metered resources like response time the current implementation of the collector does periodic snapshot every second of the metric store to the metric pipeline this sampling work well with counter and gauge values since it give high level view of the system but this feature doesn work if we want to keep track of response time to remote service like http calls to elasticsearch in this case we need structure that keep moving windows of the values this could also be used for gauges to have more granularity >>>discuss metrics v3.0.0-alpha3
rake fix broken doc generation doc generation was not updated after the changes to event and logstash core lib dir structure also the rake task now ignores plugins whose doc cannot be generated instead of bailing out in entirely and having to start from scratch again >>>docs
create deprecation banner for multiline filter>>>docs v2.2.0
default to java event and dependencies cleanups default to logstash core event java removed dependency on guava cleaned unused dependencies cleaned unused imports cleaned build gradle removed java code so it compiles on java use jar dependencies to handle jackson dependency use json unit for json related tests added gem jar creation and cleanup in build gradle for merging into feature core event java shared branch guyboertje please review relates to 4480 >>>java_event
internal structure of the metric of the metric store when merging the jvm and the web api we found out that the current way of defining namespace and keys wasn flexible enough lets try to define all all the possibilities we can have top level metrics type phase status stats events in counter done in the pr need to change namespace stats events out counter done in the pr need to change namespace stats uptime in milliseconds gauge value stats logtash version gauge value metrics type phase stats jvm memory heap used in bytes gauge value stats jvm memory used in bytes gauge stats jvm memory used percent gauge value stats jvm memory committed in bytes gauge stats jvm memory max in bytes gauge metrics type phase stats os cpu xxx detailed pipelines level collected at the pipeline level in the following case xxx is uuid of user defined string in the logstash configuration metrics type phase status stats pipelines pipeline events in counter done in the pr need to change namespace stats pipelines pipeline events out counter done in the pr need to change namespace stats pipelines pipeline plugins inputs file xxxxxx events out counter done in the pr need to change namespace stats pipelines pipeline plugins filters grok xxxxxx events out counter done in the pr need to change namespace stats pipelines pipeline plugins filters grok xxxxxx events in counter done in the pr need to change namespace stats pipelines pipeline plugins outputs elasticsearch xxxx events in counter done in the pr need to change namespace stats pipelines pipeline plugins outputs elasticsearch xxxx events out counter need to be done at the plugin level or with ack plugins level metrics theses statistic are collected by the code inside the plugin and are defined by the plugin authors metrics type phase stats pipelines pipelines plugins outputs elasticsearch xxxx error count counter stats pipelines pipelines plugins outputs elasticsearch xxxx retry count counter query all the keys are queryable on the metric store and return nested information when possible from users point of vue they will be transformed into hash query key return stats pipelines return all the pipelines information stats pipelines pipeline return all the metrics from the pipeline for keeping thing simple in the first iteration the store doesn support doing wildcards query but this could probably be done if needed in another iteration api inside the pipelines or logstash core when you want to record metric inside logstash you have to provide namespace and key to save the corresponding metric in all the following scenarios it is recommended to use variable when you are doing string interpolation the previous example will create the following maps divided by if you want to make multiple calls on the same namespace you can wrap the metric into `namespacedmetric` api inside the plugins used by dev author plugins authors need to be able to collect metric but we also need to scope where their metrics will be save when plugin is created we are giving the plugin instance specific metric instance correctly scoped with the an initial namespace metric type counter in the current state of the code we only have the counter type which is ever increasing counter we can use this to send data to elasticsearch and use the aggregation to retrieve the events per seconds in the system no calculation is done on the logstash side so the user of the api will only see the ever increasing values they will need to do their own calculation gauge more details in https github com elastic logstash issues 4488 this values is mostly snapshot in time of something we can use this for memory usage cpu usage and the uptime again this value with the sampling will allow us to graph the evolutions over time if needed response meter we will probably need something to collect response time because counter or gauge make us lose way too much granularity see https github com elastic logstash issues 4497 >>>design metrics v3.0.0-alpha1
do not override existing and newer version of plugins this will be non trivial enhancement since we do not have any state mechanism today to deal with existing currently installed plugins filing use case from the field the request for logstash to detect when local plugin is newer than the one it has in these cases do not override it use case upgraded to kafka plugin to get the cpu fix finally got around to installing logstash with the rest of the stack and noticed that the logstash install overwrote the kafka plugin with so had to install again it would be really nice if we can do some checking so extra work is not needed >>>enhancement packaging plugin_manager
add discover option to plugin command it is not uncommon for us to release newer versions of plugins outside of the full logstash release schedule so it is quite possible that newer version of plugin with bug fixes enhancements is available before the next full ls release is out it will be cool if there is for example plugin discover` command admins can periodically run which will go and check for any later and compatible plugin versions that have been released eg for the plugins that are currently installed and report back list of available ones so that the admins can then determine when it is appropriate to run the plugin update command to update them so this new option will just be check for updates and listing command certainly will require an online machine to be able to fetch the list of latest plugins available just thought >>>enhancement plugin_manager
metrictype gauge currently the metric collector only support the counter type we need to add support for gauge type to support adhoc values theses values could be the size of queue an eviction cache an uptime number of threads status >>>metrics
new plugin logstash output mqtt have created logstash output plugin for mqtt it is documented tested and ready for review https github com kompa3 logstash output mqtt >>>new-plugin
logstash freeze with stalling threads hello have logstash instance running on an ec2 ubuntu 14 04 it periodically freeze and then does not parse new incoming logs while it still listen for incoming tcp connections the only solution found so far is to kill and restart the process when killed logstash exit with the following message what can do to investigate further >>>bug needs_details
clone params for output plugins to fix validation behavior the validator for plugin will mutate the params in place causing the various output instances to share an instance of the codec this is obviously dangerous this patch restores the previous behavior fixes https github com logstash plugins logstash output tcp issues 13 issuecomment 171389649>>>blocker bug v2.2.0
add plugins dev instructions provide instructions for running plugins specs against logstash core event java fixes 4175 >>>developer-support java_event v2.3.0
better more benchmarks using logstash core event java it would be interesting to run an exhaustive set of benchmark to compare both logstash core event and logstash core event java implementations >>>java_event v2.3.0
default to logstash core event java implementation switch to use the core java event implementation by default for this we need to complete the following jar dependencies cleanups in logstash core event java 4176 add logstash core event java specific build requirements in the build rake tasks 4479 default to java event and dependencies cleanups 4494 >>>java_event v2.3.0
add logstash core event java specific build requirements in the build rake tasks the core java event build process using gradle need to be integrated in the logstash build rake tasks this depends on completing 4176>>>java_event v2.3.0
meta java event post merge review process we will launch post merge review process with ph and guy as reviewers this issues will track whichever comment prs we have this is related to the core java event rewrite issue 4191 >>>java_event v2.3.0
removed the reporter class this was used for debugging when developping the collector there is not need for theses classes to exist anymore they were used at the beginning to test the logic of the reporter >>>metrics
remove deprecated code for all new major releases is an opportunity to actually eliminate code that has been in deprecation cycle this is typically not something very high priority and ofter forgotten so though create an issue so we not forget about it >>>internal-cleanup v3.0.0
logstash doesn log failure to create new index as result of mapping error there has been report that if an index request that results in creation of an index fails due to mapping conflict with the template no error is logged and logstash discards the event this was reported in but hasn been confirmed or checked if fixed in recent x>>>bug needs_details unconfirmed
metrics refactor small improvements this pr contains few speed improvements for collecting metrics by removing unnecessary allocations way to get the uptime for pipeline and the agent filterdelegator to collect filter stats >>>metrics
fix no for 4444 too verbose deprecations warnings better method of ensuring that args are not mutated by plugin initialize note had to introduce `logstash util deep clone` as `marshal load marshal dump does not work directly on args because there is logger instance in args and marshal can dump io had to alter all the codec filter input and output base rb `initialize` to deep clone params as well as the plugin rb `initialize` to do `config init params >>>v2.2.0
stats jvm integration this pr integrated information into the webapi coming out of the java virtual machine this include hot threads information memory usage pending tasks add global stats resource where most of the relevant stats information are show format the hot threads not as hash but as plain text reply investigate the best way to represent memory consumption add options to filter the number of threads returned by the hot threads api also an option to ignore idle threads or not same behaviour as elasticsearch api does this is because the expected consumer of this api is going to be human and not software client having plain text message makes everything easy to comprehend this pr have an initial version of the hot threads report this should be improved in next versions with more detailed information fixes 3909 >>>metrics
implement exclusive grok in scenario like the below the goal is to run an event through list of grok filters and tag categorize the event today this approach suffers from the fact that there is no elegant user friendly way to exit the grok filter as soon as one of the pattern has matched all the grok filters will need to be executed regardless of the fact that match had already occurred this causes the grokparsefailure to inevitably be added to the event even though match was performed it be great to explore possibilities for making this less painful through exclusive grok just to give the idea >>>discuss enhancement
logstash init script configtest and restart broken for configfile logstash supports file for f` option but setting `ls conf dir` to file is not support in the init script this is the problematic code should test for is file file or presence of files `log failure msg` does not exist on el6 impact configtest is broken but also `restart` meaning that upgrading to results in old verison still runnning>>>bug packaging
logstash plugin docs enhancements phase show plugin versions explicitly logstash show version doc bundled with the release logstash master show all latest versions docs periodic update show logstash core version compatibility for each plugin page based on version plugin banner enhancements clearly display bundled plugins and community plugins basically two categories non community plugin and not bundled with core note community how to update community plugin not bundled with core note how to update future easy navigation between plugin versions version in url resource new plugin list structure for docs for our plugin docs were implementing new table structure with the below columns plugin name done description done github link done total downloads for logstash master latest version latest version downloads for logstash for plugins bundled in core bundled version bundled version downloads for plugins not bundled in core latest version latest version downloads>>>docs enhancement v2.3.0
fix for 4444 too verbose deprecations warnings pass deeply cloned copy of args to each output constructor invocation>>>v2.2.0
distinguish between user set and default pipeline settings fixes https github com elastic logstash issues 4443 the fix takes advantage of clamp ability to define the setters for the options these setters are only invoked when the user has explicitly set the option >>>v2.2.0
add hostname to the metadata currently some inputs add the `hostname` of the indexer which means that we can use this value in the filters to add them as tags or do any other operations since the hostname is being added at the input level each input plugin need to add the same code in order to make this happen my proposal is to add the host to the metadada field at every time at the input core level rather than the plugin level as discussed with ph today we will continue our discussion in this thread >>>discuss enhancement
runtime documentation the metrics api as an api user it would be great to have documentation for the metrics and each other we ve apis this is intended to be bundled with logstash and startup during running time locally it could be archived by reusing projects like swagger https github com oai openapi specification example http petstore swagger io api blueprint https apiblueprint org ve used with success swagger in previous projects kinda like it for their good interface related to 4463 >>>discuss docs metrics
api index resource for the metrics api it would be great for the metrics api to have something like http logstash meter elastic co 9292 directory like resource where people could see the available sources >>>metrics
internal filter metrics by namespaces as consumer of the metrics collector aim to get meaningful namespaces that let me select and fetch data easy for now we ve root base events in root base events filtered would propose to have something that matches more close semantically speaking the resources defined for 4446 so we can make something like root stats events to get all events information root stats jvm to get all jvm information root stats networking to get all events information also propose to rename root to word with bit more context what do you think might be something like metrics or logstash then we could have namespaces like logstash stats events logstash stats jvm what do you think >>>discuss metrics v3.0.0-alpha1
docs include maintainer guide twice thus generating an error http build us 00 elastic co job docs 3611 console happens because the community maintainer tag is defined twice because the document itself is included both in the index asciidoc and the contributing to logstash asciidoc>>>bug docs
data collection wire up in this pr there is the intention to connect the data generation layer logstash core metrics collection with the web api and show some real data this changes include first organization of the resources to match the initial design at 4446 pending tasks wire up static data like list of plugins etc add basic api tests adapt the api to match the initial designs at 4446 this will include an initial root resource sketch plus the events information >>>metrics
validate pipeline numeric options to ensure positive integers there were no specs here before and imho they re bit overkill for this section of code so not changing that fixes 4449 >>>bug v2.2.0
update offline plugin docs add updating all local plugins in one command fixes 4426>>>docs
create new filter plugin logstash filter excerpt there are situations where users process large events through logstash and index it on to elasticsearch typically you don need the entire event indexed and searchable but you still need to store the event for compliancy it would be nice to have filter that clones big event extracts an excerpt from it and indexes this to es naively an extraction can be the first 100 chars or we can get fancier with it maybe even logstash filter summarization plugin based on automatic summarization https en wikipedia org wiki automatic summarization the original large event can be routed to long term storage like s3 or hdfs you can still achieve this today by tagging based on size cloning and using ruby filter >>>new-plugin
invalid core gems creation for the release snapshot we ran into problem where the core gems logtash core and logstash core event were incorrectly built and the problem was that the `gem build` command was launched from the logstash root and not from the core gems directories for gems to build correctly the `gem build` command must be launched from the respective gem homes to avoid this in the future we should add rake task to build the core gems >>>enhancement
logstash forgets data type have two setups parsing sensu messages filebeat logstash1 gelf graylog filebeat logstash1 rabbitmq gelf graylog in the second setup the data type of float value is represented as 363e0 in graylog in the first setup it is stored as 363 the logstash2 instance is quite simple there is no filtering at all just input rabbitmq output gelf the logstash1 instance parses sensu messages lile this using the json filter my filter config looks like this why is the data type changed here >>>unconfirmed
need to reject pipeline batch size >>>bug v2.2.0
fix declare workers not supported docs to do correct respond to previously respond to checked for the wrong method >>>blocker v2.2.0
lumberjack plugin pipeline blocked closed sizedqueuetimeout lumberjack plugin always blocks after some time 15 minues we have 500 clients sending in around 8000 events minute via logstash forwarder lsf the setup was lsf clients x500 logstash server x2 v1 es nodes v1 the logstash servers have quite some grokking filters since we got warnings and error about pipeline slowdown and close we decided to split the filter workers from the incoming events so setup is now lsf clients x500 logstash broker x2 redis x2 logstash server x2 es x5 but here we experience the same problems the ls brokers have no filters we have tested with logstash and currently on but the problem isthe same with both versions logstash brokers have 8gb mem of which 70 is configured as ls heap size and cpu open files in logstash is set to 32k and to 65k on redhat linux nproc is set to 32k when we restart the ls brokers they start taking the lsf events back in the redis queue can even reach more then 000 000 events while the lsf clients are emptying their queue mem cpu during that period on the ls brokers is fine after some time no pattern yet detected the slowdown starts and eventually close of the lumberjack plugin java proc is still running when the plugin is closed and no errors or warnings are logged threads can go upto 1700 and then down to around 30 when we scan for connections to the redis we see that the broker is shipping events to redis and sometimes re opens the lumberjack but eventually the lumberjack is closed again and never reopens even when the connections to the redis stop all this happens within 15 minutes after the ls brokers are started only way to get things running again is restarting logstash brokers but restarting them every 15 min or less is not really an option we are considering filebeat but we can of course switch 500 clients from lsf to filebeat at this moment already have set the lumberjack workers to but then we get errors about multiline in the logstash logfile despite we don use the multiline filter no filters are used at all any help ideas are welcome if can run it with some special options to produce more logging about why the plugin is closed and not re opening again happy to try then out cheers christof>>>needs_details
design metrics api endpoints for logstash as part of the ongoing metrics implementation 3908 this issue specs all the user facing endpoints for phase aim is to be consistent as much as possible with es api so user experience is similar across products root resource request hostname skywalker version number build hash 72cd1f1a3eee09505e036106146dc1949dc5dc87 node stats pipelines stats get node stats events response jvm data jvm stats garbage collection request jvm timestamp 1453233447702 uptime in millis 211125811 mem heap used in bytes 58442576 heap used percent heap committed in bytes 259522560 heap max in bytes 1037959168 non heap used in bytes 56332256 non heap committed in bytes 57475072 pools young used in bytes 41672000 max in bytes 286326784 peak used in bytes 71630848 peak max in bytes 286326784 survivor used in bytes 260552 max in bytes 35782656 peak used in bytes 8912896 peak max in bytes 35782656 old used in bytes 16510024 max in bytes 715849728 peak used in bytes 16510024 peak max in bytes 715849728 get node hot threads default response is json human` provides human readable format response plugins expose an endpoint to get information on all plugins currently installed this is basically the output of `bin plugins list verbose` total 102 plugins name logstash output pagerduty version name logstash output elasticsearch version >>>design discuss metrics v3.0.0-alpha1
new pipeline woes with tcp output input generator count 100000 filter ruby code sleep output tcp port 3333 host localhost codec plain format sequence tmp logstash snapshot2 bin logstash config pipeline workers pipeline batch size 125 pipeline batch delay pipeline id base settings user set pipeline workers logstash startup completed tcp output exception host localhost port 3333 exception backtrace org jruby rubyio java 3682 in `select tmp logstash snapshot2 vendor bundle jruby gems logstash output tcp lib logstash outputs tcp rb 101 in `register org jruby rubyproc java 281 in `call tmp logstash snapshot2 vendor bundle jruby gems logstash codec plain lib logstash codecs plain rb 41 in `encode tmp logstash snapshot2 vendor bundle jruby gems logstash output tcp lib logstash outputs tcp rb 143 in `receive tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash outputs base rb 83 in `multi receive org jruby rubyarray java 1613 in `each tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash outputs base rb 83 in `multi receive tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash output delegator rb 119 in `worker multi receive tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash output delegator rb 65 in `multi receive tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash pipeline rb 277 in `output batch org jruby rubyhash java 1342 in `each tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash pipeline rb 277 in `output batch tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash pipeline rb 208 in `worker loop tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash pipeline rb 177 in `start workers level warn tcp output exception host localhost port 3333 exception backtrace org jruby rubyio java 3682 in `select tmp logstash snapshot2 vendor bundle jruby gems logstash output tcp lib logstash outputs tcp rb 101 in `register org jruby rubyproc java 281 in `call tmp logstash snapshot2 vendor bundle jruby gems logstash codec plain lib logstash codecs plain rb 41 in `encode tmp logstash snapshot2 vendor bundle jruby gems logstash output tcp lib logstash outputs tcp rb 143 in `receive tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash outputs base rb 83 in `multi receive org jruby rubyarray java 1613 in `each tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash outputs base rb 83 in `multi receive tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash output delegator rb 119 in `worker multi receive tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash output delegator rb 65 in `multi receive tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash pipeline rb 277 in `output batch org jruby rubyhash java 1342 in `each tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash pipeline rb 277 in `output batch tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash pipeline rb 208 in `worker loop tmp logstash snapshot2 vendor bundle jruby gems logstash core snapshot2 java lib logstash pipeline rb 177 in `start workers level warn csigint received shutting down the pipeline level warn csigint received terminating immediately level fatal 7477 7478 7479 7480 7481 7482 7483 7484 7485 7486 7487 7488 7489 7490 7491 7492 7493 7494 7495 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 185 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123>>>bug
unintentional deprecations warnings for config options with this very simple config when start logstash see this warning message as used the default values for retry max items don understand this warning message would understand this warning if have used it explicitly what do you think another question is why does it show up three times >>>bug v2.2.0
logstash falsely claims worker count was changed by user tmp logstash snapshot2 bin logstash input stdin filter multiline pattern hey what previous negate true pipeline workers pipeline batch size 125 pipeline batch delay pipeline id base settings user set pipeline workers warning manual override there are filters that might not work with multiple worker threads worker threads filters multiline level warn >>>bug v2.2.0
its buggy all over get your qa team find bugs and make it stable wasted so much time started with latest version of es and logsatsh in mac os yasomite env logstash series starts but only if reset my java opts env to whatever it wants the won start even spews out java related warning starts only when unset the pre existing java opts env var ii example code won work the one that is supposed to index to elastic search whatever is typed on console had to delete logstash template to make it work iii expected and error when gave wrong file name see below the file foo log2 is non existent non existent registering file input path pss server handheld correlated log2 level info no sincedb path set generating one based on the file path sincedb path users asingh sincedb f1c910074d207abb910e8fb33532f556 path pss server foo log2 level info pipeline started level info logstash startup completed iv hit trouble wherever lay hand on the logstah es combo >>>needs_details
rake fix issue when building regular tar thanks to ph who caught this issue in review https github com elastic logstash pull 4435 discussion r49224181>>>v2.2.0
bin plugin pack on windows creates zip only while attempting to use the `bin plugin bat pack tgz` feature from logstash running on windows ended up building zip file unexpectedly it not the end of the world as the zip is still usable but it was certainly surprise >>>adoptme bug low_hanging_fruit plugin_manager
new jruby openssl release clashes with lock file in branch jruby openssl is locked to 12 in branch https github com elastic logstash blob 902e127d710550f0ec33e4554021cd0f5c7a63c3 gemfile jruby lock l138 now that this gem has been updated to 13 running `rake bootstrap rake test install default bin plugin uninstall logstash input beats` throws an error during `bin plugin uninstall` potential fix for this is just bumping the version in the lock file>>>blocker bug v2.2.0
grok filter and nested objects fields ambiguity this may belong in the logstash plugins https github com logstash plugins repo but ll guess ll start here going through the process of changing my logstash config to be elasticsearch compliant this means replacing dot separated fields with nested fields inside of objects had look through the issues and couldn find anything exactly similar which might mean my terminology is incorrect in my grok patterns want to specify nested fields couldn see anything in the grok documentation that says couldn specify nested fields inside grok patterns figured should be able to do something like this so decided go ahead and convert my filters to for nested field allocation and running config test resulted in great good to roll however when try to run logstash with the nested fields inside the grok pattern matches to do some parsing of radius data get this error kind of interpreting this error to mean that the nested fields are being treated as regex character class which kind of make sense in the world of grok this is kind of documentation problem and or problem with the grok filter test not sure how meant to deal with this practically and it would be great to clear it up this is replicated in both logstash and logstash >>>bug
add rake tasks to create uber packages add rake tasks to create zip and tar gz for ls package with all plugins installed from losgtash repo>>>packaging v2.3.0
bump version to snapshot2 bump version update gem and lock file to point to rubygems org in preperation for release>>>release_plan
deprecating node protocol the node protocol is giant pain for both logstash users and logstash developers why node is bad for users users think they can use it to gain speed boost which it doesn actually provide after trying node they then wind up posting bug reports due to broken configurations setting up valid node is more complex than http or transport this makes for disappointed users and disappointed developers why node is bad for developers we waste time debugging node configuration errors we currently have to maintain an extra logstash output elasticsearch license plugin just for the use case of shield marvel logstash additionally the error messages generated in this scenario are plain ridiculous to debug why user like node they can see which logstashes are active via the elasticsearch node list the next major of logstash will cover this with metrics however perceived speed multicast discoverability though we now discourage this in elasticsearch imho we should deprecate node soon and consider removing it in the next major release perhaps community member would be interested in maintaining that as separate plugin >>>design discuss question v2.2.0
discuss the introduction of channel of components inside an input motivation inputs have mechanism to source data externally lets call this the source sources usually have their own internal loop that pumps data into the input via some callback mechanism block or subscriber callback often enough the source has context that should ride with the data path in the case of the file input the existing call `input run` when codecs are involved calls decode on the codec with block the block binding closes over the queue and any number of other input ivars or source context the codec does not know the content of this binding and the binding can be different for each decode call it cannot cache any one block and call it if there is buffered data that the codec must flush asynchronously it would have to cache each block along with the buffered data some inputs have extra event decoration that is dependent on the context from the source and again this decoration is done in the input via the block that the codec calls yields to it is not possible for codecs lets generically think of them as event processors to use the context given by the source it is not possible to introduce new event processors codec before or after the existing codec either declaratively or dynamically for example the stdin input source does not produce line oriented data and can behave incorrectly if it is used with multiline codec that expects line oriented data to overcome this we have fudged it somewhat by adding composite codecs the json lines codec that internally chains the line and json codecs it is not possible for the source to communicate other events to the input for example the filewatch as source can communicate when file is opened closed renamed or reached eof but presently it can only communicate data events to the file input concepts channel is double linked list collection of components it can be built statically or dynamically the head of the channel is the source component and the tail is the queuing component intermediate components are called links head tail or link is also known as the component type component wraps unit of work in simple chainable interface it is stateless and knows about its upstream and downstream neighbours when it receives call from upstream it executes the unit of work and calls the downstream component with the modified data and context the data call flow is from upstream downwards and the control call flow is from downstream upwards initially expect that control flow is backpressure the input hold the channel and its components and can exert control on the components or channel if necessary component can take metadata see `accept meta` below from the input when it builds the channel usually some configuration values it would need for its unit of work the preliminary api as implemented by the base component is head component should redefine the deliver method tail component should redefine the accept method link component should redefine the do work method all components redefining base method should call super after it has done some local work poc implementation in the file input have created this channel `watchercomponent identitymapcodeccomponent localdecoratecomponent globaldecoratecomponent enqueuecomponent` the poc is spread out across three repos file input https github com guyboertje logstash input file pull multiline codec https github com guyboertje logstash codec multiline pull ruby filewatch https github com guyboertje ruby filewatch pull some components need to be moved to ls core implications this proposal paves the way for codec chaining in the configuration each component should be unit tested some components can be shared across inputs proper backpressure signals can flow up to the source acking can flow up through the channel especially when the persistent queue persists the event this is future extension but expect something like this dynamic channels can be created where necessary we can break down some of the block heavy designs seen in some inputs difficult problems like contextual multiline match patterns might be easier to solve it is possible to have predicate components that allow or deny data flow using rules applied to context or data it is possible to have multi channels that share head component and predicate component as the first link after the head the predicate component will have be multiple downstream chains and the predicate rule outcome selects which downstream to call accept on it may be interesting consider this proposal for other parts of the pipeline outputs or filters output it will make writing new input more interesting on the one hand only the head component needs most thought and for most cases we can use generic codec component and on the other the general move to java will make writing any plugins interesting for the community in the future this proposal will make the transition to pure java inputs easier because we will have removed the block calls >>>design discuss enhancement
rake docs generate failling with dependency problems when you try to generate the documentation from the master branch it will fail when the task tries to install all the plugins >>>bug v2.3.0
rename pipeline worker settings to symbols the next generation pipeline pr changed the pipeline settings to be symbols https github com elastic logstash blob 028576ba6f141f57c180c8f3dbffa14cb24967c0 logstash core lib logstash pipeline rb l23 l29 which made the defaults printer class not show the values of workers because it expected string instead this pr changes all references to settings in the printer classes to be symbols too this targets master and fixes 4429 >>>bug v2.2.0
specified settings aren show since tmp logstash bin logstash input generator count output stdout codec dots settings user set filter workers default filter workers logstash startup completed logstash shutdown completed projects logstash git bin logstash input generator count output stdout codec dots settings logstash startup completed logstash shutdown completed>>>bug v2.2.0
large overhead when logging events because of attribute lut logging an event in logstash could become very very verbose in some places logstash events got logged on warn level for example if an output plugin is unable to connect to its destination https github com logstash plugins logstash output syslog blob master lib logstash outputs syslog rb l152 in this case the whole event object is logged guess with the `inspect` method as far as can tell in https github com jordansissel ruby cabin blob master lib cabin outputs io rb l52 the logstash event does include an attribute lut` https github com elastic logstash blame master logstash core event lib logstash util accessors rb l48 in the accessors class which is used to perform direct access to the containing object for key description from the comment in my opinion this information as almost never used if one is checking the logstash log for errors if the logstash event does include lot keys and has flat structure for every containing key nearly the whole event is printed again which results in lot redundant information which makes reading the log file much harder and in most cases does not provide any useful information in our case an event with around 40 fields keys produces single log line with 95kb that is huge is there way to send an event in smaller representation to the log are there any recommendations is it possible to modify the logging facility of logstash to reduce the output automatically may also be related to 3101>>>discuss
release of new logstash gems should trigger ci of dependents plugins taking the example of the logstash input github plugin ci badge is green but last build was done in october against logstash snapshot5 the plugin is in fact broken https github com logstash plugins logstash input github issues is there some solution to have more recent status for each plugin like simple solution scheduled builds complex solution triggered by change in the dependencies thoughts >>>discuss enhancement tests-infra
add example for updating all plugins from local cache https www elastic co guide en logstash offline plugins html install or update local plugin let add 3rd example for common use case on how to update all local plugins with single command from the cache after unpacking >>>docs plugin_manager
prevent field timestamp from being removed fixes 4370>>>v2.3.0
add section to how to write an output plugin covering changes in outputdelegator we should add short section to how to write an output plugin https www elastic co guide en logstash current how to write logstash output plugin html covering `declare threadsafe and `declare workers not supported` before we launch as the blog post covering that will link to that these changes were introduced in https github com elastic logstash pull 4391>>>v2.2.0
remove sized queue rb since logstash we now use java synchronousqueue instead of ruby sizequeue>>>v2.2.0
add simplier way to log error messages inside logstash this pr introduce loggable module that we can include into any classes and it will add the instances class methods necessary to do the logging the logging configuration is centralized at once place inside the runner and this remove the need to pass logger at initialize time or by defining custom accessor for changing it drying up the code bit by default the class will use the default logger defined by the module but it can be redefined on specific classe this pull request also change the configuration order of the logger the logger need to be configured with the right log level before its use which was not the case before >>>needs_review v2.3.0
implement proxy protocol support for tcp inputs support for proxy protocol version and optionally version for tcp inputs tcp log4j and syslog at least would be highly useful to allow logstash to sit behind an haproxy or elb load balancer >>>enhancement
default value for sprintf interpolation feature in lot places logstash allows to reference fields with the sprintf format https www elastic co guide en logstash current event dependent configuration html sprintf unfortunately if the referenced field does not exist sprintf defaults to leave the the reference untouched which may lead to very unsatisfactory results therefore suggest to allow default value for the sprintf interpolation output file path var log type default yyyy mm dd hh as delimiter between the field reference and the default value suggest taken from bash unlikely to exist in logstash event field name >>>enhancement
remove bin plugin update command without arguments `bin plugin update` when run on ls instance will update all the default plugins bundled to the latest versions published on rubygems org while this may seem useful to uptake latest bug fixes plugin development and release is isolated ls core mass update of all default plugins has the potential to cause dependency issues this is because ls release package pins the version numbers of dependency in gem lock file and update does not seem to properly handle updates to dependency see discussion here https discuss elastic co logstash fails to start after logstash output elasticsearch update 38330 and https github com logstash plugins logstash output elasticsearch issues 335 which was caused by https github com logstash plugins logstash output elasticsearch pull 334 was able to reproduce this behavior with ls and running `bin plugin update` it updated logstash output elasticsearch to among other plugins when manually update the single plugin it updates it to which is good version without dependency conflict am recommending we discourage and remove the use of `bin plugin update` and only allow individual updates to plugins also given the recent ls release cadence users do not have to run an update to get the latest big fixes to plugins thoughts >>>discuss plugin_manager
up default of pipeline workers to 100 of cores this is predicated on the fact that with the ng pipeline it is expected that workers will spend significant amount of time in iowait due to outputs like the elasticsearch output in benchmarks based on real world apache log files the best performance came out of scenarios where pipeline workers num cpu cores setting this to default to the of cores is defensive decision that should handle cases where users have particularly io heavy inputs for most users we should recommend setting the number of workers to be as high as possible until performance decreases previous benchmark information https github com elastic logstash pull 4340>>>design discuss enhancement v2.2.0
add new cli options for next gen pipeline ref https github com elastic logstash issues 4360>>>docs
warn on potential memory issues when large number of inflight messages are present fixes 4349 this warns on inflight max rather than batch size since even low batch size could be dangerous if too many workers are present `inflight max batch size pipeline workers` >>>enhancement low_hanging_fruit next-gen_pipeline v2.2.0
add http poller to default plugins list this plugin is fairly popular won increase the bundle size at all and should probably be default plugin like to target it for the release if possible >>>enhancement v2.2.0
add `wrappedsynchronousqueue offer` method expose the java offer` method of the `synchronousqueue` class this method allow the input developper to correctly apply back pressure to the network clients if you use push` it will block forever until the pipeline free some space this behavior is sufficient if the pipeline outputs are healthy but if the output stale the backpressure will be applied up to the input producers when reading file this scenario is fine since we will just stop reading the file until the thread unblock again in the context of network clients the story is bit different the clients will timeout and try to reconnect to restransmit their payload creating multiple new connection thread block on the queue in some case this will lead into oom issues this pr is the first step to communicate that the queue is under pressure >>>v2.2.0
change to single agent conf brings down logstash server new to logstash today tried updating single agent conf to test changes thinking that it would be safe but it brought down my logstash server expect that this is not correct behavior that change to an agent conf should only affect the agent itself logstash version os logstash server centos os logstash agent centos 11 here are the original and modified agent conf files along with the errors https gist github com coutotyler 846f0c9bd4ab3873f613>>>needs_details
docs for csv filter plugin don mention skip empty columns property docs for csv filter plugin don mention skip empty columns property>>>docs
logstash input bro currently integrating bro logs into logstash is cumbersome this is due to bro creating dynamic headers at the start of each file describing the fields and value types contained in the log this straddles the requirements of being either filter or an input realize the design team would prefer that inputs remain non opinioned but for the sake of this use case believe it may be necessary so have decided to go that route have decided to base this plugin on logstash input file due to it similarity https github com brashendeavours logstash input bro thank you for consideration of inclusion >>>needs_review new-plugin
use settings file to complement command line argument parsing currently logstash lists the following command line arguments with the introduction of the next generation pipeline and node identification these flags will be added with the pluggable agents metrics automatic reloading and more the big amount of setting flags will clog the cli so believe it the time to introduce settings file implementation the settings file should work together with the command line argument parser so that for example the user can either specify node name in the cli or node name in the settings file to set the name of the node option adding settings section to the config file pros single place to check for both the pipeline config and settings consistent syntax between pipeline config and settings cons many people use multiple config files how to support multiple `config blocks existing treetop code and ast is painful to manage and change with automatic config reloading and potentially remote loading it useful to ensure the two concepts are kept separately option individual yaml file for settings pros easy to understand hierarchical structure to configure core components pipeline agent logger better settings experience across elasticsearch kibana and beats cons it yaml common implementation problems no cli arg parsing tool accepts settings file so the integration between cli args and settings file must be written by us example of yaml file what now what do you think about this comments appreciated >>>breaking-compatibility config_management design discuss manageability v3.0.0
bin plugin update on wrongly states no plugin updated after updating plugins get the no plugin updated message logstash works correctly only got this from the git branch after executing `rake test install default` >>>bug needs_details plugin_manager
rename shutdowncontroller to shutdownwatcher slightly adjust the metaphor for the class that is responsible for monitoring pipeline shutdown process report on its status and intervene if it stalled>>>internal-cleanup
edit docs for life of an event to cover the ng pipeline>>>docs v2.2.0
improved semantics for outputdelegator this commit greatly improves the semantics for the outputdelegator it now has an api for declaring if an output is threadsafe which lets us economize on the number of instances we only need one shared across threads by default sets the number of workers for an output to be the number of pipeline workers for non threadsafe outputs moves the worker safe api which declares whether the plugin supports workers to the class not instance level strongly enforces the worker safety api previously warning would be logged but nothing else should provide better performance for threadsafe plugins plugin like the file output should only need mutex around the file write and could be written to be threadsafe this opens the door to multiple threads running say their codecs simultaneously this commit is built on top of some of the ideas in https github com elastic logstash issues 4367 >>>discuss enhancement v2.2.0
bump cabin to if is specified on master the runner logger will subscribe to both the logfile but also the terminal if the messages are fatal this last functionality depends on cabin some plugins might depend on specific version of cabin so this needs to be checked >>>enhancement v2.3.0
s3 output duplicate files background attempting to have filebeat send logs from several servers to single logstash instance and then write those logs to s3 have several beat listeners on different ports open on the logstash server but even when only one filebeat service has connected to the logstash server get multiple copies of the log file written to separate paths in s3 have single logstash server and cluster of servers for kafka using ansible for provisioning and adhoc commands hence the presence of the commands below but beside running the same diagnostic commands on multiple servers ansible is not germane to this issue in my opinion overview my logstash configs for the various beats listeners verify that only the kafka beat is connected port 5047 main issue expected outcome expect to find files from the kafka filebeat in the `s3 app logs kafka path and no other files on s3 at this point actual outcome on s3 have several copies of the kafka log each written to sub paths that match the four different listeners while the file sizes are slightly different ve copied these from s3 to my machine and verified that they re all kafka logs suspect that the files are getting written to the different s3 paths at slightly different times hence the slightly different file sizes >>>bug unconfirmed
default batch size makes slow ingestion stutter the default batch size for the next gen pipeline is 125 when executing slow rate pipeline in the terminal you don see what you expect terminal https cloud githubusercontent com assets 31809 11954065 4255ddf8 a89d 11e5 8815 cac3286a1a62 gif you have to set batch size to to see events flowing at seconds per event terminal https cloud githubusercontent com assets 31809 11954151 1a9df9d4 a89e 11e5 8523 30a161c9d930 gif wonder if we should set different defaults for the batches in certain situations for example if tty is true set to >>>discuss next-gen_pipeline
deprecate multiline filter plugin in favor of multiline codec multiline ml event processing is popular use case in logstash multiline event processing is complex and relies on proper event ordering the best way to guarantee ordered log processing is to implement the processing as early in the pipeline as possible today users have choices multiline filter and multiline codec the preferred tool in the logstash pipeline is the multiline codec which merges lines from single input using simple set of rules this can be used with any input source multiline filter performs similar task of aggregating multiple lines and exists because it predates the `codec` concept in logstash this filter is not thread safe and was advised not to be used when setting `filter worker` or w` to more than recently there has been number of key enhancements in ml codec proper handling of streams from multiple sources auto flushing of buffered lines circuit breakers for preventing ooms and so on at this point we feel ml filter has run its course and needs to be deprecated this would also avoid confusion for new users having to pick between the two the plan is to deprecate ml filter in version and remove it from the default package in version you can still install ml filter by using `bin plugin install` but our advice is to move to the more robust ml codec >>>release_plan v2.2.0
version conflicts in master trying to install default plugins currently `rake test install default` breaks with these conflicts >>>bug
fix to support legacy plugins specs monkeypatching pipelines because lots of plugins monkeypatch the pipeline and `output func` returns nil we need to check for this until we properly refactor this specs as discussed in 4382 replaces 4373 >>>blocker bug v2.2.0 v3.0.0
filter codec idea jsvd suggested some time ago to create filter that could leverage codecs to do the filtering which would have the advantage of avoiding dual codec filter implementations like the json codec and filter we could have only the json codec and leverage the json codec into filter codec to create json filter this issue is to keep trace followup on that idea also the same has been suggested for xml in https github com logstash plugins logstash filter xml issues 22>>>discuss
refactor specs that depends on implementation dependant pipeline mock the ng pipeline merge in master has broken lots of plugin tests specs which were dependant on mocking the pipeline based on its previous implementation we need to review and refactor these tests to avoid implementation dependant tests specs this relates to the currently failing specs meta issue 4371 short term fix is proposed in 4373 >>>internal-cleanup tests-infra
sincedb file per input using the same sincedb file for different inputs no matter whether is the same pattern or similar pattern causes the file to only store the information from single location the sincedb file seems to be completely replaced with the information of single input at time >>>docs enhancement
logstash constantly restarting under ubuntu 14 04 logstash is completely broken it constantly respawning with init logstash main process ended respawning while var log logstash logstash err is completely empty >>>needs_details packaging
update branch with gemfile and lock file>>>internal-cleanup release_plan
pass in configuration using environment variable as we live in era where containers taking over place it would be nice to assign configuration to environment variable may be logstash` and make sure logstash consumes it when no configuration file f` or configuration string e` is provided the reason is pretty simple don want to build my own image from base one just to inject some file nor want to mess around with volumes nor happy with e` because you end up with long unreadable line and at the same when you use docker compose for instance you can come up with take look at magical pipe supported by yaml which is pretty readable and allows one to use existing official image >>>enhancement
nomethoderror undefined method for nil nilclass using logstash input cloudwatch plugin and ve got the following config for logstash version input cloudwatch namespace aws ec2 metrics diskreadops cpuutilization filters tag monitored yes region eu west access key id secret access key output stdout codec rubydebug elasticsearch protocol http host 127 ve tried installing it with elasticsearch version and but in both cases logstash does not start and get the following error in the logstash err log nomethoderror undefined method for nil nilclass receive at opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch rb 493 handle at opt logstash vendor bundle jruby gems logstash core java lib logstash outputs base rb 88 output func at eval 27 outputworker at opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 244 start outputs at opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 166 thanks for your help >>>needs_details
wip developing md guidelines on the development workflow guidelines for the logstash development workflow this is wip please feel free to suggest comment amend >>>developer-support enhancement
better compatibility with specs that depend on output func monkeypatc this is temporary fix until old logstash plugin specs can be refactored to not mess with the pipeline code should fix lot of the issues in https github com elastic logstash issues 4371>>>blocker breaking-compatibility
rebased reload config from files this takes over from 4342 which no longer is clean merge to master this is fully rebased off feature management jsvd feel free to force push this branch after checking diff and close this pr if that makes sense >>>config_management enhancement v2.3.0
meta failing plugins specs under master here the survey of the currently failing specs under master at 066e778f63109d9fde2b4f00a70a68106ebe0204 ng pipeline related failures devutils pipeline mocking https github com elastic logstash devutils issues 42 bad in specs pipeline mocking https github com logstash plugins logstash input elasticsearch issues 37 https github com logstash plugins logstash input file issues 86 https github com logstash plugins logstash input pipe issues 12 https github com logstash plugins logstash input gelf issues 31 https github com logstash plugins logstash input ganglia issues 15 https github com logstash plugins logstash input generator issues 12 https github com logstash plugins logstash input tcp issues 36 out of order batches https github com logstash plugins logstash output file issues 25 unknown origin suspect this are actually related to https github com elastic logstash devutils issues 42 hanging specs https github com logstash plugins logstash input tcp issues 37 https github com logstash plugins logstash input syslog issues 24 other https github com logstash plugins logstash codec rubydebug issues https github com logstash plugins logstash input log4j issues 27 solutions short term fix proposal in 4373 real refactor required in 4382>>>meta
nomethoderror if field timestamp is missing if the field timestamp` is missing in an event the following error occurs nomethoderror undefined method `to iso8601 for nil nilclass to at opt logstash vendor bundle jruby gems logstash core java lib logstash event rb 109 encode at opt logstash vendor bundle jruby gems logstash codec line lib logstash codecs line rb 53 receive at opt logstash vendor bundle jruby gems logstash output stdout lib logstash outputs stdout rb 49 handle at opt logstash vendor bundle jruby gems logstash core java lib logstash outputs base rb 81 output func at eval 47 outputworker at opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 276 start outputs at opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 193 steps to reproduce start logstash with the following config input generator filter mutate rename timestamp timestamp output stdout >>>needs_details
option to update plugin to specific version there are use cases where user may need to update plugin to particular version that isn the latest there should be version flag for bin plugin update to enable this more context here https github com elastic logstash issues 3334>>>enhancement
sane defaults output worker setup for logstash ng pipeline now that the `ng pipeline` branch has been merged into logstash which is destined for our release now is good time to reconsider some default behavior that could be improved for the `ng pipeline` we should reconsider our default worker policy of 50 of cores propose that we raise this to 100 of cores remember that now the workers spend some time blocking on io when performing an output operation esp over network many users will see optimal numbers with more workers than cpu cores in fact benchmark results can be seen on this issue https github com elastic logstash pull 4340 we should consider defaulting the number of worker safe plugins to be the number of workers in most cases this will give the optimal result with the new pipeline we could alternatively consider creating threadsafe worker option where worker could declare itself threadsafe and share itself across all worker threads this is cleaner but probably higher effort and maybe could be done as next step for >>>design enhancement performance-improvements v2.2.0
logstash crashes on invalid ssl input ioerror closed stream while this seems caused by the logstash input tcp plugin it brings down logstash as whole so submitting the issue here can move this to logstash input tcp if required problem we noticed that after upgrading from logstash to logstash on linux rhel and centos our logstash servers would stop responding after performing vulnerability scan on the ssl enabled tcp input ports they would crash after logging the following entry to ``logstash err`` how to reproduce after some investigation we are able to reproduce this reliably using the following minimal commands run logstash with ``test conf`` note the logstash ssl certificate is signed by self signed ca run following command to crash logstash note the ``sleep 1`` ensures that the openssl command only starts after nmap has had time to start if you do not get the connected 00000003 in the output below you might want to increase this little bit output of test command sanitizing some of the output output from logstash closing remarks am using the multiline codec as that ensured more reliable reproduction of the issue however in my testing it seems that the multiline codec is not required for the code to crash was also able to reproduce full logstash crashes without just not reliably note that in all cases without multiline code logstash will close all existing ssl connections but not always crash which is an issue in itself but of lesser severity am assuming both of these issues are related so not opening separate ticket on that for now >>>bug
cleanup docs directory remove old unused markdown docs bring dir structure to mirror logstash docs repo>>>docs
ng pipeline this backports the ng pipeline patches from master to the branch as one squashed commit >>>enhancement
avoid collision with json ld since logstash is using as prefix for reserved fields like metadata` just like to point out that json ld http json ld org does the same and that since json ld is ratified w3c standard it would be nice if logstash did its utmost to avoid using the same field names to avoid collision the list of existing keywords in json ld http www w3 org tr json ld syntax tokens and keywords are context` id` value` language` type` container` list` set` reverse` index` base` vocab` graph`>>>enhancement
add deb and rpm download options for uber package deb and rpm download options for the uber package should be created as well for consistency https www elastic co downloads logstash>>>enhancement v2.2.0
update documentation about the new pipeline architecture configuration changes batch size https github com elastic logstash blob master docs asciidoc static command line flags asciidoc reference to filter stage https www elastic co guide en logstash current pipeline html update diagrams here to remove the explicit filter stage https www elastic co guide en logstash current deploying and scaling html>>>docs next-gen_pipeline v2.2.0
wip metrics structured data still work in progress >>>metrics
translation missing for the allow unsafe shutdown` fix the translation missing when running the `bin logstash help` command>>>v2.1.2
allow the agent to define some identifiers this pr allow the user to set the name of the logstash instance with the n` or name` option if no name is provided the agent will fallback to the current hostname of the machine this pr also add the `node uuid` to the agent which is unique between each new instance of the agent it will lazy generate uuid v4 on invocation fixes 4353>>>metrics v3.0.0
review and refactor all exception handling in the java event implementation following guyboertje comment on the subject in https github com elastic logstash pull 4279 discussion r47670323 agree we should refactor the exception handling and use class specific exceptions >>>internal-cleanup java_event
revert accidentally altered gemfiles in ng pipeline the ng pipeline merge accidentally included gemfile altered by `rake test install core` this reverts that change to `e390d105e4db9cc832a4613244707def2f331f5d` https github com elastic logstash commit e390d105e4db9cc832a4613244707def2f331f5d >>>bug
we need to be able to set node name from the command line the name of the logstash instance this name will be used for the agent and also from the metrics collection after discussing with andrewvc we think that n` of name` would be good name the name will be send to agent for now and show in the log if no name is given we will fallback to the current hostname >>>metrics v3.0.0
logstash web init scripts still packaged in logstash igalic log01 dpkg logstash desired unknown install remove purge hold status not inst conf files unpacked half conf half inst trig await trig pend err none reinst required status err uppercase bad name version description ii logstash an extensible logging pipeline igalic log01 dpkg etc init logstash web conf logstash etc init logstash web conf igalic log01 dpkg logstash grep logstash web etc init logstash web conf etc default logstash web etc init logstash web igalic log01 >>>bug packaging v2.2.0
unclear status of plugins for shield and watcher the following plugins sources are nowhere to be found logstash output elasticsearch license logstash output elasticsearch shield but they are mentionned in the integration docs https www elastic co guide en watcher current logstash integration html https www elastic co guide en shield current logstash html so it is difficult to help review them in particular if they are up to date with ls2 also the elasticsearch shield plugin seems in contradiction to the switch to http ssl in the standard elasticsearch output done in ls2 from ls2 the elasticsearch http protocol should handle shield connection no elasticsearch shield should in fact depend on elasticsearch java no to finish it simply cannot be installed on top of ls2 so is this plugin still required for which ls versions for sure the mentioned documentation must be updated with separation between ls1 and ls2 and maybe the gem must be yanked from rubygems https rubygems org gems logstash output elasticsearch shield or dependency on logstash core must be added for restriction >>>question
wip stoppable shutdown controller this starts the work needed to fully stop the shutdown controller across restarts it is based on 4340 but needs to be cross merged with 4342 to work currently the process exits too soon to test this code jsvd let coordinate tomorrow on the best way to do this >>>enhancement
add warning when batch size is configured too high 4155 introduces configurable batch size which can be tweaked to improve throughput however bigger batch size means more events inflight and this needs bigger java heap configuration we should add warning when the limit is too high maybe 10k events in total >>>enhancement next-gen_pipeline v2.2.0
error and possible fix in logstash grok exception handling am using logstash and found grok exception happening for some of our training and testing files can anyone please confirm if the fix is correct and why exactly the exception happens found the following the function match in the file logstash lib logstash filters grok rb needs to be changed the change is highlighted below basically added return false in the rescue exception handler and some logging informatitio the exception seems to happen for expression probably because of increased state machine but need to investigate this further think although am not sure this is only happening for unmatched patterns for now we can take the default option of unmatched for any exception happening in logstash hopefully these exceptions will be uncommon one additional thing to note is that the same line can throw multiple exceptions confirmed this by looking at the debug output information added in the exception handler `>>>needs_details
logstash crashes with org jruby rubyencoding utf8coder hi team we are using logstash to collect nginx log and send to kafka and finally save to es but these days we are suffering from the issue that logstash crash after hours running and the worst thing is that there aren many abvious error in log here attached the hs err pid log could you help to have look thanks in advance below is some of my key parameters usr local java jdk bin java xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly djava io tmpdir data0 logstash app logstash xmx500m xss2048k djffi boot library path data0 logstash app logstash vendor jruby lib jni xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly djava io tmpdir data0 logstash app logstash xbootclasspath data0 logstash app logstash vendor jruby lib jruby jar classpath usr local java jdk lib dt jar usr local java jdk lib tools jar usr local java jdk jre lib djruby home data0 logstash app logstash vendor jruby djruby lib data0 logstash app logstash vendor jruby lib djruby script jruby djruby shell bin sh org jruby main data0 logstash app logstash lib bootstrap environment rb logstash runner rb agent data0 logstash app logstash conf data0 logstash app logstash logs logstash log problematic frame 8665 c2 org jruby rubyencoding utf8coder encode ljava lang charsequence 95 bytes 0x00007fbbc2a68e62 0x00007fbbc2a68c80 0x1e2 failed to write core dump core dumps have been disabled to enable core dumping try ulimit unlimited before starting java again an error report file with more information is saved as data0 logstash app logstash hs err pid2149 log below is the content of hs err pid2149 log as couldn upload the log successfully fatal error has been detected by the java runtime environment sigsegv 0xb at pc 0x00007fbbc2a68e62 pid 2149 tid 140442648872704 jre version java tm se runtime environment 51 b16 build 51 b16 java vm java hotspot tm 64 bit server vm 25 51 b03 mixed mode linux amd64 compressed oops problematic frame 8665 c2 org jruby rubyencoding utf8coder encode ljava lang charsequence 95 bytes 0x00007fbbc2a68e62 x00007fbbc2a68c80 0x1e2 failed to write core dump core dumps have been disabled to enable core dumping try ulimit unlimited before tarting java again if you would like to submit bug report please visit http bugreport java com bugreport crash jsp current thread 0x00007fbb482c3800 javathread worker daemon thread in java id 2679 stack 0x00007fbb5a128000 0x00007fbb5a329000 siginfo si signo 11 sigsegv si code 128 si kernel si addr 0x0000000000000000 registers rax 0x0000000000001000 rbx 0x00000000ee3a4130 rcx 0x00000000ffffffff rdx 0x0000000000000000 rsp 0x00007fbb5a326600 rbp 0x0000000000000002 rsi 0x0000000000001000 rdi 0x0000000000000001 r8 0x0000000000000064 r9 0x0000000000000000 r10 0x7073782e2a3a3534 r11 0x00000000ede90c40 r12 0x0000000000000000 r13 0x0000000000000016 r14 0x00000000ee3cf3e8 r15 0x00007fbb482c3800 rip 0x00007fbbc2a68e62 eflags 0x0000000000010202 csgsfs 0x000000000000e033 err 0x0000000000000000 trapno 0x000000000000000d top of stack sp 0x00007fbb5a326600 0x00007fbb5a326600 0000000000000000 00007fbbc2e68268 0x00007fbb5a326610 00000000ee1aa778 00000000edf46148 0x00007fbb5a326620 00000000ee1aa778 00000019edf46148 0x00007fbb5a326630 ee6152f8ed7b4790 ee615118e0fc8290 0x00007fbb5a326640 00000000edf412d0 00000000ed7b4790 0x00007fbb5a326650 00000000e0fc8908 00007fbbc1386c52 0x00007fbb5a326660 00000000eb5e5430 00007fbbc2b14578 0x00007fbb5a326670 0000000500000000 00000000ede4d2f0 0x00007fbb5a326680 00000000eb8b5a60 00007fbbc1dfa711 0x00007fbb5a326690 0000000000000008 00000000e0fc8858 0x00007fbb5a3266a0 0000000000000000 00007fbbc1d9548c 0x00007fbb5a3266b0 00000000eb5e5430 00007fbbc2b31740 0x00007fbb5a3266c0 0000000000000000 00000000eb5e5430 0x00007fbb5a3266d0 00000000eb791310 00000000ede4d2f0 0x00007fbb5a3266e0 00000000e0fc88c0 00000000eb48c170 0x00007fbb5a3266f0 0000000000000003 eb3404d0c2e372dc 0x00007fbb5a326700 0000000000000020 00007fbbc1bdcecc 0x00007fbb5a326710 00000000eb8b5a60 00000000eb89f210 0x00007fbb5a326720 00000000e0fc88c0 00007fbbc1346010 0x00007fbb5a326730 00000000e0fc8268 00000000e0fc88a8 0x00007fbb5a326740 00000000edf44490 0000000000000002 0x00007fbb5a326750 00000000eb659a50 00007fbbc13faa24 0x00007fbb5a326760 00000000ed018390 eb3404d0e0effc18 0x00007fbb5a326770 00000000e0ed8d08 00000000eb89f210 0x00007fbb5a326780 e0eff910edf46148 00000000ee1aa778 0x00007fbb5a326790 00000000eb659a50 00007fbbc2e6fbdc 0x00007fbb5a3267a0 00000000e1cbab20 00000000e0fc7f98 0x00007fbb5a3267b0 00000000edbeeda8 00000000ed5e26b0 0x00007fbb5a3267c0 2000ae60edf46148 00000000eb9579d0 0x00007fbb5a3267d0 00000001002670c8 00000001000bd1c0 0x00007fbb5a3267e0 00000000edf46148 00000000eb659a60 0x00007fbb5a3267f0 00000000edf46148 00000000ee615118 instructions pc 0x00007fbbc2a68e62 0x00007fbbc2a68e42 03 d1 8b ea ff c5 3b e8 0f 8d 3f 04 00 00 66 45 0x00007fbbc2a68e52 0f 6e c1 44 03 cf 8b ea 83 c5 02 66 49 0f 7e da 0x00007fbbc2a68e62 41 89 6a 18 45 8b d1 41 ff c2 44 3b d6 0f 83 c1 0x00007fbbc2a68e72 03 00 00 4d 63 d9 66 47 89 44 5e 12 48 63 df 66 register to memory mapping rax 0x0000000000001000 is an unknown value rbx 0x00000000ee3a4130 is an oop org jruby rubyencoding utf8coder klass org jruby rubyencoding utf8coder rcx 0x00000000ffffffff is an unallocated location in the heap rdx 0x0000000000000000 is an unknown value rsp 0x00007fbb5a326600 is pointing into the stack for thread 0x00007fbb482c3800 rbp 0x0000000000000002 is an unknown value rsi 0x0000000000001000 is an unknown value rdi 0x0000000000000001 is an unknown value r8 0x0000000000000064 is an unknown value r9 0x0000000000000000 is an unknown value r10 0x7073782e2a3a3534 is an unknown value r11 0x00000000ede90c40 is an oop java nio heapcharbuffer klass java nio heapcharbuffer r12 0x0000000000000000 is an unknown value r13 0x0000000000000016 is an unknown value r14 0x00000000ee3cf3e8 is an oop klass type array char length 4096 r15 0x00007fbb482c3800 is thread stack 0x00007fbb5a128000 0x00007fbb5a329000 sp 0x00007fbb5a326600 free space 2041k native frames compiled java code interpreted vv vm code native code 8665 c2 org jruby rubyencoding utf8coder encode ljava lang charsequence 95 bytes 0x00007fbbc2a68e62 0x00007fbbc2a68c80 0x1e2 java threads current thread 0x00007fbb34012800 javathread process reaper daemon thread blocked id 26222 stack 0x00007fbb59200000 0x00007fbb59239000 0x00007fbb28030800 javathread process reaper daemon thread blocked id 23378 stack 0x00007fbb598ad000 0x00007fbb598e6000 0x00007fbb34011000 javathread process reaper daemon thread blocked id 22696 stack 0x00007fbb598e6000 0x00007fbb5991f000 0x00007fbb34012000 javathread process reaper daemon thread in native id 3866 stack 0x00007fbb5983b000 0x00007fbb59874000 0x00007fbb482e9800 javathread output daemon thread blocked id 2736 stack 0x00007fbb59439000 0x00007fbb5963a000 0x00007fbb4831b000 javathread kafka producer network thread producer daemon thread in native id 2735 stack 0x00007fbb5963a000 0x00007fbb5983b000 0x00007fbb482c6800 javathread ruby thread 14 data0 logstash app logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 163 daemon thread blocked id 2682 stack 0x00007fbb59b25000 0x00007fbb59d26000 0x00007fbb482c6000 javathread worker daemon thread in native id 2681 stack 0x00007fbb59d26000 0x00007fbb59f27000 0x00007fbb482c4000 javathread worker daemon thread in vm id 2680 stack 0x00007fbb59f27000 0x00007fbb5a128000 0x00007fbb482c3800 javathread worker daemon thread in java id 2679 stack 0x00007fbb5a128000 0x00007fbb5a329000 0x00007fbb482c0000 javathread worker daemon thread in vm id 2678 stack 0x00007fbb5a329000 0x00007fbb5a52a000 0x00007fbb482bd800 javathread file daemon thread blocked id 2668 stack 0x00007fbb5a52a000 0x00007fbb5a72b000 0x00007fbb482bc000 javathread file daemon thread blocked id 2666 stack 0x00007fbb5a72b000 0x00007fbb5a92c000 0x00007fbb482bb800 javathread file daemon thread blocked id 2665 stack 0x00007fbb5a92c000 0x00007fbb5ab2d000 0x00007fbb48028000 javathread file daemon thread blocked id 2663 stack 0x00007fbb5ab2d000 0x00007fbb5ad2e000 0x00007fbb482b8800 javathread file daemon thread blocked id 2661 stack 0x00007fbb5ad2e000 0x00007fbb5af2f000 0x00007fbb48027800 javathread file daemon thread blocked id 2659 stack 0x00007fbb5af2f000 0x00007fbb5b130000 0x00007fbbd0549800 javathread ruby thread data0 logstash app logstash vendor bundle jruby gems stud 22 lib stud task rb 22 daemon thread blocked id 2556 stack 0x00007fbb5b9fe000 0x00007fbb5bbff000 0x00007fbbd0547800 javathread referencereaper daemon thread blocked id 2555 stack 0x00007fbb5bbff000 0x00007fbb5be00000 0x00007fbbd01df800 javathread service thread daemon thread blocked id 2209 stack 0x00007fbb79f6e000 0x00007fbb7a16f000 0x00007fbbd01ca800 javathread c1 compilerthread3 daemon thread blocked id 2208 stack 0x00007fbba00af000 0x00007fbba01b0000 0x00007fbbd01c8800 javathread c2 compilerthread2 daemon thread blocked id 2207 stack 0x00007fbba01b0000 0x00007fbba02b1000 0x00007fbbd01c6000 javathread c2 compilerthread1 daemon thread blocked id 2206 stack 0x00007fbba02b1000 0x00007fbba03b2000 0x00007fbbd01c4000 javathread c2 compilerthread0 daemon thread blocked id 2205 stack 0x00007fbba03b2000 0x00007fbba04b3000 0x00007fbbd01c2000 javathread signal dispatcher daemon thread blocked id 2204 stack 0x00007fbba04b3000 0x00007fbba06b4000 0x00007fbbd01c0800 javathread surrogate locker thread concurrent gc daemon thread blocked id 2203 stack 0x00007fbba06b4000 0x00007fbba08b5000 0x00007fbbd0188800 javathread finalizer daemon thread blocked id 2197 stack 0x00007fbba08b5000 0x00007fbba0ab6000 0x00007fbbd0186800 javathread reference handler daemon thread blocked id 2196 stack 0x00007fbba0ab6000 0x00007fbba0cb7000 0x00007fbbd0009800 javathread logstash runner thread blocked id 2181 stack 0x00007fbbd57ce000 0x00007fbbd59cf000 other threads 0x00007fbbd0181800 vmthread stack 0x00007fbba0cb7000 0x00007fbba0db8000 id 2195 0x00007fbbd01e2800 watcherthread stack 0x00007fbb79e6d000 0x00007fbb79f6e000 id 2210 vm state not at safepoint normal execution vm mutex monitor currently owned by thread none heap par new generation total 19008k used 7362k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k 31 used 0x00000000e0c00000 0x00000000e1146bf8 0x00000000e1c80000 from space 2112k 92 used 0x00000000e1c80000 0x00000000e1e69e70 0x00000000e1e90000 to space 2112k used 0x00000000e1e90000 0x00000000e1e90000 0x00000000e20a0000 concurrent mark sweep generation total 90716k used 55063k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k card table byte map 0x00007fbbd429c000 0x00007fbbd4397000 byte map base 0x00007fbbd3b96000 marking bits cmsbitmap 0x00007fbbd0093158 bits 0x00007fbbc041d000 0x00007fbbc0952800 mod union table cmsbitmap 0x00007fbbd0093218 bits 0x00007fbbd4085000 0x00007fbbd4099d60 polling page 0x00007fbbd6bbc000 codecache size 245760kb used 32204kb max used 32226kb free 213555kb bounds 0x00007fbbc1000000 0x00007fbbc3020000 0x00007fbbd0000000 total blobs 8312 nmethods 7697 adapters 527 compilation enabled compilation events 10 events event 15336 569 thread 0x00007fbbd01c4000 10754 java util collections unmodifiablecollection hasnext 10 bytes event 15336 572 thread 0x00007fbbd01c4000 nmethod 10754 0x00007fbbc29c2fd0 code 0x00007fbbc29c3120 0x00007fbbc29c3198 event 15527 028 thread 0x00007fbbd01c4000 10755 rubyjit filewatch tail read file a2e2f984a72f7c7f1e45b9feefd41ae9ee4979e41442407170 block ruby file call 13 bytes event 15528 080 thread 0x00007fbbd01c4000 nmethod 10755 0x00007fbbc2fe8190 code 0x00007fbbc2fe8a60 0x00007fbbc2fee688 event 15742 377 thread 0x00007fbbd01c4000 10756 org jruby rubybasicobject id 12 bytes event 15742 378 thread 0x00007fbbd01c8800 10757 org jruby runtime ivars variabletablemanager getobjectid 85 bytes event 15742 499 thread 0x00007fbbd01c4000 nmethod 10756 0x00007fbbc1f43e90 code 0x00007fbbc1f440a0 0x00007fbbc1f44d88 event 15742 508 thread 0x00007fbbd01c8800 nmethod 10757 0x00007fbbc2ce48d0 code 0x00007fbbc2ce4ac0 0x00007fbbc2ce5668 event 16536 604 thread 0x00007fbbd01c6000 10758 org apache kafka common protocol types struct 24 bytes event 16536 617 thread 0x00007fbbd01c6000 nmethod 10758 0x00007fbbc1f43ad0 code 0x00007fbbc1f43c20 0x00007fbbc1f43d78 gc heap history 10 events event 16749 978 gc heap before heap before gc invocations 26831 full 163 par new generation total 19008k used 18903k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k 100 used 0x00000000e0c00000 0x00000000e1c80000 0x00000000e1c80000 from space 2112k 95 used 0x00000000e1e90000 0x00000000e2085f78 0x00000000e20a0000 to space 2112k used 0x00000000e1c80000 0x00000000e1c80000 0x00000000e1e90000 concurrent mark sweep generation total 90716k used 54527k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k event 16749 999 gc heap after heap after gc invocations 26832 full 163 par new generation total 19008k used 1379k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k used 0x00000000e0c00000 0x00000000e0c00000 0x00000000e1c80000 from space 2112k 65 used 0x00000000e1c80000 0x00000000e1dd8c98 0x00000000e1e90000 to space 2112k used 0x00000000e1e90000 0x00000000e1e90000 0x00000000e20a0000 concurrent mark sweep generation total 90716k used 54662k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k event 16750 567 gc heap before heap before gc invocations 26832 full 163 par new generation total 19008k used 18275k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k 100 used 0x00000000e0c00000 0x00000000e1c80000 0x00000000e1c80000 from space 2112k 65 used 0x00000000e1c80000 0x00000000e1dd8c98 0x00000000e1e90000 to space 2112k used 0x00000000e1e90000 0x00000000e1e90000 0x00000000e20a0000 concurrent mark sweep generation total 90716k used 54662k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k event 16750 584 gc heap after heap after gc invocations 26833 full 163 par new generation total 19008k used 1865k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k used 0x00000000e0c00000 0x00000000e0c00000 0x00000000e1c80000 from space 2112k 88 used 0x00000000e1e90000 0x00000000e20625c0 0x00000000e20a0000 to space 2112k used 0x00000000e1c80000 0x00000000e1c80000 0x00000000e1e90000 concurrent mark sweep generation total 90716k used 54757k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k event 16751 189 gc heap before heap before gc invocations 26833 full 163 par new generation total 19008k used 18761k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k 100 used 0x00000000e0c00000 0x00000000e1c80000 0x00000000e1c80000 from space 2112k 88 used 0x00000000e1e90000 0x00000000e20625c0 0x00000000e20a0000 to space 2112k used 0x00000000e1c80000 0x00000000e1c80000 0x00000000e1e90000 concurrent mark sweep generation total 90716k used 54757k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k event 16751 203 gc heap after heap after gc invocations 26834 full 163 par new generation total 19008k used 1598k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k used 0x00000000e0c00000 0x00000000e0c00000 0x00000000e1c80000 from space 2112k 75 used 0x00000000e1c80000 0x00000000e1e0f890 0x00000000e1e90000 to space 2112k used 0x00000000e1e90000 0x00000000e1e90000 0x00000000e20a0000 concurrent mark sweep generation total 90716k used 54835k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k event 16751 765 gc heap before heap before gc invocations 26834 full 163 par new generation total 19008k used 18494k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k 100 used 0x00000000e0c00000 0x00000000e1c80000 0x00000000e1c80000 from space 2112k 75 used 0x00000000e1c80000 0x00000000e1e0f890 0x00000000e1e90000 to space 2112k used 0x00000000e1e90000 0x00000000e1e90000 0x00000000e20a0000 concurrent mark sweep generation total 90716k used 54835k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k event 16751 785 gc heap after heap after gc invocations 26835 full 163 par new generation total 19008k used 1908k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k used 0x00000000e0c00000 0x00000000e0c00000 0x00000000e1c80000 from space 2112k 90 used 0x00000000e1e90000 0x00000000e206d348 0x00000000e20a0000 to space 2112k used 0x00000000e1c80000 0x00000000e1c80000 0x00000000e1e90000 concurrent mark sweep generation total 90716k used 54950k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k event 16752 439 gc heap before heap before gc invocations 26835 full 163 par new generation total 19008k used 18804k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k 100 used 0x00000000e0c00000 0x00000000e1c80000 0x00000000e1c80000 from space 2112k 90 used 0x00000000e1e90000 0x00000000e206d348 0x00000000e20a0000 to space 2112k used 0x00000000e1c80000 0x00000000e1c80000 0x00000000e1e90000 concurrent mark sweep generation total 90716k used 54950k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k event 16752 464 gc heap after heap after gc invocations 26836 full 163 par new generation total 19008k used 1959k 0x00000000e0c00000 0x00000000e20a0000 0x00000000eb2a0000 eden space 16896k used 0x00000000e0c00000 0x00000000e0c00000 0x00000000e1c80000 from space 2112k 92 used 0x00000000e1c80000 0x00000000e1e69e70 0x00000000e1e90000 to space 2112k used 0x00000000e1e90000 0x00000000e1e90000 0x00000000e20a0000 concurrent mark sweep generation total 90716k used 55063k 0x00000000eb2a0000 0x00000000f0b37000 0x0000000100000000 metaspace used 46795k capacity 49506k committed 49876k reserved 1091584k class space used 7710k capacity 8335k committed 8436k reserved 1048576k deoptimization events 10 events event 2945 705 thread 0x00007fbb20009800 uncommon trap reason unstable if action reinterpret pc 0x00007fbbc1e8f3f4 method java util concurrent threadpoolexecutor runworker ljava util concurrent threadpoolexecutor worker 31 event 3665 835 thread 0x00007fbb48027800 uncommon trap reason bimorphic action maybe recompile pc 0x00007fbbc2d6ecf8 method org jruby ast whilenode interpret lorg jruby ruby lorg jruby runtime threadcontext lorg jruby runtime builtin irubyobject lorg jruby runtime block lorg jruby runtime buil event 4515 198 thread 0x00007fbb482c3800 uncommon trap reason unstable if action reinterpret pc 0x00007fbbc29ee04c method org jruby javasupport util objectproxycache segment getorcreate ljava lang object iljava lang object ljava lang object 42 event 4564 015 thread 0x00007fbb482c3800 uncommon trap reason unstable if action reinterpret pc 0x00007fbbc2a12634 method org jruby javasupport util objectproxycache segment getorcreate ljava lang object iljava lang object ljava lang object 42 event 4609 596 thread 0x00007fbb48027800 uncommon trap reason bimorphic action maybe recompile pc 0x00007fbbc2d6ecf8 method org jruby ast whilenode interpret lorg jruby ruby lorg jruby runtime threadcontext lorg jruby runtime builtin irubyobject lorg jruby runtime block lorg jruby runtime buil event 5070 567 thread 0x00007fbb482c4000 uncommon trap reason unstable if action reinterpret pc 0x00007fbbc2c884d8 method org jruby javasupport util objectproxycache segment put ljava lang object iljava lang object 79 event 5555 585 thread 0x00007fbb48027800 uncommon trap reason bimorphic action maybe recompile pc 0x00007fbbc2d6ecf8 method org jruby ast whilenode interpret lorg jruby ruby lorg jruby runtime threadcontext lorg jruby runtime builtin irubyobject lorg jruby runtime block lorg jruby runtime buil event 6381 059 thread 0x00007fbb482c0000 uncommon trap reason unstable if action reinterpret pc 0x00007fbbc1ccd304 method java util weakhashmap put ljava lang object ljava lang object ljava lang object 47 event 6618 039 thread 0x00007fbb482e9800 uncommon trap reason unstable if action reinterpret pc 0x00007fbbc2c8b894 method org jruby javasupport util objectproxycache segment put ljava lang object iljava lang object 79 event 14842 187 thread 0x00007fbb482c6000 uncommon trap reason unstable if action reinterpret pc 0x00007fbbc280ebd8 method java util concurrent synchronousqueue transferstack transfer ljava lang object zj ljava lang object 189 internal exceptions 10 events event 33 067 thread 0x00007fbbd0549800 exception 0x00000000e1509bb0 thrown at hudson workspace build linux amd64 jdk8u51 3951 hotspot src share vm prims jni cpp line 735 event 33 076 thread 0x00007fbbd0549800 exception 0x00000000e150a490 thrown at hudson workspace build linux amd64 jdk8u51 3951 hotspot src share vm prims jni cpp line 735 event 33 087 thread 0x00007fbbd0549800 exception 0x00000000e150ad70 thrown at hudson workspace build linux amd64 jdk8u51 3951 hotspot src share vm prims jni cpp line 735 event 33 099 thread 0x00007fbbd0549800 exception 0x00000000e150b650 thrown at hudson workspace build linux amd64 jdk8u51 3951 hotspot src share vm prims jni cpp line 735 event 33 109 thread 0x00007fbbd0549800 exception 0x00000000e150bf30 thrown at hudson workspace build linux amd64 jdk8u51 3951 hotspot src share vm prims jni cpp line 735 event 458 378 thread 0x00007fbb482c4000 implicit null exception at 0x00007fbbc22b7eff to 0x00007fbbc22b86ed event 1535 322 thread 0x00007fbb4831b000 implicit null exception at 0x00007fbbc278d03b to 0x00007fbbc2796c81 event 2050 823 thread 0x00007fbb48027800 implicit null exception at 0x00007fbbc15edbde to 0x00007fbbc15ee5bd event 2103 013 thread 0x00007fbb4c00d800 implicit null exception at 0x00007fbbc19f35c9 to 0x00007fbbc19f3e69 event 16752 620 thread 0x00007fbb482c3800 implicit null exception at 0x00007fbbc2a68e62 to 0x0000000000000000 events 10 events event 16749 977 executing vm operation gencollectforallocation event 16749 999 executing vm operation gencollectforallocation done event 16750 565 executing vm operation gencollectforallocation event 16750 584 executing vm operation gencollectforallocation done event 16751 188 executing vm operation gencollectforallocation event 16751 203 executing vm operation gencollectforallocation done event 16751 764 executing vm operation gencollectforallocation event 16751 785 executing vm operation gencollectforallocation done event 16752 438 executing vm operation gencollectforallocation event 16752 464 executing vm operation gencollectforallocation done dynamic libraries 00400000 00401000 xp 00000000 fd 00 794901 usr local java jdk bin java 00600000 00601000 rw 00000000 fd 00 794901 usr local java jdk bin java 011f1000 01212000 rw 00000000 00 00 heap e0c00000 e20a0000 rw 00000000 00 00 e20a0000 eb2a0000 00000000 00 00 eb2a0000 f0b37000 rw 00000000 00 00 f0b37000 100000000 00000000 00 00 100000000 10083d000 rw 00000000 00 00 10083d000 140000000 00000000 00 00 3236200000 3236220000 xp 00000000 fd 00 524701 lib64 ld 12 so 323641f000 3236420000 0001f000 fd 00 524701 lib64 ld 12 so 3236420000 3236421000 rw 00020000 fd 00 524701 lib64 ld 12 so 3236421000 3236422000 rw 00000000 00 00 3236600000 3236602000 xp 00000000 fd 00 524704 lib64 libdl 12 so 3236602000 3236802000 00002000 fd 00 524704 lib64 libdl 12 so 3236802000 3236803000 00002000 fd 00 524704 lib64 libdl 12 so 3236803000 3236804000 rw 00003000 fd 00 524704 lib64 libdl 12 so 3236a00000 3236b8b000 xp 00000000 fd 00 524702 lib64 libc 12 so 3236b8b000 3236d8a000 0018b000 fd 00 524702 lib64 libc 12 so 3236d8a000 3236d8e000 0018a000 fd 00 524702 lib64 libc 12 so 3236d8e000 3236d8f000 rw 0018e000 fd 00 524702 lib64 libc 12 so 3236d8f000 3236d94000 rw 00000000 00 00 3236e00000 3236e17000 xp 00000000 fd 00 524711 lib64 libpthread 12 so 3236e17000 3237017000 00017000 fd 00 524711 lib64 libpthread 12 so 3237017000 3237018000 00017000 fd 00 524711 lib64 libpthread 12 so 3237018000 3237019000 rw 00018000 fd 00 524711 lib64 libpthread 12 so 3237019000 323701d000 rw 00000000 00 00 3237200000 3237207000 xp 00000000 fd 00 524712 lib64 librt 12 so 3237207000 3237406000 00007000 fd 00 524712 lib64 librt 12 so 3237406000 3237407000 00006000 fd 00 524712 lib64 librt 12 so 3237407000 3237408000 rw 00007000 fd 00 524712 lib64 librt 12 so 3237a00000 3237a83000 xp 00000000 fd 00 524710 lib64 libm 12 so 3237a83000 3237c82000 00083000 fd 00 524710 lib64 libm 12 so 3237c82000 3237c83000 00082000 fd 00 524710 lib64 libm 12 so 3237c83000 3237c84000 rw 00083000 fd 00 524710 lib64 libm 12 so 3238600000 3238616000 xp 00000000 fd 00 524731 lib64 libresolv 12 so 3238616000 3238816000 00016000 fd 00 524731 lib64 libresolv 12 so 3238816000 3238817000 00016000 fd 00 524731 lib64 libresolv 12 so 3238817000 3238818000 rw 00017000 fd 00 524731 lib64 libresolv 12 so 3238818000 323881a000 rw 00000000 00 00 3239200000 3239207000 xp 00000000 fd 00 524706 lib64 libcrypt 12 so 3239207000 3239407000 00007000 fd 00 524706 lib64 libcrypt 12 so 3239407000 3239408000 00007000 fd 00 524706 lib64 libcrypt 12 so 3239408000 3239409000 rw 00008000 fd 00 524706 lib64 libcrypt 12 so 3239409000 3239437000 rw 00000000 00 00 3239600000 3239671000 xp 00000000 fd 00 524705 lib64 libfreebl3 so 3239671000 3239870000 00071000 fd 00 524705 lib64 libfreebl3 so 3239870000 3239872000 00070000 fd 00 524705 lib64 libfreebl3 so 3239872000 3239873000 rw 00072000 fd 00 524705 lib64 libfreebl3 so 3239873000 3239877000 rw 00000000 00 00 7fbb00000000 7fbb00021000 rw 00000000 00 00 7fbb00021000 7fbb04000000 00000000 00 00 7fbb08000000 7fbb08041000 rw 00000000 00 00 7fbb08041000 7fbb0c000000 00000000 00 00 7fbb0c000000 7fbb0c0dc000 rw 00000000 00 00 7fbb0c0dc000 7fbb10000000 00000000 00 00 7fbb10000000 7fbb10021000 rw 00000000 00 00 7fbb10021000 7fbb14000000 00000000 00 00 7fbb14000000 7fbb14021000 rw 00000000 00 00 7fbb14021000 7fbb18000000 00000000 00 00 7fbb18000000 7fbb18035000 rw 00000000 00 00 7fbb18035000 7fbb1c000000 00000000 00 00 7fbb1c000000 7fbb1c021000 rw 00000000 00 00 7fbb1c021000 7fbb20000000 00000000 00 00 7fbb20000000 7fbb20054000 rw 00000000 00 00 7fbb20054000 7fbb24000000 00000000 00 00 7fbb24000000 7fbb24021000 rw 00000000 00 00 7fbb24021000 7fbb28000000 00000000 00 00 7fbb28000000 7fbb28040000 rw 00000000 00 00 7fbb28040000 7fbb2c000000 00000000 00 00 7fbb2c000000 7fbb2c04b000 rw 00000000 00 00 7fbb2c04b000 7fbb30000000 00000000 00 00 7fbb30000000 7fbb30021000 rw 00000000 00 00 7fbb30021000 7fbb34000000 00000000 00 00 7fbb34000000 7fbb3404b000 rw 00000000 00 00 7fbb3404b000 7fbb38000000 00000000 00 00 7fbb38000000 7fbb38021000 rw 00000000 00 00 7fbb38021000 7fbb3c000000 00000000 00 00 7fbb3c000000 7fbb3c021000 rw 00000000 00 00 7fbb3c021000 7fbb40000000 00000000 00 00 7fbb40000000 7fbb40021000 rw 00000000 00 00 7fbb40021000 7fbb44000000 00000000 00 00 7fbb44000000 7fbb44021000 rw 00000000 00 00 7fbb44021000 7fbb48000000 00000000 00 00 7fbb48000000 7fbb4831f000 rw 00000000 00 00 7fbb4831f000 7fbb4c000000 00000000 00 00 7fbb4c000000 7fbb4c021000 rw 00000000 00 00 7fbb4c021000 7fbb50000000 00000000 00 00 7fbb50000000 7fbb50021000 rw 00000000 00 00 7fbb50021000 7fbb54000000 00000000 00 00 7fbb54000000 7fbb540f3000 rw 00000000 00 00 7fbb540f3000 7fbb58000000 00000000 00 00 7fbb589bc000 7fbb589f9000 xp 00000000 fd 02 5901673 data0 logstash app logstash snappy unknown 8d9416e7 bfae 4a38 b49a 1687be44a0bf libsnappyjava so 7fbb589f9000 7fbb58bf9000 0003d000 fd 02 5901673 data0 logstash app logstash snappy unknown 8d9416e7 bfae 4a38 b49a 1687be44a0bf libsnappyjava so 7fbb58bf9000 7fbb58bfc000 rw 0003d000 fd 02 5901673 data0 logstash app logstash snappy unknown 8d9416e7 bfae 4a38 b49a 1687be44a0bf libsnappyjava so 7fbb58bfc000 7fbb58c0e000 rw 00000000 00 00 7fbb58c61000 7fbb58ce1000 rw 00000000 00 00 7fbb58ce1000 7fbb58e61000 00000000 00 00 7fbb58e61000 7fbb59061000 rw 00000000 00 00 7fbb59200000 7fbb59203000 00000000 00 00 7fbb59203000 7fbb59439000 rw 00000000 00 00 7fbb59439000 7fbb5943c000 00000000 00 00 7fbb5943c000 7fbb5963a000 rw 00000000 00 00 7fbb5963a000 7fbb5963d000 00000000 00 00 7fbb5963d000 7fbb5983b000 rw 00000000 00 00 7fbb5983b000 7fbb5983e000 00000000 00 00 7fbb5983e000 7fbb59874000 rw 00000000 00 00 7fbb59874000 7fbb59877000 00000000 00 00 7fbb59877000 7fbb598ad000 rw 00000000 00 00 7fbb598ad000 7fbb598b0000 00000000 00 00 7fbb598b0000 7fbb598e6000 rw 00000000 00 00 7fbb598e6000 7fbb598e9000 00000000 00 00 7fbb598e9000 7fbb5991f000 rw 00000000 00 00 7fbb5991f000 7fbb59924000 xp 00000000 fd 00 524316 lib64 libnss dns 12 so 7fbb59924000 7fbb59b23000 00005000 fd 00 524316 lib64 libnss dns 12 so 7fbb59b23000 7fbb59b24000 00004000 fd 00 524316 lib64 libnss dns 12 so 7fbb59b24000 7fbb59b25000 rw 00005000 fd 00 524316 lib64 libnss dns 12 so 7fbb59b25000 7fbb59b28000 00000000 00 00 7fbb59b28000 7fbb59d26000 rw 00000000 00 00 7fbb59d26000 7fbb59d29000 00000000 00 00 7fbb59d29000 7fbb59f27000 rw 00000000 00 00 7fbb59f27000 7fbb59f2a000 00000000 00 00 7fbb59f2a000 7fbb5a128000 rw 00000000 00 00 7fbb5a128000 7fbb5a12b000 00000000 00 00 7fbb5a12b000 7fbb5a329000 rw 00000000 00 00 7fbb5a329000 7fbb5a32c000 00000000 00 00 7fbb5a32c000 7fbb5a52a000 rw 00000000 00 00 7fbb5a52a000 7fbb5a52d000 00000000 00 00 7fbb5a52d000 7fbb5a72b000 rw 00000000 00 00 7fbb5a72b000 7fbb5a72e000 00000000 00 00 7fbb5a72e000 7fbb5a92c000 rw 00000000 00 00 7fbb5a92c000 7fbb5a92f000 00000000 00 00 7fbb5a92f000 7fbb5ab2d000 rw 00000000 00 00 7fbb5ab2d000 7fbb5ab30000 00000000 00 00 7fbb5ab30000 7fbb5ad2e000 rw 00000000 00 00 7fbb5ad2e000 7fbb5ad31000 00000000 00 00 7fbb5ad31000 7fbb5af2f000 rw 00000000 00 00 7fbb5af2f000 7fbb5af32000 00000000 00 00 7fbb5af32000 7fbb5b330000 rw 00000000 00 00 7fbb5b330000 7fbb5b338000 xp 00000000 fd 00 795053 usr local java jdk jre lib amd64 libmanagement so 7fbb5b338000 7fbb5b538000 00008000 fd 00 795053 usr local java jdk jre lib amd64 libmanagement so 7fbb5b538000 7fbb5b539000 rw 00008000 fd 00 795053 usr local java jdk jre lib amd64 libmanagement so 7fbb5b539000 7fbb5b739000 rw 00000000 00 00 7fbb5b739000 7fbb5b7ab000 0065a000 fd 02 5900403 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib org scala lang scala library 10 scala library 10 jar 7fbb5b7ab000 7fbb5b7ad000 00027000 fd 02 5900448 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib net jpountz lz4 lz4 lz4 jar 7fbb5b7ad000 7fbb5b7b6000 0006f000 fd 02 5900460 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib log4j log4j 17 log4j 17 jar 7fbb5b7b6000 7fbb5b7fe000 00387000 fd 02 5900383 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib org apache kafka kafka 10 kafka 10 jar 7fbb5b7fe000 7fbb5b9fe000 rw 00000000 00 00 7fbb5b9fe000 7fbb5ba01000 00000000 00 00 7fbb5ba01000 7fbb5bbff000 rw 00000000 00 00 7fbb5bbff000 7fbb5bc02000 00000000 00 00 7fbb5bc02000 7fbb5c000000 rw 00000000 00 00 7fbb5c000000 7fbb5c021000 rw 00000000 00 00 7fbb5c021000 7fbb60000000 00000000 00 00 7fbb60000000 7fbb60021000 rw 00000000 00 00 7fbb60021000 7fbb64000000 00000000 00 00 7fbb64000000 7fbb66010000 rw 00000000 00 00 7fbb66010000 7fbb68000000 00000000 00 00 7fbb68000000 7fbb695da000 rw 00000000 00 00 7fbb695da000 7fbb6c000000 00000000 00 00 7fbb6c000000 7fbb6d964000 rw 00000000 00 00 7fbb6d964000 7fbb70000000 00000000 00 00 7fbb70000000 7fbb72159000 rw 00000000 00 00 7fbb72159000 7fbb74000000 00000000 00 00 7fbb74000000 7fbb74021000 rw 00000000 00 00 7fbb74021000 7fbb78000000 00000000 00 00 7fbb78017000 7fbb7801a000 00012000 fd 02 5900436 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib com yammer metrics metrics core metrics core jar 7fbb7801a000 7fbb7801c000 0008f000 fd 02 5900398 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib org xerial snappy snappy java snappy java jar 7fbb7801c000 7fbb7801e000 00001000 fd 02 5900412 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib org slf4j slf4j log4j12 10 slf4j log4j12 10 jar 7fbb7801e000 7fbb78025000 00049000 fd 02 5900387 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib org apache kafka kafka clients kafka clients jar 7fbb78025000 7fbb7803d000 00110000 fd 02 5900424 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib io netty netty final netty final jar 7fbb7803d000 7fbb7823d000 rw 00000000 00 00 7fbb7823d000 7fbb7843d000 rw 00000000 00 00 7fbb7843d000 7fbb7863d000 rw 00000000 00 00 7fbb7863d000 7fbb78835000 rw 00000000 00 00 7fbb78835000 7fbb78840000 00000000 00 00 7fbb78840000 7fbb78c3e000 rw 00000000 00 00 7fbb78c3e000 7fbb78c50000 xp 00000000 fd 02 5899554 data0 logstash app logstash vendor jruby lib jni x86 64 linux libjffi so 7fbb78c50000 7fbb78e4f000 00012000 fd 02 5899554 data0 logstash app logstash vendor jruby lib jni x86 64 linux libjffi so 7fbb78e4f000 7fbb78e50000 rw 00011000 fd 02 5899554 data0 logstash app logstash vendor jruby lib jni x86 64 linux libjffi so 7fbb78e50000 7fbb79050000 rw 00000000 00 00 7fbb79050000 7fbb79250000 rw 00000000 00 00 7fbb79250000 7fbb79450000 rw 00000000 00 00 7fbb79456000 7fbb79494000 0025e000 fd 02 6293256 data0 logstash app logstash vendor bundle jruby gems jruby openssl 12 java lib org bouncycastle bcprov jdk15on 50 bcprov jdk15on 50 jar 7fbb79494000 7fbb794a5000 xp 00000000 fd 00 795091 usr local java jdk jre lib amd64 libnio so 7fbb794a5000 7fbb796a4000 00011000 fd 00 795091 usr local java jdk jre lib amd64 libnio so 7fbb796a4000 7fbb796a5000 rw 00010000 fd 00 795091 usr local java jdk jre lib amd64 libnio so 7fbb796a5000 7fbb79766000 rw 00000000 00 00 7fbb79766000 7fbb7977c000 xp 00000000 fd 00 795055 usr local java jdk jre lib amd64 libnet so 7fbb7977c000 7fbb7997c000 00016000 fd 00 795055 usr local java jdk jre lib amd64 libnet so 7fbb7997c000 7fbb7997d000 rw 00016000 fd 00 795055 usr local java jdk jre lib amd64 libnet so 7fbb7997d000 7fbb79b7d000 rw 00000000 00 00 7fbb79b7d000 7fbb79d7d000 rw 00000000 00 00 7fbb79d7d000 7fbb79e6d000 00c2c000 fd 02 5899533 data0 logstash app logstash vendor jruby lib jruby jar 7fbb79e6d000 7fbb79e6e000 00000000 00 00 7fbb79e6e000 7fbb79f6e000 rw 00000000 00 00 7fbb79f6e000 7fbb79f71000 00000000 00 00 7fbb79f71000 7fbb7a16f000 rw 00000000 00 00 7fbb7a16f000 7fbb80000000 00000000 fd 00 657479 usr lib locale locale archive 7fbb80000000 7fbb80021000 rw 00000000 00 00 7fbb80021000 7fbb84000000 00000000 00 00 7fbb84000000 7fbb84021000 rw 00000000 00 00 7fbb84021000 7fbb88000000 00000000 00 00 7fbb88000000 7fbb8826a000 rw 00000000 00 00 7fbb8826a000 7fbb8c000000 00000000 00 00 7fbb8c000000 7fbb8c021000 rw 00000000 00 00 7fbb8c021000 7fbb90000000 00000000 00 00 7fbb90000000 7fbb90021000 rw 00000000 00 00 7fbb90021000 7fbb94000000 00000000 00 00 7fbb94000000 7fbb94021000 rw 00000000 00 00 7fbb94021000 7fbb98000000 00000000 00 00 7fbb98000000 7fbb98021000 rw 00000000 00 00 7fbb98021000 7fbb9c000000 00000000 00 00 7fbb9c000000 7fbb9c038000 rw 00000000 00 00 7fbb9c038000 7fbba0000000 00000000 00 00 7fbba000c000 7fbba000e000 0000e000 fd 02 5900430 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib com 101tec zkclient zkclient jar 7fbba000e000 7fbba0010000 00014000 fd 02 5900441 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib jline jline 94 jline 94 jar 7fbba0010000 7fbba0013000 0001b000 fd 02 5900418 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib junit junit junit jar 7fbba0013000 7fbba001f000 000b6000 fd 02 5900392 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib org apache zookeeper zookeeper zookeeper jar 7fbba001f000 7fbba0036000 00173000 fd 02 6030581 data0 logstash app logstash vendor bundle jruby gems jrjackson lib jrjackson jars jrjackson 16 jar 7fbba0036000 7fbba00af000 010e7000 fd 00 795324 usr local java jdk lib tools jar 7fbba00af000 7fbba00b2000 00000000 00 00 7fbba00b2000 7fbba01b0000 rw 00000000 00 00 7fbba01b0000 7fbba01b3000 00000000 00 00 7fbba01b3000 7fbba02b1000 rw 00000000 00 00 7fbba02b1000 7fbba02b4000 00000000 00 00 7fbba02b4000 7fbba03b2000 rw 00000000 00 00 7fbba03b2000 7fbba03b5000 00000000 00 00 7fbba03b5000 7fbba04b3000 rw 00000000 00 00 7fbba04b3000 7fbba04b6000 00000000 00 00 7fbba04b6000 7fbba06b4000 rw 00000000 00 00 7fbba06b4000 7fbba06b7000 00000000 00 00 7fbba06b7000 7fbba08b5000 rw 00000000 00 00 7fbba08b5000 7fbba08b8000 00000000 00 00 7fbba08b8000 7fbba0ab6000 rw 00000000 00 00 7fbba0ab6000 7fbba0ab9000 00000000 00 00 7fbba0ab9000 7fbba0cb7000 rw 00000000 00 00 7fbba0cb7000 7fbba0cb8000 00000000 00 00 7fbba0cb8000 7fbba0e07000 rw 00000000 00 00 7fbba0e07000 7fbba0fdf000 03d0c000 fd 00 795204 usr local java jdk jre lib rt jar 7fbba0fdf000 7fbba18d8000 rw 00000000 00 00 7fbba18d8000 7fbba18f9000 rw 00000000 00 00 7fbba18f9000 7fbba18fa000 00000000 00 00 7fbba18fa000 7fbba4000000 rw 00000000 00 00 7fbba4000000 7fbba402f000 rw 00000000 00 00 7fbba402f000 7fbba8000000 00000000 00 00 7fbba8000000 7fbba803b000 rw 00000000 00 00 7fbba803b000 7fbbac000000 00000000 00 00 7fbbac000000 7fbbac037000 rw 00000000 00 00 7fbbac037000 7fbbb0000000 00000000 00 00 7fbbb0000000 7fbbb0033000 rw 00000000 00 00 7fbbb0033000 7fbbb4000000 00000000 00 00 7fbbb4000000 7fbbb4037000 rw 00000000 00 00 7fbbb4037000 7fbbb8000000 00000000 00 00 7fbbb8000000 7fbbb8033000 rw 00000000 00 00 7fbbb8033000 7fbbbc000000 00000000 00 00 7fbbbc000000 7fbbbc029000 rw 00000000 00 00 7fbbbc029000 7fbbc0000000 00000000 00 00 7fbbc0002000 7fbbc0006000 0001a000 fd 02 6160417 data0 logstash app logstash vendor bundle jruby gems thread safe java lib thread safe jruby cache backend jar 7fbbc0006000 7fbbc0019000 00344000 fd 00 795254 usr local java jdk jre lib resources jar 7fbbc0019000 7fbbc021b000 rw 00000000 00 00 7fbbc021b000 7fbbc021c000 00000000 00 00 7fbbc021c000 7fbbc031c000 rw 00000000 00 00 7fbbc031c000 7fbbc031d000 00000000 00 00 7fbbc031d000 7fbbc0980000 rw 00000000 00 00 7fbbc0980000 7fbbc09fa000 00000000 00 00 7fbbc09fa000 7fbbc1000000 rw 00000000 00 00 7fbbc1000000 7fbbc3020000 rwxp 00000000 00 00 7fbbc3020000 7fbbd0000000 00000000 00 00 7fbbd0000000 7fbbd0b24000 rw 00000000 00 00 7fbbd0b24000 7fbbd4000000 00000000 00 00 7fbbd4001000 7fbbd4002000 00000000 fd 02 6292122 data0 logstash app logstash vendor bundle jruby gems filewatch lib jrubyfileextension jar 7fbbd4002000 7fbbd4017000 000e5000 fd 02 6293283 data0 logstash app logstash vendor bundle jruby gems jruby openssl 12 java lib jopenssl jar 7fbbd4017000 7fbbd4027000 00083000 fd 02 6293259 data0 logstash app logstash vendor bundle jruby gems jruby openssl 12 java lib org bouncycastle bcpkix jdk15on 50 bcpkix jdk15on 50 jar 7fbbd4027000 7fbbd402e000 00000000 fd 00 657737 usr lib64 gconv gconv modules cache 7fbbd402e000 7fbbd4034000 00022000 fd 00 795322 usr local java jdk lib dt jar 7fbbd4034000 7fbbd4050000 00393000 fd 00 795251 usr local java jdk jre lib ext cldrdata jar 7fbbd4050000 7fbbd405a000 00116000 fd 00 795245 usr local java jdk jre lib ext localedata jar 7fbbd405a000 7fbbd42a7000 rw 00000000 00 00 7fbbd42a7000 7fbbd42ef000 00000000 00 00 7fbbd42ef000 7fbbd431c000 rw 00000000 00 00 7fbbd431c000 7fbbd4396000 00000000 00 00 7fbbd4396000 7fbbd4397000 rw 00000000 00 00 7fbbd4397000 7fbbd4398000 00000000 00 00 7fbbd4398000 7fbbd4498000 rw 00000000 00 00 7fbbd4498000 7fbbd4499000 00000000 00 00 7fbbd4499000 7fbbd4599000 rw 00000000 00 00 7fbbd4599000 7fbbd459a000 00000000 00 00 7fbbd459a000 7fbbd469a000 rw 00000000 00 00 7fbbd469a000 7fbbd469b000 00000000 00 00 7fbbd469b000 7fbbd479b000 rw 00000000 00 00 7fbbd479b000 7fbbd479c000 00000000 00 00 7fbbd479c000 7fbbd489c000 rw 00000000 00 00 7fbbd489c000 7fbbd489d000 00000000 00 00 7fbbd489d000 7fbbd499d000 rw 00000000 00 00 7fbbd499d000 7fbbd499e000 00000000 00 00 7fbbd499e000 7fbbd4a9e000 rw 00000000 00 00 7fbbd4a9e000 7fbbd4a9f000 00000000 00 00 7fbbd4a9f000 7fbbd4c20000 rw 00000000 00 00 7fbbd4c20000 7fbbd4f5f000 00000000 00 00 7fbbd4f5f000 7fbbd4f79000 xp 00000000 fd 00 795084 usr local java jdk jre lib amd64 libzip so 7fbbd4f79000 7fbbd5179000 0001a000 fd 00 795084 usr local java jdk jre lib amd64 libzip so 7fbbd5179000 7fbbd517a000 rw 0001a000 fd 00 795084 usr local java jdk jre lib amd64 libzip so 7fbbd517a000 7fbbd5186000 xp 00000000 fd 00 524318 lib64 libnss files 12 so 7fbbd5186000 7fbbd5386000 0000c000 fd 00 524318 lib64 libnss files 12 so 7fbbd5386000 7fbbd5387000 0000c000 fd 00 524318 lib64 libnss files 12 so 7fbbd5387000 7fbbd5388000 rw 0000d000 fd 00 524318 lib64 libnss files 12 so 7fbbd5388000 7fbbd5389000 00007000 fd 02 5900408 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib org slf4j slf4j api 10 slf4j api 10 jar 7fbbd5389000 7fbbd538b000 0000b000 fd 02 5900454 data0 logstash app logstash vendor bundle jruby gems jruby kafka java lib net sf jopt simple jopt simple jopt simple jar 7fbbd538b000 7fbbd538d000 xp 00000000 00 00 7fbbd538d000 7fbbd538f000 0001a000 fd 00 795240 usr local java jdk jre lib jce jar 7fbbd538f000 7fbbd5393000 00095000 fd 00 795106 usr local java jdk jre lib jsse jar 7fbbd5393000 7fbbd53bd000 xp 00000000 fd 00 795061 usr local java jdk jre lib amd64 libjava so 7fbbd53bd000 7fbbd55bd000 0002a000 fd 00 795061 usr local java jdk jre lib amd64 libjava so 7fbbd55bd000 7fbbd55bf000 rw 0002a000 fd 00 795061 usr local java jdk jre lib amd64 libjava so 7fbbd55bf000 7fbbd55cc000 xp 00000000 fd 00 795086 usr local java jdk jre lib amd64 libverify so 7fbbd55cc000 7fbbd57cc000 0000d000 fd 00 795086 usr local java jdk jre lib amd64 libverify so 7fbbd57cc000 7fbbd57ce000 rw 0000d000 fd 00 795086 usr local java jdk jre lib amd64 libverify so 7fbbd57ce000 7fbbd57d1000 00000000 00 00 7fbbd57d1000 7fbbd59cf000 rw 00000000 00 00 7fbbd59cf000 7fbbd667d000 xp 00000000 fd 00 795097 usr local java jdk jre lib amd64 server libjvm so 7fbbd667d000 7fbbd687d000 00cae000 fd 00 795097 usr local java jdk jre lib amd64 server libjvm so 7fbbd687d000 7fbbd6954000 rw 00cae000 fd 00 795097 usr local java jdk jre lib amd64 server libjvm so 7fbbd6954000 7fbbd699b000 rw 00000000 00 00 7fbbd699b000 7fbbd69b0000 xp 00000000 fd 00 795279 usr local java jdk lib amd64 jli libjli so 7fbbd69b0000 7fbbd6bb0000 00015000 fd 00 795279 usr local java jdk lib amd64 jli libjli so 7fbbd6bb0000 7fbbd6bb1000 rw 00015000 fd 00 795279 usr local java jdk lib amd64 jli libjli so 7fbbd6bb1000 7fbbd6bb2000 rw 00000000 00 00 7fbbd6bb2000 7fbbd6bb3000 00004000 fd 02 6029889 data0 logstash app logstash vendor bundle jruby gems concurrent ruby java lib concurrent ruby ext jar 7fbbd6bb3000 7fbbd6bbb000 rw 00000000 fd 00 2491367 tmp hsperfdata root 2149 7fbbd6bbb000 7fbbd6bbc000 rw 00000000 00 00 7fbbd6bbc000 7fbbd6bbd000 00000000 00 00 7fbbd6bbd000 7fbbd6bbe000 rw 00000000 00 00 7fffec897000 7fffec8ac000 rw 00000000 00 00 stack 7fffec8ff000 7fffec900000 xp 00000000 00 00 vdso ffffffffff600000 ffffffffff601000 xp 00000000 00 00 vsyscall vm arguments jvm args xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly djava io tmpdir data0 logstash app logstash xmx500m xss2048k djffi boot library path data0 logstash app logstash vendor jruby lib jni xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly djava io tmpdir data0 logstash app logstash xbootclasspath data0 logstash app logstash vendor jruby lib jruby jar djruby home data0 logstash app logstash vendor jruby djruby lib data0 logstash app logstash vendor jruby lib djruby script jruby djruby shell bin sh java command org jruby main data0 logstash app logstash lib bootstrap environment rb logstash runner rb agent data0 logstash app logstash conf data0 logstash app logstash logs logstash log java class path initial usr local java jdk lib dt jar usr local java jdk lib tools jar usr local java jdk jre lib launcher type sun standard environment variables java home usr local java jdk jre home usr local java jdk jre classpath usr local java jdk lib dt jar usr local java jdk lib tools jar usr local java jdk jre lib path data0 logstash app logstash vendor bundle jruby bin sbin usr sbin bin usr bin shell bin bash signal handlers sigsegv libjvm so 0xaad540 sa mask 11111111011111111101111111111110 sa flags sa restart sa siginfo sigbus libjvm so 0xaad540 sa mask 11111111011111111101111111111110 sa flags sa restart sa siginfo sigfpe libjvm so 0x90b6b0 sa mask 11111111011111111101111111111110 sa flags sa restart sa siginfo sigpipe libjvm so 0x90b6b0 sa mask 11111111011111111101111111111110 sa flags sa restart sa siginfo sigxfsz libjvm so 0x90b6b0 sa mask 11111111011111111101111111111110 sa flags sa restart sa siginfo sigill libjvm so 0x90b6b0 sa mask 11111111011111111101111111111110 sa flags sa restart sa siginfo sigusr1 sig dfl sa mask 00000000000000000000000000000000 sa flags none sigusr2 libjvm so 0x90ccf0 sa mask 00000000000000000000000000000000 sa flags sa restart sa siginfo sighup libjvm so 0x90e040 sa mask 11111111011111111101111111111110 sa flags sa restart sa siginfo sigint sig ign sa mask 00000000000000000000000000000000 sa flags none sigterm libjvm so 0x90e040 sa mask 11111111011111111101111111111110 sa flags sa restart sa siginfo sigquit libjvm so 0x90e040 sa mask 11111111011111111101111111111110 sa flags sa restart sa siginfo os centos release final uname linux 32 431 el6 x86 64 smp fri nov 22 03 15 09 utc 2013 x86 64 libc glibc 12 nptl 12 rlimit stack 10240k core 0k nproc 30638 nofile 16384 as infinity load average 41 21 63 proc meminfo memtotal 3973620 kb memfree 53740 kb buffers 221104 kb cached 1909748 kb swapcached 24808 kb active 1830232 kb inactive 1698016 kb active anon 1119824 kb inactive anon 377472 kb active file 710408 kb inactive file 1320544 kb unevictable kb mlocked kb swaptotal 4112376 kb swapfree 3429676 kb dirty 32320 kb writeback kb anonpages 1385888 kb mapped 116796 kb shmem 99780 kb slab 236428 kb sreclaimable 140596 kb sunreclaim 95832 kb kernelstack 3312 kb pagetables 100052 kb nfs unstable kb bounce kb writebacktmp kb commitlimit 6099184 kb committed as 3371800 kb vmalloctotal 34359738367 kb vmallocused 18820 kb vmallocchunk 34359709784 kb hardwarecorrupted kb anonhugepages kb hugepages total hugepages free hugepages rsvd hugepages surp hugepagesize 2048 kb directmap4k 4194304 kb directmap2m kb cpu total cores per cpu threads per core family model 45 stepping cmov cx8 fxsr mmx sse sse2 sse3 ssse3 sse4 sse4 popcnt aes clmul ht tsc tscinvbit tscinv proc cpuinfo processor vendor id genuineintel cpu family model 45 model name intel xeon cpu e5 2620 00ghz stepping cpu mhz 2000 036 cache size 15360 kb fpu yes fpu exception yes cpuid level 13 wp yes flags fpu de tsc msr pae cx8 sep cmov pat clflush mmx fxsr sse sse2 ss ht syscall nx lm rep good aperfmperf unfair spinlock pni pclmulqdq ssse3 cx16 sse4 sse4 x2apic popcnt tsc deadline timer aes hypervisor lahf lm ida arat pln pts dts bogomips 4000 07 clflush size 64 cache alignment 64 address sizes 46 bits physical 48 bits virtual power management processor vendor id genuineintel cpu family model 45 model name intel xeon cpu e5 2620 00ghz stepping cpu mhz 2000 036 cache size 15360 kb fpu yes fpu exception yes cpuid level 13 wp yes flags fpu de tsc msr pae cx8 sep cmov pat clflush mmx fxsr sse sse2 ss ht syscall nx lm rep good aperfmperf unfair spinlock pni pclmulqdq ssse3 cx16 sse4 sse4 x2apic popcnt tsc deadline timer aes hypervisor lahf lm ida arat pln pts dts bogomips 4000 07 clflush size 64 cache alignment 64 address sizes 46 bits physical 48 bits virtual power management processor vendor id genuineintel cpu family model 45 model name intel xeon cpu e5 2620 00ghz stepping cpu mhz 2000 036 cache size 15360 kb fpu yes fpu exception yes cpuid level 13 wp yes flags fpu de tsc msr pae cx8 sep cmov pat clflush mmx fxsr sse sse2 ss ht syscall nx lm rep good aperfmperf unfair spinlock pni pclmulqdq ssse3 cx16 sse4 sse4 x2apic popcnt tsc deadline timer aes hypervisor lahf lm ida arat pln pts dts bogomips 4000 07 clflush size 64 cache alignment 64 address sizes 46 bits physical 48 bits virtual power management processor vendor id genuineintel cpu family model 45 model name intel xeon cpu e5 2620 00ghz stepping cpu mhz 2000 036 cache size 15360 kb fpu yes fpu exception yes cpuid level 13 wp yes flags fpu de tsc msr pae cx8 sep cmov pat clflush mmx fxsr sse sse2 ss ht syscall nx lm rep good aperfmperf unfair spinlock pni pclmulqdq ssse3 cx16 sse4 sse4 x2apic popcnt tsc deadline timer aes hypervisor lahf lm ida arat pln pts dts bogomips 4000 07 clflush size 64 cache alignment 64 address sizes 46 bits physical 48 bits virtual power management processor vendor id genuineintel cpu family model 45 model name intel xeon cpu e5 2620 00ghz stepping cpu mhz 2000 036 cache size 15360 kb fpu yes fpu exception yes cpuid level 13 wp yes flags fpu de tsc msr pae cx8 sep cmov pat clflush mmx fxsr sse sse2 ss ht syscall nx lm rep good aperfmperf unfair spinlock pni pclmulqdq ssse3 cx16 sse4 sse4 x2apic popcnt tsc deadline timer aes hypervisor lahf lm ida arat pln pts dts bogomips 4000 07 clflush size 64 cache alignment 64 address sizes 46 bits physical 48 bits virtual power management processor vendor id genuineintel cpu family model 45 model name intel xeon cpu e5 2620 00ghz stepping cpu mhz 2000 036 cache size 15360 kb fpu yes fpu exception yes cpuid level 13 wp yes flags fpu de tsc msr pae cx8 sep cmov pat clflush mmx fxsr sse sse2 ss ht syscall nx lm rep good aperfmperf unfair spinlock pni pclmulqdq ssse3 cx16 sse4 sse4 x2apic popcnt tsc deadline timer aes hypervisor lahf lm ida arat pln pts dts bogomips 4000 07 clflush size 64 cache alignment 64 address sizes 46 bits physical 48 bits virtual power management processor vendor id genuineintel cpu family model 45 model name intel xeon cpu e5 2620 00ghz stepping cpu mhz 2000 036 cache size 15360 kb fpu yes fpu exception yes cpuid level 13 wp yes flags fpu de tsc msr pae cx8 sep cmov pat clflush mmx fxsr sse sse2 ss ht syscall nx lm rep good aperfmperf unfair spinlock pni pclmulqdq ssse3 cx16 sse4 sse4 x2apic popcnt tsc deadline timer aes hypervisor lahf lm ida arat pln pts dts bogomips 4000 07 clflush size 64 cache alignment 64 address sizes 46 bits physical 48 bits virtual power management processor vendor id genuineintel cpu family model 45 model name intel xeon cpu e5 2620 00ghz stepping cpu mhz 2000 036 cache size 15360 kb fpu yes fpu exception yes cpuid level 13 wp yes flags fpu de tsc msr pae cx8 sep cmov pat clflush mmx fxsr sse sse2 ss ht syscall nx lm rep good aperfmperf unfair spinlock pni pclmulqdq ssse3 cx16 sse4 sse4 x2apic popcnt tsc deadline timer aes hypervisor lahf lm ida arat pln pts dts bogomips 4000 07 clflush size 64 cache alignment 64 address sizes 46 bits physical 48 bits virtual power management memory 4k page physical 3973620k 52500k free swap 4112376k 3429676k free vm info java hotspot tm 64 bit server vm 25 51 b03 for linux amd64 jre 51 b16 built on jun 2015 19 28 07 by java re with gcc 20080428 red hat time fri dec 11 19 32 27 2015 elapsed time 16752 seconds 0d 4h 39m 12s >>>bug unconfirmed
fixes 4233 fix string interpolation memory leak backported from elastic logstash 4a8d6feed4977adc3dc8530b32c07ea294999ca9>>>v1.5.7
add memory usage notifications oom flow control while doing some research on the different monitoring beans given to us in the jvm an idea came to me it could be interesting to add notification layer to ls when the system is getting close to oom we could archive this not hard with the different memory thresholds notifications provided directly by the jvm what do you think ref https docs oracle com javase docs api java lang management memorypoolmxbean html>>>discuss enhancement
rabbitmq input fails to load when attempting to use the rabbitmq input the start up fails opt logstash bin logstash agent config rabbitmq conf debug reading config file config file home darinf work logstash test rabbitmq rabbitmq conf level debug file logstash agent rb line 325 method local config compiled pipeline code inputs filters outputs periodic flushers shutdown flushers input rabbitmq plugin input rabbitmq logstash util hash merge many host localhost ssl true verify ssl false queue df metrics exchange dftest prefetch count 10 durable true codec json inputs input rabbitmq output stdout plugin output stdout logstash util hash merge many codec rubydebug outputs output stdout def filter func event events event logger debug logger debug filter received event event to hash events end def output func event logger debug logger debug output received event event to hash output stdout handle event end level debug file logstash pipeline rb line 38 method initialize plugin not defined in namespace checking for plugin file type input name rabbitmq path logstash inputs rabbitmq level debug file logstash plugin rb line 76 method lookup the error reported is couldn find any input plugin named rabbitmq are you sure this is correct trying to load the rabbitmq input plugin resulted in this error no such file to load ext rabbitmq client opt logstash vendor bundle jruby gems logstash core java lib logstash plugin rb 85 in `lookup opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 304 in `plugin eval in `initialize org jruby rubykernel java 1079 in `eval opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 40 in `initialize opt logstash vendor bundle jruby gems logstash core java lib logstash agent rb 124 in `execute opt logstash vendor bundle jruby gems logstash core java lib logstash runner rb 90 in `run org jruby rubyproc java 281 in `call opt logstash vendor bundle jruby gems logstash core java lib logstash runner rb 95 in `run org jruby rubyproc java 281 in `call opt logstash vendor bundle jruby gems stud 22 lib stud task rb 24 in `initialize darinf silo work logstash test rabbitmq darinf silo work logstash test rabbitmq darinf silo work logstash test rabbitmq darinf silo work logstash test rabbitmq darinf silo work logstash test rabbitmq darinf silo work logstash test rabbitmq opt logstash bin logstash agent config rabbitmq conf verbose debug the error reported is couldn find any input plugin named rabbitmq are you sure this is correct trying to load the rabbitmq input plugin resulted in this error no such file to load ext rabbitmq client the resolution is to update the plugin bin plugin update logstash input rabbitmq updating logstash input rabbitmq updated logstash input rabbitmq to please fix in the distribution >>>bug v2.1.2
wip reload config from files add ability to detect changes in the configuration file and restart the pipeline with the changes if config file is given and is enabled then the agent will check the file every seconds and if there difference stop the existing pipeline create and start new one if there an error while creating the new pipeline the previous configuration is used again if there no difference nothing happens sending sighup to the logstash also triggers configuration reload todo since the shutdown controller doesn yet handling multiple pipelines it is disabled for now pass runner pipeline settings to the pipelines through agent>>>enhancement
using symbols in event data does not make sense changed illegal object from symbol to string since in java symbols get converted to string and symbols are not valid objects to start with as event data relates to 4191 >>>java_event
possible event corruption we ve been seeing lot of strange errors in logstash logs complaining about normal errors but dumping the event in what appears to be this weird nested format here an example you can see the event seems to repeat itself not sure if this is due to my configuration or something going wrong somewhere else running logstash with stdin and rubydebug stdout shows parsing working without issues if just copy and paste the same log line here is the relevant logstash configuration for nginx error log parsing from our config we re inputting events via filebeat and the beats input with the json codec versions filebeat logstash logstash codec collectd logstash codec dots logstash codec edn logstash codec edn lines logstash codec es bulk logstash codec fluent logstash codec graphite logstash codec json logstash codec json lines logstash codec line logstash codec msgpack logstash codec multiline logstash codec netflow logstash codec oldlogstashjson logstash codec plain logstash codec rubydebug logstash filter anonymize logstash filter checksum logstash filter cidr logstash filter clone logstash filter csv logstash filter date logstash filter dns logstash filter drop logstash filter fingerprint logstash filter geoip logstash filter grok logstash filter json logstash filter kv logstash filter metrics logstash filter multiline logstash filter mutate logstash filter ruby logstash filter sleep logstash filter split logstash filter syslog pri logstash filter throttle logstash filter urldecode logstash filter useragent logstash filter uuid logstash filter xml logstash input beats logstash input couchdb changes logstash input elasticsearch logstash input eventlog logstash input exec logstash input file logstash input ganglia logstash input gelf logstash input generator logstash input graphite logstash input heartbeat logstash input http logstash input imap logstash input irc logstash input jdbc logstash input kafka logstash input log4j logstash input lumberjack logstash input pipe logstash input rabbitmq logstash input redis logstash input s3 logstash input snmptrap logstash input sqs logstash input stdin logstash input syslog logstash input tcp logstash input twitter logstash input udp logstash input unix logstash input xmpp logstash input zeromq logstash output cloudwatch logstash output csv logstash output elasticsearch logstash output email logstash output exec logstash output file logstash output ganglia logstash output gelf logstash output graphite logstash output hipchat logstash output http logstash output irc logstash output juggernaut logstash output kafka logstash output lumberjack logstash output nagios logstash output nagios nsca logstash output null logstash output opentsdb logstash output pagerduty logstash output pipe logstash output rabbitmq logstash output redis logstash output s3 logstash output sns logstash output sqs logstash output statsd logstash output stdout logstash output tcp logstash output udp logstash output xmpp logstash output zeromq logstash patterns core >>>needs_details
keep the namespace context of the metric up to the collector service small prs for initialize rework of the collector to be able to reference of the current namespace context this will allow to write structured queries against the snapshot fixed few typos >>>metrics
split by bytes filter this is feature request idea for split filter that will split potentially huge event into multiple smaller events use case is that for application logs it can be unpredictable when it decides to dump out an gigantic stack trace or trace log with huge response bodies the byte based flush size in the future will help with this but what if single event is huge enough so that at flush size ls is still running out of memory for such edge cases it can be helpful if there is split filter that is based on size bytes that will split the large message into multiple pieces and inject key into each event so one can use it as way to link up the split events thereafter >>>discuss enhancement new-plugin
add first iteration of the webapi hi this pr add the first iteration of the webapi it include the next set of features sinatra webapp to handle the api resources set of test for the webapp code to have an embedded puma webserver that will handle the web requests notes for now the web server is created in the agent execute tried moving this to the new background service but is currently broken with this error >>>enhancement metrics
logstash immediate oom when running simple lumberjack input regression trying to upgrade from to for simple logstash `lumberjack file` pipeline observing an immediate oom on startup the oom appears to be in `org jruby ext zlib jzlibinflate` running `logstash ahlinfra monit conf logs dev man com init etc fwd receiver conf w1` configuration output hprof analysis image https cloud githubusercontent com assets 55716 11718598 add74a2e 9f4e 11e5 8217 62569ce1a10a png image https cloud githubusercontent com assets 55716 11718614 c2da7aea 9f4e 11e5 805b 67389217261b png >>>crashes needs_details
upgrade to jrjackson json decoding issues starting with see json decoding issues starting with version https github com elastic logstash issues 4316 >>>bug known_issue v2.1.2
fix for 4303 breaks with java opts set the fix for 4303 breaks when java opts` is set when it set https github com elastic logstash blob master bin logstash lib sh l51 then heap dump path https github com elastic logstash blob master bin logstash lib sh l66 will be empty which then leads to passing just https github com elastic logstash blob master bin logstash lib sh l179 to jruby which is not recognized as valid option >>>bug packaging v2.3.0
support structured logs in java event implementation this follows up discussion in https github com elastic logstash pull 4263 files r46731357 on the current incomplete java event implementation >>>java_event
new v3 event api for timestamp initialization and coercion this follows up on the idea in 4293 some plugins might need to re inject timestamp and currently the `event` timestamp initialization and coercion https github com elastic logstash blob c2ea4a7a6eedee46fb7d169773b150cc44c78713 logstash core event lib logstash event rb l250 l266 is not exposed as an example the json filter would really benefit this since it is actually reimplementing the timestamp initialization code see https github com logstash plugins logstash filter json pull 18 at this point am not sure if we should add method in the `event` or in `timestamp` for this but either way we should make the timestamp initialization public api and dry the event and the json filter >>>internal-cleanup
new v3 event api for message getter and setter this follows up on the idea in 4293 just like we have getter and setter for timestamp `event timestamp` and `event timestamp believe we should add the same for message and add `event message` and `event message the message field is central to the event and having these would avoid using clumsy fieldrefs like `event message or `event message in the plugins implementations >>>discuss enhancement
new v3 event api for internal data hash mutation this issue reboots issue 4293 and relates to 4191 the goal is to add `event` methods for the plugins to correctly manipulate the underlying data hash by abstracting away the internal implementation details and moving away from mutable interactions with the event to hash returned object the current `event append` and `event overwrite` takes an `event` as argument this is fine for some plugins and afaik `event append` is only used by multiline we can have separate discussion about these suggest adding `from hash` and `merge hash` `event from hash` would replace the `event` data completely `event merge hash` would merge in external hash content once this is in place the following plugins will need followup to use the new api filter kv see https github com logstash plugins logstash filter kv pull 21 filter geoip see https github com logstash plugins logstash filter geoip pull 56 filter json see https github com logstash plugins logstash filter json pull 18 filter csv https github com logstash plugins logstash filter csv pull 20 filter useragent see https github com logstash plugins logstash filter useragent pull 20>>>discuss internal-cleanup java_event v3.0.0
make timestamp delegate eql to time this fails in rspec >>>adoptme low_hanging_fruit
next perf steps next gen pipeline this ticket is medium to long term design goal while the next gen pipeline is much faster than the old one the synchronousqueue at its heart is still choke point there are probably options out there that could remove this choke point the best idea currently have is to couple the workers to the inputs directly an alternative idea would be to switch from synchronousqueue to work stealing queue along the lines of what java fork join pool does to reduce contention even further one other idea which may be the most practical would be to allow inputs to send batches of events across the queue in single operation sending an array of events instead of single event that would probably reduce contention to practically negligible amount the impact here is really not knowable without doing it so labeling this as high hanging fruit >>>design enhancement high_hanging_fruit next-gen_pipeline
restart in sysv startup file does not work as intended the critical things here are that log function is called that does not exist that an exit is called where return should be called made minimal change to fix this https github com elastic logstash pull 4321 besides the change this fixes should probably be applied to the other sysv files too debian and redhat and possibly the upstart file too an alternative would be to revert the change that introduced this https github com elastic logstash commit 841b87677875d1f8c31aa2d19759dbe5883bd80d >>>bug v2.1.2
fix configtest in sysv init script replace non existing log function with echo replace exit with return to make quiet function work >>>v2.1.2
logstash input blocked when it comes to heavy load using input lumberjack filter date output elasticsearch about 38 logstash process handling 20w events is it too much somehow get this log it seems that the filter worker threads all hang up timestamp 2015 12 09t14 47 44 525000 0800 message inflight events report 2015 12 09t14 47 44 08 00 input to filter 20 filter to output outputs level warn timestamp 2015 12 09t14 47 49 540000 0800 message inflight events report 2015 12 09t14 47 49 08 00 input to filter 20 filter to output outputs level warn timestamp 2015 12 09t14 47 49 525000 0800 message inflight events report 2015 12 09t14 47 49 08 00 input to filter 20 filter to output outputs level warn timestamp 2015 12 09t14 47 54 540000 0800 message inflight events report 2015 12 09t14 47 54 08 00 input to filter 20 filter to output outputs level warn timestamp 2015 12 09t14 47 54 526000 0800 message inflight events report 2015 12 09t14 47 54 08 00 input to filter 20 filter to output outputs level warn timestamp 2015 12 09t14 47 59 526000 0800 message inflight events report 2015 12 09t14 47 59 08 00 input to filter 20 filter to output outputs level warn timestamp 2015 12 09t14 47 59 541000 0800 message inflight events report 2015 12 09t14 47 59 08 00 input to filter 20 filter to output outputs level warn how should debug this problem or what else information do guys need logstash config file is like below input lumberjack port 5000 codec json ssl certificate tls certs logstash forwarder crt ssl key tls private logstash forwarder key filter date match timestamp unix timezone asia shanghai remove field version file host offset output elasticsearch cluster service elasticsearch 	host elasticsearch service yy com 9200 	protocol http 	workers >>>needs_details
better documentation on where to specify ls java opts we added ls java opts here https www elastic co blog logstash rc3 released when using the rpm there are multiple places you can specify ls java opts eg in the etc sysconfig logstash and etc init logstash files but it looks like the etc init logstash is the right place to specify it here is an example when seeing up jmx connection if you specify it in etc sysconfig logstash file this causes issues when using etc init logstash restart it will eventually end up launching multiple rmi servers and fail with bind exception eg so moved the ls java opts settings for the jmx connection from etc sysconfig logstash to etc init logstash after that am no longer able to reproduce the restart issue not sure if this is bug if not it will be nice to document this better in our guide and as comment within the sysconfig file etc >>>bug packaging
logstash performance issue hello recently observed when am generating huge log file and simultaneously using the logstash parsing on that file am seeing the speed that log file is generated is slower with logstash as compared standalone log generation >>>needs_details windows
json decoding issues starting with version java javalang arrayindexoutofboundsexception we suffered from arrayindexoutofbounds exceptions while decoding json with logstash starting from version my colleague described the problem in https discuss elastic co json en decoding issues starting with version 36543 now we could tackle down this issue the problem is related to https github com fasterxml jackson core issues 216 which got fixed with jackson version filed an issue in jrjackson to update the dependecies https github com guyboertje jrjackson issues 48 solution for logstash as soon as jrjackson is updated logstash should update to the latest version of jrjackson to fix this issue steps to reproduce logstash config start logstash with the above config provide some input the first message to throw an exception is number 114 >>>bug upstream_fix_needed v2.1.2
logstash and idmef hi folk is logstash support collect enrich transport data normalized in idmef intrusion detection message exchange format format cheers >>>adoptme enhancement question
reorganize tests in common main location the main motivation of this pr is to reorganize the tests location as of this days we ve test located in many different places for example the acceptance spec directory the test directory the spec and so on this is concern think we should fix in order to provide single location well described location that helps everyone locate old test place new test and basically have better testing experience gmoskovicz it would be nice if you can validate the windows part of this test and make sure they work as expected notes to reviewers please understand this pr as living thing and let it serve as living example the motivation of this pr is to locate test all together part from that have no special concerns about naming or final location ideas and improvements always welcome >>>internal-cleanup tests-infra v2.2.0
find city country region code from geopoint hello does anybody know if can find all these information starting from geopoint field city country region know that logstash can find several information like these using an ip and maxmind but presently do not have access to ip address only geopoint latitude and longitude thanks>>>adoptme new-plugin
fix broken integration test integration test are currently broken this pr fix the missing parts of it >>>bug
update logstash filter aggregate plugin documentation into logstash reference documentation hi yesterday some enhancements were added to asciidoc documentation in logstash filter aggregate plugin could you update logstash reference documentation to integrate these enhancements more precisely could you update logstash reference and logstash reference master using logstash filter aggregate master branch >>>docs
event clone do not copy metadata question triggered by report in https github com logstash plugins logstash filter clone issues what is the expected behaviour of the clone method regarding metadata user expectaction is that an exact copy is done data metadata but it is not currently the case colinsurprenant as you are in an heavy review of the event class could you please comment on this >>>bug
logstash input log4j2 plugin installation failing for logstash any plan to support this version plugin install logstash input log4j2 validating logstash input log4j2 installing logstash input log4j2 plugin version conflict aborting error installation aborted message bundler could not find compatible versions for gem logstash core in snapshot gemfile lock logstash core in gemfile logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash input beats java depends on logstash core java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash output http java depends on logstash mixin http client java depends on logstash core beta2 java logstash input log4j2 java depends on logstash core java logstash core java running bundle update will rebuild your snapshot from scratch using only the gems in your gemfile which may resolve the conflict bundler could not find compatible versions for gem logstash in gemfile logstash input log4j2 java depends on logstash java could not find gem logstash java which is required by gem logstash input log4j2 java in any of the sources >>>bug
init logstash configtest not consistently returning warnings not sure if this is related to https github com elastic logstash issues 4111 but it appears that when using the rpm installation the configtest of the logstash init script is not consistently reporting warnings detected via configtest see below there were no changes in the file that is in the etc logstash conf folder during the test on centos and you can see that the direct configtest call from the logstash script seems to consistently return the warnings unlike the init script the config folder has single file with the following mostly test to cause the log4j warning as reported in 4111 to show up >>>bug packaging
allow logstash to run in dir with spaces because heapdumppath is set if it contains spaces the jruby opts function will create two strings appended by even if the list of jruby opts is constructed using replacement shell script will not escape the path correct to the heap dump path option needs to be added as late as possible this is nix fix only windows is not affected fixes 4283>>>bug v2.1.1
threaddeath uncaughtexceptionhandler root cause help we just upgraded from to now we see these super un helpful errors in the error log every few minutes how can we get the root stack trace logged or possibly determine what is causing this exception java lang threaddeath thrown from the uncaughtexceptionhandler in thread thread 28 never got these errors previously prior to upgrade running logstash with debug and or verbose produces huge log file but without the error message the file does not contain threaddeath or uncaughtexceptionhandler the exception error message gets only printed to logstash err without any further information >>>bug needs_details
replace `def type func` with define singleton method when you run multiples pipeline and the config code get evaluated on every evaluation the class cached is clear everytime you were calling `func` method you had the latest evaluated code the `filter func` and the `output func` need to be unique for every instance of the pipeline this pr replace the `def` with `define single method` call ensuring the uniqueness of the code on every instance this pr is based on 4254>>>v2.2.0
create default patterns directory when installing from package it be nice if default patterns directory were created and set when installing from official packages etc logstash patterns seems reasonable find it helpful for this type of default to exist so don have to choose an arbitrary location and blog posts tutorials etc have common location to refer to >>>enhancement packaging
socketerror recv name or service not known while plugin install via proxy start issue here https github com logstash plugins logstash filter translate issues logstash version os opensuse 13 bottle x86 64 ipv4 >>>bug plugin_manager
don use chroot use su noticed this error message while debugging logstash initscript on redhat x86 64 and this is the code in question from etc init logstash` bash nice ls nice chroot userspec ls user ls group extra groups sh cd ls home ulimit ls open files exec program args ls log dir name stdout ls log dir name err >>>bug packaging
new event apis to properly abstract internal implementation some plugins assumes that `event to hash` returns in place mutable `hash` object that will directly update the event content while true now moving forward we cannot assume this behaviour it is also very bad design we need simply provide new apis to directly set fields in the event without having to go through the field reference parsing overhead and also way to set or merge new hash structure at the root of the event event this will allow plugins like the kv filter to use these new apis to optimize the data injection in the event as done now in logstash plugins logstash filter kv 21 doing this will require major version bump because it will add new api so that plugins that will use this new api can use the proper versions constrains issue 4140 is caused by this this relates to 4191 upon progress on this we need to followup on kv filter json filter>>>java_event
allow logstash to be launched from symlink these changes allow logstash to be launched from symlink only when the `readlink` or suitable version of `stat` binaries are present an error message will result if logstash is launched from symlink and the path cannot be discovered by one of these two methods the message will advise the user to use the full path instead of symlink to launch logstash fixes 4291>>>packaging v2.1.1 v2.2.0
bin logstash not symlink friendly have logstash in opt logstash` installed from rpm the problem is the utility does not add system wide executable in path when try to do it myself for the root user by symlinking to root bin` folder it dies with root bin logstash line 22 root bin logstash lib sh no such file or directory looking at the invocation shell script this is the problem cd `dirname 0` pwd bin logstash lib sh it relative to the invoked path not the shell script root machine bin dirname root bin logstash root bin should be an easy fix thanks >>>bug v2.2.0
bin plugin list show non installed plugins the bin plugin list command is broken as it shows not installed plugins by default this makes the user interaction confusing see the example can see the json codec listed but as is not installed can not remove it >>>bug plugin_manager
codec decode` should support defining metadata have encountered an issue with the lumberjack and the beats plugin combined with the multiline codec and its really hard to fix without changing the api the problem is related to spooling or the buffering of events within the codec code some protocol support adding useful metadata lumberjack rabbitmq to an event but the `decode` api only work with string it look like an async api but its more like sync api see the following example this code is simple and its always right if the codec doesn do buffering since the proc will capture the data hash if the codec do some kind of buffering like the multiline filter it will only be right if new lines trigger flush in any other context like time based eviction or when we manually trigger flush before shutting down the plugin that context will be lost we need revisit that api to add the possibility to add context or metadata to the decode or provide an object that can receive callbacks until then have implemented the eviction block to only decorate and push to the queue the events but the metadata wont be added to them this issue is related to guyboertje proposal for changing the interaction between the codec and the queues >>>discuss
provide feedback to users when trying to uninstall plugins that are dependencies of others add way to detect dependencies for plugins when uninstalling this provides feedback to users when hitting 3152 it provides this by building an initial version of dependency graph from the gemfile lock in similar way and strategy as we deal with the gemfile some notes the dependency graph will let us do lot of more things but for now the implementation is general enough in some way and simple enough in another to fit this use case keep this in mind when reviewing this add warning to the user when doing uninstall chose this path as the less intrusive one from the many options possible let me know what do you think >>>bug plugin_manager
add source as parameter to select the origin of the plugins hi this days the plugin manager pulls the plugins either from rubygems or from another source to add this extra source user need to change the gemfile we should provide an option in the plugin manager to select an extra source it would also be nice to provide command to update the sources but this might be an extra option >>>enhancement plugin_manager
fix shutdown controller when using no filters initializes filter threads to be an empty array so that the shutdown controller can deal with no filters gracefully this needs to be merged into master and fixes 4271 >>>bug v2.1.1 v2.2.0
logstash fails to start if the parent directory contains space reproduction on my macbook lt download logstash gt mkdir dir with space cd dir with space tar xvzf downloads logstash tar gz cd logstash bin logstash and get `error could not find or load main class el lostash heapdump hprof` >>>bug v2.1.1
logstash lumberjack output json enhancement currently the recommended solution to communicate between two logstash instances seems to be either over tcp output input or lumberjack lumberjack has several enhancement like compression and encryption over the tcp option for beats lumberjack was extended transformed to logstash input beats https github com logstash plugins logstash input beats to support full json the advantage of using full json is that not type information is lost which can be the case with lumberjack suggest to create based on lumberjack output the logstash output beats or an other name which would allow to send data between two ls instances with all the advantage of lumberjack but supporting full json means no potential loss of data structure >>>discuss
users updating plugins in version will hit the concurrent ruby issue hi if you re updating plugin by calling bin plugin update you will encounter the concurrent ruby error see 4141 for details this error has been fix in the last versions so the recommended way to fix this is updating your logstash related to https github com logstash plugins logstash input tcp issues 27 and 4141 >>>bug known_issue
proper java to ruby convertion and specs this pr builds on top of 4278 added the `rubyfier` class to deep convert java to ruby event data added specs this relates to 4264 and 4191 and fixes edn codec specs under java event >>>java_event v2.2.0
fix missing methods in java timestamp this pr builds on top of 4265 add missing `utc` `gmtime` and `to f` methods in the java `timestamp` add missing specs for these methods in the ruby `timestamp` specs to prevent future regressions this relates to 4264 and 4191 and fixes sqs input specs under java `event` >>>java_event v2.2.0
display source of error message in logs error messages coming from plugins input filter output often don display any source in some cases it pretty obvious where it failed but lot of the time it takes some time to figure out where it coming from it would be nice if logstash added the source plugin name at the beginning of each error message such as filter ruby to help locating where the issue is coming from here are some example of unclear messages logstash plugins logstash filter ruby 14 logstash plugins logstash filter geoip 51 logstash plugins logstash output elasticsearch 294 logstash plugins logstash input unix 15 logstash plugins logstash input rabbitmq 48 logstash plugins logstash output elasticsearch 300 >>>bug enhancement
couldn find any input plugin named file or filter translate no such file to load system info ubuntu 14 04 64 bit logstash from elastic deb repository after upgrading from deb via apt to logstash didn start correctly it told me couldn find any input plugin named file thought it was just due to failure from apt since file input is built in so forced reinstall with apt and it worked fine now after restarting logstash to debug another issue it happened again with the filter translate know it there because have post dpkg script to install that plugin when logstash is updated and could see the output of plugin installation on the screen which was successful had to reinstall the plugin manually is there anymore information needed to debug the issue >>>bug needs_details
error your application used more memory than the safety cap of 500m ubuntu 14 04 logstash plugins fully updated yesterday using bin plugin using these plugins in my config files beats grok date elasticsearch elasticsearch running on localhost sending logs to logstash from dozen instances with filebeat rc2 memory usage on that instance the drop before 10am is probably the logstash crash memory usage http imgur com sfflwmc png >>>needs_details
some inputs do not behave well when the run method is called repeatedly the file input is problematic when run is called more than once it reopens the files and file handles in `pipeline rb` the method `inputworker` will call `plugin run` if this raises an error the rescue clause will call retry this calls the `run` method again proposal we should call method on the input that puts it in `re runnable` state concerns we do not have consistent api for this we have new register run stop we don have methods specifically to prepare an input for re run we could make this the responsibility of each input to detect second call to run and do what is needed to prepare for the next run we are considering change to layered exception handling this may change how often re run might occur >>>design discuss
bug in shutdown controller when filter workers is nil if there are no filter the shutdown controller crashes >>>blocker bug v2.1.1
test should all be contained in the same directory location today we ve specs in acceptance spec https github com elastic logstash tree master acceptance spec integration https github com elastic logstash tree master integration spec https github com elastic logstash tree master spec test windows https github com elastic logstash tree master test windows this makes the test codebase disparse as one should be looking at different places specific ones for each kind of test this should be located all in one single location within the proper directory structure >>>enhancement tests-infra
change version to dev>>>internal-cleanup v2.2.0
move misplaced shutdown controller after broken merge this file belongs under `logstash core `>>>internal-cleanup v2.2.0
hundreds of sockets in close wait status hi all am having problem with an full elk stack stopping accepting logs around 12 18 hours after starting logstash the process will stop accepting logs and we ll typically see 500 600 sockets in close wait status the main process doesn appear to die often when finally gives up is recieving very small amount of logs typically few hundred events in total between 20 or so servers we have the following setup logserver logstash elasticsearch kibana java openjdk redhat enterprise linux server spec 8gb 7ghz cores logstash runs with 4gb heap and worker threads thread dumps and config can be supplied if needed often when the server hits maximum with the sockets the load average is quite low around it can reach around when we restart the logstash service and its catching up for the case of testing we have removed all filters from the pipeline we did have the multiline filter in use to capture jvm stack traces this has been removed to stop the pipeline becomeing single threaded presently our usage and config are too simple for it to be case of an underspecced vm and we seem to be at the conclusion that might be bug in logstash itself can anyone reproduce this confirm if this is known bug thanks chris >>>bug needs_details
it should be the option to generate plugin skeleton using the plugin manager it will make the plugin creator life bit more easy if there is an option to generate simple plugin skeleton from the plugin manager itself this should be easy implemented based on the current example repositories and some templates >>>enhancement
fix nil value field reference assignment in java event this pr builds on top of 4263 and also add related missing spec in ruby event this relates to 4264 and 4191 and is required to have the filter grok specs pass with the java event >>>java_event v2.2.0
meta plugins specs fixes tracking for logstash core event java as work on having all the plugins specs pass using logstash core event java will update this tracking list of the related issues prs relates to 4191 filter grok in logstash plugins logstash filter grok 62 and 4265 input sqs in 4278 codec edn 4279 filter geoip logstash plugins logstash filter geoip 56 filter kv logstash plugins logstash filter kv 20 ogstash plugins logstash filter kv 21 filter mutate logstash plugins logstash filter mutate 59 logstash plugins logstash filter mutate 61 4279 filter json logstash plugins logstash filter json 18 filter xml logstash plugins logstash filter xml 21 filter ruby logstash plugins logstash filter ruby 15 filter csv logstash plugins logstash filter csv 20 output file logstash plugins logstash output file 23 filter useragent logstash plugins logstash filter useragent 20 output graphite logstash plugins logstash output graphite 20 codec json lines logstash plugins logstash codec json lines 12 input elasticsearch logstash plugins logstash input elasticsearch 35 codec netflow logstash plugins logstash codec netflow 29 filter date logstash plugins logstash filter date 45 input imap logstash plugins logstash input imap 11 and also but not specific to java event codec rubydebug see logstash plugins logstash codec rubydebug 8>>>java_event meta
proper testable ruby event logging and java event logging support this pr builds on pr 4261 which cleans the event class and adds the following replace the ruby `event` `logger` constant with an injectable logger object which allows correct testing as discussed in issue 4253 adds testable logging support in the java `event` and makes the java `event` pass all ruby `event` specs >>>enhancement java_event
add debug option to plugin script or its help manual currently when debugging plugin install uninstall issues we can use the following for example it will be great to either expose this debugging as parameter to the plugin script or simply document this in the help of the plugin command >>>enhancement plugin_manager
cleanup event class cleaned and streamlined the event class added few comments grouped deprecated methods all core specs are passing there should not be any code logic change including the few explicit `return` removed which do not change logic >>>internal-cleanup
expose global state namespace in configuration using field reference this idea is not yet fully matured this is an early brain dump on the idea for discussion this idea resulted from discussion with jakommo about having the ability to keep information from specific event that could be passed on to following events similar to the idea of the metadata field reference feature we could expose global state or stream state context namespace through field reference using for example context which would access global per stream object that could be used to get set values using the field reference syntax in the config this would allow users to use global state without having to write custom plugin scripts and keep this in the config using the same syntax and logic using conditionals etc this could also be used to expose some of the upcoming stream identity data using guyboertje work on this can you please link the relevant issue here >>>discuss enhancement
cannot connect logstash output to an input hi have configuration here that isn working create an empty `mylog log` file modify configuration then have `while do nc 5500 done` running to see if logstash is correctly sending our events to tcp 5500 but it seems we cannot connect logstash to itself need that to to some extra computing for given output my use case is the following `json input adding fields output an email using some fields output to another input of logstash cleanup fields output amqp` here is the minimal configuration used to show the problem all get on `stdout` is >>>unconfirmed
next gen pipeline this takes over from 4155 which was pointed toward the next gen pipeline branch this new pr is pointed at master note have not included configurable values for batch size or batch delay as waiting for https github com elastic logstash pull 3872 to merge first which will certainly cause merge conflict attn this is no longer poc but production ready code this is pr that aims to accomplish the following objectives provide an in memory implementation no persistence of the pipeline described in https github com elastic logstash issues 3693 be completely backward compatible with current logstash plugins nothing should break allow for complete pipeline snapshotting even with the elasticsearch plugin to address concerns raised by jsvd in https github com elastic logstash pull 4051 this would allow forced shutdowns without losing data this would require the elasticsearch output to implement `receive multi` and no longer use its own internal queue expose new batch interface for filters and output plugins allowing them to process events in microbatches for efficiency this could have very significant potential for speed improvements for filters like the useragent filter which would only have to lookup the number of unique keys per batch vs each key individually this would also obviate the need for separate buffer in the elasticsearch output would say that along with these changes we should contemplate adding new plugin config option which would by default set the number of workers for the plugin to be the number of worker threads that will give the best user experience for this notes on implementation this is 90 the system described in https github com elastic logstash issues 3693 the one exception to this is that output plugins are assumed to be not threadsafe this was necessary to make it backward compatible with series plugins when the of output workers is equal to the number of worker threads specified with w` the behavior should be very similar to what the original behavior was think the default worker fix described above might actually be long term solution here persistence examples since this is just poc the pipeline shutdown persistence is demonstrated in the writing of two files on shutdown update this functionality remains in the `dump inflight` function but is currently never called we may enable this in future release tmp ls current batches the contents of in memory buffers before the shutdown sequence is initiated fast shutdown as described in https github com elastic logstash pull 4051 could simple write this then `exit` safely tmp ls current batches post close this is just there for debugging in the poc this is written after clean shutdown it will always be empty unless there bug in the pipeline notes for reviewers this pr involves small number of changes to the ast to enable batch oriented processing for each batch we execute the filters one by one accumulating new batch of filtered events execute `output func` once per each function which no longer invokes the output func but rather returns an array of outputs that the event should be sent to we use the info from the step above to build separate batches per output as seen in `output batch` in the pipeline this pr adds new cli options `batch size` and `batch poll wait` to control the new features of the pipeline please verify my performance results for yourself currently using this config https gist github com andrewvc b25097d19aa50df8e05f and running it with `time bin logstash that config conf` then comparing it with logstash set the default batch size to be 125 to match the elasticsearch output defaults assuming four workers 125 500 this seemed like safe default performance used the following config to test this thing out `bin logstash input generator filter mutate add field foo bar output http http method post url http localhost 4567 hi workers note that this requires little web service to hit used the following performance also worth noting this new pipeline seems in at least one micro benchmark to be as much as 63 faster doing further benchmarking was able to get the throughput up to 74k using batch size of 40 the default is 20 upping the batch size to 200 made it go down to 71k and upping it to 2000 brought it down lot to 50k so batch size has big impact probably due to not being able to use memory the cache as efficiently we ll have to do further tests with different messages sizes as well >>>enhancement performance-improvements resiliency v2.2.0
strategy for implementation specific logging specs the `logstash core event` `event` specs contains tests like this to test for specific logging calls obviously these tests don pass the java `event` implementation because first logging is not yet implemented in the java event but these tests as they are will be difficult to support in any alternate implementation because they rely on an implementation detail which is the use of specific method from specific inner object constant am not sure what would be the proper approach to correctly test logging in non implementation specific way an idea would be to use some form of dependency injection by either passing logger object to the event constructor or use class method to set logger instance in an event class variable that way we could use logging mock object in specs or something around these lines will investigate bit >>>java_event
changelog md inconsistencies across branches current problems master has changelog https github com elastic logstash blob master changelog md since master is on dev this branch should no longer receive changelogs from or since ga has changelog https github com elastic logstash blob changelog md should only have logs before beta1 only has changelog up to beta2 https github com elastic logstash blob changelog md it should have everything up to ga>>>internal-cleanup
better string interpolation cache api and spec the fix introduced in 4229 is actually too implementation specific and fails when using logstash core event java obviously the logstash stringinterpolation class does not exist >>>bug java_event
logstash input googleanalytics for consideration https github com russorat logstash input googleanalytics currently lacking tests will add those before requesting pr >>>new-plugin
better rspec defaults to use documentation formatter in rake tasks and ci default to format documentation` for all rspec tasks and when running ci tests some advantages of using format documentation` better more verbose jenkins reports visual cue to exactly where test stalls when it does>>>enhancement tests-infra v2.3.0
main gemfile logstash core version constrains related to 4243 and 4236 currently in the tag and in the release branch we pin `logstash core` to specific version for example and not range see tag https github com elastic logstash blob a566fab7d135886a33a1caadae9e548bee050179 gemfile l5 `gem logstash core branch https github com elastic logstash blob gemfile `gem logstash core snapshot3 the problem is see with this is that it will prevent upgrading logstash core if we need to either specifically or but updating installing plugin which could depend on newer version of logstash core think that for released packages we should use the pessimistic versions constrain for example in we could use 0` this will allow installing future updated logstash core versions and exclude prereleases which we typically don want in released package thoughts >>>discuss
logstash core beta vs release gem version upgraded from beta2 to ga which was in itself pita because apt thinks debian package for beta2 it looks like with gem version comparison isn greater than beta2 johnar flowr1a4 var log logstash sudo opt logstash bin plugin list bundler versionconflict bundler could not find compatible versions for gem logstash core in snapshot gemfile lock logstash core in gemfile logstash output kafka java depends on logstash core beta2 java >>>bug
plugins gemspec files includes all vendor files most plugins have this gemspec files specification the `vendor pattern will include all bundled gems if when building the gem locally when using the standard `vendor bundle path config for some plugins some files in `vendor need to be included like the geoip database in the geoip filter or jar files for other plugins we could either use other directories for non bundle gems vendored files like `vendor data` and `vendor jar` or we could exclude the gems specific directories in `vendor ph is this files specification normally standard across all plugins and updated with the plugins mass update scripts thoughts >>>bug v3.0.0
encapsulate the vendor files of the plugin inside sub directory we had few issues while pushing plugin gems to rubygems that were containing unneeded files the plugins were log bigger than they should be 20 50 megs in some case this scenario happen when we don use the bot to do the publishing some of the plugins requires downloaded files to work correctly like the https github com logstash plugins logstash filter geoip and the https github com logstash plugins logstash filter useragent plugin but the files are at the top level of the vendor directory this directory is on gitignore but it is included in the gemspec when we are generating new gem this vendor directory is also used when you do `bundle install path vendor` to isolate gems in multiple projects this is common in ruby suggest we move the required files into subdirectory of `vendor` so the gemspec explicitly include that directory instead of vendor what do you think of `vendor files` or `vendor required files` related issues https github com logstash plugins logstash input beats pull 31 https github com logstash plugins logstash codec json pull 17>>>v2.2.0
pattern not defined hello used logstash elasticsearch and grok when update to logstash and elasticsearch have issue timestamp 2015 11 20t12 23 57 757000 0300 message the error reported is host alert sensor node name not defined how can resolve it >>>needs_details unconfirmed
logstash core version constrains problem currently our gemspecs uses constrains on logstash core and soon logstash core event let call them the core gems using pattern similar to the problem with this notation is that logstash core gem release version rc1 is considered prior to because it is pre release version so gem version `2 rc1` would satisfy the 0` constrain obviously the intent in specifying 0` is to exclude anything ish but guess that semantically the current behaviour is arguable one possible solution is to specify 4` but then this notation does not allow any pre release versions to satisfy the constrain which is bad since we need to release pre release beta rc packages that uses pre release gem versions am not sure what our options are solution is required for current and future releases and should ideally be also applied to the branch this related to 4235 logstash plugins logstash output file 22 4188 4231 >>>bug discuss
snapshot doesn include the latest version of the logstash input beats november 17 2015 is the latest version see https rubygems org gems logstash input beats but it require concurrent ruby and logstash core need and is the only version that can meet the dependency requirements because it was more relaxed oh well versioning japanese ogre lock file from https github com elastic logstash blob gemfile jruby lock l249 l252 this should be fixed by https github com logstash plugins logstash input beats pull 30 which will relax the dependency think it would be best for us to be strict on the core and the related gems and be flexible on the library wdyt >>>blocker v2.1.0
obscure or unclear description of absent parameters in way there are no such options for plugins outputs elasticsearch plugin `bind host` `bind port` `cluster` `embedded` `embedded http port` `port` in the documentation for logstash or did you mean some other plugin because it unclear in the context btw why `cluster` has been taken away how should cluster discovery happen now >>>docs
core api v1 plugins gemspec broken hi while backporting https github com logstash plugins logstash output file pull 21 to the branch found the gemspec to be broken the logstash core requirement add runtime dependency logstash core that will fetch the last available dependency the fix for concurrent ruby was not backported to here we either have two options or force the version in the gemspecs as of add runtime dependency concurrent ruby or backport the fix the last two changes might require mass update of the plugins or that we have this into account when updating plugin see https github com logstash plugins logstash output file pull 22 for backport example related to 4188>>>bug known_issue
clean cache to empty previous entries this fixed intermittent core specs failures depending if `event to s` was called before the `event` specs >>>blocker bug
bug in coverage loading functions breaking the ci build if enabled after the merge of 3404 that uses common class for pack and unpack the coverage loader is broken as it basically load all files without preference see so for the pack unpack command this break when the common class is not laded before them this breaks the build as you can see in http build eu 00 elastic co job logstash regression master 493 for now coverage reports are disabled for regression test should be re enabled as soon as this is fixed >>>bug
added the code to set output to json format with stdout codec rub the example in this page shows the output in json format but does not explain how to set the stdout to show json output stdout codec rubydebug >>>docs
logstash not closing connections correctly hi have 60ish servers connected to my logstash instance they are connecting using lumberjack protocol via logstash forwarder java version https github com didfet logstash forwarder java am encountering an issue consistently where logstash will reject drop connection for some unknown reason before it retrieves the data that was sent by the server believe this is resulting in data loss using netstat to show all active lsf connections to logstash shows that the connection that was dropped has no pid attached but has data in it recv this is evidence that logstash is dropping the connection after it was established as otherwise lsf would not have send data to logstash as logstash is not closing the connections properly they are being left in close wait or syn recv with no pid attached logstash has abandoned them on the client side lsf thinks that it has an established connection to logstash still as logstash did not execute the correct shut down procedure and send the appropriate acks and continues to open new connections and send data this results in maybe or more close wait connections per client with no pid attached and full recv qs on the logstash server an unfortunate side effect of this problem of this is that once problem occurs with one server the effect snowballs and eventually all 60 servers will end up in this state with muliple close wait or syn recv connections with data piled up in their recv qs and no way to recover the data logstash is not recovering from the issue itself this problem occurs on both logstash and 0>>>bug
jps listing for logstash does not show logstash name jps listing for java processes on system running logstash shows the logstash process as main in it was not certainly the case with older logstash versions main is perhaps the jruby shell class think it would be appropriate to have logstash process register its name as logstash and be able to get listed and found accordinly when jps command is run thanks>>>enhancement
fix string interpolation memory leak when the event was serialized to string using `to s` call mostly happenning when doing logging each calls would generate new template each template was unique because it was containing the date the accumulation of templates was making logstash goes oom we aren cleaning the templates because they should stabilize to finite number >>>blocker bug v2.1.0
sincedb file is not updated properly am using logstash to parse files in folder what see in the terminal after some time message is coming logstash startup completed io console not supported tty will not be manipulated default settings used filter workers logstash startup completed there are three sincedb files created and each contains info for one file which is as follows 370201013 11863 65536 246 but ideally in each file there should be info for 10 files when press control got following message on screen 33msigint received shutting down the pipeline level warn 0mterminate batch job logstash shutdown completed after that the since db files contains the info for all the 10 files which is as follows 370201013 11851 65536 246 370201013 11863 65536 246 370201013 11869 65536 246 370201013 11899 65536 246 370201013 11881 65536 246 370201013 11857 65536 246 370201013 11887 65536 246 370201013 11905 65536 246 370201013 11893 65536 246 370201013 11875 65536 246 can you tell me how can get info for all the files in since db at the first instance >>>needs_details
should we use interactive prompts in logstash this relates to 3744 and 3404 where new interactive prompts were introduced interactive prompts are potential problem for integration tests and for automation in general should we instead default to safe behaviour and add an override command line switch and choose descriptive switch name for the context >>>discuss internal-cleanup v3.0.0
dry bootstrap environment rb logstash core lib logstash environment rb the `jruby and `windows methods have been duplicated by 3404 and we should remove them from `logstash core lib logstash environment rb` and make sure they are properly loaded at startup from `bootstrap environment rb` 4123 removed the automatic re injection of `bootstrap environment rb` into `logstash core lib logstash environment rb` so this need to be verified >>>internal-cleanup v3.0.0
core test broken see http build eu 00 elastic co view ls 202 job logstash regression 2x >>>bug
fix ci labels to show latest versions fix ci labels in the readme to report latest versions>>>enhancement
default plugins broken see http build eu 00 elastic co view ls 202 job logstash default plugins 21 console >>>bug
fixes build see http build eu 00 elastic co view ls 202 job logstash regression 20 109 jdk jdk8 label metal pool console this change fixed the concurrent ruby version in the lock file so test can run without conflicts related to 4210 >>>bug
master default plugins test broken see http build eu 00 elastic co view ls 20master job logstash master default plugins 759 console >>>bug
fix build in version branches by stub the warn local gems call in the update command this is necessary not for master but for the version branches where we actually use no local gems so this call will never be called fixes the broken build in jenkins errors after 4210 is merged >>>bug v2.1.0
update lock file with latest changes specially in plugins and dependencies fixing the concurrent ruby issue fix http build eu 00 elastic co view ls 202 job logstash regression 21 jdk jdk7 label metal pool console by updating the lock file similar fix should be applied to branch this will come in another pr https github com purbon logstash commit 3a25f5a99827dd8fed8ceb69f73bbcdadff6301e was added only as compliment so the test pass but better check 4212 for general version of it that is the one that will be merged relates to 4212 4206 where 3a25f5a99827dd8fed8ceb69f73bbcdadff6301e gets also introduced >>>bug
logstash log file showing received an event that has different character encoding than you configured hi all my logstash log file showing the below error received an event that has different character encoding than you configured if receive this warning and unable to get the text how do figure out what to set the charset to >>>needs_details
fix version path relates to 4123 this fixed the build artifacts bug introduced by 4123>>>bug
fix coverage paths for new structure by 4123 new paths from 4123 were not updated for coverage support and results in builds breaking>>>bug
edit link 404s for maintainers guide eg here https www elastic co guide en logstash current community maintainer html if you click `edit` it returns 404 but other pages checked also did this couldn find where the link should go to as at puppet camp and don really have time to dig sorry >>>docs
new lock file for 4191 this is the updated lock file for 4191 and should be merged in master and x>>>java_event
add jdbc input to default package list jdbc input is popular plugin and has been stable over the last few releases >>>v2.1.0
cannot replace field with value containing hash at the end using filter with following code if to addr mutate replace to addr to addr what is expected input to addr 123 output to addr 123 what is achieved input to addr 123 output to addr 123 if add any sign in the filter replace method behind hash the hash sign and added sign are correctly visible in the field value for example to addr works as expected if use hard coded number for example if to addr 123 mutate replace to addr 123 everything works as expected what happening here thanks for help >>>bug
pluggable agents this builds off jsvd patch 3872 to make the agent pluggable command line class for greater extensibility it will need to be either merged into jsvd branch or rebased after his branch is merged in the future notes for reviewers this should enable the following behaviors plugin authors can create an agent plugin by creating gem named `logstash agent myagent` and creating class that looks like users should be able to choose the agent they desire at startup with new cli flag agentname` >>>manageability v3.0.0-alpha1
core event class java rewrite overview rewrite the `event` class in pure java and its supporting classes like `timestamp` and `accessors` and keep 100 compatibility with current implementation of other core logstash components and all plugins purpose `event`is the main object which encapsulates data and provides and api for the plugins to perform processing on the event content having `event` implemented in pure java will improve performance make possible faster serialization by avoiding costly type conversion between jruby and java which in turn will help with an efficient persistence implementation also these critical and costly operations are related to the `event` where the java implementation should provide performance improvement fields reference getters and setters all `event` data manipulation in the config is done using the logstash field reference syntax ex foo bar baz this is implemented in the `accessors` class an optimized implementation should improve performance string interpolation `event sprintf the config syntax provides string interpolation in field references the ruby implementation was known to be slow and the java implementation should provides noticeable improvement string interpolation is heavily used in all configs strategy extract the current `event` implementation from logstash core and make it proper self contained gem which should be drop in replaceable with an alternate implementation this is completed in 4123 and the gem is `logstash core event` create the java implementation gem logstash core event java this is in progress in 4123 provide benchmarks have all core specs pass have all core plugins spec pass have all default plugins spec pass >>>discuss java_event performance-improvements v2.3.0
add new command that generate plugin this pr add plugin generator to the plugin manager so people could actually create their own scaffolds and start building their own plugin from there this makes the necessity to clone the example repos not the only option the templates added here are the current version from the example repos but templating the common vars to users can make some choices fixes 4266>>>enhancement needs_review plugin_manager v2.3.0
could not fetch specs from https rubygems org because china block the official source we use `https ruby taobao org to instead but logstash do not use the source set >>>bug
cannot run spec for plugin targeting logstash trying to publish plugin for logstash facing this issue on my own plugin but it is general to all plugin with core api v1 branch using the date plugin as example below steps to reproduce using fresh jruby install through rvm git clone https github com logstash plugins logstash filter date git cd logstash filter date checkout core api v1 bundle install bundle exec rspec and boom runtimeerror logstash expects concurrent ruby version and version is installed please verify this patch home philippe rvm gems jruby 22 gems logstash core java lib logstash patches silence concurrent ruby warning rb any idea >>>bug known_issue
multiline documentation changes multiline doc changes needed for overall messaging changes with stream identity implemented in multiline codec replace logstash forwarder instances with filebeat recommend using beats input>>>docs v2.1.0
plugin maintainer guide reviewed by alvin chen>>>docs
obfuscate the password in logstash config files some companies have requirement to obfuscate all the passwords in the configuration files >>>enhancement
add config file output to configtest this only works when the debug` flag is also enabled fixes 3243>>>needs_review v2.1.0
make all default plugins specs pass using logstash core event java related to 4123 make all tests pass for `rake test plugins` for core plugins using logstash core event java >>>developer-support java_event
jar dependencies cleanups in logstash core event java moving tasks from 4123 figure correct jar dependencies installation for dev vs release in logstash core event java lib logstash core event java figure correct jar dependencies loading for dev vs release in logstash core event java lib logstash core event java >>>developer-support java_event v2.3.0
document plugins dev gemfile requirements with new core gems structure related to 4123 when doing plugin development the plugin `gemfile` can should include both logstash core and logstash core event dependencies when needing to point to local source tree for both note that this is not required but if you need to test your plugin against local sources for either logstash core and or logstash core event you need to add them individually >>>developer-support docs java_event v2.3.0
fix concurrent ruby to in the gemspec we have removed the patch in 972e13d52e103dfaf5f8ab5c33ceb852402cde49 but we did not set the version to 2>>>v2.1.0
lsf filebeat doc items logstash docs logstash forwarder filebeat https github com elastic logstash search utf8 e2 9c 93 logstash forwarder paul remove lsf from public roadmap https www elastic co guide en logstash roadmap current index html status ongoing https github com elastic logstash docs pull 137 alvin lsf github readme https github com elastic logstash forwarder note jordan lsf blog https www elastic co blog logstash forwarder released note jordan close issues and prs in lsf repo that are marked closing suggested jordan ph >>>docs v2.1.0
rake test plugins on non windows fails on logstash input eventlog crashes trying to require the win32 eventlog gem this is because the windows specific gem has been moved from the `require` method to the file top not sure if we should add windows platform check or else jsvd ph thoughts >>>java_event
new test for integration testing last year have created `logstash kitchen` https github com elastic logstash kitchen to have minimal integration testing on top of the plugin manager and some frequently used plugins was useful at the time when we were messing with the api this implementation had few problems it was external to logstash making it harder to maintain it was slow 15 17m to run on my machine it was hard to run the test in isolations you had to run the full test suite using the plugin command is destructive we needed some kind of isolation reproducing errors and debugging was hard migrated theses tests inside logstash and changed how it behave few of the changes the tests are inside logstash making them linked to specific version of the code could be run on pull request since theses tests use the plugins manager it can affect the developer environment use `rsync` to clone the current directory to temporary directory where the tests are executed this change has two benefits it leave the current developer installation untouched but it allow you to see how the logstash installation modifies the files and this operation is fast using temporary directory allow you to reproduce the issue manually with the same setup as the test the tests can also be run in the current directory without requiring the need for rsync this is useful for jenkins running the tests takes minutes on my machine down from 17 minutes bin rspec works with this new setup this mean you can run the tests in isolation like this `bin rspec integration spec logstash config file input to file output spec rb 15` they are normal spec files you will be able to use `longshoreman` to run services with docker image like elasticsearch have consolidated some expectations in the same example to reduce the number of external process to start caveats when you write new specs they will need to manage their own dependencies make multiples `expects` on the same result this will reduce the number of external calls and make the suite faster to run the temporary directory is inside logstash am open to put it somewhere else what is left the elasticsearch integration test doesn work need help here to setup docker longshoreman to fix it this setup could possibly work with drip to make it faster it doesn currently work on my machine but didn investigate it too much expectations this is wip in progress have copied all the tests from kitchen and moved it inside logstash and fixed them to be able to run in this new environment know the test suite could be improved this is not the goal of this pr want feedback on the way have made it work and to see if people are interested in using it and improving it am aware that some files need cleanup ie `logstash helpers` this will be done when the wip tags is removed how to make it run on correctly bootstrapped test environment run this command `rake test integration local` this task will setup the initial environment if you call `bin rspec` on suite it will check if the `integration run` directory exist if it exist it will use it as the target of the test >>>v2.1.0
fix tins to the release is the latest release to support ruby fixes 4163>>>v2.1.0
tins dependency from coveralls requires ruby tins is dependency from `coveralls` which is only installed when running the tests on november 10 tins was released and they now require ruby in their gemspec https github com flori tins blob master tins gemspec l19 this change is breaking our build since coveralls only need think its safe to pin the tins version on >>>v2.1.0
unable to find jruby download logstash from here test output windows also alert to ask me how to open rb` have ruby installed but not familiar with it because it says `if you are user this is bug` so think don need to install jruby google also do not tell me how to go through it how do solve this >>>needs_details
feature jdbc output the previous ticket was closed with the release of the jdbc input this is request to track interest in an official jdbc output plugin related https github com elastic logstash issues 2476 issuecomment 128845720>>>enhancement needs_review new-plugin
set jrjackson to v0 this would be for v2 and v1 6>>>v1.5.5 v2.1.0
logstash runtimeerror can add new key into hash during iteration os centos logstash java openjdk 65 filter filter if type accesslog grok match message combinedapachelog number responsetime ms kv source request field split urldecode all fields true mutate split search text tags date match timestamp dd mmm yyyy hh mm ss logstash err runtimeerror can add new key into hash during iteration at org jruby rubyhash java 992 find or create target at opt logstash vendor bundle jruby gems logstash core java lib logstash util accessors rb 119 each at org jruby rubyarray java 1613 inject at org jruby rubyenumerable java 852 find or create target at opt logstash vendor bundle jruby gems logstash core java lib logstash util accessors rb 119 lookup or create at opt logstash vendor bundle jruby gems logstash core java lib logstash util accessors rb 98 set at opt logstash vendor bundle jruby gems logstash core java lib logstash util accessors rb 63 at opt logstash vendor bundle jruby gems logstash core java lib logstash event rb 146 filter at opt logstash vendor bundle jruby gems logstash filter urldecode lib logstash filters urldecode rb 36 each at org jruby rubyhash java 1342 filter at opt logstash vendor bundle jruby gems logstash filter urldecode lib logstash filters urldecode rb 36 multi filter at opt logstash vendor bundle jruby gems logstash core java lib logstash filters base rb 152 each at org jruby rubyarray java 1613 multi filter at opt logstash vendor bundle jruby gems logstash core java lib logstash filters base rb 149 cond func at eval 326 each at org jruby rubyarray java 1613 cond func at eval 321 filter func at eval 239 filterworker at opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 219 start filters at opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 154 kind regards michael >>>needs_details
add provision for worker threads based on threadsafe workers notes to reviewers allow the default to be set as function of cores without checking thread safety of filters allow the command line setting of 6` without checking as above move the check and alteration of thread count into the `start filters` because this allows for dynamic changes to the config before it was only checked at pipeline start after ph and colin initial review override logic from command line args refactored see agent rb and pipeline rb fixes 4130>>>v2.1.0
nextgen pipeline codename big gulp moved from https github com elastic logstash pull 4153 moved to 4254 attn this is no longer poc but production ready code this is pr that aims to accomplish the following objectives provide an in memory implementation no persistence of the pipeline described in https github com elastic logstash issues 3693 be completely backward compatible with current logstash plugins nothing should break allow for complete pipeline snapshotting even with the elasticsearch plugin to address concerns raised by jsvd in https github com elastic logstash pull 4051 this would allow forced shutdowns without losing data this would require the elasticsearch output to implement `receive multi` and no longer use its own internal queue expose new batch interface for filters and output plugins allowing them to process events in microbatches for efficiency this could have very significant potential for speed improvements for filters like the useragent filter which would only have to lookup the number of unique keys per batch vs each key individually this would also obviate the need for separate buffer in the elasticsearch output would say that along with these changes we should contemplate adding new plugin config option which would by default set the number of workers for the plugin to be the number of worker threads that will give the best user experience for this notes on implementation this is 90 the system described in https github com elastic logstash issues 3693 the one exception to this is that output plugins are assumed to be not threadsafe this was necessary to make it backward compatible with series plugins when the of output workers is equal to the number of worker threads specified with w` the behavior should be very similar to what the original behavior was think the default worker fix described above might actually be long term solution here persistence examples since this is just poc the pipeline shutdown persistence is demonstrated in the writing of two files on shutdown update this functionality remains in the `dump inflight` function but is currently never called we may enable this in future release tmp ls current batches the contents of in memory buffers before the shutdown sequence is initiated fast shutdown as described in https github com elastic logstash pull 4051 could simple write this then `exit` safely tmp ls current batches post close this is just there for debugging in the poc this is written after clean shutdown it will always be empty unless there bug in the pipeline notes for reviewers this pr involves small number of changes to the ast to enable batch oriented processing for each batch we execute the filters one by one accumulating new batch of filtered events execute `output func` once per each function which no longer invokes the output func but rather returns an array of outputs that the event should be sent to we use the info from the step above to build separate batches per output as seen in `output batch` in the pipeline this pr adds new cli options `batch size` and `batch poll wait` to control the new features of the pipeline please verify my performance results for yourself currently using this config https gist github com andrewvc b25097d19aa50df8e05f and running it with `time bin logstash that config conf` then comparing it with logstash set the default batch size to be 125 to match the elasticsearch output defaults assuming four workers 125 500 this seemed like safe default performance used the following config to test this thing out `bin logstash input generator filter mutate add field foo bar output http http method post url http localhost 4567 hi workers note that this requires little web service to hit used the following performance also worth noting this new pipeline seems in at least one micro benchmark to be as much as 63 faster doing further benchmarking was able to get the throughput up to 74k using batch size of 40 the default is 20 upping the batch size to 200 made it go down to 71k and upping it to 2000 brought it down lot to 50k so batch size has big impact probably due to not being able to use memory the cache as efficiently we ll have to do further tests with different messages sizes as well >>>next-gen_pipeline resiliency v2.2.0 work_in_progress
include jdbc logstash input plugin by default this plugin is very useful and most of our sources use it we re on secured non internet connected intranet and so have to install this plugin manually at home tar up the logstash folder transfer to usb key and walk it into work to install on our secure network additionally we just found bug was introduced in https github com logstash plugins logstash input jdbc issues 77 so ll have to repeat the process once new release comes out >>>enhancement packaging v2.1.0
moved pipeline poc moved to https github com elastic logstash pull 4155>>>resiliency v2.2.0 work_in_progress
make sure all example repos have utf encoding header this should be at the top of each of the example plugin files this is master issue to cover this for each of the plugins >>>adoptme enhancement low_hanging_fruit v2.1.0
logstash kafka input illegalstateexception hi exception kafka consumer caught exception java javalang illegalstateexception iterator is in failed state appear sometimes can work again and still throw this exception when run logstash kakfa consumer with config input kafka zk connect 2181 group id grouplog topic id topiclog codec json consumer threads rebalance max retries queue size 512 version logstash 0>>>needs_details
new aws kinesis plugins https github com codekitchen logstash input kinesis https github com samcday logstash output kinesis https github com elastic logstash contrib pull 56>>>needs_review new-plugin
add daily run on jenkins for the master branch we had an issue when gem was updated and made logstash unusable 4141 think this would have been catched if we do daily run of logstash tests >>>tests-infra
pass pipeline started and pipeline shutdown complete log messages to warn level presently by default warn level in logstash logs there is no information to say when logstash is started and when it is stopped if we activate verbose option to set info level we have more than 7500 lines of logs just at startup so it too verbose for production needs my proposition to easily add this simple information in logs is to pass pipeline started and pipeline shutdown complete log messages to warn level thereby we could have such logs by default >>>enhancement
update release notes for breaking changes in es ref https discuss elastic co dots in field names and elasticsearch 33791 and https discuss elastic co elasticseach geoip problem 33424>>>docs
concurrent ruby gem pin is not precise enough from plugin bundle exec rspec runtimeerror logstash expects concurrent ruby version and version is installed please verify this patch users jls rvm gems jruby 22 gems logstash core java lib logstash patches silence concurrent ruby warning rb>>>v2.1.0
logstash core event java event array field assignment problem in the new logstash core event java event implementation it is not currently possible to modify an array field in single operation because the array field returned is now copy of the original array for example previously it was possible to do but now the following has to be done this point do not know if it will be possible to support the old assignment style this still need to be investigated this is related to 4123 >>>internal-cleanup java_event
execute command failing if no space between and bin sh unexpected eof am calling shell script with some arguments the entire command is enclosed in quotes and the arguments are enclosed in ticks the command had been working fine in the past with version and or the command quit working when we upgraded to to fix the command had to insert space between the final tick and quote becomes failing command command apps logstash server conf alerting logstash xmatters sh product alertkey alertmessage alertseverity timestamp error logged bin sh line unexpected eof while looking for matching bin sh line syntax error unexpected end of file argument values as captured in json with output rule product bgs alertkey server configuration error alertmessage we received request that had promotion level header of monitoring but the server had promotion level environment variable of prod this means the f5 or the server is mis configured alertseverity fyi timestamp 2015 10 30t19 31 55 740z >>>packaging
field value comparison should be fault tolerant when the field doesn exist the following config when field `ver` doesn exist logstash will throw exception at runtime >>>needs_details
logstash docs enhancements for logstash plugin doc improvements https github com elastic logstash issues 4134 lsf filebeat doc changes https github com elastic logstash issues 4168 offline plugin documentation https github com elastic logstash issues 4086 pere paul shutdown semantics doc update joao command flag changes verbose config test https github com elastic logstash issues 3243 done multiline doc changes https github com elastic logstash issues 4185 guy ph>>>docs v2.1.0
fix 1574 in some cases it seems that the file permissions for the `logrotate` configuration file are not set properly this should address those cases as suggested in 1574 rotate the `logstash err` and `logstash stdout` files also fixed 1574 >>>needs_review v2.1.0
fix logrotate permissions after install in some cases it seems that the file permissions for the logrotate configuration file are not set properly this should address those cases fixes 3490>>>needs_review v2.1.0
logstash plugin doc improvements new logstash plugins parent section restructure under here anything related to plugins migrating plugins from links into table structure https github com elastic logstash issues 3418 contributing patch section submitting your logstash plugins section>>>docs meta v2.3.0
enhancement for windows testing enhancement for 3994 remove duplicated code fix messaging >>>enhancement tests-infra windows
logstash cant connect to elasticsearch on 127 am doing brand new clean install of logstash and elasticsearch version and am having issues getting logstash to connect to the elasticsearch server on the same host there is no firewall installed and can return elasticsearch server information using curl any help guidance would be greatly appreciated these are the errors get timestamp 2015 11 03t13 20 18 512000 1000 message failed to flush outgoing items outgoing count 72 exception jrjackson parseerror backtrace com jrjackson jrjacksonbase java 83 in `generate opt logstash vendor bundle jruby gems jrjackson lib jrjackson jrjackson rb 59 in `dump opt logstash vendor bundle jruby gems multi json 11 lib multi json adapters jr jackson rb 20 in `dump opt logstash vendor bundle jruby gems multi json 11 lib multi json adapter rb 25 in `dump opt logstash vendor bundle jruby gems multi json 11 lib multi json rb 136 in `dump opt logstash vendor bundle jruby gems elasticsearch api 14 lib elasticsearch api utils rb 102 in bulkify org jruby rubyarray java 2414 in `map opt logstash vendor bundle jruby gems elasticsearch api 14 lib elasticsearch api utils rb 102 in bulkify opt logstash vendor bundle jruby gems elasticsearch api 14 lib elasticsearch api actions bulk rb 82 in `bulk opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch http client rb 56 in `bulk opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch rb 353 in `submit org jruby ext thread mutex java 149 in `synchronize opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch rb 350 in `submit opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch rb 382 in `flush opt logstash vendor bundle jruby gems stud 22 lib stud buffer rb 219 in `buffer flush org jruby rubyhash java 1342 in `each opt logstash vendor bundle jruby gems stud 22 lib stud buffer rb 216 in `buffer flush opt logstash vendor bundle jruby gems stud 22 lib stud buffer rb 193 in `buffer flush opt logstash vendor bundle jruby gems stud 22 lib stud buffer rb 112 in `buffer initialize org jruby rubykernel java 1479 in `loop opt logstash vendor bundle jruby gems stud 22 lib stud buffer rb 110 in `buffer initialize level warn here is copy of my input and output configuration 02 input logcourier conf 99 output conf >>>bug
reset default worker to if using non thread safe filter see background here https discuss elastic co multiline issue 33349 ls will fail to startup in when using ml filter it should instead revert to old behavior of setting workers to and start the pipeline using the config specified in the above discuss link >>>bug v2.1.0
create plugin logstash filter transducer hi to create the https github com purbon logstash weather demo had the necessity to actually break one event into several others my situation was not possible or at less was not aware how to do it with the current plugin set basic use case is from given event that include set of columns of interest this plugin will build new event per column with the column of interest and the rest of columns not involved not of interest like this we avoid having to rework data formats that are column oriented into raw oriented one link to the actual repo https github com purbon logstash filter transducer rubygems org https rubygems org gems logstash filter transducer cheers >>>new-plugin
creating new field using logstash filter have started writing my own logstash filter based on the example filter provided on github https github com logstash plugins logstash filter example my new filter reads from jar file called classficiation jar would like to take the values coming from text and based on that classify these texts this will require creating new field and adding the classification in it the operation should result in the following input text this is happy thought classification positive however not quiet sure how should create this new field as you can see the class takes one parameter which is text would really appreciate guidance on how can create the new field for the output from this logstash filter my problem is that cannot find any sort of guide other than the following https www elastic co guide en logstash current how to write logstash filter plugin html logstash 20filte that might explain on detail how to write filter if was not an expert in jruby please help thank you >>>question
meta general implementation for handling exceptions at all levels in threads and plugins >>>work_in_progress
json parsing issue with `target` hi ve that kind of filter which works correctly it returns me multiples message per minutes with the tag jsonparsefailure` any idea why it fails when adding `target` >>>bug unconfirmed
unable to remove field on metadata fields would like to be able to clear unset any fields that any upstream process or config may set in metadata that clash with my configuration as workaround one can use mutate replace but remove field seems more natural since there is no way to replace field with `null nil undefined` perhaps that simpler change if touching remove field seems too dangerous in the mean time might want to update the docs for remove field to make it clear that it will not operate on metadata might also want to come up with some rules of engagement for using metadata it was my understanding that metadata was namespace reserved for my configuration but it possible for inputs filters and outputs to modify it as well please refer to this issue for more background https github com logstash plugins logstash input beats issues issuecomment 152673153 >>>bug
logstash core logstash core event logstash core event java this replaces 4100 and adds the logstash core event java gem as pure java implementation replacement of logstash core event purpose this is wip pr which extracts and separate logstash core and logstash core event as proper gems and also adds the logstash core event java gem which is drop in replacement of logstash core even expectations this is wip pr to gather feedback on the idea not everything has been tested and some parts have been duck taped to work with the new structure changes all current logstash core gem code in now moved in the `logstash core directory all current `event` related code has been extracted from logstash core and moved into its own logstash core event gem into the `logstash core event directory the java rewrite of logstash core event is in logstash core event java and can drop in replace logstash core event see `logstash core event java reamde md` also all specs have been reorganized into the standard spec directory structure naming for all `spec `logstash core spec` and `logstash core event spec` directories all spec files are in the exact same path as the corresponding source file no more discrepancy between the `lib and `spec dir structures todo make all core tests pass for `bin rspec spec logstash core spec logstash core event spec logstash core event java spec` make all tests pass for `rake test plugins` for core plugins using logstash core event fix tests rake tasks fix builds rake tasks>>>java_event
update logstash filter aggregate plugin documentation into logstash reference documentation hi have recently added enhancements to asciidoc documentation in logstash filter aggregate plugin could you update logstash reference documentation to integrate these enhancements to do this could you update logstash reference and logstash reference master using logstash filter aggregate master branch could you update logstash reference using logstash filter aggregate core api v1 branch >>>docs
redis input plugin host as an array from tdesrochers on october 30 2015 10 54 is there reason the redis output can use an array but the redis input cannot would like to use my domain name dns entry for many ip with the same domain name in the redis input so that can spin up new nodes as needed without changing any of my configurations if understand the current setup correctly need to have an input statement that includes each redis nodes ip address on each of my indexers such as input redis host data type list key bro redis host data type list key bro redis host data type list key bro redis host data type list key bro to help my current setup is have multiple ids sensors sending logs to local redis queue on the sensor that local queue sends data to central redis queue with redis nodes each on their own vm have logstash indexers reading from that queue and sending into multi node es cluster as stated earlier think having the redis input able to read hostname as an array or from domain name that has multiple ip addresses would be helpful in setup like mine because it would allow me to spin up new node when needed and just add that nodes ip address to my dns server and not have to change any config in my elk stack what would like to see is one statement on each of my indexer nodes that says input redis host domain name data type list key bro when redis failed to connect to one node in the array it would move onto the next and recycle the list when completed this would be greatly beneficial when scaling cluster because it would require no interaction with the logstash configs on any node and only adding nodes to dns entry just thought and please if have this information wrong correct me copied from original issue elastic elasticsearch 14379 >>>enhancement
allow command line arguments for parameters currently e` only allows you to pass in the entire block eg entire input block as parameter there are cases like the jdbc input plugin where it is useful to be able to pass in just the value for single parameter see https github com logstash plugins logstash input jdbc issues 66 issuecomment 152296564 on why e` is not an ideal workaround for the use case >>>enhancement
bin plugin help shows incorrect information for update subcommands install install plugin uninstall uninstall plugin update install plugin list list all installed plugins>>>bug low_hanging_fruit plugin_manager
reserved doesn do anything understand why this constant was created but its not used anywhere think we lived without that concept for quite while >>>v2.1.0
deprecated method `to event` in input base no current plugins uses this and it was deprecated since at least 2>>>v2.1.0
unused requires in outputs base>>>v2.1.0
unused constant `configsort` this was probably used to have some sort of preference when defining multiple options but can find trace of it in the actual code >>>v2.1.0
logstash log4j system not initialized properly when starting logstash getting cat var log logstash logstash err log4j warn no appenders could be found for logger org apache http impl conn poolinghttpclientconnectionmanager log4j warn please initialize the log4j system properly log4j warn see http logging apache org log4j faq html noconfig for more info freshly installed from website rpm qa grep logstash logstash noarch looks to be the same issue as https logstash jira com browse logstash 302 >>>bug v2.1.0
logstash event should not allow nil keys currently it is possible to create an event with nil keys using the following code `logstash event new nil 123 this should fail it really screws with things like the elasticsearch output the accessor does not have this error but should raise better error message it just happens to fail by trying to invoke `nil starts with >>>bug crashes design
wip add stream identity support to ls this after discussion on 4074 notes for reviewers you will see commented out lines that use concurrent hash they are so because could not seem to require the correct path to make the hash class appear in the concurrent module the intention is still to use concurrent hash there are some inner classes and modules done so to keep it self contained >>>enhancement v2.1.0
wip logstash core and logstash core event extraction purpose this is the wip groundwork for the proper extraction and separation of the logstash core and logstash core event gems this is mainly source tree reorganization to be able to correctly extract the logstash core event code to enable drop in replacement or update expectations this is an early wip pr to gather initial feedback on the idea not everything has been tested and some parts rakelibs have been duck taped to work with the new structure changes all current logstash core gem code in now moved in the `logstash core directory all `event` related code has been extracted from logstash core and moved into its own logstash core event gem into the `logstash core event directory also all specs have been reorganized into the standard spec directory structure naming for all `spec `logstash core spec` and `logstash core event spec` directories all spec files are in the exact same path as the corresponding source file no more discrepancy between the `lib and `spec dir structures all specs are passing using >>>v2.1.0
graphite output sending metrics every to seconds hello we re seeing an issue where the graphite output for logstash tried both and are sending metrics far too often our graphite flush interval is 10s but it looks like logstash is sending data every to seconds in less than 60 seconds logstash sends over 30 metrics haven found way to set flush interval for the graphite output to possibly curb this output ve cleaned up the tcpdump data to only show the timestamp and the metric value ve also attached the relevant sections of the configuration file please let me know what other information you need to help resolve this issue time stamp metric value 18 36 06 218506 2014 0694022039097 18 36 09 109487 0003298800007348804 18 36 09 126179 01725653926907217 18 36 11 218657 1952 9458036527249 18 36 14 109839 00027923739202897867 18 36 14 126638 01725653926907217 18 36 16 218971 18 36 19 108619 00027923739202897867 18 36 19 126874 014607345126126827 18 36 21 219442 2057 18 36 24 109335 00025691080289192054 18 36 24 127625 014607345126126827 18 36 26 218453 2029 6873941105234 18 36 29 109612 0002363693492586465 18 36 29 127553 012364850698436342 18 36 31 218892 2034 6696349903889 18 36 34 109475 0002363693492586465 18 36 34 126486 012364850698436342 18 36 36 218827 2005 5122608578213 18 36 39 109726 0002000823344717311 18 36 39 126732 01046662014722731 18 36 41 219014 1971 8579746512391 18 36 44 109592 0002000823344717311 18 36 44 126960 01046662014722731 18 36 46 219230 1926 1987000074062 18 36 49 109215 00018408463429671232 18 36 49 126185 009629755406503232 18 36 51 218614 1916 620124821668 18 36 54 109384 00016936603960377174 18 36 54 126794 009629755406503232 18 36 56 218765 1910 6858112952668 18 36 59 109545 00016936603960377174 18 36 59 127051 008859802675999827 >>>needs_details
add specs for retryable module at some point the `retryable` module authored some time ago got included in monster pr and squashed all authors details were lost and its specs have been lingering on my system so thought push them for the sake of good coverage `retryable` correclty implements configurable exponential backoff >>>needs_review
reversing the launch order of plugins in the pipeline looking at the pipeline run method we can see what if the start up order was reversed like this inputs should be the last thing to be started in the pipeline this has very nice property if problem with consumer can be detected at `output register` time then we can immediately terminate logstash before it starts receiving events currently logstash can receive an event and in the meantime some output plugin will raise an exception during register` but logstash now has inflight events bomb >>>discuss
deb package installer doesn create etc init logstash when it has been manually removed tested with logstash all deb on ubuntu precise 12 04 lts steps to repro remove existent logstash with root precise64 var lib logrotate apt get remove logstash reading package lists done building dependency tree reading state information done the following packages will be removed logstash upgraded newly installed to remove and 66 not upgraded after this operation 143 mb disk space will be freed do you want to continue reading database 62611 files and directories currently installed removing logstash processing triggers for ureadahead because it config file etc init logstash will not be removed root precise64 tmp ls al etc init logstash rwxrwxr root root 3963 aug 20 20 21 etc init logstash now remove etc init logstash root precise64 tmp rm etc init logstash install it again root precise64 tmp dpkg logstash all deb selecting previously unselected package logstash reading database 51099 files and directories currently installed unpacking logstash from logstash all deb setting up logstash processing triggers for ureadahead we can see that etc init logstash will not be installed root precise64 tmp ls al etc init log ls cannot access etc init log no such file or directory it seems that we are blindly following var lib dpkg info logstash list even if file doesn exist when we use apt get purge logstash this file gets created again before doing new installation perhaps this file should be declared as init and not config >>>packaging
encoding issue in jruby on windows produces non utf8 from ipsocket recvfrom problem observed in https github com logstash plugins logstash input gelf pull 23 issuecomment 151114545 and reported in https github com jruby jruby issues 2558 issuecomment 151102656 until this is fixed it necessary to extend the monkey patch done in https github com elastic logstash pull 2507>>>bug windows
fix doc generation for obsolete settings we introduced `obsolete` in 3977 which means we need to remove these obsolete configs from docs previous fix was broken this one properly removes configs which are obsolete see https www elastic co guide en logstash plugins outputs elasticsearch html new docs pushed to elastic co>>>docs v2.0.0
new appdynamics input plugin https github com ibm itoadev logstash input appdynamics>>>needs_review new-plugin
new zendesk input plugin https github com ppf2 logstash input zendesk>>>needs_review new-plugin
handling logstash offline plugin installs core logstash distribution with all latest plugins installed shipped at regular minor release cadence option to install plugins on an offline box from local rubygems mirror option to install plugins on an offline box from an online logstash staging instance>>>enhancement meta v2.1.0
change how we set the max heap size this pr change the name of the variable to set to change the maximum heap size on window to `ls heap size` this replace the ls min mem and ls max mem option also we change the default size of the heap from 500m to 1g fixes 3134 >>>v2.1.0 windows
running logstash from symbolic link fails possible fix workaround included logstash fails when it is invoked from symbolic link usr bin logstash for example the following line in bin logstash does not resolve symbolic links line 22 cd `dirname 0` pwd bin logstash lib sh it could be changed to something along the lines of cd dirname `readlink 0` pwd logstash lib sh similarly in bin logstash lib sh line logstash home cd `dirname 0` pwd it could be changed to something along the lines of logstash home cd dirname `readlink 0` pwd this issue occured on centos using logstash >>>bug packaging
update elasticsearch output parameter names in setting up an advanced logstash pipeline docs the setting up an advanced logstash pipeline documentation advanced pipeline asciidoc https github com elastic logstash blob master docs asciidoc static advanced pipeline asciidoc still refers to the obsolete `host` and `protocol` options both replaced by `hosts` in couple of places technically the old options still work but the documentation should recommend the current options >>>docs
kafka input spinning on cpu trying beta3 here my config debug mode logs after start up only show this logstash consumes full cpu in idle more after start up all in user mode messages from topics appear there no issue with it haven tried kafka input with earlier releases could be an old issue >>>bug v2.1.2
fix protocol defaults as per here https www elastic co guide en logstash current plugins outputs elasticsearch html plugins outputs elasticsearch protocol node is default we need to fix that second point reported here https twitter com jrhunt status 657097315446951936 >>>docs low_hanging_fruit
meta codec stream identity this issue follows up the discussion in logstash plugins logstash codec multiline 10 about supporting stream identity in codecs to solve the problem of using the multiline codec in conjunction with the file or lumberjack inputs for example since this issue involves many plugins and is an important issue to solve we should keep track of it here my last suggestion https github com logstash plugins logstash codec multiline issues 10 issuecomment 149993542 is to do the following replace the codec instantiation in the config to instead instantiate new codec multiplexer class which will ultimately expose backward compatible decode method like `decode data stream identity nil this new multiplexer `decode` method would take care of doing the bookkeeping of the stream identities vs actual codec instances this would allow to not touch update all plugins where dealing with stream identities in codecs is not important and simply update the ones like file lumberjack inputs to pass the values which makes sense as `stream identity` to the `decode` method for example for file input the current code would become for the codecs nothing would change and we can all assume single codec instance will always deal with single consistent stream >>>discuss
host setting does not exists in elasticsearch input https www elastic co guide en logstash plugins inputs elasticsearch html plugins inputs elasticsearch docinfo the documentation is wrong the `host` setting doesn exists it should be `hosts` should be >>>docs enhancement
bin plugin update should select latest compatible version and not just try to update to absolute latest version which might fail with message similar to we can now have parallel versions sequences for plugins those compatible with logstash core api v1 and logstash core api v2 currently `bin plugin update` will always select the latest absolute version to propose for update but instead it should select the latest compatible version this relates to 3744 3993 3853 >>>plugin_manager
ls heap size and ls java opts are missing from windows script currently the only way to setup the memory for logstash on windows is to manually set the `ls min mem` and `ls max mem` environment variables worse to set any `java opts` windows users are forced to modify the `setup bat` script or to add to `java opts` directly which is bad idea >>>bug windows
how should we rescue java throwables in the plugin threads and the pipeline thread background any java throwable exceptions errors thrown by jvm jruby extensions and jruby are wrapped by javaproxy and so are subclassed of object and not exception this means that `rescue exception e` will not rescue them only `rescue object e` will catch java throwable instances this has big implications for how we log all errors and how to decide whether to raise retry or not nothing we should revisit the change that ph made 3990 and reconsider jsvd pr 2386 >>>discuss
add simple integration test infra to logstash core we have good system wide integration tests in jenkins using logstash kitchen https github com elastic logstash kitchen repo these are end end tests infrastructure which validate things like installing uninstalling plugins smoke tests for es file input kafka etc we also need simple integration test bed in logstash core which tests multiple combinations of input filters codec and output using various test data sets we should aim to keep the inputs and outputs simple maybe just use the generator input or file input and file output this will help us catch issues like 4048 which could be reproduced using file input grok filter and json codec suggest using `spec integration` dir for adding these tests should also add `rake tests integration plugins` which will install dependencies run these simple integration tests ultimately it should be easy enough to drop in config file plus results expected output fixture and the rest should be taken care of by the infra >>>tests-infra
bump versions to use latest jrjackson and beats>>>v2.0.0-beta3
update jrjackson version closes 4059>>>v2.0.0-beta3
bump jrjackson version to to fix serialisation problem after grok filter>>>blocker v2.0.0-beta3
build new filter plugin using sqlite3 gem for ruby but can be installed by bin plugin hi wanted to use logstash to parse scsv file and query sqlite db in the filter so building gem file using sqlite3 gem dependency within my plugin directory use ruby to do bundle install and gem build to have my logstash filter myplugin gem had no probleme to resolve the sqlite33 dependency then use bin plugin install it can continue with problem validating home admin logstash filter geoiata logstash filter geoiata gem installing logstash filter geoiata error bundler installerror retrying 10 an error occurred while installing sqlite3 11 and bundler cannot continue supposing maybe it because bin plugin method use jruby bundler but my sqlite3 is ruby gem or it because have network issue also have tried directly download sqlite3 11 have no problem >>>needs_details
logstash input beats is now part of the default plugins>>>v2.0.0
grok failure beta2 did an upgrade of one node in our logstash cluster which was running beta1 to beta2 today very large issue could be immediately seen all the matched fields appear to not be extracted correctly here is screenshot from kibana 19 41 08 https cloud githubusercontent com assets 468579 10563295 808e9f7e 75d0 11e5 8c41 c952603ac20d png the only fields that work are those explicitly typed with the grok syntax pattern name type it would appear the start of the log message is being used these log messages parsed start with number this pattern and configuration worked fine with beta1 this may be grok or core related so am opening the bug here until cause identified there doesnt seem to be any relevant commits in the plugin that can see >>>blocker bug v2.0.0-beta3
logstash worker` thread crash am running logstash on oracle java on ubuntu trusty 14 04 lts after day or two of ingesting logs from 12 servers logstash stops processing new log entries the process is still running but is not consuming any noticeable cpu time the `stderr` log only contains this is similar to issues 3711 and 3811 but it is always only the worker` thread affected the `stdout` log only contains and the `logstash log` is has no new entries since the `sigterm received shutting down the pipeline message last time logstash was restarted sending `sigquit` to the logstash process reveals thread dump notably missing the worker` thread normally present in an operational logstash process and all other normally running threads are `waiting` the complete thread dump is available as gist https gist github com jstangroome 0fb2a9fa4ff350804db5 normally restarting logstash which requires `sigkill` ing the current process brings it back to life in the most recent occurence the restarted process failed almost immediately after processing only relatively small number of logs waiting in the redis input list the logstash host has 2gb free memory and runs at 25 cpu during normal operation at the point of failure cpu usage falls >>>needs_details
add shutdown controller to force exit on stalled shutdown start logstash with force shutdown to force exit on stallled shutdown stall detection kicks in when sigterm sigint is received check if inflight event count isn going down and if there are blocked blocking plugin threads abort logstash if stall is detected and force shutdown is enabled fixes https github com elastic logstash issues 3451 note to reviewers still working on the tests for the shutdowncontroller to experiment with the shutdown controller use pipelines like `bin logstash input generator count 10000 filter ruby code sleep output tcp port 3333 host localhost workers force shutdown` or `bin logstash input generator filter ruby code sleep 10000 output stdout codec dots force shutdown` with and without force shutdown >>>needs_review pipeline-stalls v2.1.0 work_in_progress
added jenkins badges for all main branches added jenkins status badges to show the current build status of the current three main branches of ls >>>enhancement tests-infra
elasticsearch rc1 displaying strange data from robertsmarty on october 16 2015 10 21 have logstash beta2 sending aws detailed billing data into elasticsearch rc1 so can test my setup ve setup template so all fields are doc values logstash rubydebug output looks great data is as expected elasticsearch dynamic mappings look great data types look great fields are not analysed all good then look at the data weird here small sample hopefully it ll make sense to someone index aws billing 2015 08 31 type detailed with resources and tags id 60012830 588738232867 score source version timestamp 2015 08 31t23 00 00 000z host pbneelk4001 type detailed with resources and tags invoiceid 6001283 payeraccountid 60012830 linkedaccountid 60012830 recordtype 6001283 recordid 60012830 588738232867 productname 60012830 588738232867 rateid 600128 subscriptionid 60012830 pricingplanid 60012 usagetype 60012830 58873823286 operation 600128 availabilityzone reservedinstance itemdescription 60012830 588738232867 128881676082 usagequantity 00138889 blendedrate blendedcost 00138889 unblendedrate unblendedcost 00138889 resourceid null aws cloudformation logical id null aws cloudformation stack id null aws cloudformation stack name null user env null user environment null user name null user project null user purpose null user role null user user null user workspace this is what rubydebug looks like it not the same record though version timestamp 2015 09 07t08 00 00 000z host host4001 type detailed with resources and tags invoiceid xxx830 payeraccountid xxx867 linkedaccountid xxx944 recordtype lineitem recordid 40214935098354950258880757 productname amazon simple storage service rateid 3510841 subscriptionid 112242859 pricingplanid 505699 usagetype aps2 datatransfer out bytes operation readbucketpolicy availabilityzone reservedinstance itemdescription 140 per gb up to 10 tb month data transfer out usagequantity 16e 06 blendedrate 13724872926531 blendedcost 6e 07 unblendedrate 14 unblendedcost 6e 07 resourceid 001006 emr admin aws cloudformation logical id nil aws cloudformation stack id nil aws cloudformation stack name nil user env nil user environment nil user name nil user project nil user purpose nil user role nil user user nil user workspace this worked perfectly on logstash and elasticsearch copied from original issue elastic elasticsearch 14154 >>>blocker bug v2.0.0-beta3
logstash stops processing and submitting events if log message contains certain character sequences see the gist for logmessage debugoutput logstash conf and patterns https gist github com magicdude4eva 5b71f02c8e36098a064e can reproduce this on and as soon as logstash starts processing those records it will hang and not process any further log records logstash needs to be restarted and it will then continue believe that in the logfile example https gist github com magicdude4eva 5b71f02c8e36098a064e file logfileexample txt the issue is caused by line >>>bug
fix bin bundle command invoking `bin bundle` does not use the correct logstash vendor path with this fix invoking `bin bundle` will work as intended using the correct `gemfile` `gemfile jruby lock` and `vendor bundle path>>>bug v2.1.0
usage of required variables beginning with there are set of event variables the ones that begin with that somehow are required for logstash even though this fields are required in the source code and also as core concept of logstash the pipeline let the user remove them see mutate filter or remove field in filters if something like this happen see 4020 for more details then some pipelines will complain think is important we set the expectations about this variables right see different approaches here we make this fields mandatory and make this fields impossible to be removed we move the timestamp and version out of the event hash and only use them as internal variables we allow this variables to be removed on the fence on this here see benefits of having all options this makes me thing that probably the best option would be the second one by moving the variables as internals the event hash is more clean allowing both usages more out of the box >>>discuss
file to file configuration logstash on depian installed by apt execute under root account rm root sincedb cd opt logstash touch in la total 140 drwxrwxr logstash logstash 4096 oct 14 18 21 bin rw rw logstash logstash 91278 aug 20 20 21 changelog md rw rw logstash logstash 2249 aug 20 20 21 contributors rw rw logstash logstash 3717 aug 20 20 26 gemfile rw rw logstash logstash 19507 aug 20 20 21 gemfile jruby lock rw root root oct 15 05 33 in drwxrwxr logstash logstash 4096 oct 14 18 17 lib rw rw logstash logstash 589 aug 20 20 21 license rw rw logstash logstash 149 aug 20 20 21 notice txt drwxrwxr logstash logstash 4096 oct 14 18 20 vendor bin logstash input file path opt logstash in output file path opt logstash out logstash startup completed logstash shutdown completed my expectation was the logstash was not exit just after start but was monitor opt logstash in for new lines and output them to opt logstash out with some metainformation am wrong >>>needs_details
updates contributing to logstash with information on new plugin stop apis>>>docs
adds upgrading logstash directions >>>docs
adds breaking changes section >>>docs
added filewatch bufferedtokenizer spec simple spec for `filewatch bufferedtokenizer` in `lib logstash util buftok rb`>>>v2.0.0
adding in link to codec list fixes 4029>>>v1.5.5 v2.0.0-beta2
link to available codecs from config docs it be useful if we had link here https github com elastic logstash blob master docs asciidoc static configuration asciidoc in the codec section that pointed over to the list of available codes here https www elastic co guide en logstash current codec plugins html >>>docs
freeze lockfile for jrjackson>>>v2.0.0-beta2
added an option to skip given dependencies from the license test when having conflict of interest with checking dependencies added an option to skip dependencies from the license test in this case is about jruby openssl just added lately to our gemspecs but distributed throw jruby engine this dependencies should be actioned sooner or later as the skip list should be minimal to empty >>>tests-infra
nomethoderror undefined method `to iso8601 for nil nilclass in event rb from emmanuelguiton on october 13 2015 12 24 hello used logstash instance that processes few tens of millions messages per day and that often crashes almost once everyday in logstash err ther is the following trace oct 09 2015 58 17 am org apache http impl execchain retryexec execute info retrying request to http 10 176 61 21 9200 nomethoderror undefined method `to iso8601 for nil nilclass to at opt logstash vendor bundle jruby gems logstash core java lib logstash event rb 109 retry flush at opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch rb 729 times at org jruby rubyfixnum java 275 each at org jruby rubyenumerator java 274 map at org jruby rubyenumerable java 764 retry flush at opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch rb 724 register at opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch rb 480 looking at elasticsearch rb the application crashes while trying to log an error logger error too many attempts at sending event dropping next event looking at event rb the to function called when trying to log the event assumes there is an existing timestamp field but from the trace suspect this field does not always exist so logstash crashes when trying to call to is8601 on non existing timestamp the fix seems simple testing if the timestamp field exists before trying to call its to iso8601 method sorry cannot submit patch since do not know anything about ruby copied from original issue elastic elasticsearch 14086 >>>bug needs_details
graphite and exec input are failing tests default plugin tests are failing in graphite and exec input details here http build eu 00 elastic co view ls 202 job logstash default plugins 20 322 console>>>blocker bug v2.0.0-beta2
dot notation vs elasticsearch elasticsearch will no longer accept dots in field names this will likely cause some issues with some many user configurations options suggestions one suggestion is to have the elasticsearch output plugin automatically de dot the fields with underscores or some other separator >>>discuss enhancement
logstash master default plugins fails on already fixed plugins the build fails on plugins that already have been fixed to depend on current logstash core example for latest build http build eu 00 elastic co view ls 20master job logstash master default plugins 601 console however logstash input couchdb changes latest gem https rubygems org gems logstash input couchdb changes versions depends on logstash core snapshot >>>blocker
confusing documentation options for some plugins hi from https github com logstash plugins logstash filter drop issues we noticed that because of https github com elastic logstash blob master lib logstash filters base rb l50 l125 where configuration params like remove field or add tag are defined for all filters the configuration options auto generated for some of them looks misleading in the concrete example of logstash filter drop if this drops or not an entire event having remove tag or add field is just misleading some other filters where this general configuration might be misleading are https github com logstash plugins logstash filter sleep https github com logstash plugins logstash filter ruby https github com logstash plugins logstash filter prune https github com logstash plugins logstash filter cipher https github com logstash plugins logstash filter checksum and probably some others the most simple way to implement this is by having raw base filter class one with this configs out there is also the option to refactor filter out this config options in the selected filters >>>bug docs internal-cleanup known_issue low_hanging_fruit
nand and xor operators don work judging by the definition of booleanoperator in lib logstash config config ast rb all boolean operator are implemented by interpolating the operator name into the ruby code that eval ed the logstash expression `a or b` results in the `a or b` ruby expression unfortunately there are no ruby operators named `nand` and `xor` so use of those logstash operators will result in an error message similar to this syntaxerror eval 22 syntax error unexpected tidentifier see also https discuss elastic co nand and xor operators not working 31972 >>>bug known_issue
remove deprecated config options for two small problems with the `obsolete` field we can use `plugin params` to retrieve the option hash the params method should not return the `obsolete` options lets say that you use params` method to create new instance of the plugin the new instance validation will fails even if the original option hash did not contain any options marked as obsolete since we don have any context of `dirty options` where user actually use that key it easier to not return any obsoletes values also we were defining the obsolete instance value with `instance variable set` the params` method was only used in the context of password test ref 3950>>>blocker v2.0.0-beta2
list of broken plugins for ran into few issue for my last mass publish done on october this is the list of the plugins that were not correctly published plugin why it didn work logstash filter aggregate dont have the permission to publish logstash filter alter test green now http build eu 00 elastic co view ls 20plugins view ls 20filters job logstash plugin filter alter unit logstash filter environment https github com logstash plugins logstash filter environment pull logstash filter metrics https github com logstash plugins logstash filter metrics issues 21 and https github com logstash plugins logstash filter metrics issues 19 logstash filter yaml empty repo logstash input dynamodb empty repo logstash input heroku https github com logstash plugins logstash input heroku issues logstash input perfmon empty repo logstash output logentries empty repo logstash output neo4j can run the test https github com logstash plugins logstash output neo4j issues logstash output newrelic empty repo logstash input rackspace https github com logstash plugins logstash input rackspace issues logstash output slack https github com logstash plugins logstash output rackspace issues logstash output solr http republish worked guess rubygems hiccups >>>bug shutdown_semantics
long lines in files crash logstash we have problem where some of our applications log very long lines into files 32k characters this believe is crashing logstash with socketerror send name or service not known send at org jruby ext socket rubyudpsocket java 318 register at opt logstash vendor bundle jruby gems logstash output udp lib logstash outputs udp rb 24 call at org jruby rubyproc java 271 encode at opt logstash vendor bundle jruby gems logstash codec json lib logstash codecs json rb 57 receive at opt logstash vendor bundle jruby gems logstash output udp lib logstash outputs udp rb 34 handle at opt logstash vendor bundle jruby gems logstash core java lib logstash outputs base rb 88 output func at eval 209 outputworker at opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 244 start outputs at opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 166 saw this thread relating to logstash forwarder https github com elastic logstash forwarder issues 33 but not using this also found this stackoverflow post which indicates the maximum line length http stackoverflow com questions 31299262 maximum line length supported by logstash not sure what correct whether to truncate the line or increase the maximum length but it would be nice if it didn crash we re also modifying our application to remove the log line which should never have been there in the first place >>>bug
mention field exists not exists options here https www elastic co guide en logstash current event dependent configuration html conditionals eg if you want to check field exists you can use `if fieldname and for not exists `if fieldname this is an implicit does this exist not exist and it super handy >>>docs needs_review
meta dry udp tcp graphite input plugins specs spec helpers the udp tcp and graphite input plugins are defining pretty much the same spec helper it should be dry ed up also purbon suggested some spec refactors in logstash plugins logstash input graphite pull which we should followup on >>>internal-cleanup
document running logstash as windows service using nssm please add documentation for running logstash as windows service using nssm until logstash is able to run as windows service see 3721 basically download nssm run nssm and get the gui fill in the input boxes for what to run click install service >>>docs enhancement windows
lock gems version>>>v2.0.0-beta2
bump jrjackson gem to and make adjustments to use it closes 3702 >>>v2.0.0-beta2
add byte based flush setting for es currently `flush size` is the only knob to control how much data worker sends to es but if data varies in size this can range from annoying inconsistent heap use to catastrophic on low margin system there should be some kind of `flush bytes` setting as well where each time message is slated to be added to pending bulk request the total bytes of the docs are considered >>>enhancement
change master version for dev>>>v2.0.0 v2.0.0-beta2
hardcoded port for https using beta >>>bug discuss
default plugins test failures on master failure on jenkins http build eu 00 elastic co view ls 202 job logstash default plugins 20 296 console reasons for failure lock file needs to be updated several plugins override input logstash helper using rspec configure include which breaks all other plugins that use it ganglia irc relp udp zeromq logstash input exec has utf encoding issue fixed with https github com logstash plugins logstash input exec pull logstash filter uuid tests are not passing http build eu 00 elastic co job logstash plugin filter uuid unit jdk jdk7 nodes metal pool console enabling abort on exception breaks logstash input log4j test suite enabling abort on exception breaks logstash input unix test suite eventlog spec suite should only run on windows graphite input tests are failing https github com elastic logstash issues 4018 logstash input exec fails randomly https github com logstash plugins logstash input exec issues logstash input log4j fails randomly https github com logstash plugins logstash input log4j issues 22 logstash input unix fails randomly https github com logstash plugins logstash input unix issues 13 logstash output s3 specs depend on obsolete tags https github com logstash plugins logstash output s3 issues 39 logstash output statsd fails https github com logstash plugins logstash output statsd issues 14 logstash filter clone specs depend on obsolete tags https github com logstash plugins logstash filter clone issues 2>>>blocker v2.0.0 v2.0.0-beta2
add powershell script for windows testing added three different tests release acceptance test which tests ports and run logstash default plugins which runs the same plugin installation and environment for windows simple integration which integrates logstash with elasticsearch and simple configuration ph suyograo purbon >>>needs_review tests-infra v2.1.0 windows
update all logstash plugins like have logstash plugins updated along with logstash installation via puppet could have used exec for that but running something like stops the flawless execution as well it not clear if it safe to install plugins for logstash nor it is possible to make it update only feasible versions is it possible to abandon questions and install only appropriate updates >>>enhancement
memory leak rabbitmq input plugin have memory leak for logstash try and supose it elasticsearch output plugin using phusion baseimage https github com phusion baseimage docker special ubuntu docker image my filter and input with this output section logstash was leaked output with this outputs section logstash was leaked output output gc plot screenshot 14 copy https cloud githubusercontent com assets 2276472 10287291 cb2f994c 6b9a 11e5 9f1d 98fa5b111b46 png memory stats screenshot 15 https cloud githubusercontent com assets 2276472 10287272 b9d7c4c6 6b9a 11e5 9b85 3b675e0065ac png screenshot 16 https cloud githubusercontent com assets 2276472 10287277 bb1ed3f6 6b9a 11e5 8d29 c818c413cd29 png >>>bug
allow tlsv1 for lumberjack or tcp input connections this patch requires the use of the latest version of `jruby openssl` which support tlsv1 this prs changes the monkeypatch to specify to set the `ssl version` to `tls` which allow support of tlsv1 tlsv1 and tlsv1 fixes 3955>>>v1.5.5 v2.0.0-beta2
added clearer message when filter crash when the filter workers crash logstash will stop consuming any events since we don have dead letter queue yet we can restart the workers fixes 3983>>>v2.0.0
worker thread pegs core in encoder encodeloop and processing halts logstash from official apt package on ubuntu trusty 14 04 with oracle jre 60 b27 using lumberjack input worker` thread pegs single core took three stack dumps few seconds apart and found these two different stacks for the worker thread and >>>pipeline-stalls upstream_fix_needed
fix master after we published all the plugins today we can install any plugins on master because of the logstash core constraint in plugin gemspec this allows only snapshot versions this is stop gap for now so we can get tests running on master after the beta2 we will be changing the constraint to 0` and do mass update which will allow us to make master version `3 dev` this pr will un hose the master branch>>>bug v2.0.0 v2.0.0-beta2
metrics filter does not work in logstash beta elasticsearch beta have this plugin configured in my logstash filter section have output plugins configured for elasticsearch and stdout can see the metric messages being generated every seconds stdout but they never appear in elasticsearch when run in debug mode see that indexing the document is failing with the reason looking like dot in the field name is not allowed >>>bug
when filter is raising an exception the filter worker dies when there is an exception in filter worker loop the thread dies and logstash just stop doing anything we should make sure we give more explicitly error in the log >>>bug v2.0.0
bump logstash output rabbitmq due to gem yank logstash output rabbitmq was yanked https rubygems org gems logstash output rabbitmq versions so this needs to be updated >>>bug
flush doesn happen on shutdown for some output plugins if during shutdown the inputs didn generate enough events to trigger normal flush by reaching flush size the events won be sent to elasticsearch reproduce steps start elasticsearch use logstash branch bin plugin install version beta6 logstash output elasticsearch bin logstash input generator count 50 output elasticsearch run logstash wait to finish then check elasticsearch event count output from logstash using debug https gist github com jsvd be4d7fafc2fc39b3eb8d plugins affected logstash output elasticsearch https github com logstash plugins logstash output elasticsearch issues 261 logstash output lumberjack https github com logstash plugins logstash output lumberjack issues 12 >>>blocker shutdown_semantics v2.0.0-beta2
new plugin config attribute obsolete an obsolete setting is one that will cause configuration error if it is used the purpose of obsolete` is to help inform users when setting has been completely removed the lifecycle of plugin setting is now phases available deprecated obsolete deleted available is the default and deprecated remains the same as it was logging warning the new obsolete will cause configuration error if such setting is used then later we can finally delete the config setting after it been obsolete for some time fixes 3977>>>v2.0.0-beta2
create an obsolete syntax for config options we need to create special `obsolete` syntax option for `config` the idea is to use this for config options which have been marked deprecated when `obsolete` is used on config it passes the config check but ls will fail to start and it will provide message that it has been deprecated and no longer relevant this provides better feedback for users of deprecated configs before major version config changes which are backward incompatible will be marked `deprecated` major version will remove the code usage remove documentation but keep the config option with the `obsolete` tag the next major version will delete the config completely proposed by andrewvc during the es http default work ref issue from user https github com logstash plugins logstash output elasticsearch issues 258 >>>enhancement
logstash elasticsearch configuration example documentaion issue hi logstash team the following link contains configuration examples for logstash and elasticsearch https www elastic co guide en logstash current config examples html one of the things it doesn mention is that in order for newer version of logstash and elasticsearch to work there needs to be protocol transport mentioned in the output plugin of logstash configuration section for example output elasticsearch host localhost cluster myes protocol transport stdout codec rubydebug >>>question
roadmap update with alvin changes https github com elastic logstash docs pull 127 files>>>docs v2.0.0
installed gem is not really installed as referenced here https discuss elastic co local filter plugin pretended to be installed but not listed and not working 2016 plugin is said to be installed but isn really installed this seems to happen when local gem file is built and installed all that happens is file like this is created vendor local gems e8f538bc logstash input example but nothing else >>>bug plugin_manager
remove of output in the outputs when we merge https github com elastic logstash pull 3950 all the plugins will stop to work >>>blocker v2.0.0-beta2
remove calling of filter call in the filters when we merge https github com elastic logstash pull 3950 all theses plugins will stop working >>>blocker v2.0.0-beta2
update gemfile lock in the branch to use last released plugins fixes broken http build eu 00 elastic co view ls 202 job logstash default plugins 20 247 >>>bug
how to change https rubygems org to mirror v1 v2 beta1 simply changed relative line in gemfile jruby lock and gemfile located in home dir but it seems dont work >>>plugin_manager question
mass update all plugins with api changelog>>>blocker v2.0.0-beta2
track shutdown refactor for other plugins not packaged with logstash follow up to https github com elastic logstash issues 3813 this issue focuses on plugins that are not listed in https github com elastic logstash issues 3813 recap of refactor task add `stop` public `stop public to logstash inputs base rename `teardown` to `close` remove `shutdown` `finished` `finished `running `terminating from logstash plugin refactor work needed on the plugins input plugins https github com issues utf8 e2 9c 93 is 3aopen is 3aissue user 3alogstash plugins label 3a 22shutdown semantics 22 input plugins are now shutdown by an external call to `plugin stop` instead of catching logstash shutdownsignal exception unless overridden `stop` will simply makes `stop return `true` thus allowing `run` to poll this and return after seeing the change in some plugins extra work must be done in `stop` to instruct `run` that it time to return for example in the `logstash input udp` it necessary to call socket close` to make the blocking read on the socket raise an exception thus breaking out the loop so different input plugins will require different `stop` strategies refactoring an input plugin involves removing rescue of `shutdownsignal` exception understand the nature of the `run` loop is it `while` `consumer subscribe event is there blocking operation on socket fd use `stop and or override `stop` to make run return put any other cleanup bookkeeping tasks in `close` currently done in `teardown` remove any calls to `shutdown` `finished` `finished `running or `terminating then for testing you can use the shared example provided in logstash devutils input plugin refactor logstash input drupal dblog https github com logstash plugins logstash input drupal dblog issues 10 pr https github com logstash plugins logstash input drupal dblog pull 11 logstash input dynamodb https github com logstash plugins logstash input dynamodb issues logstash input example https github com logstash plugins logstash input example issues logstash input fluentd https github com logstash plugins logstash input fluentd issues logstash input gemfire https github com logstash plugins logstash input gemfire issues logstash input github https github com logstash plugins logstash input github issues logstash input heroku https github com logstash plugins logstash input heroku issues logstash input http poller https github com logstash plugins logstash input http poller issues 36 logstash input jdbc https github com logstash plugins logstash input jdbc issues 52 pr https github com logstash plugins logstash input jdbc pull 53 logstash input jms https github com logstash plugins logstash input jms issues logstash input jmx https github com logstash plugins logstash input jmx issues 11 logstash input log4j2 https github com logstash plugins logstash input log4j2 issues logstash input meetup https github com logstash plugins logstash input meetup issues logstash input neo4j https github com logstash plugins logstash input neo4j issues pr https github com logstash plugins logstash input neo4j pull logstash input perfmon https github com logstash plugins logstash input perfmon issues logstash input puppet facter https github com logstash plugins logstash input puppet facter issues logstash input rackspace https github com logstash plugins logstash input rackspace issues logstash input relp https github com logstash plugins logstash input relp issues 10 logstash input rss https github com logstash plugins logstash input rss issues 10 logstash input salesforce https github com logstash plugins logstash input salesforce issues logstash input sqlite https github com logstash plugins logstash input sqlite issues logstash input stomp https github com logstash plugins logstash input stomp issues logstash input varnishlog https github com logstash plugins logstash input varnishlog issues logstash input websocket https github com logstash plugins logstash input websocket issues logstash input wmi https github com logstash plugins logstash input wmi issues 10 pr https github com logstash plugins logstash input wmi pull 11 logstash input zenoss https github com logstash plugins logstash input zenoss issues remove `terminating in lot of scenarios the call to `terminating might be replaced with `stop in the case of input plugins logstash output gemfire https github com logstash plugins logstash output gemfire blob 7a2ab3f2dd87ab05011f7affe53261d95933ff67 lib logstash outputs gemfire rb l64 pr https github com logstash plugins logstash output gemfire pull remove `finished` logstash output cloudwatch https github com logstash plugins logstash output cloudwatch pr https github com logstash plugins logstash output cloudwatch pull logstash output gemfire https github com logstash plugins logstash output gemfire pr https github com logstash plugins logstash output gemfire pull logstash output jira https github com logstash plugins logstash output jira pr https github com logstash plugins logstash output jira pull logstash output loggly https github com logstash plugins logstash output loggly pr https github com logstash plugins logstash output loggly pull 10 logstash output nagios nsca https github com logstash plugins logstash output nagios nsca finished pr https github com logstash plugins logstash output nagios nsca pull logstash output redmine https github com logstash plugins logstash output redmine please review https github com logstash plugins logstash output redmine pull rename `teardown` to `close` logstash codec compress spooler https github com logstash plugins logstash codec compress spooler logstash codec spool https github com logstash plugins logstash codec spool logstash input couchdb changes https github com logstash plugins logstash input couchdb changes logstash input gemfire https github com logstash plugins logstash input gemfire logstash input github https github com logstash plugins logstash input github logstash input jmx https github com logstash plugins logstash input jmx logstash input neo4j https github com logstash plugins logstash input neo4j logstash input rackspace https github com logstash plugins logstash input rackspace logstash input relp https github com logstash plugins logstash input relp logstash input varnishlog https github com logstash plugins logstash input varnishlog logstash output gemfire https github com logstash plugins logstash output gemfire logstash output google bigquery https github com logstash plugins logstash output google bigquery logstash output google cloud storage https github com logstash plugins logstash output google cloud storage logstash output influxdb https github com logstash plugins logstash output influxdb pr https github com logstash plugins logstash output influxdb pull 28 files logstash output jms https github com logstash plugins logstash output jms pr https github com logstash plugins logstash output jms pull logstash output juggernaut https github com logstash plugins logstash output juggernaut logstash output neo4j https github com logstash plugins logstash output neo4j logstash output solr http https github com logstash plugins logstash output solr http logstash output statsd https github com logstash plugins logstash output statsd logstash output webhdfs https github com logstash plugins logstash output webhdfs >>>shutdown_semantics
fix branch test by updating the gemfile and the lock file this fix 3946 by updating the gemfile and the lock file to fetch the last released plugins issues are explained at https github com elastic logstash issues 3946 issuecomment 142888343 important this pr should only be merged and tested with branch >>>blocker bug tests-infra
provide more details around trouble parsing json this error is really difficult to work with as it provides no context it be good if we logged the message that generates this as otherwise we have no way of dealing with it other than adding an `output stdout codec rubydebug to high traffic level systems just to catch the occasional error >>>enhancement
deprecated mentions in the plugins small search with the `deprecated` keyword on the plugin see these 23 results >>>v2.0.0-beta2
enormous amount of logstash processes open consuming lots of memory hi have logstash rc2 running in ubuntu 14 04 lts my problem is that logstash even not processing anything in idle status is opening lot of huge memory consuming processes until consuming almost all the memory in my production machine here you can see the output of an htop command captura de pantalla 2015 09 23 las 17 24 01 https cloud githubusercontent com assets 353755 10049805 7df2a690 6219 11e5 93c0 cf344e02f647 png does anyone could help me to avoid this thing regards >>>needs_details question
update lock file to snapshot2 while the version of core has been updated to snapshot2 the lock files are still depending on beta1>>>bug
beta1 json lines codec seems to make logstash stall or oom using logstash beta1 and trying to index json lines from file it worked perfectly with the json filter but wanted to see how the json codec compares when started it logstash didn index any message but it quickly went up to the 1gb heap limit and threw an oom the same with 2gb because was sending to solr and thought maybe this output is problematic switched to elasticsearch then it gave me warning saying java isn supported was on openjdk 79 and oomed again so switched to java openjdk 45 and now it doesn oom any more but still don see any documents in es you can find the config and log sample here https gist github com radu gheorghe e32a2ef29bc7dcb4ec10 commenting the json lines codec line makes it all work as it does with json filter so there is workaround but thought that it would be nice to know and maybe the json codec is actually more efficient even though it can only run on one thread afaik >>>bug
default to tls which is now the default in java today ls defaults to tls for securing communication over http we should default to tls java will already default to it https blogs oracle com java platform group entry java will use tls jordansissel had previously mentioned there were some issues in jruby for supporting tls but we they may have been resolved now see https github com jruby jruby issues 1737>>>enhancement v2.0.0
cleanup usage of plugins to test logstash core nowadays we use some plugins to test the behaviour of the logstash core while this is an acceptable behaviour it should be required that plugins behave as expected to run the core test the current idea is clean up current plugin usage for dummy mock plugins where need rewrite test to they don require this plugins to be used like this we ll win isolation in the test so easy to reproduce problems without the need to think if there is bug or an issue introduced by the plugins used in testing this is an initial approach to remove this issue next tasks related to that would be wrap group knowledge on how each parts of logstash should behave starting by configuration validation config mixing and pipeline behaviour this would help us write proper test that will work as reference with the reference we can start tracking more deep test refactor as they should be >>>enhancement internal-cleanup tests-infra
renaming teardown to close in plugins some plugins still use `teardown` an api that will disappear in these need to be renamed default plugins logstash filter multiline https github com logstash plugins logstash filter multiline logstash filter zeromq https github com logstash plugins logstash filter zeromq logstash input file https github com logstash plugins logstash input file logstash input generator https github com logstash plugins logstash input generator logstash input jdbc https github com logstash plugins logstash input jdbc logstash input pipe https github com logstash plugins logstash input pipe logstash input redis https github com logstash plugins logstash input redis logstash input tcp https github com logstash plugins logstash input tcp logstash input s3 https github com logstash plugins logstash input s3 logstash input udp https github com logstash plugins logstash input udp logstash input zeromq https github com logstash plugins logstash input zeromq logstash output elasticsearch https github com logstash plugins logstash output elasticsearch logstash output elasticsearch http https github com logstash plugins logstash output elasticsearch http logstash output elasticsearch java https github com logstash plugins logstash output elasticsearch java logstash output file https github com logstash plugins logstash output file logstash output redis https github com logstash plugins logstash output redis logstash output s3 https github com logstash plugins logstash output s3 logstash output sqs https github com logstash plugins logstash output sqs logstash output zeromq https github com logstash plugins logstash output zeromq logstash output lumberjack https github com logstash plugins logstash output lumberjack non default plugins note these aren priority for now can be done later logstash codec compress spooler https github com logstash plugins logstash codec compress spooler logstash codec spool https github com logstash plugins logstash codec spool logstash input couchdb changes https github com logstash plugins logstash input couchdb changes logstash input gemfire https github com logstash plugins logstash input gemfire logstash input github https github com logstash plugins logstash input github logstash input jmx https github com logstash plugins logstash input jmx logstash input neo4j https github com logstash plugins logstash input neo4j logstash input rackspace https github com logstash plugins logstash input rackspace logstash input relp https github com logstash plugins logstash input relp logstash input varnishlog https github com logstash plugins logstash input varnishlog logstash output gemfire https github com logstash plugins logstash output gemfire logstash output google bigquery https github com logstash plugins logstash output google bigquery logstash output google cloud storage https github com logstash plugins logstash output google cloud storage logstash output influxdb https github com logstash plugins logstash output influxdb logstash output jms https github com logstash plugins logstash output jms logstash output juggernaut https github com logstash plugins logstash output juggernaut logstash output neo4j https github com logstash plugins logstash output neo4j logstash output solr http https github com logstash plugins logstash output solr http logstash output statsd https github com logstash plugins logstash output statsd logstash output webhdfs https github com logstash plugins logstash output webhdfs >>>shutdown_semantics
revert wrong commit in the gemfile that introduced dev dependencies this reverts commit a6ab581979bafdf32483b7f8c126cc1ade159ee8 that introduced wrong dependencies to be in the gemfile for master this should only be merged with master >>>bug
remove deprecated config options for will also make docs nicer this pr is just to get feel of what it takes to delete existing deprecated stuff from core plugins there lot of core tests that refer this configuration variables so it may be hairy to check and remove them not sure we can do blind global search and delete >>>breaking-compatibility v2.0.0 work_in_progress
mass update on plugins for preparing logstash beta update all default plugins constraint to make sure the plugins major version is updated to or if needed >>>v2.0.0-beta2
core test should not be dependant in plugins core test should not be dependant on plugins to work this days core test need to work but for this test to be actually validating the pipeline behaviour it should be using mocks or internal dummy filters created for this special purpose otherwise when plugin has blocker update test in core are not working as expected >>>bug tests-infra
logstash master regression test hang from http build eu 00 elastic co view ls 20master job logstash regression master 419 this is related with 3895 and the need to be updated some plugins before this test pass generator plugin >>>bug tests-infra
default plugins integration test breaks in branch from http build eu 00 elastic co view ls 202 job logstash default plugins 20 228 console >>>bug tests-infra
defaults plugin test hangs on master from http build eu 00 elastic co view ls 20master job logstash master default plugins 513 >>>bug tests-infra
add support for environment variable injection in logstash plugin configuration it would be great to support environment variable injection in logstash configuration like this it would be very useful to have logstash configuration independent from its environment and so have the same logstash configuration among different environments dev test prod numerous frameworks support such feature like spring or log4j >>>enhancement
disque input and output for logstash disque is distributed message broker from the redis author it would be nice for logstash to have an input and output for it >>>adoptme new-plugin
remove unused files removed related files for compiling the grammer we have refactored the makefile using rake if you want to generate new parser you can use `rake compile all`>>>reviewing v2.0.0
logstash install first test hi try to install and test logstash according to the following tutorial https www elastic co guide en logstash current first event html have the following error cd logstash stdi output stdout erreur impossible de trouver ou charger la classe principale org jruby main could you help to understand the problem and solve it best regards franck >>>question
remove multiqueue this file was probably used at some point but its not the case anymore>>>reviewing v2.0.0
rfix cleanup require helper this file isn used in the code at all it was probably used at some point but its not the case anymore >>>reviewing v2.0.0
string interpolation skip the last character this pr fix problem when doing the interpolation with string that did not end with fieldref but with character the interpolation was ignoring the last character example fixes 3931>>>v2.0.0
multiline codec needs max age option currently by using the multiline codec on input you never get the last message from the logs the codec will wait forever for the next line to come in order to check it against the pattern this is ok if the source is very active but for sources that produce message every hour or so the multiline codec is simply not usable the multiline filter covers the above scenario but it has it own problems not thread safe and 3935 >>>enhancement
multiline filter add tag adds tag all the time even when pattern is not matched example config this results in tagging every message of the type scala with the multiline tag the expected behavior is to tag only messages that are composed of multiple lines and are matched against the pattern >>>bug
elasticsearch index template duplicates last part of field name we re using logstash to feed suricata logs that are just plain json into elasticsearch kibana stack to have not analyzed fields available ve loaded `lib logstash outputs elasticsearch elasticsearch template json` template but ve notice that this made fields like `host` into `host host raw` and `http http user agent` into `http http user agent http user agent raw` ve managed to fix it by removing name like that fields name type string index analyzed omit norms true index options docs raw type string index not analyzed ignore above 256 but have no idea how and why it fixed it >>>unconfirmed
http output plugin to support retry the http output plugin accepts any code in the 200 299 range as successful transmission ideally this would be configurable if the message fails it is currently just logged to stderr with no retry request that re try semantics be identical to those used for the elasticsearch output >>>discuss enhancement
inconsistent use of java proxy environment variable vs config some plugins utilise configuration parameter for http communication through proxy for example the elasticsearch output plugin and http output plugin both utilise the proxy config parameters they do not respect java environment variables export ls java opts dhttp proxyhost localhost however other components the plugin script seem to respect and utilise this request for behaviour to be standardised >>>discuss
field expression causes last character to be removed if field expression is used in an add field property at the end of string the last character will be dropped in the output it occupies upto position in the string where is the length of the string indexed from for example mutate 	add field intel foundation faffiliate in this case the the final pipe character will be dropped this can be solved by adding character to the end of the string thus moving the expression termination point to mutate 	add field intel foundation faffiliate >>>bug v2.0.0
undefined method `close for nil nilclass hi getting the exception in the subject for the following configuration debian logstash oracle java with debug getting this output can anyone understand where is it coming from >>>bug
fieldref syntax should allow to retrieve the epoch value in milliseconds values of the timestamp had discussion with sarwarbhuiyan over hipchat about what was the best way to retrieve the epoch value in milliseconds of the timestamp` field without using ruby filter and havent found any think getting the milliseconds values of the timestamp could be more common usecase than we think and we should provide nicer way to do it the current implementation of the `fieldref` parser supports s` which will give you the epoch time in milliseconds it would be easy to add m` to get the milliseconds this would allow people to use the add field option to retrieve the time >>>enhancement
logstash hangs because of urldecode filter was trying to apply the urldecode filter to field two times for complete decoding but because of the presence of non utf characters the second urldecode operation seems to be hanging rather than ignoring skipping the characters or printing an error sample characters after 1st urldecode xf1 xc6c x95 xc5 logstash does throws received an event that has different character encoding than you configured warning so logstash was getting stuck within 10 minutes of starting assume because of encountering log line containing the non utf characters removing the second urldecode solved the hangs instead of hanging urldecode should just ignore wrong encoding issues >>>needs_details
configuration file ordering does matter for some reason hi all this issue is the result of this https discuss elastic co logstash configuration file ordering does matter 28840 discussion per magnusbaeck suggestion https discuss elastic co logstash configuration file ordering does matter 28840 opening this issue so we all can benefit and understand logstash better running logstash with couple of switches and for some unknown reason the order of the files does matter with debug found the following didn expect seeing errors in the 3rd bullet filter output input but logstash stays up if the full log is needed can pastebin it but it will take me some time to sanitize it fwiw my config files are standardised as follows another interesting thing is that if start logstash with bin logstash etc logstash conf passing directory containing my configuration its working what is different between specifying specific files in certain order and specifying directory containing the configuration can someone explain this behaviour thanks yarden >>>bug docs
upgrade to jrjackson 4>>>v2.1.0
how to handle nil keys in event hashes from json generation viewpoint in ls jrjackson will raise generatorerror when `nil` key is found in an event during serialization see this issue for background https github com elastic logstash issues 3912 votes required can add an option that allows for nil object key value pair to be serialized as null ignore the kv pair completely create random key wdyt >>>discuss
configuring logstash logs to ship to different destinations hi is there anyway to configure logstash logs to send it to syslog for exemple like logging yml of elasticsearch>>>discuss enhancement
invalid link in wiki page tips testing your filters seems like the example url on the following wiki page is broken github com elastic logstash wiki tips testing your filters where can the correct url be found >>>question
bin plugin update fails initialize name or service not known running logstash within container from the official docker logstash image https hub docker com logstash when try to update or all plugin get the error `error updated aborted message initialize name or service not known` >>>bug plugin_manager unconfirmed
logstash stops processing after period hello not sure if there is bug here or if there is configuration issue which is causing this problem have recently setup logstash on newly installed vm running debian jessie debian logstash was installed via the repository from http packages elasticsearch org logstash debian not sure if this is relevant but including it for the sake of completeness the process for logstash was started via systemctl start logstash in the first few attempts and then via etc init logstash start on the next few when logstash stops cannot restart it via systemctl or via the init script the processes needs to be stopped with killall java no data is being logged to the log files no data is being forwarded on to the other host number of the child processes have higher cpu activity than the others as its stopping the number of entries passed from logstash to the second host decreases over time my configuration is as follows the ftarget is as follows there are 50 items in total listed in the ftarget pattens above you may have noticed that listening on 5140 there is router in front of this performing translation from 514 on the outside to 5140 on the inside for both tcp and udp this is because the process is running as the default logstash user and cannot listen on 514 without root while logstash is apparently dead the logs do continue to be passed to the server but are not processed attempted to attach strace to one of the logstash processes with higher cpu load and was returned the following over and over out of curiosity modified the nice level on one of the busier processes from 19 to during this time couple of extra logs did filter through to host2 in the error log for logstash received the following other then the start message in the log file no other logstash log files contained any further information apologies if the above is little woolly does anyone have an idea of what could be going wrong here certainly willing to provide further diags here however have had to restart the process to get it going again estimate that it will fall over again tomorrow so there may be some delay in finding information something in the back of my mind says that may have over done it on the ftarget matching but would should it really bring it down like this >>>needs_details
null key for map not allowed in json am getting logstash json generatorerror null key for map not allowed in json use converting nullkeyserializer it appears this is being called by the redis output but the class that has the problem is json rb which is in the core this error is killing logstash instead of erroring and continuing think see the problem environ nil nil in the output threw in puts to to see the object just before the crash file proc host hd1pwcs01lx digital hbc com type pidstats process cmdline sshd root pts cwd environ nil nil nil exe usr sbin sshd fd root nlwp io rchar 20021385 wchar 20283920 syscr 15614 syscw 15011 read bytes write bytes cancelled write bytes pid 16914 comm sshd state ppid 2360 pgrp 16914 session 16914 tty nr tpgid flags 4202752 minflt 1314 cminflt 420 majflt cmajflt utime 80 stime 118 cutime cstime priority 20 nice itrealvalue starttime 202608076 vsize 114155520 rss 1055 rlim 18446744073709551615 startcode 139991671406592 endcode 139991671959196 startstack 140734550035104 kstkesp 140734550031976 kstkeip 139991625048915 signal blocked sigignore 4096 sigcatch 81926 wchan 18446744071580571897 nswap cnswap exit signal 17 processor 17 rt priority policy name sshd uid euid gid egid version timestamp 2015 09 12t00 56 32 392z tags grokparsefailure logstash java version 85 openjdk runtime environment rhel el6 x86 64 u85 b01 openjdk 64 bit server vm build 24 85 b03 mixed mode think some kind of error handling should be placed somewhere to gracefully handle this error which is why am opening this as bug >>>bug
other doc dependencies on changing to http protocol first line in watcher and shield logstash integration need updates as we change to http protocol as default minor change but needs change as we re changing to http as the default there may be other changes similar to this in the docs https www elastic co guide en watcher current logstash integration html https www elastic co guide en shield current logstash html>>>docs v2.0.0
api hot threads information currently there is no way to get information about the running threads inside logstash other than collecting thread dump with `jstack` it would be great to implement an api endpoint similar to the elasticsearch `hot threads` ref https www elastic co guide en elasticsearch reference current cluster nodes hot threads html think this can be done easily by using the java management api we could probably use elasticsearch class directly and return the same results in my initial experimentations you have to use the java api because the ruby api will hide the pure java threads like the one used in manticore or the rabbit mq client >>>metrics v3.0.0-alpha1
expose metrics in logstash pipeline see functional requirements here https github com elastic logstash issues 2611 this issue is mostly for tracking sub tasks for implementation currently in logstash there is no way to easily collect metrics from runnings instance lets define our needs do we need to build custom solution or we can leverage existing code we have to keep in mind that we are currently rewriting important parts of the pipeline in pure java to leverage more speed from the jvm so we need to have an hybrid solution that will grow and adapt with the code base phase1 use cases of metrics collection in the current system we want to collect metrics from different part of the system think we should try to have low level library usable in both scenario we can provide helpers method via metaprogramming hiding away the complexity of the data collection this would allow us to turn on of off stats collecting for some part of the code from the pipeline itself in out of the queues in out of the filter method of different plugins metrics from conditionals branching detecting slow part from the plugins webservice latencies heavy computations grok retries count error count internal buffering like multilines filter lumberjack output and elasticsearch output custom metrics defined by plugins authors from the event itself metrics framework in core 3898 reporting metrics to external services 3897 provide common interface for collecting metrics in pipeline 3894 plugin specific metric collection framework no conditionals for now 3901 add support for multiples pipelines 3892 add unique id on every plugin and allow user to override it 3900 every logstash node or instance should have their own unique id 4461 internal filter metrics by namespaces 4549 add hidden flag for pipeline 4542 delete metrics when pipeline is stopped 4536 make the pipeline retrieve the node nae 4506 add guards for the metric store 4529 hide the implementations details for the metric store 4503 collect plugin metrics by default exposing metrics through rest api https github com elastic logstash issues 4446 design metrics api endpoints for logstash 3909 api hot threads information 3802 evaluate framework or routing strategy for the api endpoints 3801 evaluate how we are exposing the api endpoints 3799 api the pipeline should return the current active plugins 4575 implement basic logging 4576 add an option to output access and error logging 4574 locate logstash core lib api inside logstash core lib logstash api 4464 add runtime documentation aka map for the metric api integration tests for metrics 4573 integration test for the metrics collection benchmarking 4572 benchmarking the new metrics feature >>>design meta metrics v3.0.0-alpha1
collection of helpers to improve the testing experience from discussions we started having at 1890 and some of the work already done and discussed in the https github com elastic logstash devutils project created place holder for the logstash helpers and matchers we can use for testing you can see the initial commit of the gem at https github com elastic logstash test helpers this aims to be something like shoulda or the rspec collection matchers projects where you can just import it and start using it helpers machers this gem would also provide us with an option to test out our helpers them self and nonetheless also support other test runners whenever requested start using it would be as simple as you can also see two initial trials of using this gem at https github com purbon logstash patterns core tree feature use logstash helpers https github com purbon logstash input syslog blob feature use logstash helpers spec inputs syslog spec rb to the question should this be included in devutils see this as an independent gem being probably required throw devutils but would keep both responsibilities separated to facilitate it manageability and separations of concerns this relatets to 1890 as the initial issue that reported the need of this but also to https github com elastic logstash devutils issues 33 with dicussions how to improve the configuration test experience and https github com elastic logstash devutils issues 36 for integration what do you think >>>discuss tests-infra
link to oniguruma broken here https www elastic co guide en logstash current plugins filters grok html regular expressions we point to url that doesn exist think this is what we want https github com kkos oniguruma>>>docs
logstash output plugin for kairosdb ve written logstash output plugin to publish metrics to kairosdb cassandra kairosdb can be used as datasource for grafana https github com stevejas logstash output kairosdb this plugin borrows shamelessly from the graphite plugin it would be great if this plugin could be included under the logstash plugins as found the process of installing custom plugins to be broken in logstash the vendor local gems plugin name directory is empty after following the installation instructions and it would simplify our installation process >>>needs_review new-plugin
add support for multiples pipelines currently logstash support only one pipeline active at any time the metrics implementation could reuse the pipeline code input filter and output to send events to the metrics backend we don want any hiccups of the main pipeline possibly impacting the collection and transport of the metrics this changes could also help us do live reload of configuration or cluster management ref 3693 3774 3898>>>design manageability metrics v3.0.0
every logstash node or instance should have their own unique id when collecting stats in multi nodes or cluster environment we need way to identify specific node when investigating performance issue currently when you start logstash we don generate unique id some plugins use the local hostname to track where events came from we should generate it by default it should be unique as much as we can until we have the cluster in place we can be sure we should use random name the concept is similar to elasticsearch node name users should be able to change it with either configuration change or flag when starting logstash >>>design manageability metrics v3.0.0
add `created at` key in the metadata hash currently when we create an event we set default timestamp` with `time now` we should also save this information inside the metadata` key `created at` this would allow people to use conditionals and do special if the event was in the pipeline for too long >>>design enhancement manageability
reporting metrics to external services the first goal of collecting metrics is to make sense of it so we want to report internal collected metrics to external services also deferring metrics analysis outside of logstash free up lot of resources and allow detailed analysis with better tooling think our implementation of collecting metrics and transmitting metrics should be as lightweight as possible and have the least potential impact with the current pipeline logstash already ships with multiples outputs which send events to existing collecting service like elasticsearch and statsd it makes sense to leverage our plugins ecosystem to easily expose the metrics think defining `metrics outputs` should be only matter of adding new config option like this to make it work we have to few issues to take care of `logstash metricmessages` should be transformed into an `logstash event` which is compatible to the correct output peoples usualy use the filters to make the transformation we can add special class in the plugins supporting internal metrics to do the transformation we should be able to disable custom metric reporting when plugin is used to send metrics catch 22 this would generate lot of noise there is also few open problems which need some feedback how do we deal with the queue believe we need to create new pipeline instance for theses events to isolate this part of the system with the main one if pipeline stop because of plugin or filter it will block the entire system so if we use the main pipeline as the transport agent we will lose the metrics to possibly help us debug the situation should this queue pipeline be bounded should we use circular buffer and we drop events if the outputs can keep up we can probably do work on our side to minimize the memory footprint of the metricmessage the size will be more finite than the normal event quality of service if we use the regular outputs think when they have to deal with metric data they shouldn do any retry and act closely as fire and forget model similar to what statsd is doing with udp its okay to lose some statsd >>>design discuss manageability metrics
provide common interface for collecting metrics in pipeline the agent the pipeline and the plugins will emit some kind of metrics or performance stats if we generalize that action we are actually emitting message of the type `metric` instead of creating custom collector for the metrics think we could create some kind of internal message bus that would take care of any internal messages that the system create and let consumer subscribes to theses messages and act upon them this would allow to decouple the message from that actual work this could allow us to do some neat trick like dynamic resources allocation for slower plugins based on the metric data really high level syntax this architecture would also allow us to use the persistent queue and do replays of metrics if the system goes down and we need to >>>design discuss metrics v3.0.0
pipeline shutdown oob plugins stop this is pr reboot of 3812 from shared branch to facilitate collaboration original description by jsvd currently during shutdown the pipeline loops through input workers and calls thread raise on each input thread plugins rescue that exception to exit the `run` loop afterwards `teardown` is called for any additional bookkeeping this proposal exposes `stop` call on the input plugin class to alert an input that it should shutdown it is the plugin job to frequently poll an internal `stop method to know if it time to exit and terminate if so the `teardown` method remains to do the additional bookkeeping and it will be called by the inputworker when `run` terminates resolves 3210 and replaces 3211 >>>breaking-compatibility enhancement shutdown_semantics v2.0.0-beta2
plugin specific metric collection framework think the easiest part of the code we can instrument is probably the pipeline itself and this will give us good idea how plugin perform in real world one way to do it is to instrument the bounderies of the plugins which are the method interactings with the sizequeue the filter and the receive methods this is options require the least invasive changes and can be done in backward compatible way most the interaction or useful metrics concerning plugin are related to throughput of specific plugin to correctly instrument plugin we must be sure that every plugins has unique identifier ref 3892 3893 input suggest we change how we are sending the queue to the plugin instead of sending directly the sizequeue to run` method we can send an instrumented sizequeue and the code would look like something like this we can easily instrument push of events and probably the sizequeue contention lock since the current sizequeue is only working with events we could track when specific event enter or leave specific queue filter the majority of filter don do any buffering beside the multiline filter but since we are dealing with current time when we yield metrics we can also track the flush output the problem with the output is we don give any feedback up to the pipeline if all the events were correctly written to disk or send to es if even worse if the plugin is doing some kind of buffering the output base class need to provide way to record the metrics when we correctly send event the output also need way to track dropped events and or failures with specific message so we can track different error scenario >>>design discuss metrics v3.0.0
add unique id on every events to trace it through the performance metrics currently event created inside logstash doesn have any unique identifier which could make tracing of an event outside of logstash hard suggest we generate an internal id on every event that logstash create so we can associate recorded metrics to specific event should we allow user to override it >>>discuss metrics v3.0.0
add unique id on every plugin and allow user to override it in the configuration we can define multiples time the same plugin with different configurations but to associate the metrics to specific plugins we need to make sure we can correctly identify it this id has side effect to allow us to update the configuration of specific plugin if needed via an api propose by default every plugins input filter output and codec generate unique id this id should be still human readable to understand what it refer too users should be allowed to override it logstash should be smart enough to raise an issue if two plugins has the same id if would be awesome if codec id contains information about the plugin defining it debug` should show the id in the comment the id need to be reproducable to associated with the same plugin between each restart this is what config would look like with user defined ids >>>design manageability metrics v3.0.0-alpha1
high level metrics need currently in logstash there is no way to easily collect metrics from runnings instance lets define our needs do we need to build custom solution or we can leverage existing code we have to keep in mind that we are currently rewriting important parts of the pipeline in pure java to leverage more speed from the jvm so we need to have an hybrid solution that will grow and adapt with the code base use cases of metrics collection in the current system we want to collect metrics from different part of the system think we should try to have low level library usable in both scenario we can provide helpers method via metaprogramming hiding away the complexity of the data collection this would allow us to turn on of off stats collecting for some part of the code from the pipeline itself in out of the queues in out of the filter method of different plugins metrics from conditionals branching detecting slow part from the plugins webservice latencies heavy computations grok retries count error count internal buffering like multilines filter lumberjack output and elasticsearch output custom metrics defined by plugins authors from the event itself where do we want to expose the metrics collection think we have two different needs data collection for long terms analysis using external services the system need to be able to configure how to expose them and at what frequency we need to update them for configuration it would be nice if we could reuse how we are currently configuring plugins we have to use separate queue and separate config to make sure that data collecting and the normal operations of the pipeline doesn interfere with each other the syntax could be something like this we are thinking about supporting theses services first to elasticsearch using format similar to marvel jmx to other collecting services like statsd adhoc requests via an api theses kind of request are bit different but first let me explain few things each time the system does flush of the metrics see this as snapshot an api is simply view over window representing multiples snapshots that could be aggregated or not depending of the type of the metrics of the collected namespace discoverability every recorded metrics keys should be discoverable either in the api from custom endpoints or in the external services metrics initial requirements think most of our need are basic and we can answers our questions using standard primitives counters increment decrement how many many events we had since startup how many times plugins was restarted timers what is the speed of this specific filter which conditionals is the slowest gauges how many events in the queues each of the metrics need to be saved in specific namespace or key that represent the collected data considering the snapshots and the window maybe namespaces could have differents local retention policies collecting and metrics aggregation from the differents endpoints should be done asynchronously to not block normal pipeline operation first steps evaluate existing libraries there is lot prior work done in ruby or in the jvm to do metrics collection we should leverage theses or at least inspire us from them if they don support all we want to do initial list https github com reinh statsd https github com shopify statsd instrument http metrics dropwizard io ref 2611 >>>design manageability metrics v2.1.0
refactor run mutex for the new shutdown logic run mutex` specific refactor discussion moved here from 3812 copied comment https github com elastic logstash pull 3812 files r38965625 after re analyzing the run mutex` related code it is useful for things consistent view of the ready` and started` properties which need to be consistent across threads since the related `ready and `started methods https github com jsvd logstash blob 79d822a03929c5dd30a6b92bcf81a1a8705b18b3 lib logstash pipeline rb l54 l60 will be typically called from another thread that the one executing the `run` method to avoid calling the shutdown code before the startup is completed believe the `ready and `started methods could be implemented using atomic booleans and for the prevention startup and shutdown race condition it should be refactored in better way it really isn clear now >>>shutdown_semantics
add ready method to new plugin api as proposed discussed in elastic logstash devutils 32 and elastic logstash 3812 now elastic logstash 3895 am moving here the discussion about potentially introducing new `ready method which would mainly help for testing to know when the plugin is ready and we can call the `stop` method on it there are few things we should consider it seems this new `ready method would only be used for tests specs in which case is it really needed in public api it is hard de define the exact semantic of ready is it ready once `register` has been called or when the `run` method has been called or when `run` has completed some internal initialization in any cases the `stop` method should always be callable after `register` has been called would the equivalent of the `stop` `stop be sufficient instead of `ready we could just have threadsafe`run method that just returns `true` when the `run` method has been called thoughts >>>discuss shutdown_semantics
create timing matcher for rspec this is quite an old post https www ruby forum com topic 894409 but it gives solution >>>design discuss enhancement
do you use pry prb in logstash logstash offers the commands `bin logstash irb` or `bin logstash pry` that load the runner class start it and immediately yield command line with either irb or pry questioning the need to still have this does anyone use it what for on the other hand if it useful can we make it better ve only used `bin logstash irb` when wanted to play with logstash event but didn want to bother knowing all the necessary extra logstash rb files would need to load >>>question
delegators performance in ruby and logstash this project uses delegators for couple of things `logstash timestamp` wraps around time and `logstash stringinterpolation` used for template evaluation when doing sprintf on events while this is very useful technique to decorate objects underneath delegate will use `method missing` to wire up the delegator and the delegated object this means that all delegated behaviour will be slower than native calls how slow ve tried comparing delegator around time time itself and class that defines the delegations explicitly the results are not surprising using the forwardable delegation is 47 slower than native calls and using explicit delegation is 17 slower since both uses of forwardable are on the critical path of performance for logstash it advisable to tackle this in near future >>>performance-improvements
logstash should require java oracle marked the eol of java in april 2015 and as of july 2015 they no longer provide downloads for java logstash is good time to upgrade to java benefits being this version of java still receives improvements concurrent ruby dependency library will require java for v1 we can explore using jsr 310 the new java date time tooling https docs oracle com javase docs api index html java time package summary html as replacement to joda time benefit that it native and supports nanosecond precise times joda is millisecond precise >>>breaking-compatibility v3.0.0-alpha1
silence deprecation warnings from concurrent ruby concurrent ruby is throwing warning when running under jdk7 we have decided to silence theses errors unless you run logstash with the debug` flag fixes 3869 >>>v2.0.0-beta1
codec chaining configuration this is task issue for 3873 config syntax changes necessary to support the codec chaining implementation as will be agreed in 3874 >>>enhancement
codec chaining execution strategy this is task issue for 3873 how to implement codec chaining few ideas have been expressed introduce meta codec or codec multiplexer see logstash plugins logstash codec multiline 10 which would avoid refactoring the plugins refactor the plugins to improve codec decoupling and support chaining in the codec executor strategy>>>enhancement
meta codec chaining this is meta issue to reboot the codec chaining idea proposed in 1989 want to split this into two issues that can eventually be tackled separately the config changes necessary to support specifying multiple codecs and the actual multi codecs execution strategy in the plugins believe the latter should be agreed on first and will dictate the configuration requirements to support it purpose support multiple encoding like receiving json messages encoded in msgpack or gzip zlib for example potentially get rid of the multiline filter by combining the multiline codec with another codec like gelf tasks codec chaining execution strategy 3874 https github com elastic logstash issues 3874 codec chaining configuration 3875 https github com elastic logstash issues 3875 >>>enhancement meta
move clamp away from agent remove subcommands and clean cli move all cli parsing to runner freeing agent to solely manage pipelines remove all subcommands focusing on the agent behaviour ensure logging goes through cabin as much as possible log fatal messages to terminal even log is enabled agent now starts empty and pipeline is added and started afterwards for now it agent only supports pipeline but will easily support more than remove doc generation subcommand from bin logstash adds irb pry flag for interactive shell depends on https github com jordansissel ruby cabin pull 37>>>internal-cleanup v3.0.0-alpha1
support added for filter workers default to cpu cores wip add basic defaults module and spec use defaults in pipeline and agent>>>discuss enhancement v2.0.0
warn concurrent deprecated java is deprecated please use java still get this can we maybe monkey patch to suppress this warning until we can go to java for ls config >>>bug
move messy version into metadata version always appended field version` has internal purpose only no one behind the logstash an elasticsearch takes care about logstash internal variables therefore it should not mess the output events so it should be hidden in metadata` it affects mainly `logstash event` `logstash codecs graphite` `logstash outputs graphite` `logstash codecs oldlogstashjson` `logstash outputs gelf` `logstash output elasticsearch lib logstash outputs elasticsearch elasticsearch template json` >>>breaking-compatibility
error installing logstash output elasticsearch license plugin based on the instructions here https www elastic co guide en watcher current logstash integration html getting the following error when trying to install the logstash license plugin using logstash installed using yum on centos >>>bug
increase the default heapsize for ls to 1gb suggest we increase the default heap size `ls heap size` to 1gb 500mb seems too low but really don know how the 500mb became the default one thing we did to alleviate heap usage is reduce es output `flush size` from 5000 to 500 this is typically the source of ooms in ls also jruby is not clear about ooms when it happens tripping new user see https github com elastic logstash issues 3817 thoughts >>>discuss v2.1.0
remove agent subcommand for bin plugin we have usages of `bin plugin agent` and `bin plugin` which essentially does the same thing as mentioned in https github com elastic logstash issues 3148 it is really not necessary to use `agent` sub command lets remove it to avoid confusion >>>breaking-compatibility
change camelcase use of logstash we use `logstash` everywhere docs training material slides etc the codebase has `logstash` which every now and then trips up developers lets mass convert camelcase to lower case `class logstash inputs base logstash plugin` becomes `class logstash inputs base` and so on this breaks backwards compatibility so be done in major release >>>breaking-compatibility v3.0.0
remove deprecated options in plugins something to consider for major release here is the list of deprecated options in plugins as of august 27th 2015 >>>breaking-compatibility v3.0.0
multiline json over streaming plugins cannot work streaming plugins `tcp` and `stdin` are replacing configured `json` codec by `json lines` thanks to `fix streaming codecs but it nor help neither make sense because `json lines` told about itself so multiline json over streaming plugins cannot work results remove useless `fix streaming codecs improve doc with impossibility of working multi line json over streaming inputs ls v1 4>>>bug
malformed data sent to json codec hangs down the plugin completely bin logstash input stdin codec json output stdout codec rubydebug logstash startup completed version timestamp 2015 09 03t14 27 16 132z host localhost plugin had an unrecoverable error will restart this plugin plugin utf debug false error can convert string into integer level error logstash shutdown completed>>>bug
correct response code to align with sample in docs>>>docs
improving error message when installing plugin on the wrong ls version imagine you have ls version and you re trying to install version of plugin that is only able to work on previous versions in this example the error you re getting now is something like this error should be catchup and improved to provide simple message to the end user >>>bundler enhancement plugin_manager
add support for filter workers default to cpu cores >>>enhancement
java filter for logstash you know how there is ruby filter for logstash which enables me to write code in ruby and it is usually included in the config file as follows filter ruby code now have two jar files that would like to include in my filter so that the input have can be processed according to the operations have in these jar files however cannot apparently include the jar file in the ruby code ve been looking for solution any help >>>new-plugin
why do we include maven home jars the ls release artifacts have these jars what are these used for >>>packaging question upstream_fix_needed
mass update all plugins with version of logstash core we published ls core snapshot1 in prep for beta but all plugins have this constraint in their gemspec `s add runtime dependency logstash core this needs to be updated to `for beta1 and when the shutdown changes make it in we can pin the min version to be `2 0` also am not really sure how things are working on jenkins with this constraint plugins are getting installed on ls core now http build eu 00 elasticsearch org view ls 20master job logstash master default plugins 439 >>>enhancement multiple_plugins
documentation needs for ls tracking the documentation needs for ls launch breaking changes for ls new api for shutdown upgrade instructions doc dependency changes https github com elastic logstash issues 3911>>>docs enhancement meta v2.0.0
xml filter target setting required https www elastic co guide en logstash master plugins filters xml html plugins filters xml target the target setting should be listed as required and probably validated if omit it get an error my filter is and my xml is using logstash >>>bug docs
docs clarify if plugins are core or need installing it be nice for users to know by reading the docs if the plugin is included in core eg grok date or if they need to install it eg jdbc also including instructions on how to install yes that is repetitive but it explicit would be nice bonus >>>docs enhancement low_hanging_fruit
jenkins ignore dynamodb for now make sure all plugins tests pass http build eu 00 elastic co view ls 201 job logstash all plugins test 932 console>>>v1.5.5 v2.0.0
jenkins build failing in statsd plugin failures >>>blocker tests-infra
discuss consistent timestamp type handling there are currently two ways for which we handle invalid data assigned to the special timestamp` field if there is any issue during the initialization of new event we tag the failure if there is an issue during field setting we raise typeerror understand that these are different circumstances and why we may want to preserve this behavior but am not convinced we should keep this as it is am inclined to believe that the event should be tagged upon failure in should we keep as is https github com elastic logstash blob master lib logstash event rb l243 l245 https github com elastic logstash blob master lib logstash event rb l137 l139>>>discuss
update ot jruby 22 tests pass locally one test that failed lumberjack fails on master too 3834 >>>v1.5.5 v2.0.0-beta1
jenkins build failing in lumberjack http build eu 00 elastic co view ls 20master job logstash master default plugins >>>blocker tests-infra
update to jruby 22 http jruby org 2015 08 20 jruby 22 html>>>enhancement v2.0.0-beta1
adds new section on managing multiline events http multilion divshot io multiline>>>docs
prep for snapshot1 release for beta1>>>v2.0.0-beta1
remove watchdog this watchdog thread watching is currently unused and bugged in some context this pr remove any mention of it ref 3828>>>breaking-compatibility v2.0.0
building logstash on windows doesn work when running from jenkins ci when running inside the host jruby exe version 20 on windows master branch for logstash>>>windows
remove watchdog in the code base the current implementation of the watchdog is buggy and unused we should remove this dead code we will provide better way of doing monitoring of the pipeline in 2611 ref 1512 >>>breaking-compatibility v2.0.0
your application used more memory than the safety cap of xxxxm hello guys some days ago my logstash became unstable every 10 15 minutes see an error can not bielive that 3g is not enoght for it more over nothing was changed during last couple of days before it was enoght 500m here is my configuration how can fix it more over see that during last couple of days logstash eats more cpu that usual am using debian and `1 1` version of logstash and `1 0` of elasticsearch >>>needs_details unconfirmed
exclude pre releases when checking for update in the plugins manager in the intention to provide fix for 3818 this pr introduces some changes to exclude pre release versions from the filter validation routine that in place for the update process this follows the actual bundler out internal packet manager of dealing with prereleases bundler will always update using the update command to the last non prerelease version in order to install prerelease version actually the way is to change the name in the gemfile running bundler install this could be archived in our setup by using bin plugin install command with the right version the pre release one we could add this to the update command but would not recommend that for some reasons it breaks the bundler way of doing things and we know making bundler unhappy makes us unhappy kinda understand the reason behind this updating to pre release is actually explicit but throw uninstall install let me know what do you think cheers fixes 3818 >>>blocker bundler plugin_manager v2.0.0
new syslog codec create new syslog codec to add support for rfc3164 https tools ietf org html rfc3164 and rfc5424 https tools ietf org html rfc5424 with continued iso8601 date format support so it can be used with any input like tcp udp http and so on plan is to deprecate the current syslog input plugin since it only supports rfc3164 and is not flexible the cardinality and locations of format divergence are extremely vast especially around the many networking manufacturers formats that diverge from the standard rfc3164 old and rfc5424 newer will require custom grok patterns to successfully parse in the logstash ecosystem the intent is to ubiquitously support these two popular formats standardized by centralized logging systems forwarders like syslog ng rsyslog nxlog kiwi syslog server and other types of application loggers like syslog4j and ruby syslog rfc3164 https github com logstash plugins logstash input syslog issues 15 rfc5424 https github com logstash plugins logstash input syslog issues 14 resolve any other important issues in the syslog input plugin https github com logstash plugins logstash input syslog issues related https github com elastic logstash issues 1667>>>enhancement meta v3.0.0-alpha2
doc generation preview in the plugins side hi when developing plugin it would nice to see how the documentation for it would be like nowadays it all works from the main logstash however introducing command that able to generate it from the plugin will be very useful so having something like rake doc to get preview alike with the thing provided nowadays by logstash >>>docs plugin_manager
wip refactoring the plugin manager this pr is work in progress this pr aims to apply some pending refactorings and internal cleanups for the plugin manager for now this provide solution for refactor of pluginmanger utils rb 3746 including changes to the way namespaces are created to be using more ruby style update validations relates to 3744 by introduced more formal way of filtering validating input for update plugins and actually other inputs too relates to 3821>>>internal-cleanup plugin_manager work_in_progress
plugin manager refactoring and internal cleanups this issue tries to sum up the different issues regarding plugin refactoring internal cleanups the current open tasks issues are plugin install development should be sticky 2631 refactor of pluginmanager utils rb 3746 upgrade validation of validate major version 3744 3818 logging in the plugin manager 3656 2627 lock file to prevent concurrent access to the gemfile 2622 only install logstash plugins with the plugin manager 2047>>>meta plugin_manager
plugin manager should not present beta plugins as upgrade options rubygems defines beta as any plugin version with an alphabet character in it the code here https github com elastic logstash blob 028d76497ccef3a8d11a3528cdf6b99e8d10f070 lib pluginmanager update rb l72 should skip past these versions >>>blocker bundler v2.0.0-beta1
logstash v1 misleading error message when heapsize is too small if logstash is started with too small of heap it barfed with misleading error message fortunately just changed one value so knew exactly what broke had ls heap size 2000m and lowered it to 1000m when logstash is started the log contain exception in thread worker exception in thread elasticsearch java lang unsupportedoperationexception 	at java lang thread stop thread java 869 	at org jruby rubythread exceptionraised rubythread java 1221 	at org jruby internal runtime rubyrunnable run rubyrunnable java 112 	at java lang thread run thread java 745 java lang unsupportedoperationexception 	at java lang thread stop thread java 869 	at org jruby rubythread exceptionraised rubythread java 1221 	at org jruby internal runtime rubyrunnable run rubyrunnable java 112 	at java lang thread run thread java 745 changing the ls heap size to 1500m allows it to run again so evidently lowered it too much >>>bug
automated test to process large files with ls we need automated test which processes with es output large files with default settings and see where it breaks test for multiple document sizes and es output bulk configuration may be required >>>tests-infra
add new apache tika codec add new apache tika codec to extract metadata information from binary files this will also help users of es attachment mapper river https github com elastic elasticsearch mapper attachments if we bring this functionality into logstash>>>new-plugin
adapt plugins to new plugin api introduced by 3210 issue 3210 and pr 3812 3895 change the plugin api to add `stop` public `stop public to logstash inputs base rename `teardown` to `close` remove `shutdown` `finished` `finished `running `terminating from logstash plugin refactor work needed on the plugins input plugins https github com issues utf8 e2 9c 93 is 3aopen is 3aissue user 3alogstash plugins label 3a 22shutdown semantics 22 input plugins are now shutdown by an external call to `plugin stop` instead of catching logstash shutdownsignal exception unless overridden `stop` will simply makes `stop return `true` thus allowing `run` to poll this and return after seeing the change in some plugins extra work must be done in `stop` to instruct `run` that it time to return for example in the `logstash input udp` it necessary to call socket close` to make the blocking read on the socket raise an exception thus breaking out the loop so different input plugins will require different `stop` strategies refactoring an input plugin involves removing rescue of `shutdownsignal` exception understand the nature of the `run` loop is it `while` `consumer subscribe event is there blocking operation on socket fd use `stop and or override `stop` to make run return put any other cleanup bookkeeping tasks in `close` currently done in `teardown` remove any calls to `shutdown` `finished` `finished `running or `terminating then for testing you can use the shared example provided in https github com elastic logstash devutils pull 32 in the following manner testing the refactor clone logstash switch to pr 3895 clone logstash devutils switch to pr 32 clone plugin repository switch to refactor pr check above edit gemfile to look like run `bundle install` run `bundle exec rspec` filters and outputs both will still shutdown using the shutdownevent sent by the pipeline so no major changes necessary the work in these plugins is to remove calls that are no longer in the pipeline plugin contract `shutdown` `finished` `finished `running or `terminating rename `teardown` to `close` work to do input plugins default input plugins logstash input couchdb changes https github com logstash plugins logstash input couchdb changes issues 20 pr https github com logstash plugins logstash input couchdb changes pull 21 logstash input elasticsearch https github com logstash plugins logstash input elasticsearch issues 29 pr https github com logstash plugins logstash input elasticsearch pull 28 logstash input eventlog https github com logstash plugins logstash input eventlog issues 18 pr https github com logstash plugins logstash input eventlog pull 19 logstash input exec https github com logstash plugins logstash input exec issues pr https github com logstash plugins logstash input exec pull logstash input file https github com logstash plugins logstash input file issues 68 pr https github com logstash plugins logstash input file pull 67 logstash input ganglia https github com logstash plugins logstash input ganglia issues pr https github com logstash plugins logstash input ganglia pull 10 logstash input gelf https github com logstash plugins logstash input gelf issues 17 pr https github com logstash plugins logstash input gelf pull 19 logstash input generator https github com logstash plugins logstash input generator issues 10 pr https github com logstash plugins logstash input generator pull logstash input graphite https github com logstash plugins logstash input graphite issues logstash input heartbeat https github com logstash plugins logstash input heartbeat issues pr https github com logstash plugins logstash input heartbeat pull logstash input http https github com logstash plugins logstash input http issues 32 pr https github com logstash plugins logstash input http pull 31 logstash input imap https github com logstash plugins logstash input imap issues 10 pr https github com logstash plugins logstash input imap pull logstash input irc https github com logstash plugins logstash input irc issues 14 pr https github com logstash plugins logstash input irc issues 14 logstash input kafka https github com logstash plugins logstash input kafka issues 41 pr https github com logstash plugins logstash input kafka pull 42 logstash input log4j https github com logstash plugins logstash input log4j issues 19 pr https github com logstash plugins logstash input log4j pull 17 logstash input lumberjack https github com logstash plugins logstash input lumberjack issues 52 pr https github com logstash plugins logstash input lumberjack pull 59 logstash input pipe https github com logstash plugins logstash input pipe issues 11 pr https github com logstash plugins logstash input pipe pull 10 logstash input rabbitmq https github com logstash plugins logstash input rabbitmq issues 38 pr https github com logstash plugins logstash input rabbitmq pull 40 logstash input redis https github com logstash plugins logstash input redis issues 26 pr https github com logstash plugins logstash input redis pull 27 logstash input s3 https github com logstash plugins logstash input s3 issues 53 pr https github com logstash plugins logstash input s3 pull 55 logstash input snmptrap https github com logstash plugins logstash input snmptrap issues 11 pr https github com logstash plugins logstash input snmptrap pull 12 logstash input sqs https github com logstash plugins logstash input sqs issues 19 pr https github com logstash plugins logstash input sqs pull 20 logstash input stdin https github com logstash plugins logstash input stdin issues pr https github com logstash plugins logstash input stdin pull logstash input syslog https github com logstash plugins logstash input syslog issues 20 pr https github com logstash plugins logstash input syslog pull 21 logstash input tcp https github com logstash plugins logstash input tcp issues 17 pr https github com logstash plugins logstash input tcp pull logstash input twitter https github com logstash plugins logstash input twitter issues 27 pr https github com logstash plugins logstash input twitter pull 28 logstash input udp https github com logstash plugins logstash input udp issues pr https github com logstash plugins logstash input udp pull logstash input unix https github com logstash plugins logstash input unix issues pr https github com logstash plugins logstash input unix pull 10 logstash input xmpp https github com logstash plugins logstash input xmpp issues pr https github com logstash plugins logstash input xmpp pull logstash input zeromq https github com logstash plugins logstash input zeromq issues pr https github com logstash plugins logstash input zeromq pull 10 remove `shutdown` nothing to do remove `finished` logstash output file https github com logstash plugins logstash output file please review pr https github com logstash plugins logstash output file pull 16 logstash output kafka https github com logstash plugins logstash output kafka please review pr https github com logstash plugins logstash output kafka pull 28 logstash output lumberjack https github com logstash plugins logstash output lumberjack please review pr https github com logstash plugins logstash output lumberjack pull 10 logstash output pipe https github com logstash plugins logstash output pipe please review https github com logstash plugins logstash output pipe pull logstash output rabbitmq https github com logstash plugins logstash output rabbitmq please review https github com logstash plugins logstash output rabbitmq pull 23 logstash output s3 https github com logstash plugins logstash output s3 please review https github com logstash plugins logstash output s3 pull 30 logstash output sqs https github com logstash plugins logstash output sqs please review https github com logstash plugins logstash output sqs pull logstash output stdout https github com logstash plugins logstash output stdout please review pr https github com logstash plugins logstash output stdout pull logstash output udp https github com logstash plugins logstash output udp please review pr https github com logstash plugins logstash output udp pull remove `finished nothing to do remove `running nothing to do remove `terminating nothing to do rename `teardown` to `close` issue https github com elastic logstash issues 3952 tracks this other tasks improve the logstash input example https github com logstash plugins logstash input example documentation to reflect the new api add documentation in elastic co reference about new api signatures blog about api changes fix plugins not included by default in logstash releases https github com elastic logstash issues 3963>>>breaking-compatibility meta shutdown_semantics v2.0.0
trigger input plugin shutdown using out of band call currently during shutdown the pipeline loops through input workers and calls thread raise on each input thread plugins rescue that exception to exit the `run` loop afterwards `teardown` is called for any additional bookkeeping this proposal exposes `stop` call on the input plugin class to alert an input that it should shutdown it is the plugin job to frequently poll an internal `stop method to know if it time to exit and terminate if so the `teardown` method remains to do the additional bookkeeping and it will be called by the inputworker when `run` terminates resolves 3210 and replaces 3211 >>>breaking-compatibility enhancement shutdown_semantics v2.0.0
logstash1 crash exception in thread output java lang unsupportedoperationexception 	at java lang thread stop thread java 869 	at org jruby rubythread exceptionraised rubythread java 1221 	at org jruby internal runtime rubyrunnable run rubyrunnable java 112 	at java lang thread run thread java 745 and exception in thread ruby thread 10 usr local src logstash vendor bundle jruby gems stud 20 lib stud buffer rb 92 java lang unsupportedoperationexception 	at java lang thread stop thread java 869 	at org jruby rubythread exceptionraised rubythread java 1221 	at org jruby internal runtime rubyrunnable run rubyrunnable java 112 	at java lang thread run thread java 745 >>>needs_details
fixes broken link to watcher integration page>>>v2.0.0
updates advanced pipeline section to include tutorial dataset for users >>>v2.0.0
logstash net points to old release in its banner navigate to http logstash net docs you ll see notice this page documents logstash which is not the latest stable release the latest stable release of logstash is unless you are here on purpose you probably want to be viewing the latest documentation go to the latest available document for this page docs need to update it to 4>>>bug docs
logstasn snmp output plugin there is already an snmp input but there are also scenarios where an snmp output plugin could be useful sending messages from logstash to another tool as snmp is very common protocol there are many use cases this can come in handy >>>new-plugin
adds alvin chen new introduction section replaces the old logstash reference preface >>>docs v2.0.0
evaluate framework or routing strategy for the api endpoints in the past logstash we were using sinatra http www sinatrarb com to serve the kibana javascript code since the api will need to answer multiples web calls we should use see if we can leverage existing library to speed up the development process non exhaustive list of libraries rack https github com rack rack sinatra http www sinatrarb com lotus rb http lotusrb org lotus router https github com lotus router cuba http cuba is grape https github com ruby grape grape all the previous libraries support basic crud operations but think we should investigate if in near future we will need to support websocket or long polling stream both of theses technologies could be awesome to provide step debugger or display live stats on marvel like dashboard the minimal requirements for them are routing handling params handling and or sanitization request response content type negotiation rack based which we will need to hook into puma easy to test ref 2611>>>design manageability metrics v3.0.0
evaluate how we are exposing the api endpoints the api will need to expose his endpoints with webserver and we also have http input https github com logstash plugins logstash input http providing his own http server it probably good time to see if we offer the http server as first class service that plugins authors can hook into and add their own endpoints pro reduce the code offer centralized configuration for the certificate port ip probably via logstash yml mimic what elasticsearch is doing with their plugin architecture con shared the certificate use same port performance or blocking in the input side could possibly impact the debugging api ref 2611>>>design manageability metrics v3.0.0
the pipeline should return the current active plugins the pipeline should be able to answer the following questions returns activated plugins in that specific pipeline returns activated plugins grouped per type returns activated plugins filtered by type input output filter codec either by keeping an internal registry or asking the specific ast for that pipeline ref 2611>>>design manageability v3.0.0
attempting tcp ssl connection unrecognized ssl message plaintext connection from what understand the port being using for communication is not secure am not sure how to fix this am attempting to log to my `logstash` instance using `logback` and the `logstashtcpsocketappender` with this config this is my `logstash` config this is the error message get in full if disable ssl then the logging works as expected so my app and `logstash` can communicate don think its key problem because wouldn that tell me something like `cannot complete ssl handshake` is there specific port that need to use `logstash forwarder` is not solution here there is reason why we don want to use it currently `logstash` in hosted on an `amazon ec2 `instance which allows `tcp port` access on `port 8443` >>>needs_details
exception handling in plugins hi from the work ve been doing this days on adding test to plugins without had the chance to revisit some of them noticing an interesting pattern on them some plugins use this pattern when handling exceptions even if this might makes sense for first implementation of the plugin so the plugin is not exploding when exceptions are thrown think we should improve the way we handle exceptions so we could do fine granularity control in some of the plugins there where situation when this exceptions hid errors that would be nice otherwise to notice relates to 2477 >>>design enhancement internal-cleanup
path validation semantic being confusing require file dir to exist from doing work on the test for the nagios plugin faced with the fact that the path validation expects the file to actually exist however the semantics of this validation even if useful for most of the current plugins is not clear propose to introduce new validation that has this same semantics while having path only as validation of real system path >>>bug
input salesforce for consideration https github com russorat logstash input salesforce this plugin provides way to pull salesforce data into your logstash pipeline this is an issue to start the process of making it ready for production >>>new-plugin
find better method for determining names of plugins without whacking everything named base this code https github com elastic logstash blob master lib logstash config mixin rb l63 precludes the use of mixins with name of base very confusing we should have stronger test using `is `>>>bug design internal-cleanup
azure search support azure has search service which is based on elasticsearch https msdn microsoft com en us library azure dn798935 aspx 255 mspperror 2147217396 it would be nice to have input output plugin that used the azure specific api >>>new-plugin
init script from rpm package ignores javacmd setting from etc sysconfig logstash hi version affected shipped in rpm system centos issue repro if you set custom javacmd path inside etc sysconfig logstash it won have any affect in how logstash is run logstash will be started with default java ignoring this setting fix one way of fixing this is to export javacmd variable inside etc init logstash diff for line 51 export path home ls heap size ls java opts ls use gc logging export path home ls heap size ls java opts ls use gc logging javacmd>>>packaging
path validation when it does not exist from doing work on the test for the nagios plugin faced with the fact that the path validation expects the file to actually exist however the semantics of this validation even if useful for most of the current plugins is not clear in this pr the changes introduced are introduce the file or dir validation to be used when you want to make sure path is actually there for example with the nagios command or an ssl certificate remove the file exists validation from the path check this will return now also an instance of pathname so the plugin using this will be responsible of for example creating the file when need as soon as this gets green light we should be sure to update related plugins who trust path to be used actually to validate the file or dir exist fixes 3793>>>enhancement
replace message queue with message broker it minor but we seem to be recommending mq rather than generic broker here https www elastic co guide en logstash current deploying and scaling html we should update this >>>docs
timestamp parsing fails with cannot convert instance of class org jruby rubyobject to class java lang string hi using the logstash package on debian wheezy with the following versions logstash openjdk jre headless amd64 7u79 deb7u1 getting the following message at this point not quite sure what causing it suspecting the following tidbit in the config but cannot be certain namely the target part any ideas >>>needs_details unconfirmed
adds section on managing multiline events has details on multiline plugin configuration >>>docs
syslog msgs for stacktracelines are loosing info about program last week upgrade logstash on our loghost from to and we are now seeing 011 files on our loghost the something is the 1st word from the msg it looks like the problem is with the stacktraceexception lines where the program field isn added and instead it uses the 1st word from the msg weird thing is that doesn have problem with it is there something changed in that can cause this and how to circumvent this no other software then logstash on the loghost was updated message aug 24 15 54 00 ad005 011java lang runtimeexception there was an error in processtask version timestamp 2015 08 24t13 54 00 091z host 111 11 11 message aug 24 15 54 00 ad005 011at eu comparegroup services stats tasks processtask run processtask java 74 version timestamp 2015 08 24t13 54 00 092z host 111 11 11 message aug 24 15 54 00 ad005 011at java util concurrent threadpoolexecutor runworker threadpoolexecutor java 1142 version timestamp 2015 08 24t13 54 00 094z host 111 11 11 >>>needs_details
ping logstash health edit using version `1 4` is there way to `ping` `logstash` for its health am using `logstash` behind an `amazon elb` which needs to pass health check currently it is set up to attempt to open `tcp` connection on `port 5000` which is where `logstash` is running but it consistently fails am looking for way to return `http 200 status` if possible or plugin command line option to enable this to happen is this possible >>>question
logstash rpm permission issue hello yesterday installed logstash from the rpm in the repo am using rabbitmq as input and output module starting logstash with regular user account other than logstash or root causes an error fix thanks daniel>>>bug
exception in filterworker probably urlencode plugin version of logstash is version of jdk is 45 following is my configuration input file path data logs nginx access log start position beginning stdin filter grok match message hostname requesthost ipv4 requestip notspace requestremoteuser httpdate requesthttpdate qs requesturl number requesthttpstatus int number requestbodysentbytes int qs requesthttpreferer qs requesthttpuseragent qs requesthttpxforwaredfor number requesttime float date match requesthttpdate dd mmm yyyy hh mm ss kv source requesturl field split trimkey trim mutate convert launch integer screendpi float screenwidth integer screenheight integer longitude float latitude float urldecode all fields true output elasticsearch protocol transport cluster mc es ai index logstash busybox mm dd host 10 162 65 105 stdout codec json following is the error message timestamp 2015 08 24t07 09 51 349000 0800 message exception in filterworker exception backtrace org jruby rubyhash java 991 in home mucang app logstash vendor bundle jruby gems logstash core java lib logstash util accessors rb 65 in `set home mucang app logstash vendor bundle jruby gems logstash core java lib logstash event rb 146 in home mucang app logstash vendor bundle jruby gems logstash filter urldecode lib logstash filters urldecode rb 36 in `filter org jruby rubyhash java 1341 in `each home mucang app logstash vendor bundle jruby gems logstash filter urldecode lib logstash filters urldecode rb 36 in `filter home mucang app logstash vendor bundle jruby gems logstash core java lib logstash filters base rb 163 in `multi filter org jruby rubyarray java 1613 in `each home mucang app logstash vendor bundle jruby gems logstash core java lib logstash filters base rb 160 in `multi filter eval 157 in `filter func home mucang app logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 219 in `filterworker home mucang app logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 157 in `start filters level error following is example of our nginx log some of the sensitive infos are replaced busybox xxx com 39 71 227 24 aug 2015 09 00 12 0800 get api xxx xxx list htm productid protocol platform android srv appname xxx product e9 a9 be e8 80 83 e5 ae 9d e5 85 b8 vendor xxx renyuan xxx version system kot49h manufacturer yulong systemversion device coolpad 208675 hd imei xxx productcategory xxx operator androidid xxx mac 3c 3a91 3a57 3aa2 3a9c 3ab5 appuser xxx pkgname com xxx xxx screendpi screenwidth 720 screenheight 1280 network wifi launch 19 webviewversion firsttime 2015 06 11 2020 3a59 3a22 usercity 123456 5c46565957561c4550555c gpstype baidu cityname e6 b5 8e e5 8d 97 e5 b8 82 citycode 123456 gpscity 123456 longitude 180 9733 latitude 336 719 ipcity 123456 schoolname e6 b3 89 e6 97 ba e9 a9 be e6 a0 a1 schoolcode 123456 sign xxx http 200 3057 mozilla linux android coolpad 8675 hd build kot49h applewebkit 537 36 khtml like gecko version chrome 30 mobile safari 537 36 059 >>>needs_details unconfirmed
docs include all possible actions in es output currently for the es output https www elastic co guide en logstash current plugins outputs elasticsearch html plugins outputs elasticsearch action we state valid actions are index delete` and then go on to mention index delete and also create and create unless exists we just need to update the first sentence to include the other two >>>docs
logstash on os error permission denied var lib logstash xxx hi ve upgraded to logstash on os and now getting this error usr local bin logstash agent usr local etc logstash conf logstash conf plugin had an unrecoverable error will restart this plugin plugin var log suricata eve json sincedb path var lib logstash codec utf type suricataidps start position beginning debug false stat interval discover interval 15 sincedb write interval 15 delimiter error permission denied var lib logstash 13472 87395 399540 level error errno eacces permission denied var lib logstash 13472 87395 203614 initialize at org jruby rubyfile java 363 new at org jruby rubyio java 853 atomic write at usr local cellar logstash libexec vendor bundle jruby gems filewatch lib filewatch helper rb 33 sincedb write at usr local cellar logstash libexec vendor bundle jruby gems filewatch lib filewatch tail rb 235 sincedb write at usr local cellar logstash libexec vendor bundle jruby gems filewatch lib filewatch tail rb 205 teardown at usr local cellar logstash libexec vendor bundle jruby gems logstash input file lib logstash inputs file rb 157 inputworker at usr local cellar logstash libexec vendor bundle jruby gems logstash core java lib logstash pipeline rb 203 synchronize at org jruby ext thread mutex java 149 inputworker at usr local cellar logstash libexec vendor bundle jruby gems logstash core java lib logstash pipeline rb 203 start input at usr local cellar logstash libexec vendor bundle jruby gems logstash core java lib logstash pipeline rb 171 please help >>>bug
input csvfile for consideration needed to process csv files with first line schemas that can vary from file to file but see there no clean way to do so with today plugins in some forum comments see that improved csv handling is on the to do list went ahead and coded up subclass of logstash input file that adds csv parsing with first line schema mode the fundamental csv parsing logic is largely borrowed from logstash filter csv albeit extended with first line schema mode be interested in having it considered for submission as standard plugin code tests are at https github com jweite logstash input csvfile1 and particularly to get some other eyes on my code as it my first logstash plugin ps while initially considered enhancing logstash filter csv ultimately concluded that the only 100 reliable way to restart stream processing mid file was to re read the file schema row something that only the file input plugin can always do >>>needs_details new-plugin
the error reported is uninitialized constant concurrent delay executor in logstash logstash stopped if insert lumberjack input configuration but strange part is it doesn tell me when do configtest it says everything is ok this is the error message logged in the log file timestamp 2015 08 22t08 28 52 633000 0000 message the error reported is uninitialized constant concurrent delay executor note but there is no issue with other input configurations like tcp collectd those input method have tried so far only problem with lumberjack input is this bug in new release or did make any mistake in the configuration note using the same configuration in logstash that doesn hit with the problem my configuration input tcp port 5000 type logs udp port 25827 codec collectd type collectd lumberjack port 5055 type logs ssl certificate etc pki tls certs test example com crt ssl key etc pki tls private test example com key output stdout codec rubydebug >>>bug v1.5.5
displayed error message when connect from logstash to logstash with using lumberjack please let me know solution workagound for the below issue built logstash server v1 this logstash server can recieve logs from logstash forwarder v0 on windows but the one cannot recieve logs from logstash v1 with using lumberjack on windows the below is error message on command prompt logstash logstash bin logstash bat agent logstash logstash conf logstash conf io console not supported tty will not be manipulated logstash startup completed 31mclient write error trying connect backtrace logstash logstash vendor bundle jruby gems jls lumberjack 24 lib lumberjack client rb 132 in `ack logstash logstash vendor bundle jruby gems jls lumberjack 24 lib lumberjack client rb 120 in `write sync logstash logstash vendor bundle jruby gems jls lumberjack 24 lib lumberjack client rb 41 in `write logstash logstash vendor bundle jruby gems logstash output lumberjack lib logstash outputs lumberjack rb 71 in `flush logstash logstash vendor bundle jruby gems stud 21 lib stud buffer rb 219 in `buffer flush org jruby rubyhash java 1341 in `each logstash logstash vendor bundle jruby gems stud 21 lib stud buffer rb 216 in `buffer flush logstash logstash vendor bundle jruby gems stud 21 lib stud buffer rb 112 in `buffer initialize org jruby rubykernel java 1511 in `loop logstash logstash vendor bundle jruby gems stud 21 lib stud buffer rb 110 in `buffer initialize level error 0m 31mclient write error trying connect backtrace logstash logstash vendor bundle jruby gems jls lumberjack 24 lib lumberjack client rb 132 in `ack logstash logstash vendor bundle jruby gems jls lumberjack 24 lib lumberjack client rb 120 in `write sync logstash logstash vendor bundle jruby gems jls lumberjack 24 lib lumberjack client rb 41 in `write logstash logstash vendor bundle jruby gems logstash output lumberjack lib logstash outputs lumberjack rb 71 in `flush logstash logstash vendor bundle jruby gems stud 21 lib stud buffer rb 219 in `buffer flush org jruby rubyhash java 1341 in `each logstash logstash vendor bundle jruby gems stud 21 lib stud buffer rb 216 in `buffer flush logstash logstash vendor bundle jruby gems stud 21 lib stud buffer rb 112 in `buffer initialize org jruby rubykernel java 1511 in `loop logstash logstash vendor bundle jruby gems stud 21 lib stud buffer rb 110 in `buffer initialize level error 0m also the below is conf for logstash v1 input 	eventlog 	type win32 eventlog 	logfile application security system output 	lumberjack 		hosts ip address of logstash server 		port xxxx 		ssl certificate lumberjack crt >>>needs_details unconfirmed
ast pipeline refactor merged filter output stage in service of the new pipeline execution model https github com elastic logstash issues 3693 issuecomment 127672028 we need the ast to be turned into new executor primitives currently we compile `input `filter and `output to execution functions the new pipeline has different characteristics that require the filter and output units to be merged what we need the ast to yield going forward is the input side should remain the same this function must be threadsafe current outputs must be internally wrapped in unique mutex to ensure correct behavior we should create new `logstash output threadable` class for threadsafe outputs outputs utilizing workers should be rewritten to be `threadable` outputs not inheriting from threadable must be wrapped in mutex>>>design discuss v2.2.0
richer plugin configuration syntax currently working with configurations is awkward for few reasons mixins can namespace their configuration it would be nice to let plugin including mixin include all its configs under certain root level config perhaps multiple times under different names doc generation is weird with the current comment syntax this precludes programatic config generation and nesting use of ivars makes plugin authors work around naming conflicts if have config var now named `queue` for the queue name must later write queue inst somequeue new queue prefer to write queue somequeue new config queue name ph mentioned having full separate configuration class agree would like some sort of `configuration` object that could be used something like in the example below think the syntax here could be better but would like all the capabilities used here >>>design discuss
method compact added to java integrations add compact and compact methods to java util collection>>>bug v1.5.5 v2.0.0
file input stops reading file logstash windows have logstash running on windows have syslog server writes to logfile that logstash points to config file vi logstash apache conf input file type syslogs path start position beginning sincedb path logstash sincedb syslog db filter if message drop if type syslogs grok match message year year monthnum month monthday monthday time time ip sourceip sysentry facility sysentry severity greedydata syslog message 		add field datetime time month monthday year date match datetime hh mm ss mm dd yyyy mutate remove field month monthday time year output if grokparsefailure in tags elasticsearch host es2907 protocol http index logstash groksyslogsfailure yyyy mm dd else if type syslogs elasticsearch host es2907 protocol http index logstash syslogs yyyy mm dd logstash reads all 247 log files in everything is ok but when it is done it just stops reading the logfile from even when the syslog server adds entries to the log file if restart logstash picks up the sincedb and reads the latest entries from the logfile and the stops again does it have anything to do with my windows mapped drive have turned on the debug log at the last line reads timestamp 2015 08 21t13 43 57 944000 0200 message discover file glob glob is 150502sys 00 log 150503sys 00 log 150504sys 00 log 150505sys 00 log 150506sys 00 log 150507sys 00 log 150508sys 00 log 150509sys 00 log 150510sys 00 log 150511sys 00 log 150511sys 01 log 150512sys 00 log 150512sys 01 log 150512sys 02 log 150513sys 00 log 150513sys 01 log 150514sys 00 log 150515sys 00 log 150516sys 00 log 150517sys 00 log 150518sys 00 log 150519sys 00 log 150519sys 01 log 150520sys 00 log 150520sys 01 log 150520sys 02 log 150521sys 00 log 150521sys 01 log 150522sys 00 log 150523sys 00 log 150524sys 00 log 150525sys 00 log 150526sys 00 log 150527sys 00 log 150528sys 00 log 150528sys 01 log 150529sys 00 log 150530sys 00 log 150531sys 00 log 150601sys 00 log 150602sys 00 log 150603sys 00 log 150604sys 00 log 150605sys 00 log 150606sys 00 log 150607sys 00 log 150608sys 00 log 150608sys 01 log 150609sys 00 log 150610sys 00 log 150611sys 00 log 150612sys 00 log 150612sys 01 log 150613sys 00 log 150614sys 00 log 150615sys 00 log 150616sys 00 log 150617sys 00 log 150618sys 00 log 150619sys 00 log 150620sys 00 log 150621sys 00 log 150622sys 00 log 150623sys 00 log 150624sys 00 log 150625sys 00 log 150626sys 00 log 150627sys 00 log 150628sys 00 log 150629sys 00 log 150630sys 00 log 150701sys 00 log 150702sys 00 log 150703sys 00 log 150704sys 00 log 150705sys 00 log 150706sys 00 log 150707sys 00 log 150708sys 00 log 150709sys 00 log 150710sys 00 log 150711sys 00 log 150712sys 00 log 150713sys 00 log 150714sys 00 log 150715sys 00 log 150716sys 00 log 150717sys 00 log 150718sys 00 log 150719sys 00 log 150720sys 00 log 150721sys 00 log 150722sys 00 log 150723sys 00 log 150724sys 00 log 150725sys 00 log 150726sys 00 log 150727sys 00 log 150728sys 00 log 150728sys11 00 log 150728sys12 00 log 150729sys 00 log 150730sys 00 log 150731sys 00 log 150801sys 00 log 150802sys 00 log 150803sys 00 log 150804sys 00 log 150805sys 00 log 150806sys 00 log 150807sys 00 log 150808sys 00 log 150809sys 00 log 150810sys 00 log 150811sys 00 log 150812sys 00 log 150813sys 00 log 150814sys 00 log 150815sys 00 log 150816sys 00 log 150817sys 00 log 150818sys 00 log 150819sys 00 log 150820sys 00 log 150821sys 00 log 2015 01 01 csv 2015 01 02 csv 2015 01 03 csv 2015 01 04 csv 2015 01 05 csv 2015 01 06 csv 2015 01 07 csv 2015 01 08 csv 2015 01 09 csv 2015 01 10 csv 2015 01 11 csv 2015 01 12 csv 2015 01 13 csv 2015 01 14 csv 2015 01 15 csv 2015 01 16 csv 2015 01 17 csv 2015 01 18 csv 2015 01 19 csv 2015 01 20 csv 2015 01 21 csv 2015 01 22 csv 2015 01 23 csv 2015 01 24 csv 2015 01 25 csv 2015 01 26 csv 2015 01 27 csv 2015 01 28 csv 2015 01 29 csv 2015 01 30 csv 2015 01 31 csv 2015 02 01 csv 2015 02 02 csv 2015 02 03 csv 2015 02 04 csv 2015 02 05 csv 2015 02 06 csv 2015 02 07 csv 2015 02 08 csv 2015 02 09 csv 2015 02 10 csv 2015 02 11 csv 2015 02 12 csv 2015 02 13 csv 2015 02 14 csv 2015 02 15 csv 2015 02 16 csv 2015 02 17 csv 2015 02 18 csv 2015 02 19 csv 2015 02 20 csv 2015 02 21 csv 2015 02 22 csv 2015 02 23 csv 2015 02 24 csv 2015 02 25 csv 2015 02 26 csv 2015 02 27 csv 2015 02 28 csv 2015 03 01 csv 2015 03 02 csv 2015 03 03 csv 2015 03 04 csv 2015 03 05 csv 2015 03 06 csv 2015 03 07 csv 2015 03 08 csv 2015 03 09 csv 2015 03 10 csv 2015 03 11 csv 2015 03 12 csv 2015 03 13 csv 2015 03 14 csv 2015 03 15 csv 2015 03 16 csv 2015 03 17 csv 2015 03 18 csv 2015 03 19 csv 2015 03 20 csv 2015 03 21 csv 2015 03 22 csv 2015 03 23 csv 2015 03 24 csv 2015 03 25 csv 2015 03 26 csv 2015 03 27 csv 2015 03 28 csv 2015 03 29 csv 2015 03 30 csv 2015 03 31 csv 2015 04 01 csv 2015 04 02 csv 2015 04 03 csv 2015 04 04 csv 2015 04 05 csv 2015 04 06 csv 2015 04 07 csv 2015 04 08 csv 2015 04 09 csv 2015 04 10 csv 2015 04 11 csv 2015 04 12 csv 2015 04 13 csv 2015 04 14 csv 2015 04 15 csv 2015 04 16 csv 2015 04 17 csv 2015 04 18 csv 2015 04 19 csv 2015 04 20 csv 2015 04 21 csv 2015 04 22 csv 2015 04 23 csv 2015 04 24 csv 2015 04 25 csv 2015 04 26 csv 2015 04 27 csv 2015 04 28 csv 2015 04 29 csv 2015 04 30 csv 2015 05 01 csv 2015 05 02 csv level debug file logstash vendor bundle jruby gems filewatch lib filewatch watch rb line 132 method discover file best regards kre>>>windows
mutate lowercase empties content of field in logstash the following lines will cause my hostname field to become null empty same lines worked in and if remove them my field gets valued note that the hostname field in my case can come from previously renamed field >>>blocker
wrong date and added elasticsearch upsert support>>>v2.0.0
bundler clean is broken our strategy for purging uninstalled or unused plugins with either or does not work the dual `invoke` calls as shown above should work but does not because there is some stale context state in bundler in fact if calling `logstash bundler invoke clean true from fresh process works as shown by purbon in 3731 relates to 3678 3731 >>>bug
the `plugin update` command update the plugins but don give user feedback concerning the updated plugins logstash input stdin logstash snapshot3 bin plugin install version logstash input stdin validating logstash input stdin installing logstash input stdin installation successful logstash snapshot3 bin plugin list verbose stdin logstash input stdin logstash snapshot3 bin plugin update updating logstash codec collectd logstash codec dots logstash codec edn logstash codec edn lines logstash codec es bulk logstash codec fluent logstash codec graphite logstash codec json logstash codec json lines logstash codec line logstash codec msgpack logstash codec multiline logstash codec netflow logstash codec oldlogstashjson logstash codec plain logstash codec rubydebug logstash filter anonymize logstash filter checksum logstash filter clone logstash filter csv logstash filter date logstash filter dns logstash filter drop logstash filter fingerprint logstash filter geoip logstash filter grok logstash filter json logstash filter kv logstash filter metrics logstash filter multiline logstash filter mutate logstash filter ruby logstash filter sleep logstash filter split logstash filter syslog pri logstash filter throttle logstash filter urldecode logstash filter useragent logstash filter uuid logstash filter xml logstash input couchdb changes logstash input elasticsearch logstash input eventlog logstash input exec logstash input file logstash input ganglia logstash input gelf logstash input generator logstash input graphite logstash input heartbeat logstash input http logstash input imap logstash input irc logstash input kafka logstash input log4j logstash input lumberjack logstash input pipe logstash input rabbitmq logstash input redis logstash input s3 logstash input snmptrap logstash input sqs logstash input stdin logstash input syslog logstash input tcp logstash input twitter logstash input udp logstash input unix logstash input xmpp logstash input zeromq logstash output cloudwatch logstash output csv logstash output elasticsearch logstash output elasticsearch http logstash output email logstash output exec logstash output file logstash output ganglia logstash output gelf logstash output graphite logstash output hipchat logstash output http logstash output irc logstash output juggernaut logstash output kafka logstash output lumberjack logstash output nagios logstash output nagios nsca logstash output null logstash output opentsdb logstash output pagerduty logstash output pipe logstash output rabbitmq logstash output redis logstash output s3 logstash output sns logstash output sqs logstash output statsd logstash output stdout logstash output tcp logstash output udp logstash output xmpp logstash output zeromq no plugin updated logstash snapshot3 bin plugin list verbose stdin logstash input stdin logstash snapshot3 bin plugin install version logstash input stdin validating logstash input stdin installing logstash input stdin installation successful logstash snapshot3 bin plugin update logstash input stdin updating logstash input stdin no plugin updated logstash snapshot3 bin plugin list verbose stdin logstash input stdin logstash snapshot3 >>>bug v2.1.0
release prep for 5>>>v1.4.5
upgrade lumberjack lib>>>v1.4.5
geolocator filter to lookup string to convert to geopoint it be nice to have an geolocator enrichment filter which calls something like openstreetmap nominativ or something like geopy https pypi python org pypi geopy which has support for multiple sources to lookup approximate longitude and latitude information once string is looked up that can be cached in memory disk to make it fast for subsequent lookups of the same string in the same run this is very useful for enriching datasets with addresses or city names so that we can map them easily in kibana without people having to write their own specific filter in ruby this isn always perfect as some locations are not exact matches so we could as second pass strip out configured list of keywords such as near off over an alternative might be that the user has dead letter queue with the ones that haven got successful lookup>>>new-plugin
shell out filter plugin idea new filter plugin which can shell out to any external program and uses stdin stdout json protocol to pass events in out of that external bin which executes the actual filtering this stdin stdout json protocol could be used in streaming way to avoid having to spawn the external bin on every invocation >>>design discuss new-plugin
possible memory issues with logstash and higher is ok hi there have been several other bugs reports related to logstash taking too much memory encountered similar issues as well environment windows server 2012 jre 60 logstash configuration is pasted below installed logstash filter aggregate es max mem 384m running and higher have tried all of them causes the java process slowly taking more memory as can be seen on screenshot below ending up with gbs of memory consumed the java heap is fine as can be seen from the screenshots suspect the native memory usage to be the problem here have tried to remove all filters and elasticsearch output just keeping the inputs and stdout output with the same result on this doesn happen as can be seen on screenshot below so this leads me to conclusion that something bad happened in causing this behavior would be very glad if you checked that thanks logstash https cloud githubusercontent com assets 8549536 9357859 7584b4a4 4689 11e5 8bb7 ac29d15d037b jpg logstash https cloud githubusercontent com assets 8549536 9357860 7587dfb2 4689 11e5 8ea8 1ba3a44b3185 jpg logstash config >>>bug upstream_fix_needed v2.1.0 windows
configtest misses invalid conversion type in mutate convert version logstash installed from the official repo apt description an invalid field type in mutate conversion doesn raise any flags when run with configtest when it errors out it does suggest you use configtest though to reproduce add the following to your config filter mutate convert some field configtest cant see me run logstash configtest opt logstash bin logstash etc logstash conf configtest run logstash for real opt logstash bin logstash etc logstash conf output from command line configtest opt logstash bin logstash etc logstash conf configtest deprecated use `require concurrent instead of `require concurrent ruby configuration ok output in logstash stdout opt logstash bin logstash etc logstash conf deprecated use `require concurrent instead of `require concurrent ruby error cannot register filter mutate plugin the error reported is invalid conversion type configtest cant see me expected one of string integer float boolean you may be interested in the configtest flag which you can use to validate logstash configuration before you choose to restart running system >>>enhancement
core specs behave randomly even with the same seed currently running `bin rspec spec seed 2992` multiple times will yield this is happens in unicode trimmer spec https github com elastic logstash blob master spec util unicode trimmer spec rb because of the randomized testing spec https github com elastic logstash blob master spec util unicode trimmer spec rb l46 l54 that uses `stress it` from ruby flores https github com jordansissel ruby flores blob master lib flores rspec stress rb l101 l105 it seems to be possible to define the number of iterations in flores so se can seed it with the rspec seed value>>>tests-infra upstream_fix_needed
rpm deb packages should install symlink into usr local bin for ease of use think this would be more compliant to the least surprise principle that after installing logstash through official packages the logstash command is immediately usable doing so could be seemingly easily done by just creating symlink into usr local bin logstash pointing to opt logstash bin logstash so that typical linux installations having usr local bin in their path can use logstash immediately thanks lot >>>enhancement packaging
logstash load error win32ole am using the logstash1 release and still see this issue error1 https cloud githubusercontent com assets 13470204 9313984 1dcd97e4 44f4 11e5 9d63 fb309968c8e4 png simple conf https cloud githubusercontent com assets 13470204 9313985 1eb47056 44f4 11e5 92d1 6c15fcb539a8 png java environment java version 51 java tm se runtime environment build 51 b16 java hotspot tm 64 bit server vm build 25 51 b03 mixed mode >>>bug windows
refactor pluginmanager util rb all utility methods are directly in the `logstash pluginmanager` module the naming is weird here we should probably introduce `logstash pluginmanager util` module to be consistent with file name and also not pollute the main `logstash pluginmanager` namespace >>>internal-cleanup
bring in minimal rubocop config hi there is another pr 3485 willing to bring in rubocop to logstash however rubocop is mix there with ruby style guide so the chances to bring this pr in soon are low in this pr wanted to include minimal rubocop configuration including rake task so we can actually get rubocop in sooner this configuration include the check for the encoding that would have caught the last utf encoding issues checks for complexity and metrics checks for security find this minimal configuration but feel free to bring your ideas to improve it cheers>>>enhancement tests-infra
refactor logstash pluginmanager update validate major version this method https github com elastic logstash blob 028d76497ccef3a8d11a3528cdf6b99e8d10f070 lib pluginmanager update rb l70 l80 introduced by pr 3423 has few issues this method like all other lower level methods which directly interact with rubygems should be in the `util rb` module we should avoid as much as possible lazy require calls don think we have prior art for introducing an interactive in the logstash ui and don think this has been properly discussed in terms of strategy what about automated updates did we consider instead to introduce something like force` options the `validate major version` method name is confusing you actually have to read the code to understand it >>>internal-cleanup
multiline filter failure on output to elasticsearch seems to be location dependent within an input file hi logstash first off relatively new to logstash elasticsearch so apologies if this is either known issue or stupid error on my part more likely to be the latter think ve got an odd issue with logstash elasticsearch have an input file containing 000 log entries each of which spans multiple lines when read the file with logstash into elasticsearch with the multiline filter enabled get grokparsefailure on one of the records basically because logsearch has split one of the multiline records in half the second half doesn conform to the grok pattern so get an error don know why get this error which happens consistently however from further testing have noticed the following the error always occurs to the record at particular point in the file the record at line 185 this occurs whatever the record at this line is reordering the data within the test file doesn change this if disable the output to elasticsearch and simply log to an output file the error does not occur at all in this case all 000 records get processed correctly my logstash configuration file is shown below input 	file 		path applications elastic bwlogreader test test logs test multiline log 		 		type tibco bw type to identify those logs will need this later 		codec plain charset iso 8859 		start position beginning 		sincedb path applications elastic bwlogreader test logstash sincedb filter 	multiline 		patterns dir applications elastic bwlogreader test logstash patterns 		pattern tibco datestamp 		negate true 		what previous 	if type tibco bw 		 extract main fields 		grok 			patterns dir applications elastic bwlogreader test logstash patterns 			match message 						 tibco datestamp log time int bw app name application word engine word log level notspace log type greedydata log msg 		 		 		 extract bw job id 		grok 			patterns dir applications elastic bwlogreader test logstash patterns 			match log msg 						 greedydata job posint job id greedydata 		 		 		 if job id not found in previous grok can happen for log lines such as rv advisory messages generate default field value 		if job id 			mutate 				add tag job id found 			 		 else 			mutate 				add field job id none 				add tag job id not found 			 		 remove the original and now parsed message field only leave it in place if we ve had parsing failure as it then allows us to look at the input line which failed useful for debugging 	if grokparsefailure not in tags 		mutate 			remove field message 		 update timestamp field to contain the timestamp in the bw engine or adapter log event 	date 		match log time yyyy mmm dd hh mm ss sss yyyy mm dd hh mm ss sss iso8601 		locale en 		target timestamp output 	elasticsearch 		host localhost 	file 		path applications elastic bwlogreader test logstash output txt sample of the input file was using is shown below couldn find way to attach the actual file to this issue perhaps someone can tell me how to do that 2015 aug 16 09 35 52 000 gmt bw application engine info bw user job 123456789 log entry 11 12 13 14 15 16 17 2015 aug 16 09 35 52 001 gmt bw application engine info bw user job 123456789 log entry 21 22 23 24 25 26 27 2015 aug 16 09 35 52 002 gmt bw application engine info bw user job 123456789 log entry 31 32 33 34 35 36 37 2015 aug 16 09 35 52 003 gmt bw application engine info bw user job 123456789 log entry 41 42 43 44 45 46 47 didn see the error until got up to log entry 24 ve also attached image from beyondcompare which shows the comparison output with the elasticsearch output enabled and disabled image https cloud githubusercontent com assets 13835597 9309232 24d311ca 4500 11e5 8672 1f12ee4f5fb5 png hopefully someone can tell me if this is known issue or what doing wrong for information using logstash elasticsearch cheers steve >>>bug
update change log for with the lumberjack changes concerning dropped events>>>v2.0.0
logstash with pdf files logstash is converting pdf files text into some unreadable format something like x8c xc9 xb3qdx u001c9 u0011 x84p x99 x8d xb6v x9fv how can read whole pdf in one single event in readable format from kibana >>>needs_details
plugins without tests hi there are bunch of plugins without no test at all this is situation that should be amended soon if you are getting test to any of this plugin feel free to update this issue if you don know how to start tracking test please don hesitate to ask we re more than willing to help this would be also good starting point to start contributing to logstash plugin list logstash codec dots merged logstash codec fluent merged logstash filter sleep merged logstash filter syslog pri merged logstash filter uuid merged logstash input eventlog windows expert for this gmoskovicz jsvd ph logstash input ganglia merged logstash input graphite merged logstash input irc merged logstash input rabbitmq merged logstash input sqs merged logstash input udp merged logstash input unix merged logstash input zeromq merged logstash output ganglia merged logstash output gelf merged logstash output hipchat merged logstash output http merged logstash output irc merged logstash output lumberjack merged logstash output nagios merged logstash output nagios nsca merged logstash output null merged logstash output pagerduty merged logstash output pipe merged logstash output sqs ph on it will be done in v2 update logstash output stdout merged logstash output tcp ph on it logstash output udp merged logstash output zeromq happy testing >>>adoptme fix-it-friday meta tests-infra
seeing some exceptions in lsf coming from ls closing the connection running ls jdk 51 lsf is with the follwing configs if the data coming in 3500 isn in valid json format you get ls logs lsf logs note the frequency of the issue>>>bug
redis input skipping events hello in my setup have logstash agents redis logstash es from the redis to the right all components run on the same machine testes connection with from logstash to es and all events are forwarded properly something is wrong with redis input when send events aaa bbb ccc ddd to redis thay are properly displayed in redis cli unfortunately when investigate the debug log from the logstash which has redis input see following logs for event aaa filter received output received flushing output after that there are messages for event bbb but the output received is missing filter received flushing output there are no entries about ccc or ddd out of ideas how to troubleshoot it further any ideas or suggestions please here is the logstash configuration >>>bug
logstash on windows won read custom patterns hi logstash on windows won read custom patterns file use patterns dir grok 			patterns dir devtools logstash patterns it works only when put the patterns file in devtools logstash vendor bundle jruby gems logstash patterns core 10 patterns best regards>>>windows
bringing back jar dependencies to logstash including offline support for it hi in an effort of having good citizenship in the gems world embedding jars the way we do it nowadays in logstash and has been done for long time in jruby projects is not optimal to do this work there is set of tools like https github com mkristian jar dependencies mantained by herr mkristian in ls we removed the usage of jar dependencies because our way of using it was not providing us with all the necessary features we aim for we should be sure managed dependencies are downloaded and setup during plugin installation this could happen in many situations for example with proxies etc enable offline installation of plugins add test in logstash to be sure jars are packaged in the plugins when the gem is build installed etc >>>bundler enhancement packaging
add robots txt to logstash net website host currently google and guess the rest web search engines too finds the not latest version when searching for some documentation and think it not the way it should be the solution for this is adding the file robots txt in the root of the host currently http logstash net robots txt http logstash net robots txt returns 404 thanks >>>docs internal-cleanup
single element string array is considered as field selector conditional like this is compiled as instead of believe it because single element array is recognized as field selector it looks excluding in `selector element` https github com elastic logstash blob master lib logstash config grammar treetop l236 as well fixes this particular case assume it won help in the case of single numeric element array though is it feasible >>>bug
fix update plugins list to not include uninstalled but not purged plugins this pr is the first attempt to provide closure to 3678 to users are able to clean stale dependencies left behind by the plugin manager comments having clean command is not the best solution we should be able to actually let bundler know we aim to clean from given environment actually this only happen to me when another process is kick in so the environment is fresh possible solutions use bundler with clean env if possible use new process remove stale dependencies by code after doing some investigation on and the solution was either not working as expected or having too complicated setup end up implementing the proposed solution by colinsurprenant in the review process so now we ve clean environment after uninstall my expectation and update works only with the gems available in the gemfile test has been added to logstash kitchen project fixes 3678>>>bug
fixes broken cross document link in advanced pipeline section >>>v2.0.0
split codecs into encoders and decoders related to 1833 codecs should be split into encoders and decoders to avoid some false assumptions and therefore semi trappy behavior this would also make it much easier for plugins to clarify what they will handle json via an decoder but since there would not be an equivalent decoder for rubydebug then obviously it would not work >>>discuss enhancement
wip shutdown improvement this pr takes the code from 3211 and adds shutdown controller that detects stalled pipeline teardowns and allows forced exits change shutdown sequence to not rely on thread raise refactor plugins to accomodate shutdown refactor detect stalled teardown and allow for forced exit add fourth stage to pipeline to receive dead letter events>>>work_in_progress
add the missing magic header encoding utf so all internal strings are utf in ruby this has been found thanks to the work on 3718 we might like to work on internal check for this probably with the inclusion of rubocop or other kind of changes >>>bug enhancement v1.5.4 v2.0.0
memory leak in seem to have memory issue with logstash also tried snapshot2 after couple of hours the java runtime takes up all available ram and after period of time it just crashes logstash does not have this problem with the same config when monitor the java runtime it continuously and steadily takes up more and more ram until it crashes this is the output what can do more to help fix this >>>bug unconfirmed
enable running as windows service it would be nice if logstash could be installed as windows service >>>enhancement windows
logstash truck factor as part of my phd research on code authorship we calculated the truck factor tf of some popular github repositories as you probably know the truck or bus factor https en wikipedia org wiki bus factor designates the minimal number of developers that have to be hit by truck or quit before project is incapacitated in our work we consider that system is in trouble if more than 50 of its files become orphan without main author more details on our work in this preprint https peerj com preprints 1233 we calculated the tf for logstash and obtained value of the developer responsible for this tf is jordan sissel author of 60 of the files to validate our results we would like to ask logstash developers the following three brief questions do you agree that the listed developer is the main developer of logstash do you agree that logstash will be in trouble if the listed developer leave the project if he wins in the lottery to be less morbid does logstash have some characteristics that would attenuate the loss of the listed developer detailed documentation thanks in advance for your collaboration guilherme avelino phd student applied software engineering group aserg ufmg brazil http aserg labsoft dcc ufmg br >>>question
logstash file reading `require concurrent` instead `require concurrent ruby` hi all am getting below error after starting fresh logstash my elasticsearch on localhost is running fine am missing something didn find useful posts about that it is working fine when use standard input but want to read logs from file root vz37980 elk logstash bin logstash test conf deprecated use `require concurrent instead of `require concurrent ruby notimplementederror block device detection unsupported or native support failed to load blockdev at org jruby rubyfiletest java 67 device at root elk logstash vendor bundle jruby gems filewatch lib filewatch helper rb 67 sincedb write at root elk logstash vendor bundle jruby gems filewatch lib filewatch tail rb 233 sincedb write at root elk logstash vendor bundle jruby gems filewatch lib filewatch tail rb 206 teardown at root elk logstash vendor bundle jruby gems logstash input file lib logstash inputs file rb 152 inputworker at root elk logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 203 synchronize at org jruby ext thread mutex java 149 inputworker at root elk logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 203 start input at root elk logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 171 aug 11 2015 42 05 pm org elasticsearch common macaddressprovider getsecuremungedaddress warning unable to get valid mac address will use dummy address test conf input file path var teamcity buildserver system artifacts msc all builds 578 server log start position beginning filter if path access mutate replace type apache access grok match message combinedapachelog date match timestamp dd mmm yyyy hh mm ss output elasticsearch host localhost stdout codec rubydebug >>>known_issue
make sure all lookups using event sprintf are returned as utf the changes in this pr make sure all lookups done using event sprintf are returned as utf before this pr if the event was not there another encoding was used >>>bug v1.5.4 v2.0.0
fix formatting make it consistent>>>docs enhancement v2.0.0
other social media inputs ve been asked by few companies monitoring twitter with ls if we re looking to extend to other networks like linkedin or facebook raising this to see if there is any interest in the community for these >>>discuss new-plugin
logstash file input plugin can handle multiple files within directory on windows have folder that has all the log files want to process but nothing got directed to elasticsearch when do input file path users desktop logs txt start position beginning but works when do file path users desktop logs log1 txt start position beginning the first works on mac but doesn on windows any fix >>>windows
`groksample log` link broken in documentation at https www elastic co guide en logstash current parsing into es html there broken link reference to `tbd co groksample log` the commit that introduced it is 4e8bd0f15ad02e9d066d7954021e31206c5d6b4d would have liked to submit pull request to fix the link but the `groksample log` doesn seem to be in the repository >>>bug docs
openssl ssl sslerror received fatal alert handshake failure in http output hi just upgraded from to almost everything works perfectly except my http output now fails with `openssl ssl sslerror received fatal alert handshake failure` for all events tried google and the irc channel but haven been able to get to the bottom of this no idea if this is connected to https github com elastic logstash issues 3657 using the output config the output is trying to connect to hooks slack com but fails can connect ok from the host running logstash here debug` log output please let me know if can provide any other useful information >>>bug v1.5.4
logstash crashes with java lang unsupportedoperationexception after running for couple of days just under 10 mil events my logstash crashed with this in `logstash err` im running version `logstash 2` and my configuration file is this think thats the second time ve observed that but got no evidence to support that >>>needs_details
docs clarify that strings can be either single or double quoted>>>v2.0.0
output plugin server sent events sse is there an output plugin that facilitates server sent events sse http www html5rocks com en tutorials eventsource basics already >>>new-plugin
doc reorg this commit reorganizes the toc for the logstash doc suite >>>docs v2.0.0
pipeline performance degradation when json parser is given string that is not parseable note this issue describes an abnormal situation that we can do much about other that inform if the source line is not one of string true false number null then the json parser will raise an exception which we handle but it slows everything down the original input still flows down the pipeline however this raise rescue behaviour is normal all we can do is document it perhaps later when we have internal metrics the user can be warned that the processing rate has deteriorated from normal >>>docs performance-improvements
logstash shutting down with exception related to opentsdb logstash is shutting down with below exception am using opentsdb output plugin read that each output plugin should run in different thread and whenever it times out it should retry or in worst case it should just kill output thread but this is not happening in my case please help opentsdb output configuration output if responsetime opentsdb host opentsdb ip port 4343 metrics component responsetime responsetime host host exception am getting ioerror connection timed out write at org jruby rubyio java 1412 write at org jruby rubyio java 2490 puts at org jruby rubyio java 2380 receive at opt logstash vendor bundle jruby gems logstash output opentsdb lib logstash outputs opentsdb rb 87 handle at opt logstash vendor bundle jruby gems logstash core java lib logstash outputs base rb 88 output func at eval 242 outputworker at opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 244 start outputs at opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 166 >>>bug
logstash crashes after running for some time on windows using logstash on windows server 2008 after running for some time between 30 minutes and 24 hours usually logstash crashes with core dump is also written out other interesting error info full error log is at http pastebin com hcxzsdi2 my configuration file is at http pastebin com vhpc93rm let me know if you need any other info >>>bug windows
strange log redis input ve found big problem right now use command redis cli 123123123 monitor grep redis input not find abort redis input info bug in kibana html find the following information my logstash server config is >>>needs_details
discover file glob hi trying to configure logstash to receive cloudtrail files but for testing purposes we locally stored json file and use this as an input following this http techblog mdsol com 2014 01 27 parsing amazon cloudtrail json logs with customized logstash build html but when ran java jar logstash 07 dev medidata flatjar jar agent etc logstash conf combined conf debug automatic template management enabled manage template true level info file etc logstash conf logstash 07 dev medidata flatjar jar logstash outputs elasticsearch http rb line 104 template search url template search url http localhost 9200 template level debug file etc logstash conf logstash 07 dev medidata flatjar jar logstash outputs elasticsearch http rb line 112 discover file glob etc logstash conf cloudtrail json glob is etc logstash conf cloudtrail json level debug file etc logstash conf logstash 07 dev medidata flatjar jar filewatch watch rb line 117 researching found this to be related to permission and deletig sincedb file but this didn help and kind of stuck at this point >>>question
prepare for jrjackson release jenkins integration testing with jrjackson 9000 branch if possible update gem dependency when jrjackson is released update core json rb remove java integrations integration testing with jrjackson gem performance checks release >>>enhancement performance-improvements v2.0.0-beta2
use ruby rake test does not work hi on master doing does not work having bundler complaining about missing gems that in reality are properly installed and reachable >>>bug bundler
trying setting up elk stack hi im new to this so many guides are available but every single is special in part installed elasticsearch logstash and the forwarder then when start logstash on the server with simple direct output and saving to es checking es works too with http 172 16 50 66 9200 search pretty works then with conf file bin logstash logstash1 conf its gettin startet ok kibana or something to view decited to install later want to have it running first without kibana if thats possible installed forwarder on client when try starting the forwarder root localhost opt logstash forwarder bin logstash forwarder config opt logstash forwarder bin forwarder conf 2015 08 05 14 10 03 882581 options 2015 08 05 14 10 03 882981 config arg opt logstash forwarder bin forwarder conf 2015 08 05 14 10 03 883016 idle timeout 5s 2015 08 05 14 10 03 883028 spool size 1024 2015 08 05 14 10 03 883039 harvester buff size 16384 2015 08 05 14 10 03 883049 flags 2015 08 05 14 10 03 883059 tail on rotation false 2015 08 05 14 10 03 883069 log to syslog false 2015 08 05 14 10 03 883080 quiet false 2015 08 05 14 10 03 883588 network servers 172 16 50 66 5000 ssl certificate etc ssl logstash crt ssl key etc ssl logstash key timeout 15 files paths var log log var log messages fields type syslog paths var log apache2 access log fields type apache 2015 08 05 14 10 03 884474 failed unmarshalling json invalid character after top level value 2015 08 05 14 10 03 884492 could not load config file opt logstash forwarder bin forwarder conf invalid character after top level value think pasted all paths right think in the logstash forwarder err took this seems like client want to connect but its not allowed opened on both client and server all nessesary ports logstash forwarder err 2015 08 05 14 26 25 827708 failure connecting to 172 16 50 66 dial tcp 172 16 50 66 5000 connection refused 2015 08 05 14 26 26 829432 connecting to 172 16 50 66 5000 172 16 50 66 2015 08 05 14 26 26 829731 failure connecting to 172 16 50 66 dial tcp 172 16 50 66 5000 connection refused 2015 08 05 14 26 27 831514 connecting to 172 16 50 66 5000 172 16 50 66 2015 08 05 14 26 27 831954 failure connecting to 172 16 50 66 dial tcp 172 16 50 66 5000 connection refused 2015 08 05 14 26 28 833471 connecting to 172 16 50 66 5000 172 16 50 66 2015 08 05 14 26 28 833777 failure connecting to 172 16 50 66 dial tcp 172 16 50 66 5000 connection refused tried so much on configure the settings and still not working can someone help sorry for my bad english glan>>>question
provide mechanism for dumping unsuccessful events to file the elasticsearch output has seen lot of issues from users recently with logstash stalled or retrying after unsuccessful attempts of indexing in we introduced retry logic to handle transient failures from bulk requests and this may have surfaced more user frustration this problem exists in general in logstash where in we retry constantly by design for events which were unsuccessful in 2607 we proposed dead letter queue dlq to handle such unsuccessful or poison events dlq has dependency on persistent queue infrastructure 2605 which is targeted for in the interim we should have solution to shunt or redirect poison events to file which would allow logstash pipeline to continue processing subsequent events this will also help shutdown issue 3451 until we have the dlq specifically pluggable dlq provide general interface to abstract the logic of sending rogue events from outputs each plugin provides its own expectation of when an event is rogue and can be shunted for example in es output mapping errors as first implementation use file per output to store these events make it optional feature flagged also need to provide config to rotate the file based on size age having file based store allows users to use the file input and json codec to reprocess the events if necessary once persistent queue is ready 2605 make it the default implementation of the dlq having pluggable interface allows users to plug in kafka or external queues until we have the in built dlq this was proposed by talevy and jsvd during the discussions of https github com logstash plugins logstash output elasticsearch issues 144 and 3451 thoughts >>>design enhancement
backport tcp leak fix from history https github com elastic logstash issues 1509 https github com elastic logstash issues 1522 https github com elastic logstash pull 3679 only minor changes required for the cherry pick to pass tests >>>v1.4.5
use of metadata in based on https github com logstash plugins logstash output elasticsearch issues 218 and other similar requests propose that we start putting much of the metadata in inputs into the metadata` field in logstash this may allow for much cleaner output for many users additionally we could have flag within the input block perhaps that if set puts those fields into the event as with doing this could also pave the way to using metadata` more for plugins which is good thing think >>>discuss enhancement
next generation pipeline architecture for persistence and performance this discusses next steps in persistence continuing from 2609 summing up conversation colinsurprenant and suyograo had this morning colin work on jruby mmap queues https github com colinsurprenant jruby mmap queues is going well took the time to look at some other queues out there including deep dives in both tape https github com substack tape and chronicle https github com openhft java chronicle both have their issues and fully agree with colinsurprenant approach with the custom queues performed my own work on pipeline level refactors to deal with latency and input semantics related to persistence it was agreed during the meeting that we should introduce pluggable pipelines to test out new concepts and experiment with them earlier pluggable queues had been discussed but after looking into it the queue tends to be tightly bound to the pipeline so that is the logical place to make pluggable abstraction made number of notes myself on new pipeline prototype that focusses on reducing latency while improving throughput will provide notes on that below in comment once have written out all my thoughts >>>design next-gen_pipeline resiliency v2.2.0
allow finer logging configuration for config compilation pipeline and plugin system logging levels should be configurable per subsystem and by subsystem mean configuration compilation pipeline plugins for example this would allow person to start logstash only with debug level for the plugins currently debug is somewhat cumbersome to use due to amount of information it outputs specially at the beginning >>>enhancement logging_improvements
lumberjack to lumberjack data loss under congestion sending from logstash to logstash using lumberjack input output plugins results in data loss if logstash suffers back pressure from its filters outputs the forwader show the same behavior my test using two logstash instances client and server client config server config starting the server then the client and allowing both to run for while makes the server output flows such as >>>blocker bug v1.5.4
jruby crash after update hi just tried updating my logstash from to but are getting crash when try to start logstash this is what see think the problem is related to bouncycastle versions and that jruby does not support newer versions of this library in my ubuntu 14 04 enviroment have other applications installed that also uses bouncycastle but of more recent version can find bouncycastle jars in my java installation folder at and can also see the bundled bouncycastle jars inside the logstash directory so what think is happening is that logstash jruby is preferring the bouncycastle libraries in the classpath but these are incompatible with the jruby version could this be the case anyway to get around this problem >>>bug
changelog>>>v1.5.4
handle non hotspot javas in version check fixes https github com elastic logstash issues 3677 >>>v1.5.4 v2.0.0
update changelog for the master and 6>>>v2.0.0
release and pr update lock pr update the changelog release rc1 gem create rc1 package smoke test remove rc tag official release official package create blog post update discuss tweet>>>meta release_plan
fixes tcp input memory leak hey folks quick and dirty imported this commit https github com elastic logstash commit 7b6ab95124cb1b4107e15ae78aeb2e4e4bb4c6d9 to the branch fixed this https github com elastic logstash issues 1509 please check and bump release it this troubled us on big cluster installation big time memory grows fast and kills the servers without this >>>v1.4.5
ls bin plugin uninstall not removing gem bash bin plugin install logstash output circonus bin plugin uninstall logstash output circonus bin plugin update bin plugin install logstash output circonus bin plugin install logstash output riemann bin plugin uninstall logstash output circonus bin plugin uninstall logstash output riemann bin plugin update>>>bug bundler plugin_manager v2.0.0
logstash java version checking how to allow known good version ve reviewed issue 2547 and get what trying to be achieved have we thought of an easy way to allow java version that known to be good can this check be disabled updated with known pattern for something like ibm java in my case bin logstash agent foo conf pluginpath myplugins verbose nomethoderror undefined method `captures for nil nilclass parse java version at opt logstash153 vendor bundle jruby gems logstash core java lib logstash util java version rb 33 bad java version at opt logstash153 vendor bundle jruby gems logstash core java lib logstash util java version rb 51 warn on bad java version at opt logstash153 vendor bundle jruby gems logstash core java lib logstash util java version rb 10 main at opt logstash153 vendor bundle jruby gems logstash core java lib logstash runner rb 32 root at opt logstash153 lib bootstrap environment rb 48 this is what get from ibm java maybe we can add simple allow ibm java if ibm j9 vm is detected or inspect more closely and look for based on oracle 7u51 b11 java version java version java tm se runtime environment build pxa6470sr6fp1 20140108 01 sr6 fp1 ibm j9 vm build jre linux amd64 64 compressed references 20140106 181350 jit enabled aot enabled j9vm r26 java726 sr6 20140106 1601 b181350 jit r11 b05 20131003 47443 02 gc r26 java726 sr6 20140106 1601 b181350 cmprss j9cl 20140106 181350 jcl 20140103 01 based on oracle 7u51 b11 tks quick work around would be appreciated so can test ls153 out in my environments >>>enhancement v1.5.4
ls double ingestion of log when rotated based on glob path starting with ls logs referenced with glob path start being ingested second time as the log is being rotate at 00 00 utc sincedb file content initially shows the log inode 16648175 changing name access logstash log access logstash log 2015 07 30 but then no longer being tracked kibana shows doubling of log volume starting 00 00 utc the previous day stopping ls removing the sincedb file and starting ls resets the problem until the next rotation testing was run on identical systems the one using no globs in path did not experience the problem os ubuntu 12 04 lts precise pkg logstash all deb 025e540e9276946871396a739042acbdd93d4e6f java oracle 51 >>>blocker bug v1.5.4
new getting started initial commit for new getting started tutorial material >>>docs v1.5.4
add note on setting ls heap size>>>docs
http output gives storecontext error depth error have logstash sending simple json messages to test bottle server set up and they work fine however when try to set http output up with more sophisticated url as an endpoint get this error message times in row for every log entry that send to logstash warning unimplemented method called storecontext error depth the service whose rest api using gets the json message correctly but it would be nice to remove this error message using logstash my http filter http headers authorization the appropriate authorization content type application json http method post url the appropriate url >>>bug
docs fix the old names in link logstash plugin has many old names in their readme md such as https github com logstash plugins logstash filter elasticsearch pull 17 >>>docs plugin_manager
specifying custom tags via ls command this can be achieved today by updating every ls config for the ls instance to add tags to the event it will be nice if there is ls instance level feature allowing custom tags to be added via the ls command which applies to all configurations run by the ls instance >>>enhancement
do not force `verify mode` with our stronger ssl settings we have discovered that in some cases and some plaftorms configuring default `verify mode` when creating ssl tcpserver could make the certificate verification fail ruby default behavior is to use `nil` when creating new ssl context this revert that change keep in mind that all tcp clients using ssl must use `verify peer` as their verify mode to prevent man in the middle attack fix https github com elastic logstash issues 3657>>>v1.4.5 v1.5.4
concurrent ruby warning received when starting ls from https discuss elastic co getting warning while using the latest version of logstash 26379 `warning received deprecated use require concurrent instead of require concurrent ruby >>>bug v1.5.4
syslog example in doc does not parse pri properly could be missing something but just reviewing by inspection it looks like the example provided in this config doc doesn account for the pri field https www elastic co guide en logstash current config examples html processing syslog messages it includes the syslog pri filter but don think the syslog pri filter would do anything because the preceding grok filter doesn parse out syslog pri field >>>docs
support private gem repositories for plugins add support for hosting ls plugins gems in private gem repo as an alternative to rubygems org >>>enhancement plugin_manager
add section in ref docs to handle multiline logs we need to clarify when to use multiline filter and multiline codec there are concerns about thread safety and ordering of events which needs to be clearly addressed related https github com elastic logstash issues 1808>>>docs
ability to govern log file generated by logstash currently logstash writes to single log file if logging is enabled this can result in complete usage of disk space causing system to freeze have issues pragmas should be introduced such that log files can be rotated overwritten and size per each users spec >>>enhancement logging_improvements manageability
logstash ssl problems something is funky with logstash ssl not sure what yet tests with self signed cn localhost certificate on java 79 white check mark lsf to ls ls to ls `certificate verify failure` ls to ls `certificate verify failure` ls to ls `server key exchange invalid` ls to ls `socket closed` openssl client to ls `rsa eay public decrypt data too large for modulus ssl routines ssl3 get key exchange bad signature` related tickets https github com elastic logstash issues 3640 https github com elastic logstash issues 3650 https github com elastic logstash issues 3644 https github com elastic logstash issues 3712>>>blocker bug meta v1.5.4
display error message instead of stack trace when trying to update plugins with wrong privilege noticed that when not having the permission to update shows something like this elevating my privileges fixed it however it would be nice to have an error message instead of this >>>enhancement packaging
agent conf behaviour surprising just spent while debugging this myself but in essence the files in etc logstash conf interact with each other which is unlike any other conf directory ve used before which has also confused number of others http lookonmyworks co uk 2014 04 17 multiple configuration files for logstash can they be completely isolated from each other >>>enhancement
jruby upgrade this pr hold the necessary updates to include jruby as default engine for logstash pending tasks calling rake from the system ruby check with jruby ruby code and ruby code make rake bootstrap and related calls like rake test install core install gems in the right bundle directory so the system can pick them up later make use ruby work as expected state of the pr all works as expected for now having the same behaviour as master keep in mind if you aim to use use ruby to run test there is an known issue also in master 3701 where it does not locate gems properly for the rest this pr is in good health to be reviewed and merged if good this to be aware when testing keep in mind there are two scenarios here using as system ruby an engine of the jruby branch while having vendored the jruby one or using as system ruby also the jruby both should work when running the test there is known issue 3701 of using use ruby and rake also in master >>>enhancement stalled
please update logstash repository hey logstash guy please update the centos repositories with logstash http packages elasticsearch org logstash centos at the moment you can get only the release cheers kai>>>packaging
update to jruby 9k stable release jruby 9k has been released http jruby org 2015 07 22 jruby html test torward near by bundle of it as logstash default engine should be started >>>enhancement
tcp input triggers openssl ssl sslerror certificate verify failed on ls hi today tried to upgrade from logstash to both versions were installed using package repository our logstash machine is an openvz container running debian7 8gb memory 3gb allocated for logstash java version after installing installed environment filter plugin logstash configuration consists of lumberjack and tcp input several filters and es outputs which use the transport protocol the error occurred on the tcp input which accept tls connections from our cdn log shippers in order to clarify things both and installations used the same ssl crt key pair this issue is different than 3644 as here the ssl error is triggered in the tcp input and not in the lumberjack input which worked perfectly with logtash forwarder testing the tls connection with openssl client logstash 153 ip port connected successfully unfortunately didn copy the connection output had to downgrade back to until this issue is resolved thanks yarden>>>bug v1.5.4
mutate convert is flattening array of into single element instead of maintaining array the following creates an array properly an array of element in some cases json output the following creates flattens that array to just single value instead of maintaining the array for json output json output would like for the array to be maintained and represented in json as such is this bug or feature request the documents state that all values in the array are casted not that the array structure is lost >>>bug
wrong links when trying to edit http and irc input plugin documentation the links to edit http plugin documentation at https www elastic co guide en logstash current plugins inputs http html points to the https github com logstash plugins logstash input irc edit master lib logstash inputs irc rb and the irc in the documentation points to http on github >>>docs
file rotation problems on freebsd reported information here configs https gist github com dlangille facdff8652f5bdf2677b log file list https gist github com dlangille 33187660bf0ad453e094 >>>bug
docker lumberjack log driver we should write lumberjack driver for docker this is the best way to record logs in docker and we should have first class support since logstash forwarder is written in go and docker is written in go this shouldn be too bad there is an existing syslog driver but it behaves badly causes container to exit when it can connect additionally syslog is not as nice as lumberjack more about docker log drivers https docs docker com reference run >>>enhancement
add configcheck to init and make sure to check config before restarting using the deb package 5rc2 and most likely rc3 and ga when using service to start logstash it will tell you that it started correctly if you have an invalid configuration java did logstash started but exited immediately because the config is invalid so this patch adds an option to check the config before starting it superseding 3304>>>missing_cla packaging v2.1.0
logstash lumberjack input failed to tls handshake after upgrading to saw error messages like failed to tls handshake with port after upgrading logstash server from to windows nxlog input is fine but all my lumberjack inputs are failing can nc to the logstash server port from logstash forwarder but couldn find other information in logstash forwarder log files or logstash server log events >>>bug
file input plugin automatic deletion of processed files we are currently evaluating the elk stack for our company and discussed how to handle network failover or how to recover from crash somewhere in the elk stack in the most simple way we came to the conclusion that this would be to configure log4j2 with failoverappender and just write all log events in file in that case when everything is ok again we would like to copy the failover files to directory where logstash picks them up and processes the according events the problem we see here is that we don know about the status of the processing we are talking about 70 100 applications and probably hundreds of files so what we would like to have is an additional configuration options delete processed or something like that so that every processed file is automatically deleted it would also possible to move the finished file somwhere else at least we think such behavior could be of great value for some specific situations >>>enhancement
logstash mixing throttled and non throttled inputs hi opening this ticket on the root logstash repository as the title may be relevant to more than one of plugin feel free to reassign as necessary intro we use logstash with both throttled and unthrottled inputs the configuration is as follows elasticsearch 2x6 core intel xeon 0ghz with ht total of 24 cores 30gb heap 10x1tb partitions java version 79 openjdk runtime environment icedtea 7u79 deb8u1 openjdk 64 bit server vm build 24 79 b02 mixed mode cluster consists of one data master node and search load balancer node master data false logstash openvz container debian 8gb memory 3gb heap 64 filter threads java version 75 openjdk runtime environment icedtea 7u75 deb7u1 openjdk 64 bit server vm build 24 75 b04 mixed mode lumberjack input plugin is latest version and includes the circuit breaker mechanism configuration example current behaviour in times of low throughput outside heavy input hours the event flow seems balanced between cdn logs and all other log types during heavy input hours we suffer from serious degradation in lumberjack inputs nginx rails postfix whereas tcp input cdn log throughput stays pretty much the same these images show the discrepancy between tcp logs and other lumberjack logs for given time period tcp records cdn logs https cloud githubusercontent com assets 4204371 8850102 df163ea2 314d 11e5 9362 35116433a0f5 png lumberjack nginx records nginx logs https cloud githubusercontent com assets 4204371 8850123 f27ec50e 314d 11e5 92fc 93a2b412737d png nginx event count by production host nginx by host https cloud githubusercontent com assets 4204371 8850124 f7b453f4 314d 11e5 896b 02a7468c63ce png nb from around 21 00 the tcp logs drop off completely for some time and the lumberjack input is much lower from then on this is detailed in the last screenshot above where each colour is production app server we have four high volume production app servers on lumberjack inputs as well as our low volume staging servers each one outputs both nginx and rails via logstash forwarder its interesting and possibly relevant that prior to the hiccough all four servers were pretty much throwing an equal number of log information but afterwards the proportions seemed to change below are the exceptions we got from logstash log files during the high throughput timeframe heres what we assume might be happening based on the behaviour described above the tcp input which has no circuit breaker hammers the pipeline and blocks or throttles the lumberjack input from pushing events when lumberjack input cant push event to its filter event queue it refuses new connections the lumberjack circuit breaker limits shippers one by one starting with the heavy hitters logic is equivalent or at least similar to tcp repeated cuts in half the throughput of the top abusers until things stabilize and then slow raising of limits out of all this comes the following is there any basis for our assumptions above is our use case sane is such setup mixing circuit breaker and non circuit breaker inputs sane can any logstash developers confirm or deny our hypotheses above bottom line what do we have to do to enable our logstash instance to cope with this were happy to answer any requests for more detail on our setup and try any suggestions that the community may have about how to move forward thanks yarden and devops team>>>question
logrotation error string not matched when rotating log file get the error plugin had an unrecoverable error will restart this plugin and logstash stop processing input chain how to reproduce stop logstash remove sincedb file clean watched logdata folders start logstash move log file with contents to watched folder with name `my log` wait until file is picked up from logstash and then simulate rotation wait again until processed and then put some contents again in file you get then in logstash log file following exception every 3s and processing stops config logstash version and with logstash all works without errors >>>bug
openssl ssl sslerror certificate verify failed hi am running logstash as server and my clients are using logstash 7e387fb not logstash forwarder on ubuntu 14 04 when upgrade my client to the latest version 5608c19 it cant connect anymore with following error in the changelog of it says improved default security for ssl but what exactly does that mean use self signed certificate but connect through fqdn and the cn is configured for that why should that fail thanks bert2002>>>bug
problem with sending logs to elasticsearch when java8 is used this problem was mentioned here https discuss elastic co elasticsearch output error 2105 and it appears when java is used >>>bug needs_details
added case insensitive option to regex hi added case insensitive option to regex so you can use it as mlb tim>>>stalled
restore rack dependency because http input needs it see https github com logstash plugins logstash input http pull 15>>>blocker v1.5.3
new jdbc filter plugin this plugin allow to execute jdbc querys with input from the input and the previous executed query this plugin was develop to respond to this forum post https discuss elastic co how to get jdbc data from multiple queries 25631 the configuration format for this plugin is the same with another options for this jdbc input plugin that allready submit pull request https github com logstash plugins logstash input jdbc pull 30 new with ruby and don know how to program the test batery needed to submit plugin under your rules this any information is needed please contact me source code https github com pafq logstash filter jdbc>>>needs_review new-plugin
can run plugin tests according to the plugin guide https www elastic co guide en logstash current how to write logstash input plugin html clone and test should be able to clone plugin and run the following to test bundle exec rspec however when do this get range of error first one was opt logstash vendor bundle jruby bin bundle exec rspecbash opt logstash vendor bundle jruby bin bundle home jenkins workspace logstash create rpm artifact 15 jdk jdk7 label metal bad interpreter no such file or directory it appears the path to jruby in bin bundle was hardcoded to some build path fixed that to point to opt logstash vendor jruby bin jruby however then get this error gem path opt logstash vendor bundle jruby gems opt logstash vendor bundle jruby bin bundle exec rspec gem loaderror could not find bundler among 15 total gem checked in gem path opt logstash vendor bundle jruby gems opt logstash vendor jruby lib ruby gems shared execute `gem env` for more information to specs at opt logstash vendor jruby lib ruby shared rubygems dependency rb 315 to spec at opt logstash vendor jruby lib ruby shared rubygems dependency rb 324 gem at opt logstash vendor jruby lib ruby shared rubygems core ext kernel gem rb 64 root at opt logstash vendor bundle jruby bin bundle 22 yet bundler appears to be part of the logstash install ls opt logstash vendor bundle jruby gems bundler opt logstash vendor bundle jruby gems bundler 10 opt logstash vendor bundle jruby gems bundler opt logstash vendor bundle jruby gems bundler opt logstash vendor bundle jruby gems bundler is there way can get the plugin tests to run am using logstash >>>developer-support
update lock file to use version>>>v1.5.3
bump version to 3>>>v1.5.3
changelog 3>>>v1.5.3
discussion of where we can place message delivery guarantees in this ticket we ll discuss improving the reliability of logstash this relates to queue persistence >>>dead-letter-queue design discuss pipeline-lifecycle
backport ssl strength improvement to parent https github com elastic logstash pull 3579 this pr cherry picks the ssl change from 3579 with small minor merge conflicts because `lib logstash patches rb` didn exist in specs pass >>>v1.4.4
improve docs for how to check for the presence of field in 2442 simple example was added to the docs but the example is ambigious the patched doc says you can test whether field was present regardless of its value people used to dynamic languages will not be helped much by that wording because it doesn explicitly clarify if the expression is true even if the value of the field is false like an empty string or undef nil please extend to wording to clarify he behaviour if the value of the field is false >>>docs enhancement
docs field reference should be documented in the how to write logstash filter plugin documentation on how to write logstahs filter is clear and really helpful for beginners there one point that it is not covered is how to use the fieldname syntax see https discuss elastic co field reference syntax 25589 >>>docs enhancement
use elasticsearch v1 7>>>enhancement v1.4.4
docs gen config options in mixin is not getting generated tried generating docs for https github com logstash plugins logstash input jdbc which has configs in mixin file https github com logstash plugins logstash input jdbc blob master lib logstash plugin mixins jdbc rb the configs get pulled to the asciidoc but the comments associated with it is not getting rendered steps >>>docs
issue with documentation and inserting logstash version screen shot 2015 07 16 at 11 10 50 am https cloud githubusercontent com assets 5283926 8731311 5b3e24e8 2bab 11e5 908b a89ec2c534fb png the logstash version variable isn being injected properly into the doc found on this page https www elastic co guide en logstash current getting started with logstash html>>>docs
use echo instead of trace or emit this should fix test failure on centos where emit gives command not found which as the last command run in stop causes stop to always return exit code 127 >>>v1.5.3
split current logstash event object into own gem for more modularity within the logstash core it would be great to see the existing logstash event to be split out into its own gem that can possibly be swapped with another implementation >>>design discuss manageability
logstash crash for loaderror no such file to load restclient installed logstash on centos vm test environment my previous installation was logstash and kept the same configuration files used with previous version when launch logstash get the following error loaderror no such file to load restclient require at org jruby rubykernel java 1072 require at application nfmoss vendors logstash vendor bundle jruby gems polyglot lib polyglot rb 65 register at ruby filter init eval at org jruby rubykernel java 1111 register at application nfmoss vendors logstash vendor bundle jruby gems logstash filter ruby lib logstash filters ruby rb 29 each at org jruby rubyarray java 1613 start filters at application nfmoss vendors logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 154 run at application nfmoss vendors logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 81 execute at application nfmoss vendors logstash vendor bundle jruby gems logstash core java lib logstash agent rb 150 run at application nfmoss vendors logstash vendor bundle jruby gems logstash core java lib logstash runner rb 91 call at org jruby rubyproc java 271 run at application nfmoss vendors logstash vendor bundle jruby gems logstash core java lib logstash runner rb 96 call at org jruby rubyproc java 271 initialize at application nfmoss vendors logstash vendor bundle jruby gems stud 20 lib stud task rb 12 use ruby filter for my use case and need the rest client gem but this gem isn present under my installation path application nfmoss vendors logstash vendor bundle jruby gems so tried to install the rest client gem with the command sudo gem install rest client after execution of command sudo yum install rubygems but get another error building native extensions this could take while error error installing rest client error failed to build gem native extension usr bin ruby extconf rb mkmf rb can find header files for ruby at usr lib ruby ruby gem files will remain installed in usr lib ruby gems gems unf ext for inspection results logged to usr lib ruby gems gems unf ext ext unf ext gem make out now don know what have to do work in test environment not in developing environment some suggestion thanks >>>packaging
split filter is not working as expected split json array array have json message with an array in an array want to split that into multiple events this is my configuration input stdin codec json filter split field bean if bean method split field bean method first array with items inner array items foo somevalue bean name bean1name method name bean1meth1 max name bean1meth2 max name bean2name method name bean2meth1 max name bean2meth2 max all fine as need it foo somevalue bean name bean1name method name bean1meth1 max version foo somevalue bean name bean1name method name bean1meth2 max version foo somevalue bean name bean2name method name bean2meth1 max version foo somevalue bean name bean2name method name bean2meth2 max version now the problems the first array has two items inner array just one foo somevalue bean name bean1name method name bean1meth1 max name bean2name method name bean2meth1 max as you can see the method is written as list again not what want foo somevalue bean name bean1name method name bean1meth1 max version foo somevalue bean name bean2name method name bean2meth1 max version next problem the first array has one item foo somevalue bean name bean1name method name bean1meth1 max that is working at all only string and array types are splittable field bean method is of type java javautil linkedhashmap split rb 46 in `filter use logstash 2>>>bug
manually merge changes to pleaserun these changes were made to pleaserun but are being manually merged here for now see https github com jordansissel pleaserun pull 86>>>packaging v1.5.3
add new section for plugin manager cli>>>docs
codecs should support target option it is often the case for input filter plugins that `target` configuration option is desired this option will decode the source into specific field of an event this can be desirable to simplify processing and provide strict segmentation of data and metadata the current codec interface however does not support this `codec decode` will yield `logstash event` with timestamp` and other metadata there is no way to know if these fields were in the source data that is being decoded or were injected into the event there is therefore no safe way to decode data with codec and know precisely which fields were in the original event propose adding `target` option to `codec decode` this would make this functionality easy to implement in plugins unfortunately due to the interface exposed in the codec api this would need to be added to every existing codec plugin ideally this refactor would also change the interface codec plugins use expecting them to return `hash` objects not full `logstash event` objects propose renaming all current plugins `decode` methods to `decode hash` and having `logstash codecs base decode` wrap `decode hash` to return `logstash event` and perform the `target` work internally >>>design discuss
provide systemd unit file would be nice if you could provide systemd unit file in addition to the sysv and upstart init scripts especially now that debian has moved to systemd by default >>>enhancement packaging
when adding values to event instances the class should handle the conditional add apply the tell don ask principle turn this into this the method name could be called anything or equals literal translation store when unset set unless add if unset add if missing insert as opposed to update replace >>>internal-cleanup
roadmap for v1 meta issue to cover the release defining enhancements for v1 this does not include bug fixes stalled outputs will prevent proper shutdown 3451 operational concern offline plugin installation 2376 event class rewrite use better defaults for workers pools buffers 1512 for all issues currently targeted to see here https github com elastic logstash issues is 3aopen label 3av1 is 3aissue >>>release_plan roadmap
change logstash config to json currently logstash has it own config format which doesn have existing syntax checks in editors humbly suggest and request that this should be changed to json or at least yaml so we can use regular editors with syntax parsing for editing the files >>>discuss roadmap
refactor all usage of def module module class style declarations there are potential problems with this style of class declaration in that while the class is associated with the referenced namespace it is defined in the root scope it is not idiomatic ruby inner classes must also be declared with the full namespace reference otherwise they end up being defined on the root namespace we should make attempt to fix this as we go think we all don want to see lot of indentation the original reason for coding like this think everyone will be happy with note in jruby there is no need for semi colons >>>discuss internal-cleanup
docs messaging queue messaging broker on this https www elastic co guide en logstash current deploying and scaling html page we refer to messaging queues which may inadvertently mislead people to thinking we recommend prefer mq products when the concept is something more general suggest that we `s queue broker then either leave it as concept for the user to then define or provide some commonly used ones such as redis mq and kafka >>>discuss docs
update lock file for snapshot1>>>v1.5.3
feature add ability to bin plugin install gem files from http links example >>>enhancement
much needed love for contributing md closes 3547>>>docs v1.5.3
fix typo and remove reference to version compatibility link closes 3588>>>docs v1.5.3
rake task to generate docs is broken if you try to generate the documenation for logstash the process if broken outputing this error generated when running the rake docs generate docs task >>>bug docs
performance regression in basic json handling from the performance regression test introduced thanks to https github com elastic logstash performance testing noticed that the general performance of json handling is slowing down the most critical one seems to be for the json lines codec where is actually lot faster than recent versions screen shot 2015 07 10 at 11 33 20 https cloud githubusercontent com assets 68540 8616018 27801902 26f8 11e5 98ab 89aaf775c57c png screen shot 2015 07 10 at 11 34 00 https cloud githubusercontent com assets 68540 8616017 277cf600 26f8 11e5 8e87 b101e2752951 png details about the legends can be seen in the screenshots feel free to ping me for more details if necessary >>>bug performance-regression
bad url to ls overview page reported here https discuss elastic co recommended es version for logstash docs link broken 25143 https www elastic co guide en logstash current getting started with logstash html make sure they match based on the logstash version http www elastic co overview logstash youre running we re linking to http www elastic co overview logstash instead of https www elastic co products logstash or maybe the downloads page >>>docs
support for bare ungemified local plugins using pluginpath option restore the pluginpath` option to support bare ungemified local plugins solves 3580 >>>v1.5.3
integrate community driven logstash plugins into logstash reference documentation this would be nice to integrate into logstash reference documentation https www elastic co guide en logstash current index html all community driven plugins that are hosted in logstash plugins github account furthermore it would fulfill benefits announced here https www elastic co guide en logstash current how to write logstash filter plugin html contributing your source code to ulink url https github com logstash plugins logstash plugins ulink >>>docs plugin_manager
logstash problem with closing bracket in file output message format test parameters test message fname foo lname bar logstash config input stdin codec json output file codec plain path tmp my log message format fname tags fname using the config above results in missing closing bracket at the end of the log line in tmp my log message format fname tags fname foo tags foo no closing bracket adding space before the final bracket in the logstash config adds the space and final bracket message format fname tags fname space between and foo tags foo closing backet adding another field after closing bracket results in bracket being output message format fname tags fname lname added lname to end foo tags foo bar closing bracket>>>bug v1.5.5
bump jrjackson gem to to fix rubybasicobject bug>>>v1.5.3
fix plugin manager install and update commands to work properly with no internet env private gem repos add all defined sources to rubygems so verification can talk to all the repositories even the private ones fix the workflow for using private gem repo and fixed issues with 3576 fixes https github com elastic logstash issues 3576 >>>bug v2.1.0
new filter ldapresolve as we had the need to resolve user name and unix group from some application logs with just the uidnumber we developed logstash plugin to fullfill our needs https github com ericdeveaud logstash filter ldapresolve https rubygems org gems logstash filter ldapresolve would like to have feedback review tests comments and suggestion on this one regards example assume we have on ldaps with no authent an user john doe with uidnumber 25377 that pertains to group nobody for example with following envent structure and the following init configuration we will get this output >>>needs_review new-plugin
install logstash plugin from local gem repository would like to host logstash plugin built as gem in an artifactory rubygems repository and install it using the opt logstash bin plugin install command where can set the path of my local rubygems repo for logstash to source the gem from >>>enhancement plugin_manager v2.1.0
add back pluginpath command line option in plugins went through big revamp separating it into individual gems the de facto way of developing custom plugins was to create ruby gems and installing it on ls using the following ways publish to rubygems org and `bin plugin install building the gem locally and installing using `bin plugin install changing the `gemspec` to point https github com logstash plugins logstash output elasticsearch running your unpublished plugin in logstash to github repository remotely or to cloned copy on disk using git or path plugin path` we need to add back `bin plugin pluginpath` to allow users to point to ruby files which contain custom plugin code this will allow for rapid prototyping and experimenting with new plugins issues custom plugins not recognized in rc4 https github com elastic logstash issues 3227 support for using custom plugins using pluginpath https github com elastic logstash issues 3553 discuss https discuss elastic co logstash new plugin system too restrictive 24247>>>enhancement meta plugin_manager v1.5.3
improve default security for sslcontext with monkeypatch new defaults cipher suite based on mozilla intermediate set from https wiki mozilla org security server side tls at time of writing disable sslv2 explicitly disable sslv3 explicitly disable compression if possible the ssl option setting came from the ruby ftw library ftw connection apache licensed am author and transitively through work published by jmhodges to improve ruby ssl strength include specs to ensure we never include export or weak ciphers by default using this patch to test the security improvements according to `www howsmyssl com` shows much improved results testing this processed the json output jq for easier reading the purpose of the above is to test the default behavior of sslcontext jruby 19 this patch reports no cipher problems jruby 19 without this patch has several weak ciphers used under mri similar cipher selection problems are observed without this patch weak export ciphers other weak small key ciphers rc4 complaints with this patch no cipher complaints are reported by www howsmyssl com one other note because jruby defaults to tls and only makes cbc ciphers available under the mozilla intermediate cipher set believe and howsmyssl com agrees that these defaults still make the beast exploit problem switching to tls should fix this but we need to do more research to determine the what if any impact it will have if we force tls to be the default >>>blocker v1.5.3
make init script stop configurable behavior on timeout if logstash doesn shutdown fast enough we should give the user configurable option for doing `kill 9` as an alternative to giving up like it does today proposal to have termination timeout action setting in the etc default or sysconfig whatever that defaults to ignore but has an option for kill where instead of ignoring it will kill if logstash hasn terminated fast enough >>>packaging v1.5.3
feature add option to write pid file it would be good if logstash can write pid file if needed maybe it would be startup argument >>>enhancement
support private gem repositories for plugins the current implementation of the command bin plugin install ignores any gem repo that is not rubygems to reproduce this used https github com geminabox geminabox build plugin myself that is not released at rubygems add the new gem source in several ways like gem sources gem server adding it below the line source https rubygems org in the gemfile and update the gemfile lock make it the only possible source in the gemfile also updating the gemfile lock if we aim to support private gem repositories we should load all sources related 2376>>>bug bundler plugin_manager v2.1.0
fails to shutdown hi there we ve hit the following issue with logstash failing to shutdown on our lumberjack indexing node our architecture is logstash shipper file inputs to lumberjack output logstash indexer lumberjack input port 555 filters output elasticsearch when restarting the logstash indexer instance that is listening on the lumberjack input service logstash restart the result is that the pipeline shuts down but the process isn ended see the sigterm in the below this is not occurring all the time and we ve only hit this issue twice timestamp 2015 07 08t05 51 33 214000 0000 message lumberjack input the pipeline is blocked temporary refusing new connection level warn timestamp 2015 07 08t05 51 33 779000 0000 message circuitbreaker close name lumberjack input level warn timestamp 2015 07 08t07 39 56 617000 0000 message sigterm received shutting down the pipeline level warn timestamp 2015 07 08t07 39 58 635000 0000 message circuitbreaker rescuing exceptions name lumberjack input exception logstash sizedqueuetimeout timeouterror level warn timestamp 2015 07 08t07 39 58 635000 0000 message circuitbreaker rescuing exceptions name lumberjack input exception logstash sizedqueuetimeout timeouterror level warn timestamp 2015 07 08t07 39 58 642000 0000 message circuitbreaker rescuing exceptions name lumberjack input exception logstash sizedqueuetimeout timeouterror level warn timestamp 2015 07 08t07 39 58 717000 0000 message circuitbreaker rescuing exceptions name lumberjack input exception logstash sizedqueuetimeout timeouterror level warn timestamp 2015 07 08t07 39 58 718000 0000 message circuitbreaker rescuing exceptions name lumberjack input exception logstash sizedqueuetimeout timeouterror level warn timestamp 2015 07 08t07 39 58 718000 0000 message circuitbreaker open name lumberjack input level warn the result is that you have client still connected to sigterm pipeline as the process is still up but it is doing nothing it is not accepting data or sending any data to any output elasticsearch in out case tcp 153 ffff xxx xxx xxx xxx 5555 ffff xxx xxx xxx xxx 39454 established tcp 83 ffff xxx xxx xxx xxx 5555 ffff xxx xxx xxx xxx 35446 established tcp ffff xxx xxx xxx xxx 5555 ffff xxx xxx xxx xxx 35274 established 10881 java tcp ffff xxx xxx xxx xxx 5555 ffff xxx xxx xxx xxx 56818 established 10881 java tcp ffff xxx xxx xxx xxx 5555 ffff xxx xxx xxx xxx 7731 established 10881 java tcp ffff xxx xxx xxx xxx 5555 ffff xxx xxx xxx xxx 28076 established 10881 java tcp ffff xxx xxx xxx xxx 5555 ffff xxx xxx xxx xxx 37296 established 10881 java the additional issue is the the restart script sysv init script does not notice that the process isn killed and attempts to start another logstash instance which you can see from the log failure to bind to 5555 as the old process is still up and is bound to that port timestamp 2015 07 08t10 16 34 669000 0000 message the error reported is address already in use bind address already in use apologies do not have thread dump or heap for you shall attempt to get this the next time we hit this issue this is the 2nd time we ve seen this >>>bug pipeline-stalls
about elasticsearch template json used to modify elastic search template json in log stash lib logstash outputs elasticsearch and it will make sense wonder where should modify in log stash find one in deep bundle directory but find it doesn make sense please help me thanks>>>question
bin plugin install local thing gem still tries to reach rubygems org reported on discuss elastic co https discuss elastic co shield logstash offline install 25072 think this is because bin plugin updates the gemfile and then runs the equivalent of `bundle install` which will ask rubygems org for manifest of current gems while it tries to apply the gemfile >>>bug bundler plugin_manager
issue with mutate add field and parentheses have the following filter which works perfectly on v1 so when `destinationhostname myhost` and `destinationaddress 4` the expected result is `destinationiphost myhost when this filter is processed with v1 the result is `destinationiphost myhost 4` missing the final character also when tried changing the filter to got this result on v1 `destinationiphost myhost `>>>bug
cannot branch on existence of field it is sometimes important to branch on whether an event contains specific field example currently `if not matches when either the field `a` is `nil` or `a` is not found it is not possible to distinguish between the two this issue raised itself when user in discuss attempted to do so no clean solution was found reference to existing closed jira issue https logstash jira com browse logstash 1422 https discuss elastic co check existence of field and checking null value in field 24968 >>>enhancement
gemspec on all logstash plugins points homepage to logstash documentation when going to the webpage of plugin on rubygems like output kafka https rubygems org gems logstash output kafka the homepage link will always go to http www elastic co guide en logstash current index html can we do better maybe point it to its individual documentation page https www elastic co guide en logstash current plugins outputs kafka html know we don publish this url for all plugins but having bad default because of corner case doesn seem right an alternative is the github repository >>>enhancement plugin_manager
make plugin inspect show number config parameters>>>v1.5.3
logstash deadlock multiline filter too slow when parsing very huge event 100k hello logstash stop forwarding logs trying to parse huge event that can be multi line logstash version plugin version logstash input file logstash filter multiline logstash output redis took theads dump that you can find here http pastebin com 0mmzfqt9 >>>bug pipeline-stalls
remove version command from runner bin logstash is now handled by the agent https github com elastic logstash blob master lib logstash agent rb l39 l40 so this code is not needed test apply this patch and run bin logstash v>>>breaking-compatibility v3.0.0-alpha1
patterns directory gone from top level of logstash v1 we used to be able to add our own local patterns into the top level patterns directory in logstash v1 that seem to have been moved deep inside the gems directory found in vendor bundle jruby gems logstash patterns core 10 patterns if that is the case please add patterns flag where we can specify additional patterns directory our current workaround is to create symlink from the deep patterns dir back to the top level of logstash ugly but allow us to get existing configs working again >>>question
grok oniguruma pattern not parsing field and type results in int field in elasticsearch this oniguruma pattern now results in the field int in elasticsearch and not throughputtime as an int type in elasticsearch we noticed this issue after upgrading from to the problem presented itself in of logstash replication is as follows message info 2015 07 03 01 46 13 420 processor successfully dispatched message with pii 0022311562901666 correlationid 426f54b9 0dac 4c44 9d30 8cb815febe3f and throughput time 1760 config running in results in the following running in results in the following simple command line examples ve looked at the changelog md and nothing indicate breaking change with regards to grok and this field matching and type specification is this known issue thanks dom>>>bug
debian ubuntu init script returns incorrect exit codes hey the init script used for debian and ubuntu doesn respect lsb specification http refspecs linuxbase org lsb lsb core generic lsb core generic iniscrptact html notably start always exit with stop always exit with restart always exit with and will happily start logstash even when it was unable to stop it moreover the integration is pretty poor by using echo instead of log helpers this makes the script outputs text even when quiet boot has been configured good skeleton for an init script is available as etc init skeleton http sources debian net src sysvinit 88dsf 41 2bdeb7u1 debian src initscripts etc init skeleton but of course debian ubuntu specific from what understand the new init script has been generated by `pleaserun` maybe this is just matter of running `pleaserun` to get an updated and fixed version but this doesn seem the case just looking at the template used >>>enhancement packaging upstream_fix_needed
logstash directory not getting created after upgrading to logstash from hi after the recent logstash upgrade to the logstash subdirectory under opt logstash lib cannot be found the following is the folder structure previously getting formed in logstash logstash version https cloud githubusercontent com assets 12824518 8494330 9711634c 2181 11e5 9ff6 ae9b370498f0 jpg the logstash folder would contain the necessary plugins dependencies which we use after the logstash upgrade it was found that the logstash folder along with the other ruby files went missing henceforth our newer deployments started to fail missing the dependencies looked at the change log but couldn find any right reference what is the workaround for this are these files directories being moved to different location >>>plugin_manager
support for using custom plugins using pluginpath we need support for pluginpath with just released v1 am getting the following errors when start logstash bin logstash filterworkers 10 pluginpath export content logstash plugins config export content logstash config logstash clamp usageerror unrecognised option pluginpath signal usage error at export content logstash vendor bundle jruby gems clamp lib clamp command rb 103 find option at export content logstash vendor bundle jruby gems clamp lib clamp option parsing rb 62 parse options at export content logstash vendor bundle jruby gems clamp lib clamp option parsing rb 28 parse at export content logstash vendor bundle jruby gems clamp lib clamp command rb 52 run at export content logstash vendor bundle jruby gems logstash core java lib logstash runner rb 80 call at org jruby rubyproc java 271 run at export content logstash vendor bundle jruby gems logstash core java lib logstash runner rb 96 call at org jruby rubyproc java 271 initialize at export content logstash vendor bundle jruby gems stud 20 lib stud task rb 12 >>>enhancement plugin_manager v1.5.3
logstash file input plugin performance issue in production hi am seeing performance issue when running logstash reading log file and sending logline events in production that am not seeing in test in production am seeing logstash rate low at around 200 250eps after troubleshooting suspected the issue was manifesting itself within file input plugin so used barebones config that included only the file input metrics filter and stdout to print the 1m rate will paste my test config below in test the rate was high starting at 4500eps and rising steadily to 8000eps in production the rate was low around 200eps constantly sometimes however intermittently in production the rate would be good initially 4500 eps but then immediately slowly degrade to 200 eps again it would never maintain rate as we see in test modified file rb to print message everytime it queues 1000 events to witness this slowness within the plugin in production could see that it took seconds to queue 1000 events did not see anything going on with cpu or io also tried various settings on the file input plugin with the input eg no multiline codec only single path single explicit fully qualified path and all had same result low performance about 200 eps here is the barebones config used to see this issue input file path somelogfile log type core sincedb path some path sincedb filter metrics meter events add tag metric flush interval 10 output if metric in tags stdout codec line format rate events rate 1m here is the modification made to file rb run function note get the same results with or without this change only added this to see the issue manifesting at the input plugin level so here are the test results in my test environment vagrant vm can see good performance queueing upto 5000 events sec note this steadily climbs to upwards of 8000 eps pipeline started level info logstash startup completed 1000 events 2015 07 02 16 31 33 utc 1000 level info 1000 events 2015 07 02 16 31 33 utc 2000 level info 1000 events 2015 07 02 16 31 34 utc 3000 level info 1000 events 2015 07 02 16 31 34 utc 4000 level info 1000 events 2015 07 02 16 31 34 utc 5000 level info 1000 events 2015 07 02 16 31 34 utc 6000 level info queued 6000 events in 16 31 34 1000 events 2015 07 02 16 31 35 utc 7000 level info 1000 events 2015 07 02 16 31 35 utc 8000 level info 1000 events 2015 07 02 16 31 35 utc 9000 level info 1000 events 2015 07 02 16 31 35 utc 10000 level info 1000 events 2015 07 02 16 31 35 utc 11000 level info 1000 events 2015 07 02 16 31 36 utc 12000 level info 1000 events 2015 07 02 16 31 36 utc 13000 level info 1000 events 2015 07 02 16 31 36 utc 14000 level info 1000 events 2015 07 02 16 31 36 utc 15000 level info 1000 events 2015 07 02 16 31 36 utc 16000 level info 1000 events 2015 07 02 16 31 36 utc 17000 level info 1000 events 2015 07 02 16 31 37 utc 18000 level info 1000 events 2015 07 02 16 31 37 utc 19000 level info 1000 events 2015 07 02 16 31 37 utc 20000 level info 1000 events 2015 07 02 16 31 37 utc 21000 level info 1000 events 2015 07 02 16 31 37 utc 22000 level info 1000 events 2015 07 02 16 31 37 utc 23000 level info 1000 events 2015 07 02 16 31 37 utc 24000 level info 1000 events 2015 07 02 16 31 37 utc 25000 level info rate 5089 metrics plugin output rate steadily increases upwards of 8000 eps this is production can see that it takes seconds to queue 1000 events and the rate reporting is very low timestamp 2015 07 02t07 10 08 209000 0000 message pipeline started level info timestamp 2015 07 02t07 10 10 349000 0000 message 1000 events 2015 07 02 07 10 10 utc 1000 level info rate timestamp 2015 07 02t07 10 13 555000 0000 message 1000 events 2015 07 02 07 10 13 utc 2000 level info timestamp 2015 07 02t07 10 15 722000 0000 message 1000 events 2015 07 02 07 10 15 utc 3000 level info timestamp 2015 07 02t07 10 18 866000 0000 message 1000 events 2015 07 02 07 10 18 utc 4000 level info timestamp 2015 07 02t07 10 20 984000 0000 message 1000 events 2015 07 02 07 10 20 utc 5000 level info rate 419 41754562910046 note have run the same test in production multiple times intermittently have seen seen it start off with 4000 5000 events sec but then it slowly declines back to 200eps running it for extended periods of time in production performance consistent at 200 eps stumped on this one cannot reproduce in the test environment any ideas or things to look at thanks reece >>>bug
update contributing md file with latest changes this file https github com elastic logstash blob master contributing md has not been updated in while need to bring this page up to date>>>docs
detailed troubleshooting deployment guide as an extension for what palecur is working on in 3525 we should add another section to describe in detail troubleshooting tips advanced deployment guides this should benefit intermediate users of ls suggestions from dougmcclure on content he like to see from https github com elastic logstash pull 3525 issuecomment 117812362 can we talk about how scale up using load balancers like haproxy and distributing load across logstash farm dealing with very large numbers of incoming tcp connections dealing with plugins that do not support multiple threads eg multiline finding the sweet spot for heap mem cpu usage for each logstash instance running multiple instances of logstash on single box use of syslog as the queue >>>docs
parsing xml freezes logstash using the following etc logstash conf 10 use conf configuration file to run logstash basically trying to parse the data out of the xml you can see the xml later in this issue but want to point out that need to parse the test string out of the xml this is why using the getdata xpath expression which works in desktop xml xpath editors then we run logstash as we copy sample xml into the stdin the problem is that logstash just freezes doesn output anything in neither of the logs doesn accept new input strings but just isn working anymore the only way to actually stop it is to does anybody have any clues why that happens and what we re doing wrong we re guessing this has something to do with the xml input filter which is defined in the following file opt logstash vendor bundle jruby gems logstash filter xml lib logstash filters xml rb >>>bug pipeline-stalls
separate the submitting new plugin to ls section this is buried in the how to write plugin docs we need to move it out to its own section and make it directly navigable from the table of contents https www elastic co guide en logstash current how to write logstash input plugin html contributing your source code to ulink url https github com logstash plugins logstash plugins ulink from user on twitter suyograo hi we 39 ve been developing plugin for logstash how should we proceed in order to have repository here https co jzt8hj3b6d mdash joo quarteu alves joaoqalves june 30 2015 suyograo that 39 what happens when you don 39 read the documentation until the end thanks mdash joo quarteu alves joaoqalves july 2015 >>>docs
inclusion of logstash input blueliv in logstash plugins organization https github com blueliv logstash input blueliv>>>needs_review new-plugin
logstash plugins versioning packaging hi all was wondering if for all those logstash plugins out there is there yum repo source to fetch those instead of using the opt logstash bin plugin install update unless there is way to fetch specific versions of plugin already tried the help but it didn say anything about specific versions one could use pin to pinning version is required for operational management and ensuring that the same version is used when installing them at different times day1 version is day5 version is day8 version is etc etc thanks alex >>>packaging
upgrading debian package loses all plugins upgrading by debian package loses all installed plugins steps to reproduce install logstash via `dpkg logstash deb` install plugin opt logstash bin plugin install my awesome filter gem` upgrade logstash via `dpkg logstash deb` try to start logstash with configuration that requires my awesome filter logstash will fail to start because it cannot find the filter maybe this could be avoided by installing plugins to separate directory how does elasticsearch handle this elasticsearch always preserves plugins on upgrade thank you >>>bug packaging
`event remove` doesn work with metadata andrewvc found this issue when working on the http poller if you save any information in the metadata` field and try to rename the key with the mutate filter the filter will create the target field with nil value and the data will remain with the metadata` the mutate filter actually use the remove` method to remove and return the value of the key but the current implementation only give access to the `accessors` hash which include all the `non metadata` field see https github com elastic logstash blob master lib logstash event rb l203>>>bug internal-cleanup
wrong namespace for json serialization>>>blocker v1.5.2
logstash fails to bind to port lumberjack input plugin hi guys trying to install an elk stack on production machine and during startup logstash seems to continually do this loaded org jruby ext openssl utils from file opt logstash vendor jruby lib ruby shared jopenssl jar loaded rubyjit module 0xaa7e604 normalize key 62a82f4a26b627393d03ebd39bbfeb26d9821b65361149577 block ruby file from jvm defineclass the error reported is no message available if run the shell script directly logstash implies that it has problem binding to the port or that the ssl cert has an issue know the ssl cert is fine and there is nothing preventing the process binding to the port bin logstash agent etc logstash conf vv config logstash codecs rubydebug metadata false level debug file logstash config mixin rb line 112 method config init config logstash outputs stdout codec level debug file logstash config mixin rb line 112 method config init config logstash outputs stdout type level debug file logstash config mixin rb line 112 method config init config logstash outputs stdout tags level debug file logstash config mixin rb line 112 method config init config logstash outputs stdout exclude tags level debug file logstash config mixin rb line 112 method config init config logstash outputs stdout workers level debug file logstash config mixin rb line 112 method config init starting lumberjack input listener address 1514 level info file logstash inputs lumberjack rb line 45 method register the error reported is no message available org jruby ext openssl x509cert java 204 in `initialize org jruby ext openssl x509cert java 181 in `initialize opt logstash vendor bundle jruby gems jls lumberjack 22 lib lumberjack server rb 41 in `initialize opt logstash vendor bundle jruby gems logstash input lumberjack lib logstash inputs lumberjack rb 46 in `register opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 148 in `start inputs org jruby rubyarray java 1613 in `each opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 147 in `start inputs opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 80 in `run org jruby ext thread mutex java 149 in `synchronize opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 80 in `run opt logstash vendor bundle jruby gems logstash core java lib logstash agent rb 150 in `execute opt logstash vendor bundle jruby gems logstash core java lib logstash runner rb 87 in `run org jruby rubyproc java 271 in `call opt logstash vendor bundle jruby gems logstash core java lib logstash runner rb 92 in `run org jruby rubyproc java 271 in `call opt logstash vendor bundle jruby gems stud 19 lib stud task rb 12 in `initialize running on rhel x64 logstash and java openjdk 79 thanks chris >>>bug
capability to change iso8601 precision hi in the method logstash timestamp to iso8601 it interesting to add iso8601 precision as parameter we can already do this with the basic function iso8601 in ruby best regards >>>enhancement
logstash default plugins test failures finished in 58 seconds files took 72 seconds to load 609 examples 37 failures http build eu 00 elastic co view ls 201 job logstash 15 default plugins 173 looks related to 3526 >>>blocker bug
logstash crashes with geoip filter found this while reviewing the test failure in acceptance tests http build eu 00 elastic co job logstash integration 15 docker suite logstash config label metal pool 45 console don know if this is red herring or not but geoip filter crashes ls in snapshot1 version narrowed down to this filter by elimination it could be that something else in pipeline is triggering this but this config brings out the crash during startup checked with same config and its all good config >>>blocker bug
initial draft of deploying and scaling logstash >>>docs v1.5.3
update lock file with changes>>>v1.5.2
add changelog 2>>>v1.5.2
service never stop am using amazon linux 2015 logstash and this configuration file when try to stop logstash service sometimes it never dies and sometimes have this error https github com logstash plugins logstash input zeromq issues 5>>>pipeline-stalls
bump jrjackson gem to to fix rubybasicobject bug jrjackson cannot encode objects inheriting from rubybasicobject which is blocking fix for https github com logstash plugins logstash input twitter issues 15>>>v1.5.3
inclusion of logstash filter bytes2human in logstash plugins organisation https github com robin13 logstash filter bytes2human>>>needs_review new-plugin
inclusion of logstash filter math in logstash plugins organisation https github com robin13 logstash filter math>>>needs_review new-plugin
logstash rabbitmq output exception hi we got an issue after upgraded the logstash from to where the rabbitmq output connection was error it kept retrying but never success below an exception we got could you shed some light on this please timestamp 2015 06 27t13 00 10 157000 0000 message rabbitmq connection error ioerror will attempt to reconnect in 10 seconds exception backtrace opt logstash vendor bundle jruby gems march hare java lib march hare exceptions rb 121 in `convert and reraise opt logstash vendor bundle jruby gems march hare java lib march hare channel rb 965 in `converting rjc exceptions to ruby opt logstash vendor bundle jruby gems march hare java lib march hare channel rb 963 in `converting rjc exceptions to ruby opt logstash vendor bundle jruby gems march hare java lib march hare channel rb 595 in `basic publish opt logstash vendor bundle jruby gems march hare java lib march hare exchange rb 77 in `publish opt logstash vendor bundle jruby gems logstash output rabbitmq java lib logstash outputs rabbitmq march hare rb 40 in `publish serialized org jruby rubyproc java 271 in `call opt logstash vendor bundle jruby gems logstash codec json lib logstash codecs json rb 44 in `encode opt logstash vendor bundle jruby gems logstash output rabbitmq java lib logstash outputs rabbitmq march hare rb 31 in `receive opt logstash vendor bundle jruby gems logstash core java lib logstash outputs base rb 88 in `handle opt logstash vendor bundle jruby gems logstash core java lib logstash outputs base rb 79 in `worker setup level error timestamp 2015 06 29t06 55 47 300000 0000 message rabbitmq connection error marchhare channelalreadyclosed will attempt to reconnect in 10 seconds exception backtrace opt logstash vendor bundle jruby gems march hare java lib march hare exceptions rb 121 in `convert and reraise opt logstash vendor bundle jruby gems march hare java lib march hare channel rb 965 in `converting rjc exceptions to ruby opt logstash vendor bundle jruby gems march hare java lib march hare channel rb 963 in `converting rjc exceptions to ruby opt logstash vendor bundle jruby gems march hare java lib march hare channel rb 595 in `basic publish opt logstash vendor bundle jruby gems march hare java lib march hare exchange rb 77 in `publish opt logstash vendor bundle jruby gems logstash output rabbitmq java lib logstash outputs rabbitmq march hare rb 40 in `publish serialized org jruby rubyproc java 271 in `call opt logstash vendor bundle jruby gems logstash codec json lib logstash codecs json rb 44 in `encode opt logstash vendor bundle jruby gems logstash output rabbitmq java lib logstash outputs rabbitmq march hare rb 31 in `receive opt logstash vendor bundle jruby gems logstash core java lib logstash outputs base rb 88 in `handle opt logstash vendor bundle jruby gems logstash core java lib logstash outputs base rb 79 in `worker setup level error >>>question
add type to grok patterns is there any reason to not use types in the default patterns for example in commonapachelog https github com gemsi grok blob 389d18866adc70f1a5c7ec7a0127789bfc80b965 patterns base l95 why do we have number bytes instead of number bytes int thanks >>>enhancement
logstash fails with notation in range filter hi all am using range filter but am getting following error messages if am using notation error expected one of at line 29 column 52 byte 807 after filter range ranges message 1000 tag short message 1001 1e1000>>>docs needs_review
bundle http input plugin with default plugins>>>packaging v1.5.2
add unicode trimmer utility function this is mainly in support of https github com logstash plugins logstash output sns issues looked around the ruby world and couldn find an intelligent unicode byte trimmer this algorithm is probably lot more sane than rails which just goes byte by byte >>>enhancement
update roadmap with post status and most recent planning couple of changes remove status since that is ga now move some ongoing items toward the bottom windows performance add better defaults section in manageability >>>docs v1.5.2
add documentation to describe offline plugin install we added ability to install plugins offline in https github com elastic logstash pull 3404 and there are changes to cli that needs to be documented https www elastic co guide en logstash current command line flags html>>>docs v2.2.0
standardize on http client libraries used in logstash today we have multiple http client libraries used in logstash and its plugins that need http transport functionality for example ruby ftw https github com jordansissel ruby ftw is used in logstash output http jruby manticore https github com cheald manticore is used in es output do we need to standardize on one library or should we use faraday which allows pluggable backends standardizing would provide consistent configurations across the board more importantly it provides us the knowledge to fix bugs add features like security control timeout settings etc rapidly manticore has better performance but works only on jruby so should we be using this for all plugins thoughts >>>design discuss
logstash benchmarking profiling efforts preface this issue is intended to wrap up the benchmarking and profiling efforts around the logstash project and it ecosystem this is actually very important and relevant topic that will serve as common ground for engineers decision makers developers and people interested to know what can they archive with logstash the internet is nowadays full of benchmarking done with the technical people not in mind unlike them in this efforts we will have special consideration to be open by providing the necessary tooling and data available so you re actually able to perform the same analysis as we do and archive your own conclusions your feedback is going to be very valuable objective there are set of objective to be archived with this efforts going to summarize them here for more details please check related issues when available benchmarking the logstash core pipeline logstash is basically data transport processing pipeline the first step to benchmark understand is how performant is the raw pipeline here we encounter several challenges like the memory consumption log formats encoding codecs etc benchmarking the most popular plugins inputs filters outputs the next step would be to see how logstash is performing with the most common set of plugins because none is just using the default pipeline and everyone is using configuration makes sense to see how logstash is doing with the most popular ones methodology to build this benchmarks we aim to build different use case combinations with the intention to match real life usage the initial bullet points are log lines can be of different sizes for this benchmark we aim to use log lines of kb kb kb kb and 10 kb number of events can vary lot too here we ll build versus 000 events 10 000 events 100 000 events and 000 000 events ingestion rate is another moving part for logstash here we aim to target several ingestion rates where you basically can fetch one of the previous variables and target logstash in given time frame but we should not forget data formats this vary lot and can also be source of performance analysis from our experience most common formats are apache nginx logs json logs syslog rsyslog formats nxlog event logs for windows firewall logs most common vendors java log4j dotnet application logs for this one we can take es as an example and last but not least we should consider in which kind of configurations people is using logstash for this we aim to test in several different ones including machines virtualization jvm and jruby versions etc tooling to run this analysis we will need to build integrate some tooling here is the list of the ones we ll need for synthetic log generator logstash can ingest very diverse set of data formats sizes etc to enable the run of this benchmark and also the distribution of it we aim to create synthetic generator that will enable us to generate load to run the tests this tool will enable the reproduction of test without complications benchmarking framework at logstash we believe on getting things faster and better every release so to archive this we ll get you us with framework that will let us run the set of benchmarks described here regression framework running benchmarks is just another kind of test you should run in regular basis who has never faced with performance regressions as we aim to catch them as early as possible we ll also build regression framework to use as complementary test public dashboards the last point will to run the benchmarks in regular basis and make the outcome public in similar way as you can get for elasticsearch at http benchmarks elasticsearch org annex profiling benchmarking grok is well known that grok can be slow if not used properly we aim to provide also an annex benchmark on this filter to help people see how fast do they grok expression go annex most common plugins as seen the most popular plugins are inputs file tcp udp syslog lumberjack windows eventlog elasticsearch redis kafka rabbitmq filters grok translate geoip json multiline xml kv geoip date csv codecs multiline json json lines outputs elasticsearch redis rabbitmq kafka annex most common used ha setups kafka rabbitmq redis we re going to keep updating this as the benchmarking initiative gets going on including related issues numbers archived etc contributions are more than welcome feel free to report here your feedback ideas etc happy benchmarking related issues 3477>>>design enhancement meta performance-improvements tests-infra
fold plugin script into logstash or rename both elasticsearch elastic elasticsearch 11797 and kibana elastic kibana 4204 are moving plugin functionality into the main elasticsearch and kibana script respectively one of the main reasons for this is to be better linux citizen and allow downstream distribution packaging without name clashes eg in the current fedora elasticsearch package they can ship the plugin script should logstash follow suit or at least rename plugin to logstash plugin >>>breaking-compatibility enhancement v3.0.0
consolidate all the http rest input plugins we have need for an input plugin which calls external services to retrieve data and insert it into ls pipeline lot of folks have shown interest in this and have called it `logstash input rest` it is hard to write generic one size fits all plugin which works to consume every rest service out there the main goals for this plugin should be provide an easy way to ingest restful resources decide how we schedule the pulls periodically one time and shutdown support security ootb https and basic auth works as template plugin if there is an use case which does not get solved by this plugin it is easy to clone copy and modify to suit the needs in other words code should be easy to understand and well documented default codec as json test the rest input with variety of use cases and end points alternatively should there be rest filter in the same vein to enrich events the following prs need to be evaluated and consolidated with the above goals in mind https github com elastic logstash issues 3489 https github com elastic logstash issues 3387 https github com elastic logstash issues 3419 we need one rest input to rule them all >>>new-plugin
invalid multibyte character am getting this error in logstash log logstash is not sending any logs to the elasticsearch nodes tcpdump shows no traffic to them using the redis module to pull data in index it and send it to elasticsearch nodes timestamp 2015 06 23t17 09 04 145000 0000 message 62 62 9a fa 9a fa 9a fa 25 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 25 62 62 62 62 9a fa 9a fa 9a fa 25 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 25 62 62 9a fa 9a fa 9a fa 25 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 9a fa 25 9a fa 9a fa 25 >>>needs_details
use the new logstash util decorators to add new fields and tag events following up on wiibaa work in https github com elastic logstash pull 2390 he refactored out `add field` and `add tag` functionality into util which can be reused we need to scan existing plugins that use this functionality to add tag on failure and replace it with this util `logstash util decorators add tags` >>>enhancement internal-cleanup
new filter plugin docker metadata hi trying to adapt this fluentd filter https github com fabric8io fluent plugin docker metadata filter into logstash filter it does not seam really hard the plugin basically do extract the id of the container from the path of it logfile call the docker api to get metadata with `docker container get container id info` put those metadata into fields since don have any ruby background struggle adapt the code any help would be welcome >>>new-plugin
where is the noop filter hi since my update to can found the noop filter why this plugin has been deleted best regards >>>question
logs exception missing without restart hi some logs are only written on disk after restart for example have this problem with log message exception in filterworker use logstash do you know this issue best regards >>>needs_details question
if an output plugin stop retrieving elements from the queue the stop sequence does not work if an output plugin stops retrieving elements from their queue logstash is going to stall as already known but if this happen during the shutdown sequence then logstash is not able to finish gratefully as expected the bottleneck code can be seen for example from https github com elastic logstash blob master lib logstash pipeline rb l117 l120 or from https github com elastic logstash blob master lib logstash pipeline rb l126 l129 imagine the situation where the output plugin is into an infinite loop of retry even if an error is happening then the queues are going to fill up and the logstash shutdown event is never going to be in until the back pressure is relieved for now until the semantic of the pipeline is change to handle this output plugins should be responsible or not entering infinite loops one example of this can be seen at https github com logstash plugins logstash output redis pull where in case of redis being offline the output enters an infinite loops of retries never going to consume any new event so stalling everything >>>bug known_issue pipeline-stalls
logrotate config file invalid file mode in rpm hey this was tested under and rpm package and centos fixing file mode basically iogstash own log file rotation doesn work out of the box >>>bug packaging
new filter plugin http rest hi guys ve created new logstash filter plugin which can be used to handle complex rest calls it supports custom headers and parameters as well as the logstash sprintf format to use event fields as configuration values sample config github https github com lucashenning logstash filter rest rubygems https rubygems org gems logstash filter rest use it to gather environment information and to obtain public encryption key for each event but think there are several use cases currently the test makes sure that json rest call works as expected feedback and suggestions are most welcome >>>needs_review new-plugin
logstash output stalls when using http json post and status 204 is send back we re using logstash output to send json to rest api and the api answered with status 204 when processing is ok when we do this the ls output stalls and stops processing output for approx 30 seconds we have on avg 2000 events second process by different logstash workers when we change the status to 200 processing works as expected https www elastic co guide en logstash current plugins outputs http html https en wikipedia org wiki list of http status codes 2xx success >>>bug
add synchronous codec encode method to aid in testing debugging mocking out codec for plugin testing is irritatingly hard due to the async api while the async api is fine believe the synchronous logic should be wrapped in blocking encode sync` method that would make tests like this look like this this was inspired by the discussion over this pr on the sns input https github com logstash plugins logstash output sns pull files r32961911 >>>breaking-compatibility discuss enhancement v3.0.0
add ruby style guide plus matching rubocop file this pr is working progress pr with an initial version of the style guide only roughly edited the first two bullet points and matching rubocop file feel free to dump here your particular points of views about the style guide as soon as we ve an initial agreement over the style guide we ll create matching rubocop checks for that fixes 3462 >>>design discuss enhancement ruby_style_guide work_in_progress
add periodic report of inflight events during shutdown logstash can be prevented from exiting due to inflight messages that are residing between inputs and outputs once pipeline shutdown is called there will be periodic report every seconds showing which queues still have events for example starting logstash with the following config and then typing ctrl will report each seconds >>>enhancement v1.5.3
logstash input for cloudwatch we need an input to read logs directly from aws cloudwatch should be similar to https github com logstash plugins logstash output cloudwatch >>>needs_review new-plugin
logstash logstash can send json that contains lists to mongodb hi everybody am trying to insert json in mongodb using logstash output mongodb plugin the json objects contain arraylists fields so getting this exception nomethoderror undefined method `bson type for java javautil arraylist 0x745ad733 am using logstash thank you >>>bug unconfirmed
logstash stalls since we ve upgraded to from we ve been seeing random logstash stalls there is nothing in the logs before it happens but then we start seeing the only other error we ve seen is but not sure if its related here are couple of stack traces https gist github com jlintz 200442667e07cc500ed0 >>>bug pipeline-stalls
logstash fails to startup rubyjit error hi guys wondering if someone can help me trying to install an elk stack on production machine and during startup logstash seems to continually do this loaded org jruby ext openssl utils from file opt logstash vendor jruby lib ruby shared jopenssl jar loaded rubyjit normalize key 62a82f4a26b627393d03ebd39bbfeb26d9821b65361149577 block ruby file from jvm defineclass the error reported is no message available running on pretty clean virtualbox instance don seem to have any issues so inclined to think the state of the os install is the problem any suggestions on what can do at this point before clean install running on rhel x64 logstash and java openjdk 79 thanks chris >>>question
release new logstash event gem last release to rubygems org was https rubygems org gems logstash event versions 02 on sep 2013 we need to release new version for compatibility >>>developer-support
option to limit the size of logstash internal logs and rotate them from user the logstash option allow to write logstash internal logs to the given file but there is no option to limit the size of the file and rotate the log file the user will like to have the option to limit the size of logstash internal logs and rotate them >>>enhancement manageability
performance improvements for plugins meta issue to track and study performance of some plugins which are super popular in we improved grok performance 2x throughput in parsing apache logs similarly we need to focus on the next batch of plugins and see if we can fix any bottlenecks specifically we should benchmark existing performance to get baseline cc purbon use profiler and find the hotspots from fix low hanging issues or obvious issues if not happy with numbers consider poc test rewrite in java plugins to focus on first iteration redis input kv filter tcp input lumberjack input kafka input user agent filter https github com logstash plugins logstash filter useragent issues 5>>>meta performance-improvements
workaround the version check for pre released plugins this is because it looks like rubygems is not activating them by default so gem specification find by name is not able to locate them by default this issue might be related to https github com rubygems rubygems issues 988 and https github com rubygems rubygems issues 938 fixes 3449>>>bug bundler reviewing v1.5.3
make inspecting collections bit more friendly fixes 3308 superceeds previous patch>>>reviewing v1.5.2
file input does not work correctly for new files we recently found an issue in where file input crashes when new files are added to dir being watched this also fails when you use wildcard to watch files of certain type and new file is added which matches the pattern the underlying issue has been fixed in filewatch ruby plugin https github com logstash plugins logstash input file issues 51 waiting verification from user https github com jordansissel ruby filewatch issues 58>>>blocker known_issue v1.5.2
add comma after new line was added this breaks package creation>>>v1.5.2
logstash xml filter crashing hi guys ve been migrating our logstash configuration to be compatible with logstash from logstash in our configuration we have xml filter when start logstash in the terminal so it prints the stdout to the terminal window and new event comes through get the follwoing exception it seems that the nokogiri has been updated since could it be that the xml filter is using some methods that are no longer available >>>bug crashes fix-it-friday
generate gem depdendency information add rake test license to generate yaml output on current gem depedencies part of https github com elastic logstash issues 3468>>>reviewing tests-infra
removing reference of `fieldreference` this module was replaced by `lib logstash util accessor rb`>>>reviewing v1.5.2
add lgpl as valid licence for logstash runtime dependencies easy as the title say fix the case of the geoip gem cc jordansissel suyograo can you guys review and merge this one thanks>>>v1.5.2
fix the coverage analysis throw simplecov to take care of all files our actual coverage analysis report were not accurate mostly because of files not being really analyses by simplecov while this pr does not solve the source issue it workaround the situation proving us back with reports in good shape this pr also add detailed groups and filters to the coverage configuration so the reports gets more clear this configuration is logstash core specific so added it here description of the error source the problem actually life in doing the simplecov require before or after the logstash bundler setup without build still not clear who might be the offender but doing the simplecov setup before this call overcome the error for now >>>bug reviewing tests-infra
better java event inspect fixes 3308 ph can you check this out when you get chance >>>v1.5.2
need of common coding style guide as big as the logstash code base is getting and specially with having many contributors lots of different coding styles will encounter in order to simplify the codebase manageability and in order to simplify reviews we should work out common coding style this style guide should help reviews and also be enforced throw tools like rubocop cc suyograo jordansissel >>>design discuss docs ruby_style_guide
data loss in logstash used rabbitmq as broker to logstash to elasticsearch via http protocol use access log for testing filled it by scriopt that sends 5000 requests so the amount of data is 5k of indexed files to es at that point while killing logstash lost about 200 messages after talk on irc changed protocol to node and lost of messages went to 40 or nothing so it was fine after change of sizedqueue to for everything result was still about 40 that showed it aint fine second time bit different way got nxlog via tcp logstash rabbitmq with killing logstash lose about 700 messages logstash used was in version tested with version nxlog connection with ssl logstash rabbitmq made tests as above and have lost 700 messages from 5k running in could not kill logstash or close it only kill worked but as mentioned before with this sizedqueue it should not lose such big number of data since with lost max 40 on kill >>>needs_details
logstash breaks json message by mixing in another message hi all experiencing weird exceptions where lumberjack input mixes messages from different servers logstash is running on debian7 openvz container receiving messages from 30 logstash forwarder shippers example log any ideas thanks yarden>>>question
lumberjack connections stay in close wait state have some problem with logstash after some times lumberjack doesn accept new connections collected data for debug os freebsd release p10 in this case lumberjack doesn accept new connections freebsd kernel message running process part of jstack command in normal state >>>bug
add micro benchmark runner add `rake benchmark run` task to run micro benchmark on specific part of the code it uses the benchmark ips gem to generate them see https github com evanphx benchmark ips for usage>>>reviewing v1.5.2
update the plugin jar dependency documentation as discussed at https github com elastic logstash pull 2980 issuecomment 112597218 the documentation at https www elastic co guide en logstash current how to write logstash input plugin html jar dependencies is now out of date with the new jar dependency vendoring method ideally the new documentation would include some details about how best to get your required jars into `vendor including their runtime dependencies not very familiar with the jvm or maven so that was the most difficult part for me >>>bug docs
add verbose to grok log level pattern matching currently the default grok patterns for loglevel does not include handling for log levels that are pushing out in verbose though trace is there to save me just having to use the regex in the grok pattern it be great if this could be included in the default pattern >>>enhancement
add notice txt to logstash we need to add notice txt to logstash distributables we should document copyrights of jars used from apache software foundation we also need to audit third party compiled code used in logstash and add information to comply with their licenses >>>docs v1.5.3
warn on java version fixes 2547 jordansissel is stderr puts the best place to put this wasn sure if we should force message like this to stdout or if it should use regular logging mechanisms sometimes regular logging is ignored by users >>>v1.5.2
stalled outputs will prevent proper shutdown this is meta issue to track related shutdown issues problem logstash refuses to stop if the output is stalled details if the output plugins are stalled and not popping events from the filter to output` and back pressure propagates upon shutdown request the `logstash shutdown` event will never be pushed because queues will be full and so plugins shutdown will not happen this relates to shutdown refactor proposals in 3211 and 2477 related issues exception in output thread silently locks up logstash 2130 outputs can crash silently locking up entire pipeline 2545 logstash stalled blocked 0rc2 2846 fails to shutdown 3575 service never stop 3520 logstash freeze 3440 logstash wont kill after rabbit problem 3203 >>>bug meta pipeline-stalls v2.1.0
use environment jruby pr 1242 rebranding>>>v1.5.2
prerelease plugins cannot be used bin plugin list verbose logstash output http logstash output http pre bin logstash debug output http plugin not defined in namespace checking for plugin file type output name http path logstash outputs http level debug file logstash plugin rb line 133 method lookup the error reported is undefined method `version for nil nilclass users jls build logstash vendor bundle jruby gems logstash core java lib logstash util plugin version rb 26 in `find version users jls build logstash vendor bundle jruby gems logstash core java lib logstash util plugin version rb 36 in `find plugin version users jls build logstash vendor bundle jruby gems logstash core java lib logstash config mixin rb 219 in `print version notice users jls build logstash vendor bundle jruby gems logstash core java lib logstash config mixin rb 206 in `validate users jls build logstash vendor bundle jruby gems logstash core java lib logstash config mixin rb 102 in `config init users jls build logstash vendor bundle jruby gems logstash core java lib logstash outputs base rb 52 in `initialize users jls build logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 292 in `plugin eval in `initialize org jruby rubykernel java 1107 in `eval users jls build logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 30 in `initialize users jls build logstash vendor bundle jruby gems logstash core java lib logstash agent rb 109 in `execute users jls build logstash vendor bundle jruby gems logstash core java lib logstash runner rb 87 in `run org jruby rubyproc java 271 in `call users jls build logstash vendor bundle jruby gems logstash core java lib logstash runner rb 92 in `run org jruby rubyproc java 271 in `call users jls build logstash vendor bundle jruby gems stud 19 lib stud task rb 12 in `initialize bin plugin uninstall logstash output http error uninstall aborted message this plugin has not been previously installed aborting on fresh install bin plugin install projects logstash output http logstash output http gem validating users jls projects logstash output http logstash output http gem installing logstash output http installation successful and now logstash works on the plugin bin logstash debug output http and uninstalling works too bin plugin uninstall logstash output http uninstalling logstash output http >>>bundler
logstash can not reliably create tests for my grok patterns howdie we want to roll out currently we are on we have bunch of tests to make sure our patterns are correct but half of them are not passing with for the sake of easy debug have supplied working and failing test here if you want my real tests and configs please let me know curiously noticed that grok matching does not work unless the source field comes from previous operation to reproduce how setup logstash my tests specs test output >>>bug tests-infra v1.5.3
gelf listener died hi there have es logstash and there an input gelf on 12201 port by udp in my config have lot of docs receiving by this input but it lot of exceptions also message gelf listener died exception logstash json parsererror no content to map due to end of input at source 7221f4fe line column backtrace opt logstash vendor bundle jruby gems logstash core java lib logstash json rb 37 in `jruby load opt logstash vendor bundle jruby gems logstash core java lib logstash json rb 35 in `jruby load opt logstash vendor bundle jruby gems logstash input gelf lib logstash inputs gelf rb 109 in `udp listener opt logstash vendor bundle jruby gems logstash input gelf lib logstash inputs gelf rb 62 in `run opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 177 in `inputworker opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 171 in `start input level warn at source 7afd729d line column backtrace opt logstash vendor bundle jruby gems logstash core java lib logstash json rb 37 in `jruby load opt logstash vendor bundle jruby gems logstash core java lib logstash json rb 35 in `jruby load opt logstash vendor bundle jruby gems logstash input gelf lib logstash inputs gelf rb 109 in `udp listener opt logstash vendor bundle jruby gems logstash input gelf lib logstash inputs gelf rb 62 in `run opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 177 in `inputworker opt logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 171 in `start input level warn please give me some advice >>>bug pipeline-stalls unconfirmed
event enrichment via dynamic lookup event enrichment via dynamic lookup as plugin lookup table could reside on csv file database table in both case the data should be reloadable periodically to allow new values to be loaded without need to restart logstash cacheable with max amount of memory entries in cache configurable filter lookup name this lookup type csv jdbc elasticsearch type specific params file path jdbc string etc source field code then all the values in columns for matched source field could be available within logstash pipeline for further processing this lookup column name not everything here might make sense as could be ignoring implementation limits challenges though it should be start >>>discuss enhancement new-plugin
installing empty plugins if you install with bin plugin an empty aka no gemspec plugin ls does not complain during the installation process however afterwards bin plugin list does not show the gem content wise it was not good enoughs details even rare this situation could happen think we should detect them somehow and react as expected for example reporting the error to the user and aborting the installation >>>bug bundler
logstash freeze after upgrading to logstash from it freezes atleast once every day so far has gone on for days now the logstash instance where this happens all of them have job input from redis and output to es when try to stop it it fails to stop as well etc init logstash stop killing logstash pid 8979 with sigterm waiting logstash pid 8979 to die waiting logstash pid 8979 to die waiting logstash pid 8979 to die waiting logstash pid 8979 to die waiting logstash pid 8979 to die logstash stop failed still running from my graphs of es indexing rate and redis queue size it seems that it especially happens around index rollover where the redis queue builds up and then after 10 minutes the indexing rate goes to how can debug this further >>>pipeline-stalls
new input plugin cloudwatch created cloudwatch plugin to pull aws metrics into logstash https github com eagerelk logstash input cloudwatch sample config the code is fully documented but it needs tests guidance on if this is something useful and on what tests to add are welcome >>>needs_review new-plugin
fix it friday theme doc improvements this week theme jun 12 2015 for fix it friday is docs improvement specifically we should target in the following priority clean todos in logstash reference docs 3268 update plugins to consistently use the hash syntax across the board 3432 identify plugins with poor documentation and file tickets>>>docs fix-it-friday
docs update plugins to consistently use the hash syntax across the board there are few plugins listed below that use the old syntax key value for config that has validate hash` property we need to make sure they consistently use the key value syntax for example https github com logstash plugins logstash codec graphite blob master lib logstash codecs graphite rb l20 logstash codec graphite logstash filter elasticsearch logstash filter environment logstash filter grok logstash filter kv logstash filter metrics logstash filter mutate logstash filter prune logstash filter translate logstash filter xml logstash filter zeromq logstash input drupal dblog logstash input zeromq logstash output circonus logstash output cloudwatch logstash output csv logstash output email logstash output gelf logstash output graphite logstash output graphtastic logstash output http logstash output influxdb logstash output jira logstash output librato logstash output metriccatcher logstash output pagerduty logstash output riak logstash output riemann logstash output statsd logstash output zeromq>>>docs fix-it-friday
jdbc sql plugin proposal link to plugin here https github com logstash plugins logstash input jdbc purpose of the issue understand any features or databases to provide support for with the jdbc plugin for logstash as the community jdbc river https github com jprante elasticsearch jdbc becomes deprecated what is the purpose of logstash input jdbc generic plugin for supporting all databases as input which have jdbc connectors to be leveraged for creating specific plugins for databases for example logstash input mysql https github com talevy logstash input mysql integration point between logstash and popular databases like mysql postgres oracle mongodb what does logstash input jdbc do it runs sql query and generates input events for each resulting row the option to schedule the query is also available important fields `statement` any valid sql statement will work `parameters` you are able to specify parameter values for use in the sql statement using the reference syntax `schedule` valid cron schedule is accepted here for when to execute the statement special parameters for now the only special parameter is sql last start` which is the time in which the last query was executed this can be used within the `statement` to limit the rows being processed to only new rows as queries are executed under their specified schedule how to use installation will show how this is used with `mysql` download jdbc driver library from here http dev mysql com downloads connector then point to library in logstash config for many of the popular databases we can write wrapper plugins on top of `logstash input jdbc` as was done for `logstash input mysql` which would make configuration more straightforward >>>discuss new-plugin
cached stringinterpolation is slower for simple string with no template tag the new caching mechanism make simple template that doesn contain tags slower than the previous implementation that wasn using compiled template not sure why it is the case the logic is similar to what we were using before am not generating template if there is no present in the string see https github com elastic logstash pull 3425 for details and numbers >>>enhancement v1.5.2
add runtime license test in the spirit of what kibana https github com elastic kibana blob dc07a456cd146ec6a3deaf412520c66523602920 tasks config licenses js has to check for dependency licenses created this small test with this we can test core but also plugin dependencies in regular basis throw the ci environment >>>enhancement tests-infra v1.5.2
add caching mechanism for the sprintf calls this pr allow the event class to compile `sprintf` the first time and reuse the template for the other calls this strategy speeds up considerably calls that uses date formatting or use fieldref its bit slower if you don do any string manipulation you can run the benchmark of this new version against the old version with `rake benchmark` benchmark new event on each iteration >>>v1.5.2
using private offilne gem server might not work there was report on irc that using private gem server in the gemfile did not work as expected the `bin plugin install no verify xxx` command would just hang running the command with the `debug 1` options is returning this the machine has no direct access to the internet and there is no proxy available >>>known_issue
validation warning when updating plugins between major versions this pr adds validation phase and warning if you re updating plugins between major versions fixes 3383>>>enhancement v1.5.2
use latest snapshot1 logstash core>>>v1.5.1
new input plugin rest call hi ve just created new input plugin it allows logstash to make periodic call to rest api currently only json and send the resulting json in an logstash event the idea behind this plugins came from need to read springboot metrics endpoint instead of configuring jmx to monitor my java application memory gc etc https github com maximede logstash input rest cheers maxime>>>new-plugin
docs organize plugin documentation better today the plugins docs are rendered as long list we should look into adding table with multiple columns to organize the docs better the columns can be current version quick description link to github link to rubygems org and so on documenting plugins bundled in core https github com elastic logstash issues 3841 concerns on mobile readability https github com elastic logstash issues 2226>>>docs
logstash document improvements meta issue to track improvements to logstash reference docs https www elastic co guide en logstash current index html add deployment guide section for logstash https github com elastic logstash issues 3416 https github com elastic logstash issues 3410 improve getting started docs tutorial https github com elastic logstash issues 3414 organize plugin documentation better https github com elastic logstash issues 3418 add glossary of logstash terms add section for handling multiline logs 3659 consistency pass over plugin reference docs across and https github com elastic logstash issues 3413 upgrading logstash add xref for ls input plugins to es integrations page>>>docs meta
docs add deployment guide section for logstash add multi chapter deployment reference guide for logstash docs this should cover both scaling for throughput and also for achieving high availability this doc should start with simple scenario to deploy ls using file input and es as sample output we can then introduce more complex deployment architectures using diagrams specifically it should cover simple instance logstash with file input and es output no filters we should assume this to be clustered es setup and use the `http` protocol to index events same setup as above but we introduce filters maybe grok filter we can then document the use of multiple workers to increase throughput using 8` flag introduce lsf as light weight shipper which collects logs from edge nodes and ships to centralized ls server assume user has horizontally scaled es talk about following configuration options manual list of nodes in es output `hosts` options we round robin on each request for ha introduce hardware load balancer which talks to multiple es client nodes introduce transport client with sniffing option scale out logstash throughput by introducing parallel pipelines by starting new ls instances each sharing the workload or processing completely separate configs file twitter etc introduce the use of message brokers to split the pipeline into shippers and indexers phases list available options like redis kafka rabbitmq high availability logstash setup using load balancer in front of the inputs also talk about instances going down and how to monitor them using heartbeat plugin for now >>>docs
update pluginbody asciidoc updated the link for asciidoc formatting>>>missing_cla
docs improve getting started docs tutorial split the getting started to short version and long advanced version update this content with plugins add more examples for sending logs and non log data like tweets to destinations remove any old outdated references add glossary of common terms>>>docs
docs consistency pass over plugin reference docs across and remove todos from existing plugins docs https github com elastic logstash issues 3268 remove charset enumerated values we render big blog of charsets for every input since it is deprecated for example https www elastic co guide en logstash current plugins inputs drupal dblog html plugins inputs drupal dblog charset convert remaining markdown formatted lines to asciidoc>>>docs
new input plugin logstash input algolialogs ve created new logstash input plugin https github com erwanpigneul logstash input algolialogs it just retrieve last logs from an algolia app disclaimer this is my first writing ruby code >>>needs_review new-plugin
logstash plugin crash with rest client dependency hi have an issue regarding logstash plugins which have dependency to ruby rest client https rubygems org gems rest client receiving an event causes the following exception when netrc file with 0600 permissions is created in home xxx logstash throws this exception for further information please see https github com cyli logstash output slack issues https discuss elastic co logstash rest plugin exception with rest client and netrc 1917 could this be logstash bug >>>crashes
site migrate logstash net content and redirects to elastic co it time to merge logstash net purpose into elastic co fully main points new users google for things and find old versions of content on logstash net instead of newer content relevant to the current release of logstash seo for logstash net isn great right now and the marketing team has better visibility tooling to improve this problem on elastic co infrastructure the documentation tooling we use to build and maintain elastic co is pretty nice and logstash net docs infrastructure is no longer maintained our wonderful tech writers are most experienced with elastic co docs infrastructure not logstash net steps already taken lots of work moving logstash docs to be on elastic co done long ago setup redirects on logstash net and logstash net docs to redirect to elastic co in the correct places done since few weeks steps to take next announce eol of next eol version of logstash setup permanent redirects for all the old docs older than or equal to the most recent eol version to redirect to the most appropriate location on elastic co plugin docs etc provide public archive tarball of the current state of logstash net in the emergency case that someone needs access to the ancient docs>>>docs
show errors encountered when validating plugin rather than saying it does not exist currently if you attempt to install plugin and an error occurs the plugin installer just reports the plugin does not exist for example if turn off my internet connection this pr reports the errors if there are any instead of reporting the plugin does not exist for example the above scenario would now report >>>v1.5.1
warning about inflight messages when trying to stop logstash when you send signal to logstash and if it is processing in flight events it will not stop immediately it will first stop the input and wait for existing events in the internal buffer to completely drain before quitting we should provide feedback to the user that it is waiting for events to drain so it is clear that ls is not stuck but this is designed behavior we should also suggest force kill option introduced in https github com elastic logstash pull 3379 but warn that users will lose data >>>pipeline-lifecycle pipeline-stalls v1.5.1
doc update repositories asciidoc the wording was unclear this clarifies our intent and the verbiage >>>docs
manage plugins to be installed offline the motivation of this pr is to enable users to dump set of plugins to later be managed in machines that have no internet connection this introduces set of new commands that enable offline plugin management bin plugin pack let you create bundle with all plugins currently installed in ls instance plus their dependencies by default this package of plugins is created as zip files in windows and tar gz in unix machines bin plugin unpack from previously created package this command lets you install it in another logstash instance add the local flag option to the bin plugin install command when the new flag is passed the plugin manager will fetch the plugins from local file system directory created when doing the bin plugin unpack add the local flag option to the bin plugin update command this command has the same behaviour and motivation as the one for the bin plugin install expected workflow the expected workflow would be user created package with the necessary plugins from ls that has internet access with the generated bundle zip tgz the user unpack this file into ls that has no internet then using the local flag when doing install or update he can install plugins from the local filesystem other options added bin plugin pack bin plugin unpack relates fixes to 2376 >>>bundler enhancement v2.1.0
logstash sometimes doesn process any logs after startup using logstash with input plugins `courier` `tcp` and `pipe` output plugins `elasticsearch` `statsd` it sometimes hangs right after it finishes starting jstack shows http pastebin com mzqud04j any idea what going on >>>pipeline-stalls
logstash crashing the whole time hi running on rhel logstash elastsearch redis the indexer connecting to redis reading stuff and shipping it to elastisearch ist crashing ll tried severeal configurations playing with workers on elastic with threads on redis and option on logstash logstash ist crashing in any of these configs loading the redis queue actually workaround restarting logstash every min at the moment can not understand how does it works for anybody ve just started with big project and around 1200 hosts to collect logfiles from and it is just crashing >>>bug crashes needs_details
all plugins test failing from http build eu 00 elastic co view ls 201 job logstash all plugins test 586 console and http build eu 00 elastic co view ls 20integration job logstash integration all plugins 537 console error message so looks like there is gem still forcing to use the old rspec 14 that should be updated >>>bug v1.5.1
doc logstash net docs redirect is 404 http logstash net docs has banner mentioning the latest version the link at the end pointing to docs is broken maybe we have dummy page there which redirects to https www elastic co guide en logstash current index html or having this link in the banner directly screen shot 2015 06 08 at 14 39 58 https cloud githubusercontent com assets 1595958 8046031 8bc35ebc 0dec 11e5 98cc b36bc1eb841c png >>>docs
fix the packaging issue caused by bundle and the jruby kafka gem from http build eu 00 elastic co job logstash create zip artifact master 36 jdk jdk7 label metal pool console it can be reproduced locally but just doing then jruby kafka is complaining without this pr changes looks like the way 3336 was fix made logstash input kafka not to be so happy but now it works as expected >>>bug v1.5.1
fix all plugins test check for non released plugins fix the case where plugin is released and has similar name to one still not released fixing failured on the all plugins test for example http build eu 00 elastic co job logstash integration all plugins 533 console as it has been there for long time now >>>bug v1.5.1
new plugin for linux systems logstash input proc figured instead of writing input exec commands and parse their outputs would write plugin that would read the proc directory directly https github com eperry logstash input proc was hoping for some feed back there is more to be added but it is functional now currently implemented is meminfo vmstats process details stats file descriptors environment varables threads and bunch of other stats the goal will be to extract every file in the proc directory and have flags to turn on and off those stats >>>needs_review new-plugin
new input plugin logstash input perfmon ve created new input plugin for gathering performance metrics on windows on windows performance metrics can be collected using windows performance monitor this plugin collects the same sort of counters by using the command line tool typeperf github repo https github com nickmramirez logstash input perfmon ve added this gem to rubygems org https rubygems org gems logstash input perfmon ve also verified sending its data to redis output then to elasticsearch and kibana >>>new-plugin
new input plugin logstash input httpclient ve created new logstash input plugin https github com bradvido logstash input httpclient it acts as http client and periodically queries http server processing the response body using the provided codec it also optionally uses few custom `x logstash http headers to indicate to the server how fast it is processing events and the server can also indicate if more events are available in which case the client doesn wait the sleep interval before getting more events it currently has no tests pr welcome but is working well for us disclaimer this is my first writing ruby code >>>new-plugin
add support for multiline conditionals with the `else if` statements this is followup of the issues 2850 and 3281 the following configuration was compiled to ruby like this and making the intepreter fails >>>bug
exception in inputworker with udp input and line codec hi testing logstash and have this issue no problem with logstash logstash configuration logstash error do you have this problem best regards >>>bug
failing test on the branch on jenkins http build eu 00 elastic co job logstash regression release jdk jdk8 label metal pool lastbuild console failures logstashconfigparser compile with multiline conditionals should compile successfully failure error expect eval result compile not to raise error expected no exception got syntaxerror eval 23 syntax error unexpected kor or anotherthing with backtrace spec core config spec rb 65 in root spec core config spec rb 65 in root rakelib test rake 17 in root spec core config spec rb 65 in root rakelib test rake 17 in root >>>blocker v1.5.1
add warning to bin plugin update when updating to new major version of plugin soon there are going to be some backwards incompatible changes bubbling up in plugins and it would be helpful to users to understand that there is risk in updating to such versions maybe it ll look something like this >>>enhancement v1.5.2
logstash hangs while reading configuration can get logstash running with my working config file from logstash it just hangs without dropping any errors in logs have it installed as service on ubuntu 14 04 lts var log logstash files as logstash log and logstash err are of size and don have any lines sudo service log stash service says running and left it for few hours with no effect my config is pretty large around 10k lines but it is mostly conditional if else blocks with mutate filter inside and it is running without any issues on running logstash agent with debug option doesn show any data other that one line reading configuration any suggestions how can get more details from logstash or get it fixed thanks>>>pipeline-stalls v1.5.1
allow forced termination through multiple sigint create the ability to force logstash to exit in stalled situation >>>enhancement v1.5.1
remove the synchronize on the `flush filters to ouputs we were synchronizing on the tick and the flush call in some situation it could set logstash in deadlock when the queue was blocked and the tick occurred the flush call was already thread safe since only one worker can start the flushing process fix https github com elastic logstash issues 3361>>>blocker v1.5.1
ability to run action after log file process improvement while there are times that logs are continually written and you want to always look for new entries the more common practice is that logs are generated for each day and after that day has passed it will never be written to again idealling we would like to clean up the log files compress copy to s3 delete locally as soon as possible after processing by logstash think it would be helpful if logstash could run process after log has been processed once it hit the end and it not updated for amount of time would think the file input config would just have parameter of post process script and idle time for finish or similar >>>enhancement
read from file misbehavior trying to read logs from file while more logs are added to it every time one log is added logstash reads again all the previous log events my input configuration setup is the following one file path path to logs type type if not wrong this should read starting from the end of the file and from the line stored in sincedb but instead logstash is reading the whole file again thanks>>>needs_details
json input codec writes to stdout even if no stdout is defined>>>needs_details
sysvinit scripts don touch var lock subsys file kill scripts fail during shutdown hi firstly should say that this is my first ever issue ve raised on github so please go easy on me ve found that when using logstash in an auto scaled amazon ec2 environment using the sysvinit scripts in this project the termination of an instance causes an ungraceful shutdown of the logstash process meaning that the elasticsearch cluster that the logstash clients had joined previously are left to remove the terminated instance following the timeouts in the elasticsearch fault detection routine by adding the var lock subsys file at service start in an init script on an amazon linux ami subsequent instance termination does gracefully stop the logstash process and the client node is disconnected from the elasticsearch cluster in clean manner the presence of the var lock subsys file seems to be requirement for the chkconfig generated kill scripts to operate during instance shutdown see https fedoraproject org wiki packaging sysvinitscript careful handling of 2fvar 2flock 2fsubsys 2f 3cservice name 3e mechanism hope this is useful clive>>>enhancement packaging
allow setting the timezone for sprintf in logstash event class regular problem that arises for users is that logstash uses utc time everywhere although this is suitable and usually highly desirable for timestamps there are other places where using utc doesn make sense and leads to unexpected results for end users one particular example is with the elasticsearch output plugin as discussed here https github com logstash plugins logstash output elasticsearch issues 165 allowing for example an option to change the default timezone for everything but timestamps would result in better experience for the end user many of whom expect the in reference to the issue above indexes to be rotated on local time rather than utc and better integration with other tools services on the server like cron and curator called through cron which usually operate in local time the following branch seems to have the beginnings of fix for this https github com elastic logstash compare elastic master talevy sprintf with tz>>>adoptme enhancement
install plugin fails not sure if this issue is simular to issue 3336 but when attempt to install an example created its the same to example codec but names are different plugin it says plugin install tmp logstash codec logcat gem validating tmp logstash codec logcat gem installing logstash codec logcat installation successful but after looking for the plugin in my list of plugins don see it there and when try to uninstall the plugin get plugin uninstall tmp logstash codec logcat gem error uninstall aborted message this plugin has not been previously installed aborting is this because installing gave me false positive >>>bug needs_details
replacing mailing list address with discussion forum address please let me know if should cherry pick this into other branches as well >>>reviewing v1.5.1
on windows bugfix jruby 2558 rb breaks plugins using peeraddr with parameter `wrong number of arguments calling peeraddr for following file is the cause https github com elastic logstash blob f97c01da0631566e0ec07c9a076286e22a8f43a9 lib logstash patches bugfix jruby 2558 rb seems to be very old patch that re implements `peeraddr` albeit not allowing any parameter `tcpsocket peeraddr` and `udpsocket peeraddr` have allowed parameter in mri since at least http ruby doc org stdlib libdoc socket rdoc ipsocket html method peeraddr and in jruby since https github com jruby jruby commit d835b3c2adf7f87fbbc8e4cfe8b952c65fd3c3a9 this parameter allows reverse lookup to be disabled mri allows numeric symbol as well as boolean value but jruby only supports the boolean value however using either when using logstash breaks the plugin >>>v1.5.1 windows
fix the uninstall of plugins fixes 3336 by doing bundler setup call that was not done beforehand like this bundler and subsequently gem specification is aware of plugins installed when invoking the bin plugin command for now the way to test this is by building plugin as gem by then installing it and uninstall it so bin plugin list verbose is not showing it anymore >>>bug v1.5.1
deadlock in logstash with filter flusher hello ve noticed on one my multiline worker nodes getting very frequent deadlocks in the worker thread and pipeline thread other nodes are perfectly fine so seems one of those annoying race conditions with very specific triggers also nodes without multiline filter and therefore with 8` for multiple workers are fine too investigating the java stack trace https gist github com driskell 2173a91ac3de78e035e9 and trying to locate the equivalent ruby code it looks like there is possibility of race condition in regards to the filter flusher if there only one worker probably would never happen in mri ruby because of green threads but jruby native threads think it could if the following happens between the filterworker `pop`ing off flush event and processing it in the mutex new event is pushed onto the queue to fill it the flush interval triggers and blocks trying to add flush event to the queue then the filter worker will block trying to obtain the lock however the lock is held waiting for the queue to free up which will never happen because the worker reading from the queue is blocked deadlock if find time ll try pr think the solution is to push only single flush event to the queue and not push another until that one is processed so just needs flag inside the mutex say filter flush pending` that way if the circumstances above occur number wouldn block as it wouldn try to add another flush event >>>blocker bug v1.5.1
few bad redirects on logstash net the following are redirecting to elastic co correctly but are directing users to pages that are missing these should be easy to fix but here the list docs version docs version filters advisor docs version filters grep docs version filters grok docs version filters grokdiscovery docs version filters noop docs version filters useragent docs version flags docs version inputs collectd docs version inputs gemfire docs version inputs s3 docs version outputs amqp docs version outputs elasticsearch docs version outputs elasticsearch html docs version outputs elasticsearch http docs version outputs file docs version outputs s3 docs version release notes>>>docs
user group deletion shouldn be mandatory currently the debian prerm maintainer script for logstash demands to remove the logstash user group from passwd shadow files and fails if it cannot do so assuming that the logstash user is in passwd shadow means that the logstash package will not finish uninstalling removing purging for systems with ldap or any other user account database this change simply allows the maintainer script to complete with error message even if the user group deletion requests fail then the package can finish uninstalling properly >>>packaging
task update plugin versions to be bit more correct user on irc reported confusion at seeing this output we should update all the well maintained plugins to have better version numbers etc for example grok is version https rubygems org gems logstash filter grok>>>v1.5.2
logstash leaking cpu apologize if this is something that has been fixed but we ve been experiencing cyclical cpu leak on logstash that eventually resolves itself by killing the process which restarts are service and keeps things running for another few days here is what it looks like aws instance screen shot 2015 06 01 at 51 20 am https cloud githubusercontent com assets 5272967 7912376 d5374468 0834 11e5 81ea 462c6c23e122 png orange line is the average cpu for the instance in 15 minute intervals we re using the sqs input and the elasticsearch http output and process pretty regular stream of about records per second >>>bug needs_details
java lang runtimeexception could not generate dh keypair during plugin installation reported by johntdyer and moved from https github com elastic logstash issues 3260 am having issues verification as well but for logstash input stomp which just started happening out of the blue today logstash plugins logstash input stomp crash output here https gist github com jordansissel 2f06cfcf420dcad5c46c jordansissel edited this to trim the large text and put it into gist >>>bug known_issue
grok custom pattern problem can start with number logstash hi it was previously ok with logstash it now bug with logstash my pattern file contain grok pattern with name starting with number step to reproduce add this pattern to grok patterns 123 date year 123 date year date year year date start logstash with the following commands logstash agent filter grok match message 123 date year logstash agent filter grok match message year date year results logstash pi mars logstash bin logstash agent filter grok match message 123 date year 2015 message 2015 version timestamp 2015 06 01t08 50 55 018z type stdin host mars year 2015 123 date 2015 interrupt received shutting down the pipeline level warn pi mars logstash bin logstash agent filter grok match message year date year 2015 message 2015 version timestamp 2015 06 01t08 51 13 516z type stdin host mars year 2015 year date 2015 logstash pi mars logstash bin logstash agent filter grok match message 123 date year the error reported is invalid group name pi mars logstash bin logstash agent filter grok match message year date year logstash startup completed 2015 message 2015 version timestamp 2015 06 01t08 42 46 059z type stdin host mars year 2015 year date 2015 please correct this or just write it somewhere in red inside the documentation edit please note that name like this date 123 custom is ok because the name is not starting with number ve just made the test m0dm>>>adoptme bug
dead link on plugin milestones page see the version notice on http logstash net docs plugin milestones it links to docs plugin milestones` which 404s >>>docs
error while using socket class think the following error is because you don have the socket class fully implemented in the bundled jruby with logstash jruby 19 001 require socket true jruby 19 002 socket option bool inet socket keepalive true argumenterror wrong number of arguments calling bool for from irb in evaluate from org jruby rubykernel java 1107 ineval from org jruby rubykernel java 1507 in loop from org jruby rubykernel java 1270 incatch from org jruby rubykernel java 1270 in catch from usr local rvm rubies jruby 19 bin irb 13 in root >>>needs_details
docs remove es plugin reference because it is confusing to users the docs had an es plugins aside which is very confusing to users because ls has plugins too plenty of them `bin plugin install lmenezes elasticsearch kopf` see here https github com elastic logstash issues 3248 issuecomment 104477776 >>>v1.5.1
update repo docs to use latest version `branch` variable is now defined at top level fixes 3248>>>v1.5.1
document default log location for rpm deb packages>>>docs
remove pkg build sh as it was old and unused fixes 1735>>>v1.5.1
uninstall plugin fails if install plugin using gem file and after that try to remove with the command `bin plugin uninstall plugin name` it fails saying that plugin is not installed >>>bug v1.5.1
install specific version of plugin fails `plugin install version` fails from https discuss elastic co install specific plugin version 1407 >>>bug
fix permissions after install debian package etc logstash was getting 775 perms in the debian package this manually sets 755 to etc logstash fixes 3305>>>v1.5.1
docs cleanup cli for removed `web` section and plugin path` added docs for plugin interaction for `bin plugin` fixes 3280>>>v1.5.1
include message in errors with uninitialised variable user had problem whereby device generating logs changed what was being sent to ls this caused the variable to no longer be populated and it was generating this error would it be possible to include the full message when we error on this sort of thing also can we try to catch this thing before we get to the point above and error the event out >>>discuss enhancement
logstash on windows misses file rotation have log managed by nssm that rotates when it reaches 2gb when this happens the file gets renamed and new empty one is created logstash stops parsing the new file until it manually restarted and then everything works again this happes on windows server 2012 r2 where worked without problems >>>bug windows
logstash rpm install can start as service reported by user os centos logstash weird thing is if you start ls manually using the same config file it starts fine maybe rpm is loading an empty config file >>>bug packaging
error no such file to load bundler ve ran the boostrap scripts mentioned in the readme and then ran the test command and got the following error my ruby version is `ruby 2p95` >>>developer-support
logstash fails to uninstall with yum installed using the repository when do yum erase logstash get the following error loaded plugins security setting up remove process resolving dependencies running transaction check package logstash noarch will be erased finished dependency resolution dependencies resolved package arch version repository size removing logstash noarch logstash 127 transaction summary remove package installed size 127 downloading packages running rpm check debug running transaction test transaction test succeeded running transaction error in preun scriptlet in rpm package logstash logstash noarch was supposed to be removed but is not verifying logstash noarch failed logstash noarch complete >>>bug packaging
enable finer control of log levels per plugin per message etc for non trivial applications simply enabling v` to get more insight into what happening results in being drowned in debug output some means of finer control of log levels would be very helpful some possibilities per plugin control perhaps via `log level attribute it might not do much to start with but once there common attribute defined plugin developers can start using it per message control perhaps via meta attribute combine the two so that an input plugin can set meta attribute to trace messages from that plugin for efficiency be happy to see this extra logic only enabled when logstash is run with an extra option perhaps require single v` to enable the extra checks follows on from 3307 and years of annoyance at the verbosity of v` >>>enhancement v3.0.0
wip add way to start jmx monitor session add way to start jmx monitoring for logstash instance without having to remember all the different options >>>enhancement
wip make minitar non runtime dependency minitar is only used for the build process so it should be listed in the gemfile as build dependency and not included in the logstash core gemspec this pr try to fix this >>>enhancement
missing unique filter plugin in running config check results in plugin is missing >>>bug
bump version to latest lumberjack for bug fixes>>>v1.4.3
raspberry pi2 logstash installation benoiton figured how to setup logstash on the raspberry pi2 think we should either maybe try to include the missing library as described in jruby jruby 1561 or document in howto blog wiki the installation steps in 3287>>>docs enhancement
duplicate java opts in logstash launch command line arguments `java opts` are repeated on the command line when logstash is launched this has been seen in deb package context do not know if this is the case in all launch contexts this has been reported in 3287>>>bug packaging
installing plugins in logstash using proxy hello trying to install custom plugin into my logstash according to the documentation should be able to do so with this command bin plugin install logstash filter cidr however when try it get this root elky usr local logstash bin plugin install logstash filter cidr usrlocal logstash vendor jruby lib ruby shared rubygems specification rb 102 warning unrecognized time zone localtime io console not supported tty will not be manipulated validating logstash filter cidr plugin logstash filter cidr does not exist error installation aborted verification failed for logstash filter cidr we are behind proxy and set this environment to get through it http proxy http www 8080 can anyone help me or point me in the right direction so can get this plugin installed thanks regards johan gregoire >>>bug needs_details
update to jruby 20 and cleanup legacy patches>>>enhancement v1.5.1
permission denied error permission denied var log logstash 9844 4050 994333 hi guys having weird problem with logstash on centos when start logstash it crashes after just under two minutes only error in logs is the following repeated over and over timestamp 2015 05 25t19 43 08 410000 0000 message plugin had an unrecoverable error will restart this plugin plugin var log network log sincedb path var log logstash start position beginning type syslog tags asa log delimiter error permission denied var log logstash 9844 4050 994333 or var log logstash level error ve verified all permissions after giving logstash rwx to var log noticed the logstash xxxx yyyy zzzzzz files being created is that expected behaviour this problem does exist as well if run logstash as root best regards daniel>>>question
logstash unable to remove field with nil value if it comes from redis input running logstash have file with csv data that read into logstash and parse using the csv plugin some fields will always be empty and gets value of null then do some checking and remove these fields before shipping to elasticsearch this all works fine unless first ship the csv data to redis and then parse it then unable to remove the fields with value null here are two small config files that can use to recreate this issue redis send conf redis receive conf on the sender typing the string to stdin on the receiver agent get this output just like expect however leaving the first field empty it does not remove the field but if type the same string in stdin on the receiver agent it removes the field ve tried the above in logstash as well but didn encounter the issue in that version >>>adoptme bug
calling inspect on an event instance doesn return the content of an arraylist calling inspect on event which contains an arraylist will return the instance id instead of returning string of the actual content `` instances ``>>>adoptme bug
how to change log level in the output plugins hi all used elasticsearch as an output with the logstash and could get some info level logs when elasticsearch output plugin startup how could change the output plugin log level want to see some debug logs to track some issues ve try debug` and verbose` options it does not work thanks >>>question
debian package creates rwx for root on etc logstash this is probably not major issue but user noted that the permissions on etc logstash` create via our deb package are bit wonky etc logstash` has root root permissions and the root group has rwx to it not sure if this is security issue doubt many admins assign any other accounts to the root group but it is an odd permission >>>enhancement v1.5.1
add configcheck to init and make sure to check config before trying to start using the deb package 5rc2 and most likely rc3 and ga when using service to start logstash it will tell you that it started correctly if you have an invalid configuration java did logstash started but exited immediately because the config is invalid so this patch add an option to check the config and it also makes sure to check the config before starting see elastic logstash 2901 on side note in the headers required start doesn need syslog>>>missing_cla packaging
logstash stops processing with 100 cpu ve found since upgrading from to that logstash will process messages for some period of time and then stop without any errors being logged the process will run at 100 cpu per core depending on how many `filterworkers` have been enabled so two cores would lock out if have workers the logstash process looks like we re running jdk 79 on amazon linux our `logstash log` file looks like this once logstash stops processing thread dump from the logstash process yields the following the configuration is pretty large and is split into various files so we can customise for different environments ve tried to rename things that are private and going to redact couple of the files and describe what they do so hopefully you ll get the picture the last of the configuration files are repeats of roughly the same sort of thing we ve got over 100 of those sorts of `grok` patterns ve tried various configurations but can seem to make it work reliably for any length of time in terms of normal volume of use we ll tend to get about 35k messages per hour so it nowhere close to our bigger logstash cluster which quite happily handles about 4m messages per hour at peak times haven upgraded that cluster since want our development cluster to work reliably first which is where discovered this problem any help or advice would be greatly appreciated the processes are still running and dead and can provide more information if required >>>bug needs_details pipeline-stalls
configtest validates the syntax of the configuration but not the content of it nowadays running logstash with the configtest option let you check the syntax of your configuration but not the content of it there are multiple issues open regarding the expectations about this test related issues 3297 3199 2901 2437 2325 2074 1609>>>discuss enhancement known_issue
provide multiple internal loggers migrated from 1600 from https github com elastic logstash issues 1600 issuecomment 71285923 colinsurprenant think this belongs in our discussion of multiple internal loggers where we could allow users to silence log messages from certain plugins context provide functionality to elasticsearch configurable per component log levels >>>enhancement
fixed spelling mistake>>>missing_cla
failing on windows doing getting started examples java build 40 windows x64 first unexpected output logstash bin logstash v` io console not supported tty will not be manipulated` unexpected logstash 0` then to an example that does work stdin output stdout io console not supported tty will not be manipulated` logstash startup completed` hello world` 2015 05 21t19 34 29 934z hello world` then to an example that does not work stdin output stdout codec rubydebug io console not supported tty will not be manipulated` log stash then exits no error message even when debug is on thank you >>>windows
add these encoding specs for event validate value these specs were originally written for the `accessor` class and the `strict set` method used with rspec but now this has been refactored using `event validate value` these encoding specs could probably be incorporated in the `event` specs relates to 3290 >>>internal-cleanup tests-infra
how to collect jvm metrics of running logstash instance would like to gather jvm metrics of the running logstash java process ubuntu 12 04 and push it to graphite any idea what the best way to achieve that >>>enhancement
sincedb saves file position in the middle of line when logstash is stopped the file position written in the sincedb file is in the middle of line and if you do some custom filtering on that log write custom ruby code block for example this can easily lead to logstash freezing after restart because of values missing in the first retrieved line with no good way to understand what happened but the logstash file input documentation http logstash net docs inputs file clearly states that by default each event is assumed to be one line ve spent many hours on this issue already and when this bug happens you only get useless error messages like this that contain only references to logstash internal java ruby files exception in filterworker exception backtrace org jruby rubykernel java 2057 in `dup usr local logstash vendor jruby lib ruby date format rb 833 in parse usr local logstash vendor jruby lib ruby date rb 1823 in `parse ruby filter code in `register org jruby rubyproc java 271 in `call usr local logstash vendor bundle jruby gems logstash filter ruby lib logstash filters ruby rb 37 in `filter usr local logstash vendor bundle jruby gems logstash core java lib logstash filters base rb 162 in `multi filter org jruby rubyarray java 1613 in `each usr local logstash vendor bundle jruby gems logstash core java lib logstash filters base rb 159 in `multi filter eval 55 in `cond func org jruby rubyarray java 1613 in `each eval 52 in `cond func eval 41 in `filter func usr local logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 219 in `filterworker usr local logstash vendor bundle jruby gems logstash core java lib logstash pipeline rb 156 in `start filters level error example assume logstash is installed at usr local logstash` logstash config input file path usr local logstash input txt type test sincedb path usr local logstash input sincedb sincedb write interval stat interval start position beginning output file path usr local logstash output txt example input data https gist githubusercontent com kipras 0579d663288f2535e37b raw 44f198119730733d9ff97c8fcea342ad7ef4df1b input txt steps to reproduce install logstash create `logstash conf` in logstash directory with the content specified above put the source data input txt in the above gist in logstash directory in the logstash directory run `bin logstash logstash conf` right after logstash starts up on you get the message `logstash startup completed` on you get the message using milestone input plugin file quit it with ctrl note that this is easier to do with logstash because it notes when it starts processing input and it closes more easily sometimes doesn respond to ctrl for some time you have to hit it several times and hope for the best check `input sincedb` it should contain one line with numbers the last number contains the position in the file where logstash stopped this position should be lower than the file size so logstash would have to continue from that point after it is restarted save this number lets call it `sincedb pos` open `output txt` with text editor and scroll all the way to the bottom note the position line number of the last outputted json entry lets call it `last line` restart logstash again with `bin logstash logstash conf` open `output txt` again go to the line after `last line` you will see that the `message` of the json is trucated it does not contain the full input line if logstash consumed the entire file before you were able to close it or by some miracle logstash did stop at line break delete `input sincedb` delete `output txt` try again start from step optional manually check `sincedb pos` to see that it indeed saved position in the middle of line run dd count 500 if input txt of input txt cut bs skip now open `input txt cut` and note that it indeed starts from the middle of line doesn begin with capital letter this seems kinda critical as this leads to generating bad output data in the best case and freezing logstash with no clue as to what happened in the worst case whenever this issue happened during testing for me and my ruby filters would break if changed the stored `sincedb` file position value to position in between lines the position of line break it worked correctly logstash versions observed to have this behavior again note that it easier to debug this issue with explained above >>>enhancement
bad documentation handling for geo point types in logstash as user want to be able to use the kibana4 maps in order to do that the user has to create geo point property there is no documentation available how to create geo point property from longitude latitude furthermore there should be dedicated filter for geo point types done in way that you don need to do the cumbersome mutate rename convert oddysee current oddysee logstash filter template extension proposal >>>enhancement
accessors correct use of lut and cleanups	 while working on java implementation of the `accessors` class realized commit b7ba48d393f9d17a8a4f377d8739af4fdf9c0343 introduced errors with the lut` usage resulting in less efficient code and also some unnecessary code complexity the slowdown is really dependant of the type of config used but config doing multiple lookups on the same field reference will benefit from this fix benchmarks are showing 10 30 better performance the following test results in 28 improvement using fix accessors at 320607aa04c9459c692e0238045d9001737241a6 using master at 99741e57a2e36e1ca509c3af146efe1581ad452a >>>bug v1.5.1
when something is not jsonable the service stop the stacktrace doesn show the root cause don know if it my specific plugin or something else but it crash does logstash have to panic for json drama >>>bug crashes v1.5.2
csv header of type causes type type instead of desired type solved the initial problem here if csv has column of type during filtering can result in type being set to type instead of what is desired in the input stage preventing comparisons to be done properly renaming the column by adding something before type seems to fix it edit this has been tested with csv that pipe delimit not sure if it problem with other delimiter methods >>>bug
memory consumption try to use es ls on raspberry pi2 cores and 1gb ram logstash is started with ls heap size 128m ps cols 1000 cputime etime rss args logstash time elapsed rss command 04 24 17 04 43 20 637712 usr bin java xmx128m xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly jar opt logstash vendor jar jruby complete 11 jar opt logstash lib opt logstash lib logstash runner rb agent config etc logstash log var log logstash logstash log input file path var rlog messages start position beginning sincedb path var lib logstash sincedb type syslog filter grok match message timestamp iso8601 syslog timestamp sysloghost syslog hostname data syslog program posint syslog pid greedydata syslog message tag on failure grokparsefailure syslog if type syslog if grokparsefailure syslog in tags syslog pri date locale match syslog timestamp mmm hh mm ss mmm dd hh mm ss iso8601 mutate replace source host syslog hostname replace message syslog message remove field syslog hostname syslog message syslog timestamp remove field message host path output elasticsearch host 127 >>>bug
multiple logstash instances for kafka think this is indeed wanted feature my consuming logstash it tuned for performance doesn manage to catch up with traffic on kafka cluster when connect second logstash instance from another machine it starts to process all the events alone would be great to use kafka high level consumer if there is one for ruby to balance the input >>>question
regression of the running time of rspec for logstash running my logstash unit test with rspec but with logstash the test running time is 5x longger than logstash run the test with the following commands `bin plugin install development` `bin rspec test rb` is there some plugin should be installed for improve the performance of rspec of >>>needs_details performance-regression tests-infra unconfirmed
blocking exception in xml filter for xpath parsing hello all using logstash to parse xml files downloaded with wget using xpath to transform it to json data it sometimes occurs that the xpath parsing fails resulting in blocking exception when this happens logstash stops processing the files cannot kill logstash with ctrl and have to kill it with its pid then flush the sincedb file also remove the downloaded xml files to prevent them from being inserted twice in elasticsearch when start logstash again when logstash starts again the files get parsed without problem the files are downloaded with xml dwl extention to prevent the file input from using them the downloaded files are then transformed then moved in the folder the file watches to xml extension file is it possible that logstash tries to read the xml files while they re not fully moved to the destination even though they re 40kb max is it possible to make logstash fails safely and not interrupt the parsing currently running logstash cheers >>>question
remove pluginpath command line option from documentation documentation still references pluginpath but it is no longer supported in and log stash won startup if it is present would be good to update the documentation with note indicating it has been removed and perhaps link https www elastic co guide en logstash current command line flags html >>>docs enhancement v1.5.1
dont allow creating new files outside the document root before this fix people were able to use the string interpolation of the event event sprintf to generate files outside the defined path this pull request try to extract document root from the configuration and sandbox the creation of new file in that environment >>>enhancement v1.4.3
lumberjack input maximum connection exceeded after running for while logstash doesn output any event to es instead lot of warnings are written to the log file btw why does it say max clients nil when executing `sudo lsof grep logstash` lot of unclosed connections are listed any idea why this happens from time to time >>>bug v1.5.2
logstash dies after some time hi today ve upgraded to logstash version on ubuntu 14 04 x86 64 and it seems to hangs after some time without any notification in the logs whatsoever when try to stop the process with issuing or get the following and then have to do to kill the process and it goes on and on started logstash manually with the debug option and after some time it died again but got the following line at the end the debug output stops at this point and the process hangs have lot of logshtash senders which just use lumberjack to the main node to send encrypted logs and they are upgraded to and they work fine it seems that the master logstash with elasticsearch output has problem somewhere which is causing it to hang here the output config at the moment ve reverted back to logstash thanks and regards >>>bug crashes needs_details
logstash stops working after few events the only error see is this line almost constantly >>>bug pipeline-stalls unconfirmed
new plugin logstash output webhdfs created an output to write event data to hdfs via webhdfs logstash output webhdfs https github com dstore dbap logstash output webhdfs it seemed to be useful to others so if it meets the requirements concerning code quality like it to be added to the logstash plugins writing tests without webhdfs node accessible for running the tests against seems bit problematic thus currently the test will only make sure that omitting required parameters will throw an error and that the default values are what they are supposed to be >>>new-plugin
got error with elasticsearch output plugin logstash this is my output conf output statsd host 192 168 100 namespace log services increment logsource outputmsgpersec if services service1 elasticsearch cluster test index service1 yyyy mm dd host 10 10 protocol http template name service1 statsd host 192 168 100 namespace byte counting count body bytes sent body bytes sent if services service2 elasticsearch cluster test index service2 yyyy mm dd host 10 10 protocol http template name service2 elasticsearch cluster test host 10 10 protocol http and this is error when running this config timestamp 2015 05 19t15 48 35 380000 0700 message retrying failed action with response code 429 level warn timestamp 2015 05 19t15 48 46 379000 0700 message got error to send bulk of actions to elasticsearch server at 118 69 73 194 read timed out level error timestamp 2015 05 19t15 48 46 382000 0700 message failed to flush outgoing items outgoing count 12 exception backtrace opt logstash vendor bundle jruby gems manticore java lib manticore response rb 35 in `initialize org jruby rubyproc java 271 in `call opt logstash vendor bundle jruby gems manticore java lib manticore response rb 61 in `call opt logstash vendor bundle jruby gems manticore java lib manticore response rb 225 in `call once opt logstash vendor bundle jruby gems manticore java lib manticore response rb 128 in `code opt logstash vendor bundle jruby gems elasticsearch transport lib elasticsearch transport transport http manticore rb 50 in `perform request org jruby rubyproc java 271 in `call opt logstash vendor bundle jruby gems elasticsearch transport lib elasticsearch transport transport base rb 187 in `perform request opt logstash vendor bundle jruby gems elasticsearch transport lib elasticsearch transport transport http manticore rb 33 in `perform request opt logstash vendor bundle jruby gems elasticsearch transport lib elasticsearch transport client rb 115 in `perform request opt logstash vendor bundle jruby gems elasticsearch api lib elasticsearch api actions bulk rb 80 in `bulk opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch protocol rb 100 in `bulk opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch rb 437 in `submit opt logstash vendor bundle jruby gems logstash output elasticsearch java lib logstash outputs elasticsearch rb 462 in `flush opt logstash vendor bundle jruby gems stud 19 lib stud buffer rb 219 in `buffer flush org jruby rubyhash java 1341 in `each opt logstash vendor bundle jruby gems stud 19 lib stud buffer rb 216 in `buffer flush opt logstash vendor bundle jruby gems stud 19 lib stud buffer rb 193 in `buffer flush opt logstash vendor bundle jruby gems stud 19 lib stud buffer rb 112 in `buffer initialize org jruby rubykernel java 1507 in `loop opt logstash vendor bundle jruby gems stud 19 lib stud buffer rb 110 in `buffer initialize level warn >>>question
update to jruby 20 http jruby org 2015 05 05 jruby 20 html>>>enhancement v1.5.1
add option to disable metadata handling metadata handling adds extra string comparisons for every `event` field reference getter or setter when metadata is not useful in particular configuration we know these extra string comparisons are not free we could add an option to disable metadata handling and have different method implementations that we could pick depending on the option >>>discuss enhancement
logstash stops processing when an anomaly in event stream is found dont know if this question bug is am ingesting the aws elb access logs and at times due to how elb logs there are entries like this the above in principle must be single line and without the carriage but that is how elb is reporting it and there is nothing we can do about it guess but the moment this is encountered logstash stops processing with an exception so my question is is there grok which can catch this type of anomaly in otherwise large stream of data if not how can we skip such events and get to the next event ideally it would be nice if logstash would go on to next event >>>pipeline-stalls question
fix todos in logstash reference docs cleanup any occurrence of todo in ls docs logstash codec cef logstash codec oldlogstashjson logstash filter date logstash filter dns logstash filter json logstash filter metrics logstash filter mutate logstash filter range logstash filter ruby logstash filter zeromq logstash input file logstash input ganglia logstash input imap logstash input log4j logstash input lumberjack logstash input pipe logstash input redis logstash input relp logstash input s3 logstash input tcp logstash input unix logstash input websocket logstash input zenoss logstash input zeromq logstash output circonus logstash output elasticsearch logstash output email logstash output file logstash output google bigquery logstash output google cloud storage logstash output graphite logstash output http logstash output librato logstash output loggly logstash output nagios logstash output nagios nsca logstash output opentsdb logstash output redis logstash output s3 logstash output sns logstash output websocket logstash output zeromq>>>docs fix-it-friday
formal informal specs about parts of logstash expected behaviour in order to validate properly the different parts of logstash we need documentation of what is expected out of it this ticket is fill in order to start discussing possible ways to do this documentation specs good way to start documenting is the configuration grammar so we can add test on it next steps would be to document the pipeline stc >>>discuss docs enhancement tests-infra
newline interpretation in logstash is not as you can expect as noticed in 3238 newline interpretation by the config compiler might be not as you expected if we take as an example what you might expect is that you replace newline character with newline however what really happen is that we transform the two characters with newline because although you could expect that you are really replacing newline this happen like this because characters are not interpreted to newline but deal as character if you really want to replace the newline character you need to create config with an space related with 3238 3239 1645>>>bug enhancement known_issue
make bat scripts work if path has spaces fixes 2904 and 3246>>>v1.5.1 windows
fix string interpolation error when transforming characters to utf8 as we discover thanks to 3238 if into the configuration there are characters like the transformation was not properly done this caused that for example the regular expression used in the mutate plugin for the gsub where not working properly reviewer can use the use case presented in 3238 to test this behaviour pd this was also happening in previous releases fixes 3238 >>>bug v1.5.1
logstash crash when using output plugin websocket starting logstash version with the websocket output plugin configurated logstash crash with the following error this error is present either in the windows version windows7 64 bit either in the linux version centos there is also an error on udp input plugin but think it is already signaled >>>bug
regression conditionals spread across multiple lines now fail version version same computer configuration file java ruby everything only different logstash version >>>bug unconfirmed v1.5.1
mutate must be in its own code block if you attempt to combine multiple mutations inside of one mutate block then you get unexpected results broken config input foo abc123 output notice how both foo and bar are that is bad if you expand the config out to use multiple mutates it works properly this is either bug in the mutate or bug in documentation nowhere that can find does the documentation mention that combining mutates together is bad >>>bug unconfirmed
logstash updating plugin claims no plugin updated even though it was see here checking on disk the plugin has indeed been updated >>>bug needs_details v1.5.1
fixed typo >>>docs missing_cla
make untar extract message only when debug true small clean up improvement >>>enhancement tests-infra
permission denied opt logstash bundle install the `logstash noarch rpm` package using user that is not the `logstash` user then try to run logstash version` you will get if it is run using `sudo logstash logstash version` it works not sure if this is the right way to run it documentation is light in this area >>>bug discuss v1.5.1
update documentation to new release we should revisit the documentation to be sure it all naming as the current ga for example https www elastic co guide en logstash current package repositories html is still referencing to repos >>>bug docs
java exception when trying to run plugin commands version logstash ga issue when trying to do plugin list get java exception achan lsc011 scl bin pwd opt logstash bin achan lsc011 scl bin plugin list error exception thrown by the agent java rmi server exportexception port already in use 9994 nested exception is 	java net bindexception address already in use achan lsc011 scl bin sudo etc init logstash restart killing logstash pid 27913 with sigterm waiting logstash pid 27913 to die waiting logstash pid 27913 to die logstash stopped logstash started achan lsc011 scl bin plugin list error exception thrown by the agent java rmi server exportexception port already in use 9994 nested exception is 	java net bindexception address already in use achan lsc011 scl bin plugin list error exception thrown by the agent java rmi server exportexception port already in use 9994 nested exception is 	java net bindexception address already in use achan lsc011 scl bin sudo sudo plugin list error exception thrown by the agent java rmi server exportexception port already in use 9994 nested exception is 	java net bindexception address already in use do have this configuration in logstash lib sh java opts to enable jmx monitoring for jmx monitoring java opts java opts dcom sun management jmxremote java opts java opts dcom sun management jmxremote port 9994 java opts java opts dcom sun management jmxremote authenticate false java opts java opts dcom sun management jmxremote ssl false also there is nothing else running on that port achan lsc011 scl bin netstat an grep 9994 tcp 9994 listen>>>bug
switching from to file input explodes for file path with space in folder name logstash config with logstash logstash quits with an error `cannot find folder folder` tried using globing got the same failure `>>>bug v1.5.1 windows
grok regex matches anything in some cases trying to match not sure how why this is going wrong but it appears that the grok pattern matcher doesn work correctly in all cases somehow have this pattern matching `2015 03 31 11 38 03 0000` pattern python input 2015 03 31 11 38 03 0000 22008 info booting worker with pid 22008` my list of applied patterns results from the grok debugger logstash has similar results >>>bug
allow outputting resulting config file when merging multiple ones bin logstash show config my config files dir don start just show resulting config input all merged inputs filter all merged filters output all merged outputs >>>discuss enhancement v2.1.0
site set up redirects for logstash net to elastic co for logstash release the new docs infrastructure for logstash and beyond is hosted on elastic co we ll want to update logstash net to ferry users to the correct locations the complexity of logstash net hosting caused us to delay possibly forever migration of the old logstash documentation to elastic co this means logstash and older documentation has not been migrated and still exists on logstash net in order to serve new and old users most effectively propose the following redirect logstash net root url to the logstash product page https www elastic co products logstash redirect logstash net docs to http www elastic co guide en logstash current index html update the `docs` link at the page header to link to http www elastic co guide en logstash current index html update the `bugs` link to point to https github com elastic logstash issues was `elasticsearch logstash` update the `home` link to point to the logstash product page ideally like to keep an eye on the impact of this change after we make it to see if we ve negatively hurt folks ability to find information cc sylvie777 sejiek >>>docs v1.5.2
gsub doesn like regex expressing single backslash want to replace single backslash and using valid regex to do so gsub doesn like this seems like need to work this bug around with >>>bug
string interpolation in the configuration parser is broken for newline characters alike was mutate gsub doesn work on json extracted field with backslash ok gsub replacing works on plain message field problem gsub replacing doesn work on json field note this seems something specific with replacing slashes in json replacement in json field with no works >>>bug
failed expansion results in the expression kills other expansions expected variable should expand to if `variable` is absent variable failing should not affect expansion of other observed with logstash on the `opentsdb` output we see variable expands to variable if `variable` is absent see also 2530 variable failing causes all other expansions in the output block to fail wouldn believe either of these if hadn seen the output configuration yes know we shouldn have prefixed everything interesting with we re also re using version` and `tags` worse `tags` is my fault ne er mind output `put usage 1431488930 user id user id app app subapp subapp action action user type unknown env env first visit useful useful wut method linux use `lsof logstash` to dump files open by the `logstash` user note the pid and the file descriptor numbers associated with your output for example our pid is `19578` and we re talking to opentsdb port `4242` on file descriptors `30` `31` and `32` plug them into an `strace` command append `2 grep to the command line to filter out everything except the write dumps feed in the data for which you re seeing problems in our case we saw this whenever subapp` was absent expansion started working again when we forced subapp` to have value >>>bug
old docs update changes to elastic brand>>>docs
bump versions for es kibana and jruby es is not recommended so would like to bump version to latest and latest kibana tested `node` `transport` and `http` protocol with es and they work fine `make test tarball` fails consistenty >>>v1.4.0
question steps to run logstash with native ruby and not jruby hi hoping to use logstash on small server limited to embedded java and 512m of ram and can it just very slow start up and sucks up lot of resource that need elsewhere would like to use native linux ruby instead of jruby to hopefully free up resources so am setting use ruby but runner rb dies at line 46 `kernel require rb 56 in require cannot load such file i18n loaderror guessing that this is path issue gems home and gems path and that there is interplay between logstash and the native ruby libs as neophyte ruby could someone point me to guide or point out some other doc that could point the way so that have stable install even though am aware of the date and es limitations thanks >>>mri_support
improve missing development dependencies exception upon running bin rspec as reported in 3229 when running `bin rspec` from release package the first exception raised because the development dependencies are not installed is which is not very user friendly we should catch this and propose to the user he might need to do once the development dependencies are installed running `bin rspec` produces this exception because there is no `spec dir as discussed in 2776 either we ship with the `spec dir or we modify the rspec script to exclude inexistant `spec dir note that it is otherwise possible to run specific existing spec using `bin rspec my spec rb` for example >>>enhancement
rspec do not exist for logstash rc4 how to run tests with rspec in logstash rc4 >>>enhancement
docs error the life of an event consequences and expectations hello all could be wrong but am assuming that this line is suppose to have only one grow unlimited queues grow grow unbounded regards austin>>>bug docs
custom plugins not recognized in rc4 normally drop my custom plugins into lib logstash output and they are recognized as expected in rc2 and rc3 in rc4 upon startup logstash compliains that it can find the plugin this was an rc4 rpm install on top of rc2 any changes in rc4 that would cause this >>>question
logstash redis input timeout missing data hello experiencing some issues with logstash and the redis input loosing data wondering if anyone else has seen this issue if redis has no data added to the queue at least once an hour see redis timeout restating plugin error the data is then all pulled from the list in one go and out of 10 messages only will arrive in elasticsearch to try and track down if there was timeout condition added test message to redis once an hour 1431330002 916917 rpush data test 1431330953 161801 blpop data 1431330953 821474 blpop data 1431330959 191131 blpop data 1431330959 867708 blpop data 1431333602 272291 rpush data test 1431334560 613347 blpop data 1431334560 613396 blpop data 1431334566 661423 blpop data 1431334566 668555 blpop data test message added 1431333602 gmt mon 11 may 2015 08 40 02 gmt logstash restarts redis plugin and picks up message 1431334560 gmt mon 11 may 2015 08 56 00 gmt logstash server timestamp 2015 05 11t07 55 58 829000 0000 message failed to get event from redis name default exception backtrace opt logstash vendor bundle jruby gems redis lib redis client rb 222 in `io opt logstash vendor bundle jruby gems redis lib redis client rb 220 in `io opt logstash vendor bundle jruby gems redis lib redis client rb 228 in `read opt logstash vendor bundle jruby gems redis lib redis client rb 96 in `call opt logstash vendor bundle jruby gems redis lib redis client rb 201 in `process opt logstash vendor bundle jruby gems redis lib redis client rb 309 in `ensure connected opt logstash vendor bundle jruby gems redis lib redis client rb 191 in `process opt logstash vendor bundle jruby gems redis lib redis client rb 270 in `logging opt logstash vendor bundle jruby gems redis lib redis client rb 190 in `process opt logstash vendor bundle jruby gems redis lib redis client rb 96 in `call opt logstash vendor bundle jruby gems redis lib redis client rb 179 in `call with timeout opt logstash vendor bundle jruby gems redis lib redis client rb 244 in `with socket timeout opt logstash vendor bundle jruby gems redis lib redis client rb 242 in `with socket timeout opt logstash vendor bundle jruby gems redis lib redis client rb 178 in `call with timeout opt logstash vendor bundle jruby gems redis lib redis rb 1038 in bpop opt logstash vendor bundle jruby gems redis lib redis rb 37 in `synchronize file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby monitor rb 211 in `mon synchronize file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby monitor rb 210 in `mon synchronize opt logstash vendor bundle jruby gems redis lib redis rb 37 in `synchronize opt logstash vendor bundle jruby gems redis lib redis rb 1035 in bpop opt logstash vendor bundle jruby gems redis lib redis rb 1064 in `blpop opt logstash lib logstash inputs redis rb 148 in `list listener opt logstash lib logstash inputs redis rb 229 in `listener loop opt logstash lib logstash inputs redis rb 245 in `run opt logstash lib logstash pipeline rb 163 in `inputworker opt logstash lib logstash pipeline rb 157 in `start input level warn timestamp 2015 05 11t07 55 58 833000 0000 message plugin had an unrecoverable error will restart this plugin plugin 10 49 240 121 key data data type list name default error connection timed out level error was still seeing lost data so increased the addition of the test message to every 15 mins this appears to have stopped the issue was seeing not sure on the root cause at this time any ideas thanks luke >>>needs_details
plugin install broken if the project name have spaces update if you run bin plugin install from directory that have spaces then the sh script gets consufed while looking for logstash lib sh and can not continue original message as discovered from http build eu 00 elastic co view ls 201 job logstash 20regression 201 20 release jdk jdk7 label metal pool console it actually complains about not properly finding the logstash lib sh file in https github com elastic logstash blob master bin plugin l1 l11 this does not happen with mac before assessing the severity we should also check packaging is healthy >>>bug plugin_manager
grok conversion not working in logstash rc4 looks like when do number latency int or number latency float in the grok match latency is still being stored as string >>>needs_details
plugin installation why local gem installation differs from rubygems org installation if install plugin directly from rubygems org the plugin is installed like logstash provided plugins in logstash vendor bundle jruby gems` for example `bin plugin install logstash filter environment` but if manually download the gem on rubygems org and then install it using local install `bin plugin install path to logstash filter environment gem` the plugin is installed in logstash vendor local gems so my questions are why is there difference why is there this random intermediate folder ps on numerous servers there is no internet connection mainly for security reasons and it not possible to install plugin directly from rubygems org manual download elsewhere is firstable necessary >>>question
metadata not shown in rubydebug take following output code even though `metadata` is `true` metadata contents is not shown in test log file logstash rc4 noarch>>>enhancement
add libc6 dev dependency for packages jsvd found that adding libc6 dev dependency fixed the file input file watch issue https github com elastic logstash issues 3127 for oracle jdk we should add this dependency for our deb rpm packages as workaround until it is fixed upstream https github com jruby jruby issues 2913 >>>bug
unset cdpath fixes 3207 `bin logstash` bin plugin` bin rspec` do `cd` to find `logstash lib sh` so cdpath has to be unset before that cd >>>blocker bug
logstash syslog input causing udp listener died error hi all am trying to receive syslog input from syslog server which is being fed logs from docker containers via logspout am rather sure that configured the input correctly to receive syslog on port 5000 here is my input config for syslog syslog port 5000 type docker log and here is my full input config on pastebin http pastebin com qcx5tfti here is the error am receiving http pastebin com jjxzsulx the port is being used by logstash as shown by ve tried reading up on this ticket https github com elastic logstash issues 1896 but don think this is reserved port issue or permissions issue could anyone help me debug this error from what can tell my configuration is correct >>>bug
rspec tests doesn work on windows can run rspec tests with success on linux but that doesn work on windows it seems that rspec doesn detect test examples here is the result when execute `bundle exec rspec` with `logstash filter multiline` plugin on windows my environment windows 64 bits java logstash rc4>>>tests-infra windows
wip refactor input plugin and pipeline shutdown as proposed in 3210 includes code cleanups in the files touched most important relevant changes are in `logstash pipeline rb` and `logstash plugin rb` thes changes works with the core plugins referenced below the unreferenced core plugins do not require any changes >>>shutdown_semantics
design plugins shutdown sequence refactor proposal we need to refactor the shutdown sequence involving the input plugins and establish clear shutdown semantic current design currently the base plugin class exposes the following methods related to shutdown `shutdown` only the lumberjack input plugin of all input filter output codec call this method never overridden does nothing `finished` called from many plugins never overridden does nothing `teardown` called from many plugins overridden by many plugins for the plugin shutdown bookkeeping `finished only the rackspace input plugin uses it `running only the sqs input uses it `terminating hand full of plugins uses it current input plugin shutdown sequence description there are basically situations all input plugins have exited normally they have somehow reached the end of their input the plugin will exit its `run` method the plugin thread will exit the pipeline thread will call the plugin `teardown` method `sigint` or `sigterm` is received and the pipeline needs to terminate the input plugins and the pipeline sig signal is trapped in the pipeline thread `pipeline shutdown` is called from the signal handler all input plugins threads are injected an exception wakeup like this `thread raise logstash shutdownsignal `thread wakeup` all input plugins `teardown` methods are called in sequence normally the plugins exit their `run` method and threads at which point the pipeline thread will again call the input `teardown` methods an uncatched exception in the input plugin the plugin `teardown` method is called from the pipeline thread the plugin is restarted by calling the plugin `run` method again in `begin retry` problems current semantic is not clear and shutdown handling is inconsistent throughout the plugins injecting rogue exception by doing raise in the live thread is very bad idea and can lead to many weird problems see this post discussing the related problems http blog headius com 2008 02 ruby threadraise threadkill timeoutrb html per the previous reason `logstash shutdownsignal` exception can happen virtually anywhere event in the `teardown` method `teardown` is called twice on the input plugins in `sigint` `sigterm` situation thread safety issues are not clearly defined understood in the current design suggested refactor here my suggestion for first iteration cleanup once cleaned up we will be able to more easily build upon it and start thinking about decoupling further the plugin execution lifecycle from the pipeline in further iterations we basically need things for the input plugins signal the plugin it need to stop ask the plugin to do its bookkeeping once it is stopped for this suggest that the plugins exposes only methods `stop` `stop and `close` `stop` is called from outside the plugin thread from the pipeline thread and is to ask the plugin to stop this method must be thread safe bacause it will be called from outside the plugin thread `stop returns true if the stop method was called and can be used within the plugin to verify if stop was requested `close` is called once when the plugin is stopped to perform any final bookkeeping the way to know plugin is stopped is simply by waiting the return of the plugin `run` method when the run method exits and the plugin thread exits this is only when the `close` method should be called once the same semantic can be applied to the filter and output plugins which would support shutdown modes the current mode of inserting `shutdown` event in the queue so that all inflight events will be processed before the filter and output plugins are closed new mode using the `stop` method for an immediate shutdown in which case the inflight events will be lost when not using queue persistence in other words with queue persistence we will be able to do an immediate shutdown without loosing inflight events >>>bug design shutdown_semantics
upstart not behaving as configured have logstash freshly installed on ubuntu server 14 04 and using oracle java redirected log output to another directory instead of var log but failed to grant the proper permissions to the logstash user this caused logstash to immediately exit saw cpu usage peg because upstart was respawning logstash as fast as it could etc init logstash conf has the stanza respawn with no parameters and no respawn limit according to http upstart ubuntu com cookbook respawn in this case the default limit parameters 10 would apply meaning that upstart should try to restart 10 times over second interval and then give up this seems like reasonable configuration instead it acting as if its respawn limit is unlimited as it never gives up retrying this is not reasonable behavior as upstart is permanently stealing cpu cycles from other services and futilely wasting them this bug is request to fix upstart keep alive behavior regarding logstash so that it does not cripple the server when logstash cannot run >>>question
bin plugin doesn work if cdpath env var is set the fix is to unset cdpath env var in bin plugin the bin logstash lib sh already unsets cdpath but bin plugin does cd to find logstash lib sh so it needs to be explicitly unset before that cd >>>blocker bug v1.5.0-rc4
to have known issue documentation it would be nice hi having central place for known issues and workaround that make the system happy again would be good to have this can be good source of knowledge when user might encounter some issues >>>docs enhancement
logstash regression test not testing with dev version logstash regression test is testing with the released logstash core gem and not using the current code version logstash regression test should test with the existing code while we should have another job testing with the logstash core gem >>>bug tests-infra
running test in logstash creates gemfile lock file hi doing creates new gemfile lock file might be bundler is not properly patch here to use the gemfile jruby lock file >>>bug needs_details unconfirmed
logstash wont kill after rabbit problem can kill logstah with kill when there problem in rabbitmq logstash 5rc3 killing logstash pid 33582 with sigterm waiting logstash pid 33582 to die waiting logstash pid 33582 to die waiting logstash pid 33582 to die waiting logstash pid 33582 to die waiting logstash pid 33582 to die logstash stop failed still running >>>needs_details pipeline-stalls
initialize the `metadata accessors` when setting the metadata with hash when we set the metadata key with hash we need to setup the accessor class or our access logic will not work fixes https github com elastic logstash issues 3195>>>blocker
mutate convert int causes ungraceful crash added this in logstash config file notice int not integer thanks to torrancew on irc for catching my error mutate convert disk read int convert disk write int then when when restarting logstash it crashes with this error cat logstash stdout sending logstash logs to var log logstash logstash log an unexpected error occurred this is probably bug you can find help with this problem in few places chat logstash irc channel on freenode irc irc via the web http goo gl ti4ro email logstash users googlegroups com bug system https logstash jira com the error reported is undefined local variable or method `valid types for changing int to integer fixed the issue this is on rhel sudo yum list installed grep logstash logstash noarch 2c0f5a1 logstash >>>needs_details
metadata field conditional issues have been using logstash 5rc3 and attempting to do conditional on field in the metadata the following is gist of the output of the rubydebug codec on stdout with metadata true https gist github com hugespoon ba7e714a772f20572eca the output configuration is also included for additional background the es bulk codec is being used on my input source but it seems to be parsing things out into metadata properly as you can see from the rubydebug output >>>blocker bug v1.5.0
fix the documentation generation fix 3184 by fixing the pattern for the class definition line otherwise sometimes there is no need to have it defined like logstash so the first should be optional this leats the generation process create the class description again generated all the docs and check few and saw this part always generated as side efect it cleanup bit the rake task used to generate the documentation as the pattern used was very long >>>bug docs
refactoring the doc generation process the way that documentation is generated nowadays is nice but good refactoring plus some strength up is going to be very nice to have things that can be improved are refactore the code base to remove old code and make everything bit more clear adding test for the process add strength checks the documentation generation should not stop if plugin can not be parsed for example >>>docs enhancement
few minor improvements and pending cleanups clean up pending development dependencies from the logstash core gemspec including crossed reference to rspec and reference to logstash devutils add gems as build dependency in the gemfile is used when doing an install all task and failed in the ci env like octokit fix this kind of error http build eu 00 elastic co view ls 201 job logstash all plugins test 460 console>>>enhancement
new feature request docker files for power platform sles rhel ubuntu hi have written dockerfile for building logstash from source and to run the test cases have built and tested the source code available on git successfully through the dockerfile for ppc64le architecture the dockerfile is successfully run on following platforms ubuntu 14 10 suse linux 12 rhel kindly suggest me where can which repository contribute this dockerfile for logstash regards christina >>>enhancement
docs class description is not getting converted to asciidoc trying to generate doc after installing all plugins first off `rake docs generate docs` is not working again then tried manually generating docs the asciidoc is created without the class description blob every other section is generated fine >>>bug docs
shutting down logstash with outputs warning message tried with rc4 snapshot2 tar package with `stdin` input started logstash trying to stop via c`and pressing any key stops ls bit outputs the warning message d` works fine >>>bug
rake options are skipped in logstash the rake command is not passing properly the list of option to the embedded one when calling this by using the embeeded ruby this is because we use rake file to embeed some code that will be executed before the rake taks and actually call the embeeded ruby with that check at https github com elastic logstash blob master rakelib rubycheck rake l28 l35 at this level of interaction options like to list the task are lost only the files are keep it very nice to use as developer command like rake to list all tasks available then we would have also other nice option commands like in my experience nice improvement to have >>>enhancement
create zip jobs failing at ci as in the ci error propose we add this dependency the same way we added the others to fix 3171 http build eu 00 elastic co job logstash create zip artifact 15 87 jdk jdk7 label metal pool console>>>blocker bug v1.5.0-rc4
pending plugins with issues with logstash home there are couple of missing plugins with pending issues regarding logstash home https github com logstash plugins logstash input syslog issues https github com logstash plugins logstash patterns core issues 32 will apply and share with pr the same idea of the fix introduced to mutate in order to provide fix to them >>>blocker bug v1.5.0-rc4
move the logstash home mocking for specs in devutils see logstash plugins logstash filter mutate 25 and logstash plugins logstash filter grok 23 since it seems these are the only two failing just patched mutate the same way as grok but this is patch that probably belongs in devutils cc jsvd >>>enhancement
package build is broken due to bad file descriptor errors while installing gems to run ``artifact deb ``artifact rpm or the all plugins test where mass installation of plugins is being done make the process to break with errors like from the artifact deb build this is afecting all the package build except zip and tar the all plugins test >>>blocker bug bundler v1.5.0-rc4
install plugin from private gem repository it would be nice if on the command bin logstash install plugin name we can pass the source something like this bin logstash install plugin name source http www myprivategemrepo com>>>enhancement
service fails to stop v1 rc3 after upgrading to rc3 from rc2 still have the same issue https github com elastic logstash issues 2796>>>unconfirmed v1.5.0-rc3
no events pushed to es rc2 rc3 after upgrading to rc3 from rc2 events are only pushed to es for couple of seconds after starting logstash service can be seen in kibana after couple of seconds es kibana doesn show any incoming events anymore logstash service is running properly and the log files don give any hint the configuration settings are already provided here https github com elastic logstash issues 3003>>>needs_details unconfirmed
all plugins broken after rc4 snapshot1 hi after we merged 3111 all plugins are broken if you clone do bundle install run bundle exec rspec the plugins complain with >>>blocker bug
environment when not in package context this fixes the issue where executing `bin bundle rspec` in dev plugin dir with the new logstash core code aborts with error missing logstash home environment variable >>>blocker v1.5.0-rc4
remove unsused files>>>v1.5.0-rc4
support remote or local gem packaging rake artifact tar will either build the local `logstash core` gem and embed it in the package if the `gemfile` contains gem logstash core path or othewise rely on the rubygems `logstash core` if there is no path specification>>>enhancement
bin plugin update fails when there is local gem installed build local `foo logstash plugin gem` and install on logstash core do `bin plugin update` it fails with we should ignore this local gem and update remaining gems installed via rubygems re word the warning so it is more developer friendly >>>enhancement
clean logstash core gemspec dependencies version constrains building the logstash core produces lots of warnings >>>bug v1.5.0
cannot grok or mutate split records see also 1820 and 2816 in logstash you were unable to mutate or grok records that were split using the split filter as documented this was resolved in 1820 and consequently this functionality worked as described in logstash 0rc2 unfortunately it seems there has been regression in rc3 with this issue please see https gist github com ianmacl 17346ceacd25988e1040 for example config input and output with 0rc2 and 0rc3 as packaged in the deb files on the repo >>>bug v1.5.0-rc4
conflicting jar versions can cause plugins not to work properly raised becuase of conflict with lucene versions between elasticsearch and neo4j the test raised the situation where having two conflicting versions cause the plugins not to register to reproduce this issue install logstash input neo4j install logstash output elasticsearch add development dependencies run the plugin test then you will get an error like but if for example you install the logstash output neo4j and the logstash output elasticsearch the neo4j plugin output an error as it can has conflict with the lucene version lucene jars being used are this happen now with lucene but guess it can happen with other dependencies alike in the feature too >>>bug discuss
lock file prevents install with version of plugins that are needed by others in release the lock file will contain the reference to plugin locked version even after being uninstalled if other plugins depend on it example >>>bug bundler known_issue plugin_manager
docs clarification around index type deprecation using rc3 yet the docs don show this as deprecated >>>docs
write developers doc or blog about event initialization in codecs input plugins want to document for developers the different strategies when initializing building new `logstash event` this usually happens in codec `decode` method but codec less input plugins can also do that there are basically ways using the event field reference syntax for example using hash quick benchmark for this shows that using hash is more than twice as fast as using the field reference syntax which is really meant for event manipulation from the logstash config the reason for this is that there is extra logic required to parse the field reference string as opposed to directly manipulating `hash` >>>docs
windows file plugin error incorrect function not having much luck to read any files with rc3 on windows jre 10 it always fails with the error below but will read different amount of lines each time it run before failing using very simple conf file which works in rc2 >>>unconfirmed upstream_fix_needed windows
runner cleanup not because of the runner trots in 3111 unilaterally removed `bin logstash rspec` in favor of `bin rspec` it still up for debate if we are going to keep `bin logstash rspec` because it was there or not the runner class need cleanup do not think that the support for `irb` and `pry` should be there these are development tools `docgen` does not belong there it packaging tool `plugin` is redundant to `bin plugin` just like `rspec` is redundant to `bin rspec` the `agent` concept is not needed anymore since that only what logstash is now suggest we move `irb` `pry` and `docgen` as seperate commands in the `bin dir with the startup script cleanups in 3111 is it now super simple to do see the new bin plugin https github com colinsurprenant logstash blob fix logstash core bin plugin doing this we will gain the choice of including them in the package or not and it better separation of concerns since logstash is always `agent` suggest we simply ignore that argument if we see it and just pass all argument parsing to the agent class the only remaining option would be `bin logstash version` we could either convert it to version` and pass it to the agent class for the sake of backward compatibility or remove deprecate its support in favor of `bin logstash version` >>>breaking-compatibility enhancement internal-cleanup v3.0.0
much needed readme refresh updated urls updated need help links revamped developing testing and building sections added links to plugins development these instructions are compatible with pr 3111>>>enhancement v1.5.0 v1.5.0-rc4
notimplementederror block device detection unsupported or native support failed to load hi am trying to run logstash rc3 on ibm aix and got the following error only have file input can anybody help thanks >>>bug
inconsistent package version number separators rc2 rc3 confuse apt the debian packages went from using to to separate the rc suffix versions are sorted lexicographically so apt thinks rc2 is newer than rc3 not deal breaker but it requires doing forced downgrade ex rc2 rc3 1>>>bug packaging v1.5.0-rc3
logstash stalls logstash rc3 hi ve noticed after upgrading to rc3 that logstash hangs freezes after few seconds of starting just using the netflow codec os centos x64 ps ef grep logstash root 30204 28111 11 10 06 pts 00 00 48 usr bin java xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xmx500m xss2048k djffi boot library path opt logstash vendor jruby lib jni xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xbootclasspath opt logstash vendor jruby lib jruby jar classpath djruby home opt logstash vendor jruby djruby lib opt logstash vendor jruby lib djruby script jruby djruby shell bin sh org jruby main opt logstash lib logstash runner rb agent etc logstash conf debug root 30665 6116 10 13 pts 00 00 00 grep color auto logstash rpm qa grep logstash logstash rc3 noarch strace 30204 process 30204 attached futex 0x7f83e910a9d0 futex wait 30221 null input udp port 6544 type netflow codec netflow output if type netflow elasticsearch host localhost template etc logstash elasticsearch template json template overwrite true cluster elasticsearch index netflow yyyy mm dd else elasticsearch host localhost cluster elasticsearch if type netflow stdout codec rubydebug >>>bug
netflow codec support for ipfix was wondering if the current netflow codec would could support decoding ipfix flow rather than netflow v5 unless am mistaken wouldn it be as simple as updating lib logstash codecs netflow netflow yaml https github com elastic logstash blob v1 lib logstash codecs netflow netflow yaml with the values from http www iana org assignments ipfix ipfix xml did find this ticket wanting ipfix input plugin https github com elastic logstash issues 2525 however feel that with the tcp input plugin and the netflow codec this could be accomplished without an additional input plugin >>>question
wip testing how to docs rspec features listing background testing pipeline like logstash might become hard process there has been lots of improvements and simplifications for the testing of logstash however one of the few things missing is good document where people can refere in order to know how to write test this issue aim to be place to discuss and show how to write great test for logstash using the last features of rspec3 after we re happy with the content in here the objective is to generate wiki page where everyone can go rspec features in this section we ll do an overview of the different rspec features and might be useful for you when planning your tests suites rspec core the rspec core provides the structure for writing executable examples of how your code should behave describe context and examples subjects let other important features hooks before around and after filters metadata formaters rspec mocks test double framework for rspec with support for method stubs fakes and message expectations on generated test doubles and real objects alike allow and expect constraints spies dealing with legacy code rspec expectations collection of assertions that lets you express expected outcomes on an object in an example equality matchers comparison matchers predicate matchers type matchers custom matchers composing matchers best practices for rspec but also general for testing use context have short and clean descriptions becomes one assertion per test use subjects use let and let mock and stub but with caution use descriptive factories your test want to be independent structure your test layout >>>docs ruby_style_guide tests-infra work_in_progress
store encrypted es password in config file or allow prompt the password for es user is stored in plain text in the logstash config file which is not secure it would be better if the password is masked or encrypted in the config file or prompt for the password at logstash startup >>>enhancement v2.0.0
dos using malcrafted packet it possible to bring logstash lumberjack input down and thus stop it from accepting logs via following runtimeerror unknown frame type 101 header at opt logstash vendor bundle jruby gems jls lumberjack 22 lib lumberjack server rb 149 feed at opt logstash vendor bundle jruby gems jls lumberjack 22 lib lumberjack server rb 100 run at opt logstash vendor bundle jruby gems jls lumberjack 22 lib lumberjack server rb 227 invoke at opt logstash vendor bundle jruby gems logstash input lumberjack lib logstash inputs lumberjack rb 71 rpm qf opt logstash vendor bundle jruby gems logstash input lumberjack lib logstash inputs lumberjack rb logstash rc3 noarch>>>bug v1.5.1
logstash 5rc2 stops passing through events stacktrace included have zeromq input and statsd and elasticsearch output logs http pastebin com svnjgf7d config http pastebin com e6umv9gq when upgraded to 5rc2 found that after some period of time data would no longer make it to elasticsearch or statsd looking at the network traffic and memory usage it appears that logstash was continuing to accept traffic but was no longer sending traffic out have attached graphs which show this this doesn happen immediately it generally happens after number of hours it also doesn happen consistently we have 18 indexers and generally only one or two will go down before we catch it and kick it have not yet had chance to create test environment in which to replicate this logentries https cloud githubusercontent com assets 176534 7417993 3e2f424c ef38 11e4 9046 a994c938782a png memoryusage https cloud githubusercontent com assets 176534 7417992 3e2f1fec ef38 11e4 932d 9bc1b2cd939a png network https cloud githubusercontent com assets 176534 7417991 3e2e99e6 ef38 11e4 9a59 35046be9a7df png >>>bug unconfirmed
update readme with changes from 3111 3111 is removing the `rspec` subcommand for `bin logstash` instead you can use `bin rspec` will need to update the section https github com elastic logstash testing also we should explain the strategy of `logstash core` gem and how we can update it>>>enhancement v1.5.0-rc4
support consistent env variables between the linux and windows startup scripts the supported environment variables are not consistent between linux and windows for example in linux we use `ls heap size` while on it `ls min mem` and `ls max mem` don know what the history is for this but think we should make them consistent as much as possible >>>enhancement v2.1.0 windows
pluginmanager undefined method `signal error made typo in the plugin name calling bin plugin and got the following error message suppose the method should be change to `signal usage error` where relevant in `pluginmanager install rb` but as this file is being moved in 3111 the fix should either wait for it to be merged or included there to avoid conflicts colinsurprenant could your pr grow little more >>>bug windows
logstash 5rc3 unable to split on previously split events within same filter conditional block this was working in logstash 5rc2 logstash 5rc3 logstash filter split input data foo bar split foo bar bob foo bar ping foo bar expected output event foo bar event foo bar event foo bar event foo bar what doesn work output what kinda works output any assistance would be appreciated thank you >>>bug unconfirmed
elasticsearch output failed with response of 400 hi am using 5rc3 on windows tried to specify variable index naming scheme in my elasticsearch output like this in my output section 		elasticsearch 			host localhost 			cluster evtglogs 			embedded false 			index logstash environment yyyy mm dd 		 when using this config my events won ship to es and get the following error in my logstash output failed action with response of 400 dropping action full message is below any idea what ve misconfigured thanks in advance markus timestamp 2015 04 29t14 36 02 060000 0200 message failed action with response of 400 dropping action id nil index cancelled false data message 29 04 2015 14 35 50 at010000sat26 8280 info 140 1430310950636 at010000sat26 8280 84 12 16 104 yview16 user16 viewtest16 m001 ez vtg aaa handler ezvtg rh bbb reactivate 78 36390 1430310950714 78 ok version timestamp 2015 04 29t12 35 50 000z type tomcat host at010000sat26 path head tomcat tomcat logs att systrace log environment dev server at010000sat26 instance head hostname at010000sat26 port 8280 envpath severity info requestid 140 startts 1430310950636 hostname2 at010000sat26 port2 8280 path2 rhost 84 12 16 104 uid yview16 username user16 viewtest16 reqpath m001 ez vtg classname aaa handler ezvtg rh bbb rhcmd reactivate notransresponsetime 78 outbytes 36390 endts 1430310950714 responsetime 78 conwaittime servicewaittime concurreq rc reasoncode ok timestamp 14 35 50 04 29 2015 rhandcmd aaa handler ezvtg rh bbb reactivate environment level warn >>>unconfirmed
how to create an alias on two indexes with logstash in the cluster that am working on there are two main indexes let say indexa and indexb but these two indexes are indexed each day so normaly have indexa yyyy mm dd and indexb yyyy mm dd what want is to have one alias that gathers indexa yyyy mm dd and indexb yyyy mm dd together and named alias yyyy mm dd does anyone know how to gather two indexes in one alias with logstash thank you in advance>>>question
error when flushing to elasticsearch jackson classnotfoundexception in ve seen this behavior in beta1 upwards there some very weird behavior ve experienced with some logstash configs that arises at an indeterminate time after logstash has been started at high level this is the stack trace that seeing ve seen this `com fasterxml jackson module afterburner ser beanpropertyaccessor` exception happen either within few seconds of the pipeline starting up or after hours of operation it can vary widely can reproduce this with pretty small config narrowed down the combination of twitter elasticsearch after some trial and error and although the plugins seem to be the ones exacerbating the bad behavior the fact the trace is coming from deep within logstash deserialization makes me think it deeper problem note that changing `protocol` to `node` seems to help with the problem suspect that this old jrjackson issue https github com guyboertje jrjackson issues 12 is tangentially related but too far removed from the codebase to say for sure my environment can get additional diagnostics if needed >>>bug unconfirmed v1.5.1
slim down the skip list from plugins that are now released and accesible this list was intended to be used to keep away empty plugins however some of them got now graduated so are fully released and testable in our infrastructure this pr aims to have this plugins up and running as expected for our configuration purbon>>>resiliency v1.5.0-rc4
notimplementederror block device detection unsupported or native support failed to load issue am encountering the following error when trying to use the file input to watch var log syslog and var log auth log have run the following on the log files the following exception stack trace is from var log logstash logstash err if run interactively using the error reported is bad file descriptor bad file descriptor root logstash1 lsb release description 	ubuntu 14 04 lts root logstash1 opt logstash bin logstash logstash rc3 root logstash1 java version java version 45 java tm se runtime environment build 45 b14 java hotspot tm 64 bit server vm build 25 45 b02 mixed mode >>>bug known_issue
logstash looking for where it shouldn be keep getting this is my logstash log but everything ve seen says that type is valid timestamp 2015 04 28t16 04 42 699000 0500 message error expected one of at line 24 column byte 537 after input if >>>question
udp listener died with logstash rc3 since upgrade from rc2 to rc3 logstash randomly crash >>>needs_details
kafka plugins fail to install in master the kafka plugins installation is failing to reproduce then the exception minus the bundler traces is >>>bug
argumenterror cannot pack type org jruby rubytime while trying use tcp output with fluent codec am trying to export my logstash log to fluentd forwarder by but got the error message below any clue >>>bug needs_details
docs asciidoc generation broken tried to use `rake docs generate` which internally installs all plugins on core and generates docs also tried the command directly >>>bug docs v1.5.0
exception 232 213 212 395 hi am getting the following exception for few logs when they match two of my patterns in my logstash configuration file it seems that logstash generates matched pattern but it does not contain any of the fields that had configured in the pattern it does however contain the tag for the pattern itself generated small input file which contained only the problematic log enteries the strange thing is that this problem never happens for the first log amongst these log messages but happens for the rest of the logs the following is the debug log https gist github com nipunarora 51d156fe0d48b8b3996e logstash configuration https gist github com nipunarora 13c240f866fef12e6e7b sample input data https gist github com nipunarora f404141e68587b0f8fcf >>>unconfirmed
rc3 ruby filter fails with undefined variable event this ruby filter we ve been running fine in filter ruby code begin if event message nil event message event message force encoding ascii 8bit encode utf invalid replace undef replace replace end rescue end now fails on rc3 with undefined local variable or method `event is this regression or has something else changed >>>bug
local installation of plugins through path or gem depends on git because in gemspec` file the preconized way to specify files list is based on git files `git ls files` split when install plugin on logstash and worse when run logstash with local plugin installed logstash needs `git` in `path` the problem is that git is not installed on every machine where logstash is present for example if want to install plugin on logstash production environment git is probably not installed so to avoid git dependency it could be nice to prefer something like this in gemspec` file `s files dir lib spec gemspec md contributors gemfile license >>>bug bundler
make ubuntu package compliant with quality expectations ubuntu uses lintian to check the quality of the package structure file permissions etc and on ubuntu 15 it identifies some issues this should be easy to fix >>>enhancement packaging
input file start position beginning doesn work for me as the title am tying logstash and found the file input doesn work only the newly appended file records was printed out here is my configuration input stdin file path apps apache access log start position beginning filter if type apache access this is where we use the type from the input section grok match message combinedapachelog output stdout elasticsearch host localhost >>>question
use either local core lib dir or logstash core gem will fix 3096 adds the concept of `logstash home` vs `logstash core` where `logstash home` points to the package root while `logstash core` points to the directory containing the core code `lib logstash both can be the same when in development using repo clone or different when packaged where `logstash core` points to the `logstash core` gem under `vendor bundle it looks like it working well but haven fully tested the package generation because did not have internet on my flight hence the wip this is an early release so we can have more eyeballs on the idea also did few cleanup of what thought was dead unused code >>>enhancement v1.5.0-rc4
0rc3 failing on windows hi have downloaded the rc3 from here https www elastic co downloads logstash unzipped and run through logstash bat agent apps logstash conf debug getting this error nameerror uninitialized constant logstash environment gem const missing at org jruby rubymodule java 2726 windows at apps logstash lib logstash environment rb 98 root at apps logstash lib logstash patches bugfix jruby 2558 rb require at org jruby rubykernel java 1071 root at apps logstash lib logstash patches rb require at org jruby rubykernel java 1071 root at apps logstash lib logstash patches rb require at org jruby rubykernel java 1071 root at apps logstash lib logstash environment rb require at org jruby rubykernel java 1071 root at apps logstash lib logstash runner rb not ruby skilled but from what found the gem class should be part of ruby itself but it seems the code does not see it maybe jruby compat issue running this on windows 2012r2 >>>needs_details v1.5.0 windows
question logstash rc2 and logstash log is growing fast in my logstash 0rc2 setup have no stdout output defined in my configuration but see that the logstash log file is growing very fast into multiple gb size previously till beta1 the log file logstash log would only be populated when there was stdout output defined is this feature or bug if feature is there way to reduce it >>>needs_details
rc3 filters undefined local variable or method `event` as reported by wjimenez5271 using rc3 while debugging https github com elastic logstash issues 3092 config https gist github com wjimenez5271 d145cf8906752b5a5cbe>>>blocker bug
improvement suggestion for logstash plugin repos sorry to be creating this request here but https github com logstash plugins has many repository to make this improvement suggestion it would definitely be of great help if git repository for every logstash plugins as they will be maintained separately contains readme md relevant to that plugin along with may be examples or use cases as of now most or all of them have boiler plate readme md changelog md showing the changes made in the same spirit as it is done here https github com docker docker blob master changelog md >>>enhancement
remove logstash core directories and fix paths to use the logstash core bundled gem the rc3 package includes the `logstash core` gem and also has the `lib `spec and `locale directories in the root of the package this is redundant and we should leverage our `logstash core` gem for this heres what suggest add the `spec and `locale directories in the `logstash core` gem remove the `lib `spec and `locale directories from the package root when building the artifacts add the concept of both package home dir and core home dir fix the `bin scripts the `environment` module and the few places that rely on file to use the proper package home dir or core home dirs make sure these work in the dual dev package contexts where in dev the `logstash core` code is local and in the package context the `logstash core` code is under the `vendor bundle directory make the `logstash core` gem proper plugin updatable by the plugin manager this is the last mile to our gemification process and will allow us to update the core code without having to necessarily release whole new package this is very very very useful for bug fixes the changes are not very complicated and think we should aim for >>>enhancement
logstash user survey results in case you hadn heard about it we asked all of our community members to tell us more about how they use logstash including praise and pain points we just published the results of this survey on our blog https www elastic co blog logstash user survey results in this blog post we shared our summary of the results as well as provided links to the raw results in case anyone is interested in doing more analysis this issue has been opened to discuss results of the survey share additional analysis and offer feedback and suggestions for future surveys thank you all >>>discuss
logstash significantly slows down with longer grok pattern hi have been using logstash to parse my logs lately wanted to add few more fields to my logs after updating my grok patterns for it logstash has significantly reduced its speed was getting around 3k output before the new pattern now around 200 to 300 had around 20 fields back then increased more what is the reason for this sudden performance degrade >>>question
update hello search conf to avoid version mismatch update hello search conf to avoid es logstash version mismatch error>>>missing_cla
npe with lumberjack and logstash sharing in case its helpful >>>needs_details
add docs for setting jvm options fixes 3042 >>>v1.5.0-rc4
warning when running any shell commands reproduced on windows server 2012 r2 and ubuntu when executing any logstash command have this warning `io console not supported tty will not be manipulated` this message doesn impact the execution of any command possibly jruby issue and fixed in 20 https github com jruby jruby issues 1614 issuecomment 94798150 dot not recall having this warning on the previous rcs when doing the smoke testing on windows >>>bug
regression build failing in master http build eu 00 elastic co job logstash regression master jdk jdk7 label metal pool 258 console >>>tests-infra
suricata syslog json parsing has anyone setup remote suricata box and sent the logs to elk in json have my suricata box sending syslogs to my elk setup using the json format the logs are showing up in kibana but they are not fully parsed and getting the jsonparsefailure in the tag added as well here is my config and log file input udp port 5143 type suricataidps format json event filter if type suricataidps mutate add tag suricataidps json source message apr 22 07 09 24 hp suricata timestamp 2015 04 22t07 09 23 726014 flow id 140548582938816 in iface eth1 event type fileinfo src ip 129 253 55 56 src port 80 dest ip 24 237 218 244 dest port 62494 proto tcp http url filename wdws wdtvlive ws wdtvlive asmx wdpromo state closed stored false size 167 tx id >>>question
clean the jenkins package generation jobs as discussed with ph and purbon we need to remove the first task that runs the tests prior to generating the artifacts in the artifacts jenkins jobs was there any particular reason for using ruby for the jenkins artifacts task if not we should change it to jruby >>>blocker v1.5.0
not updated when we run the `bin plugin update` command it and we have plugins to upgrade it upgrade them but doesn show which plugins were upgraded >>>blocker v1.5.0-rc3
bin plugin update will make plugin functions unusable tried with rc3 snapshot6 un tar and run `bin plugin list` things work as expected update plugins we know mutate was published to on rubygems old version packaged in artifacts first bug it says no plugin updated after that sequence no plugin commands will work >>>v1.5.0-rc3
fix leading whitespace in repo docs there were leading spaces instead of when rendered as markdown to html it would result in each line starting with space so if you copy paste into file you get an invalid logstash repo file >>>missing_cla
latest logstash 0rc3 snapshot5 broken on all platform io console not supported tty will not be manipulated gem loaderror you have already activated jar dependencies 13 but your gem file requires jar dependencies prepending `bundle exec` to your command ay solve this setup at logstash rc3 snapshot5 logstash rc3 snapshot5 vendor bundle jruby gems bundler lib bundler runtime rb 34 each at org jruby rubyarray java 1613 each at logstash rc3 snapshot5 logstash rc3 snapshot5 vendor jruby lib ruby forwardable rb 201 setup at logstash rc3 snapshot5 logstash rc3 snapshot5 vendor bundle jruby gems bundler lib bundler runtime rb 19 setup at logstash rc3 snapshot5 logstash rc3 snapshot5 vendor bundle jruby gems bundler lib bundler rb 122 setup at logstash rc3 snapshot5 logstash rc3 snapshot5 lib lo gstash bundler rb 51 execute at logstash rc3 snapshot5 logstash rc3 snapshot5 lib lo gstash pluginmanager list rb 20 run at logstash rc3 snapshot5 logstash rc3 snapshot5 vendor bundle jruby gems clamp lib clamp command rb 67 execute at logstash rc3 snapshot5 logstash rc3 snapshot5 vendor bundle jruby gems clamp lib clamp subcommand execution rb 11 run at logstash rc3 snapshot5 logstash rc3 snapshot5 vendor bundle jruby gems clamp lib clamp command rb 67 run at logstash rc3 snapshot5 logstash rc3 snapshot5 vendor bundle jruby gems clamp lib clamp command rb 132 root at logstash rc3 snapshot5 logstash rc3 snapshot5 lib lo>>>blocker v1.5.0-rc3
codec json lines initializes charset incorrectly causing it to be ignored ve been trying to get nxlog with logstash to work for days now and couldn manage to get charsets straight what buggued me was that logstash would always complain about input not being valid utf even when set it to expect cp1252 even stranger some people said things broke starting and that using line codec then json filter worked as workaround to json lines so set out to put debug output everywhere in logstash code and see why after little trip in codec code then the config parser to confirm it was working there then back to the codecs find this in line codec converter is declared in register now can only imagine jsonlines to reuse json and lines codecs what do you think it does overwrite converter or something it seems to just change the initialization parameter and for some reason this is ignored when if register is ever called ll try to dig bit deeper to see why apparently this bug has been around for about two years reported bunch of times and hasn been fixed yet could someone do something about this >>>bug v1.5.1
run all tests on java and java today we have few tests on jenkins which run on java and java we should make sure all our tests integration and unit are run on multiple versions >>>enhancement tests-infra
fix an issue with bin plugin update with no arguments and no locally installed gems fixes https github com elastic logstash issues 3062>>>blocker v1.5.0-rc3
bin plugin update fails on fresh packaged release error was >>>blocker v1.5.0-rc3
review merge plugins new timestamp json api updates https github com logstash plugins logstash input puppet facter pull https github com logstash plugins logstash output redmine pull https github com logstash plugins logstash output mongodb pull https github com logstash plugins logstash output graphtastic pull https github com logstash plugins logstash output metriccatcher pull https github com logstash plugins logstash output google bigquery pull https github com logstash plugins logstash output datadog pull https github com logstash plugins logstash output datadog metrics pull https github com logstash plugins logstash output circonus pull >>>meta
updated wms filter lost from contrib recently found out that the wms wmts plugins were not migrated from contrib to own repo bundled them together in https github com wiibaa logstash filter wms and updated them to for your review this plugin contains the original commits made to contrib my corrections https github com elastic logstash contrib pull 107>>>needs_review new-plugin
updated to reflect the mass publish after 2832>>>blocker v1.5.0-rc3
detect the to use of `to json` plugins developpers should not use the ruby implementation of `to json` but instead use our `logstash json dump` or `logstash json load` which use the jrjackson gem >>>docs ruby_style_guide
logstash crashes if it encounters communication problem this issue is related to 2992 if logstash 5rc2 encounters problem writing to elasticsearch it will cause logtsash to crash full logs are shown here http pastebin com tdy8kway the interesting lines are because of issue 2992 the logstash service will fail to be restarted by the upstart watchdog on ubuntu 14 04 the config files are >>>bug
add an rspec shim in the spirit of https github com elastic logstash pull 3037 this pr adds new rspec shim so users can run test in the same way as they do with the command provided by rspec >>>enhancement
provide guidance on the right way to set charset we have deprecated the charset option http www elastic co guide en logstash current plugins inputs tcp html plugins inputs tcp charset it will be nice to provide the now recommended alternative along with the deprecation message eg >>>docs
document the new java opts strategy we should add documentation for the changes merged in 2942>>>enhancement v1.5.0-rc3
fix relative pathname lookup while installing local gem file fix the pathname lookup for installing new gem files >>>blocker bug v1.5.0-rc3
contributing output elasticsearch groom plugin would like to contribute an output plugin that developed https github com itzg logstash output elasticsearch groom there are several scripts solutions out there most notably curator https github com elastic curator however that one specifically is python based and others are typically cron driven nothing wrong with python it just yet another system dependency preferred solution that was more logstash and facilitates self regulating logstash ecosystem of time based indices also wanted to define `index` templates once and use that to define both the creation and grooming specifications have included inline documentation and rspec tests it is also published to rubygems https rubygems org gems logstash output elasticsearch groom please let me know if more pipeline configuration examples would help to clarify the intent and usage >>>needs_review new-plugin
bin bundle shim add the `bin bundle` shim this shim is essentially the same shim as the one supplied with the bundler gem but includes our bundler patches for the lock` file naming this allow doing `bin bundle exec rspec` for example or any other bundle command very useful with that we can get rid of `bin logstash rspec` >>>enhancement v1.5.0-rc3
uninitialized constant logstash outputs tcp tcpsocket hi while trying to output to tcp socket logstash throws following error tested the socket messages can pass through have installed logstash over ubuntu 14 04 package the input consumer works and don think the input can have an impact but still any idea could only find one similar issue back in february 2014 on the logstash but no answer >>>bug needs_details needs_tests unconfirmed
fix for java map merge method conflict fixes logstash plugins logstash filter multiline 10 related to jruby issue jruby jruby 1249>>>blocker
remove the if branch the tests still passes when investigating this https github com logstash plugins logstash filter multiline issues 10 issue found out that we always set metadata to hash and it cant be nil the tests was actually checking if the metadata was empty >>>v1.5.0-rc3
using logstash we receive stat st dev error when reading from file hi whenever we re trying to read file in order to capture the log information we get the following error notimplementederror stat st dev unsupported or native support failed to load dev major at org jruby rubyfilestat java 188 we ve tried to execute several changes we ve found on the web but no success was obtained our test conf file is input stdin file path home borak correo prueba txt type log thanks in advance >>>unconfirmed
unable to parse json using json filter hello am trying to use the json filter but having some issues here is an example of the json am trying to parse and the filter is very basic right now as soon as turn this on start seeing the following in logstash log this is on logstash rc2>>>v1.5.0
new plugin date formatter based from https github com elastic logstash issues 2315 issuecomment 73651485 have created the following plugin that is ready for review https github com wiibaa logstash filter date formatter can you please have look and setup the repo in logstash plugins if ok for you related discussions 2315 2818 and https github com logstash plugins logstash filter date issues 10>>>needs_review new-plugin
plugin request azure application insights output it would be very nice to have an application insights azure microsoft com en us services application insights plugin that would allow people who run their service on microsoft azure to send their traces directly to application insights not care about the storage or anything else and leverage ai right away microsoft is providing ruby sdk https github com microsoft applicationinsights ruby which should make everything easier >>>new-plugin
fixes 2987 this ensures that add field fieldname true and add field fieldname false actually result in true boolean values fixes 2987>>>v1.5.0-rc3
windows rc2 error on shutdown when sincedb path nul using this config file on windows so that can easily test out filter this seems to work but when end the process logstash has an error and with debug >>>bug windows
check for plugins to be released hi one regular issue with the plugins test pipeline has been that we search for plugins in github while most of them are released to rubygems and perse usable some are not this pr search rubygems and make sure there is plugin with the name that can be installed >>>tests-infra
new plugin log4j2 input would like to contribute back the log4j2 input plugin to the logstash community it is available here https github com jurmous logstash log4j2 what would it take to get it in the logstash plugins >>>new-plugin
failing event spec on deserialized json input the new event spec introduced in 2997 talevy does not work with deserialized json input as exposed with new event spec strategy to test both normal hash and hash from deserialized json introduced in 2991 this need to be figured out >>>blocker v1.5.0
more instances of elasticsearch vs elastic some changes here too >>>docs
this merges in the changes from logstash docs see https github com elastic logstash docs pull 78 fixes 3011>>>docs
doc merge back in changes from logstash docs the edit url tags bits need to be here >>>docs
better filter documentation the documentation for the various filters should include better documentation including before and after examples that clearly illustrate the transform >>>docs needs_details
simplify or eliminate boilerplate code plugins need to load jars each plugin that has to load jars needs to have jars rb` file with the fixed block of code this amount of code should not be necessary we should reduce this to liner executed during `register` or `initialize` or even detect the presence of jars automatically >>>enhancement
logstash heap size exceeds default memory cap of 500m rc2 the standard heap size is set to max of `500m` it seems that this is not enough in our environment since logstash keeps dying often mostly without logs sometimes the following event can be found in var log logstash logstash err` know that maximum of 20 events are stored in the pipeline for each phase input filter output but why does the heap still grow to more than `500m` which heap size should be used in production environment any hints for debugging why logstash service keeps dying we are using the following plugins inputs exec lumberjack tcp pipe filters multiline grok mutate drop mutiline date json outputs es thanks sven>>>blocker bug v1.5.2
updates to keep inline with logstash docs this change is almost exclusively 80 column formatting to make reading easier on smaller screens in include pluginbody asciidoc the changes are to use the macros in logstash docs rather than our own local ones >>>docs
doc update to ensure edit links point to correct repository this is in conjunction with https github com elastic docs issues 5>>>docs
logstash can not be restarted ve encountered this problem times now over the course of month brand new install of logstash 5rc2 on ubuntu 14 04 will get into state where can not stop or restart the process installed with chef using community cookbooks when attempting to restart logstash it timesout and says got term also asking stackoverflow for help in identifying the problem http unix stackexchange com questions 195998 how to identify why process wont die >>>bug
add java collection delete support with specs more java integration specs this solves 2261 >>>blocker
new plugins neo4j input and output just created two new plugins to manage graph data with logstash https github com purbon logstash input neo4j https github com purbon logstash output neo4j the input basically read events regularly from neo4j database and create events out of it it can be used in order to important graph data throw logstash on the other hand there is the neo4j output that is able to write time based index in neo4j coming from ls it would be great to have them review by the community and know if they are good >>>new-plugin
logstash beta issue with filter message exception in filterworker exception backtrace org jruby rubystring java 1159 in ruby filter code in `register org jruby rubyarray java 1613 in `each ruby filter code in `register org jruby rubyproc java 271 in `call opt logstash vendor bundle jruby gems logstash filter ruby lib logstash filters ruby rb 38 in `filter eval 5875 in `initialize org jruby rubyarray java 1613 in `each org jruby rubyenumerable java 805 in `flat map eval 5871 in `initialize org jruby rubyarray java 1613 in `each org jruby rubyenumerable java 805 in `flat map eval 5868 in `initialize org jruby rubyarray java 1613 in `each org jruby rubyenumerable java 805 in `flat map eval 5858 in `initialize org jruby rubyproc java 271 in `call opt logstash lib logstash pipeline rb 268 in `filter opt logstash lib logstash pipeline rb 206 in `filterworker opt logstash lib logstash pipeline rb 150 in `start filters level error this is an error when ran logstash for filtering when occur error logstash doesn skip this error to pass another it stop filtering and need restart>>>needs_details
lost message in multiline codec every time run the multiline codec always lost line of file it happened previously with the multiline filter but have test it and seems to work right because need to increase the workers am using the multiline codec is there something like the issue with the filter am using the 5rc2 logstash>>>needs_details
doc change repositories to package repositories this is back porting change already in logstash docs>>>docs
add the idea of jar manager to handle jar dependencies in 2937 and 2954 we discussed the idea to build jar manager in order to change the way we re loading the jar dependencies within our code base this pr add the concept of jar manager responsible of finding and loading jars as dependencies collaterally this pr also removed the load elasticsearch jars method as it legacy code that was there from the early days when the es jars were shipped with ls and not in the plugins this new jar manager is in use in https github com logstash plugins logstash input log4j pull https github com logstash plugins logstash output elasticsearch pull 101 https github com logstash plugins logstash output elasticsearch ec2 pull https github com logstash plugins logstash input drupal dblog pull relates to 2974 for now it still need bit more test to be sure everything is working as expected >>>blocker enhancement reviewing
lack of settings for input and ouput for redis cluster when set an output to node in redis cluster redis it can not direct to other nodes in redis cluster automatically port 7000 to 7005 are used by redis cluster logstash logstash simple conf input stdin output redis host localhost 7000 data type list key key count stdout codec rubydebug logstash logs exception redis commanderror moved 15454 127 7002 supposed that it may be caused by logstash redis client role was not started in cluster mode >>>enhancement v2.0.0
bad mutate filter behavior due to nil type checking so have config in which am trying to rename delete fields which occasionally have nil values when rename field with the mutate filters rename parameter get new field but the event fails to remove the old field when use the remove field parameter it simply fails to remove the field event remove calls the del accessor the problem lies with the del accessor in logstash lib logstash util accessors rb here is the offending code unless target nil prevents me from deleting and properly renaming fields within logstash via mutate when the value of the field ie target is nil perhaps this check should be removed >>>bug v1.5.1
migrate logstash repository instructions to elastic co migrate http logstash net docs repositories to elastic co >>>docs
mutate filter lowercase and uppercase not working logstash rc2 adding mutate filter lowercase or uppercase in the config has no effect >>>bug
having references to git repo to install plugins in the gemfile is not working as in the process of having test suite that test all plugins vs the current master version and not with the last release in rubygems encountered with the need to use the git notation in the gemfile coming from clean env bootstrapping the env to then modify the gemfile to get one like link https gist github com purbon 614b02184ab4702731c2 and then running debug bin plugin install no verify to install the new plugins to check the output you can review https gist github com purbon 55bd782f682506250945 having no clear information about problems if then you aim to run rake test core the output getting is more env info git clones are download and reported under vendor bundle jruby bundler gems the error command change if you include gem plugin name before the ones that used git >>>bug
add namespaces to avoid configuration redundancy this is first of all feasibility question when working with the `couchdb changes` input plugin encountered that am going to have lot of redundant configuration parameters now am wondering if it was possible to develop an input plugin that allows for something call setup namespaces the idea is that it allows you to setup hash dictionary at the beginning of the input chain that you can merge in in later stages enough with the words here is the configuration format have in mind believe the reasons for something like this are quite obvious if not or if there is another mechanism to keep configurations dry please let me know >>>discuss enhancement
file input multiline filter file size limit and entity size limit background currently working on production implementation of logstash and elastic we are indexing data from sql server files are being published from sql server and we are using the file input to grab all the files to index into elastic we ran into bug where the last entry in the file gets dropped using the multiline filter looks like thats bug in logstash still being worked on https groups google com forum searchin logstash users multiline 20last logstash users syxigp8sstk hhtj6jeplksj questions since we are putting this into production getting lot of questions about size limits what is the limit on the file size that logstash can input what is the limit of each entity that is indexed google searches tell me 4096 is that correct anybody know the answers to these >>>question
is there library of logstash configuration examples really struggling with how to use logstash filters to format syslog input into reasonably index able output for elasticsearch to consume several of my colleagues and have spent many hours trying to understand how to configure logstash the available documentation is less than ideal and at times directly misleads the novice reader for example http logstash net docs filters date where it suggests filter date match logdate mmm dd yyyy hh mm ss says nothing about the fact that logdate must be an indexed field from grok stanza that syntax example makes you think logdate magically exists just like message magically exists have watched many of videos by jordan sissel searched the web asked on the irc channel http webchat freenode net channels logstash etc and still can figure out what good logstash configs look like what would be really helpful is to have library of example logstash configuration files knowledgeable users have created over time the files don need to be documented nor clean just directory filled with examples would be nice if the contributor wants to obfuscate some of the file names in inputs and output that would be fine but is unnecessary can help but believe that hundreds or thousands of different configuration files are out there that have been used some bad some good and some better my goal is to take raw syslog data of all sorts and enhance the data with labelled knowledge before inserting it into elasticsearch seems like pretty reasonable thing to do but turns out to be very hard to understand given the lack of examples ve got something working but can seem to extend it very well need to parse format hundreds of different record types have some of my own grok patterns created and thus can even use the grok debugger because can seem to extend the patterns available there logstash looks like great tool but the learning curve is really tough thanks ed>>>docs question
simple log file reader test produces sincdb write rename sync failed when running the logstash rc2 tar gz release candidate obtained from wget http download elastic co logstash logstash logstash rc2 tar gz on an x86 linux machine we get the following error when we ctrl out of the test program to end the program this test works on logstash version csigint received shutting down the pipeline level warn 	logstash shutdown completed sincedb write rename sync failed gsa yktgsa h1 00 ralphbel logstash test sincedb new gsa yktgsa h1 00 ralphbel logstash test sincedb permission denied gsa yktgsa h1 00 ralphbel logstash test sincedb new or gsa yktgsa h1 00 ralphbel logstash test sincedb level warn the script that produced follows bin bash simple log stash test wrapper thisdir `dirname 0` thisdir `readlink thisdir` set logstashdir home logstash rc2 bin logstashdir home logstash bin logstash scr tmp logstash test scr logstash data tmp logstash test data note sincedb has to have the end so the jruby stuff works correctly sincedb thisdir sincedb touch sincedb cat logstash scr eof input file path logstash data start position beginning sincedb path sincedb output stdout codec rubydebug eof cat logstash data eof mar 15 03 35 02 dccxcat run parts etc cron daily 89799 finished logrotate eof cat logstash scr set logstashdir logstash logstash scr set rm logstash scr rm logstash data java version information follows java version 45 openjdk runtime environment rhel el6 x86 64 u45 b15 openjdk 64 bit server vm build 24 45 b08 mixed mode ralphbel gasmaster logstash test >>>bug
having an invalid gem file in root of the folder breaks rake bootstrap on clean logstash clone >>>bug bundler needs_details
getting notimplementederror fstat unimplemented unsupported in logstash err hi writing input and output plugins for dropbox input https github com javifr logstash plugin input dropbox output https github com javifr logstash plugin output dropbox for now everything is working fine in my local machine but on my remote machine an elk installation of ubuntu in digital ocean according to this https www digitalocean com community tutorials how to install elasticsearch logstash and kibana on ubuntu 14 04 tutorial ve been able to install both plugins but once try to start the logstash service getting notimplementederror fstat in my var log logstash logstash err file and the service stops running my input conf file my filter conf file my output conf file my var log logstash logstash err think the error is coming from function in the output plugin that is trying to get the size of file file https github com javifr logstash plugin output dropbox blob master lib logstash outputs dropbox rb l233 some ideas on why is this happening may be need to install something on the machine in order to be able to size file >>>needs_details
elasticsearch input get parent field what is the way of getting parent field of document using elasticsearch input thanks>>>question
version rc3 snapshot1 bump first snapshot released for testing rc3 closes 2949>>>blocker
bundling jar dependencies with the main gem the way jar dependencies are managed through ruby maven and jar dependencies have had many issues so as noticed in https github com elastic logstash issues 2937 issuecomment 90608786 we aim to do to embeed the jars within the gem in other words we want to download the jars and package it at gem creation time and not at install time note this is actually meta issue to track the necessary changes in the different projects the list of plugins that might need to be changed are https github com logstash plugins logstash input log4j https github com logstash plugins logstash output elasticsearch https github com logstash plugins logstash output elasticsearch ec2 https github com logstash plugins logstash input drupal dblog others that are slightly related with this change as they use jars or have wrong unexpected dependencies https github com logstash plugins logstash input elasticsearch https github com logstash plugins logstash filter elasticsearch https github com logstash plugins logstash input jdbc an special deal goes with https github com logstash plugins logstash input kafka https github com logstash plugins logstash output kafka as they use internally jar dependencies this is wip list of plugins to be change so there might be new ones added but at the end we should be able to remove all references in devutils and the other projects of jar dependencies ruby maven etc this will help to provide fix to 2937 https github com logstash plugins logstash input log4j issues and help to build an offline installation package easy related issue 2376 >>>blocker bug enhancement v1.5.0
publish logstash core snapshot version as part of testing for 2928 we need to publish new version for logstash core gem lets publish snapshot version before we are ready for rc3 version the version should be rc3 snapshot>>>blocker
what is the best way to clean up the elasticsearch db have been searching for clean way other than curator to handle data retention for elasticsearch through logstash is curator the only way at the moment if so suggestion to maybe adding retention config field for elasticsearch plugin any help would be great >>>question
allow the installation of plugin from gem` refactor the plugin this plugin add the feature to install plugins from gem` file under the hood it will decompress and install the file in local directory and update the gemfile to point to that gem and execute `bundle install` to fetch the dependencies this pull request also add few refactors of the plugins manager classes into smaller functions also the backup logic was moved inside the gemfile classes my suite of local tests and my smoke test currently work with this branch fixes https github com elastic logstash issues 2779>>>blocker
rc2 output issue logstash json generatorerror cannot find serializer for class org jruby ruby object logstash json generatorerror cannot find serializer for class org jruby ruby object jruby dump at elk logstash rc2 lib logstash json rb 45 to json at elk logstash rc2 lib logstash event rb 152 encode at elk logstash rc2 vendor bundle jruby gems logsta sh codec json lib logstash codecs json rb 44 receive at elk logstash rc2 vendor bundle jruby gems logsta sh output kafka lib logstash outputs kafka rb 165 handle at elk logstash rc2 lib logstash outputs base rb 88 initialize at eval 28 call at org jruby rubyproc java 271 output at elk logstash rc2 lib logstash pipeline rb 279 outputworker at elk logstash rc2 lib logstash pipeline rb 235 start outputs at elk logstash rc2 lib logstash pipeline rb 163 33mudp listener died exception socketerror recvfrom name or service not known backtrace elk logstash rc2 vendor bundle jruby gems lo gstash input udp lib logstash inputs udp rb 79 in `udp listener elk logstash rc2 vendor bundle jruby gems logstash input udp lib lo gstash inputs udp rb 49 in `run elk logstash rc2 lib logstash pipel ine rb 174 in `inputworker elk logstash rc2 lib logstash pipeline 168 in `start input level warn 0m>>>bug v1.5.0
fix conditionals regression the performances modifications included in 2869 introduced bug in the conditionals this is proposed fix the problem is that any filter that generated extra events ex clone followed by conditionals the extra events would not be checked by the conditionals this pr generates new cond func for each conditional similar to the filter func which takes multiple events as input and returns multiple events these cond func are called from the filter func and within other cond func if the conditionals are nested did not do any performance tests for this obviously this will have performance penalty >>>blocker
java opts ls java opts parsing strategy from 2914 we discovered that the set of gc variables used where not really optimal for the logstash use case this pr aims to be place where we can solve this as enabling the ls java opts externally so the end user can set their own java opts when he will use another set of gc configurations more suitable for the ls use case the second option is still pending decent benchmark even some numbers has been gathered and the current ones seems not the best ones specially because we don have sudden spikes of gc needs our ygc is more important than the rest will use this pr to write down benchmarks before we decide to with set of configs do we move relates to 1763>>>enhancement
issues with different version name schemas between rubygems and maven moved from the logstash input log4j repo to here as is where it belongs got on step further having successfull bundle install by using specific logstash core gem version in the gemspec strongly suspect that ruby maven is having hard time because logstash core gem versioning does not follow maven convention for qualifier http docs oracle com middleware 1212 core maven maven version htm maven401 so for him none of the available version in rubygem https rubygems org gems logstash core are following the rule thus failing this should be fixed with release hopefully or if you do an rc3 please try naming it with dash rc3 as all versions with qualifier are older than the same version without qualifier release version thanks wiibaa for bringing this more details in the old issue https github com logstash plugins logstash input log4j issues it relates to https github com elastic logstash pull 2932>>>bug
sincedb write failed dev null new permission denied bin logstash logstash rc2 on shutdown ctrl on mac get this warning sigint received shutting down the pipeline level warn sincedb write failed dev null new permission denied dev null new level warn is this benign warning or have got something setup wrong thanks >>>bug v1.5.0
docs getting started page not correct on the getting started with logstash your docs say to run this bin logstash input stdin output stdout what missing is the agent in the command line besides that if you try and run bin logstash bat agent the help message is output the help clearly states that the default behaviour for is an empty string which should pipe stdin stdout if you run bin stdin output stdout in windows cmd shell then you re greeted with no such command usage logstash command args and in powershell bin stdin output stdout was unexpected at this time in cygwin with ruby sdk and debug tools installed bin logstash agent input stdin output stdout error unable to access jarfile cygdrive users rcoe logstash vendor jar jruby complete 11 jar and finally when run on an ubuntu 14 04lts openstack vm run the command and it seems to run but when type hello into another another console get nothing in the shell invoked the command from see screen shot logstash https cloud githubusercontent com assets 11742613 6949375 06a08b1e d882 11e4 8a05 3f5f13ca246c png in all cases am running java 31 b13 on windows and 40 b25 on unbuntu am running logstash am also importign the tabexpansion module in powershell but cmd doesn use that so not sure how to escape the so it gets through to the ruby interpreter also can find the monolithic jar that used to exist any thoughts seems pretty strange that nothing try will run this guessing it java but haven gone down the route of installing out of date versions thanks >>>docs
bump version rc3 this is to merge in the branch when ready to release rc3>>>blocker
logstash not parsing timestamp correctly yes know am playing with fire logstash v2 fresh pulled from git today 03 31 15 around 11am pst using configs that work in ls v1 failed with errors like these in ls v2 dev timestamp 2015 04 01t00 40 40 867000 0000 message unrecognized timestamp value setting current time to timestamp original in timestampfield value 1427848229276 level warn timestamp 2015 04 01t00 40 40 868000 0000 message failed parsing date from field field timestamp value 2015 04 01t00 40 40 866z exception level warn here is the json record that caused the above error mildly scrubbed header eventheader container node js environment ei3 eventtype eventversion guid zzzb2abf43421daaa2705a92ccefda7a instance 11 nano 276000000 server abc1 app1250 stg example com service tablet fe time 1427848229276 version fields level debug memberid requestid no rid osname no name osversion clientversion ts 2015 04 01t00 30 29 276z network null message lcache updating cache server host abc1 app1250 stg example com source tab fe tags timestamp 2015 04 01t00 40 40 867z version tags timestampparsefailure timestamp 1427848229276 type mob server logstash node abc1 app904 stg example com here is the filter filter date match timestamp unix remove field timestamp mutate remove field command rename host logstash node convert header eventheader guid string >>>bug
shutdown robustness and test tasks refactored test tasks and added robustness in shutdown handling and other thread safeties this issue also relates to logstash plugins logstash input tcp logstash plugins logstash input syslog logstash plugins logstash input generator logstash plugins logstash input file 21 logstash plugins logstash input gelf logstash plugins logstash input pipe logstash plugins logstash input redis logstash plugins logstash input relp logstash plugins logstash input heartbeat elastic logstash devutils 25>>>blocker
non gracefull way of handling closed indices had my indexers jam because of closed indices and logstash trying to insert stuff into them that caused that no logs was going to es during that time there should be way to either remove those logs or send them to file or anything that could work >>>enhancement resiliency
beginning guide for writings tests for our plugins we have really nicely written guide to write new plugins for logstash but they don cover how to write tests know writing tests is something we see really important as project and we should encourage people to write them but explaining testing isn easy since we are refactoring our tests suite and writing new helpers to help us the developer to tests against the pipeline we should take few time to write some documentation or best practices so everyone can improve their code and support people to add them in their pull request ref https github com elastic logstash issues 2915>>>docs
handle spaces in paths clone repo to logstash repo directory or any directory with path try to run anything in bin from outside the repo logstash repo bin plugin you get the following output dirname extra operand `repo bin plugin try `dirname help for more information logstash repo bin plugin line 16 bin logstash lib sh no such file or directory>>>packaging
xx useconcmarksweepgc java opts slows down logstash by 20 per 2859 we realized that using the xx useconcmarksweepgc` `java opts` slows down logstash by about 20 >>>enhancement v2.3.0
elasticsearch input filter needs to be able to limit queries to only the latest index it seems that the elasticsearch input is designed to pull all data from one cluster to be able to only search amount of minutes hours days from now would open up the possibility to use logstash to query log data stored in elasticsearch and either alert on them or create summary using the kibana index config you could specify index pattern like logstash yyyy mm dd then you config it to run every and then amount back most cases it would be the same value for example run every 10 minutes search from now to 10m with the query level error then using count of the returned value and conditionals that if this level is above then output to email another use case for this would be to create daily reports >>>needs_details
how do distinguish logs output and logstash diagnostic messages when using stdout plugin >>>enhancement
forwarding and multiline like to watch set of files path defined with wildcards on machine forward using logstash forwarder to machine process with logstash on machine all log files contain multiline messages which would like to join where is the right place to do it filter or an input codec on machine or want to do as little as possible of processing on if have one lumberjack input on and define multiline codec there am in danger of messages originating from different files on ending up in one multiline message on apologies but the documentation is note very clear on this >>>question
installing plugins from package so ve installed the logstash package on ubuntu using the repo here http logstash net docs repositories wondering how can install logstash plugins though figured navigating to opt logstash and doing the same sudo bin plugin install contrib would work however that gives me the following do need to download these plugins from somewhere is there another package none of this seems to be documented anywhere >>>question
windows event log error invoke of nextevent error on windows server 2012 r2 when try to use the `eventlog` input like so in my configuration file the log gets blasted with these errors this is one whole intact message judging from the code here the timeout is second https github com logstash plugins logstash input eventlog blob master lib logstash inputs eventlog rb l54 cannot figure out why this is timing out though another thing is that the log will just fill way up with these gigantic errors easily creating megs upon megs almost got up to gig of log data that is really redundant and unnecessary would almost expect the input to give up after it hits an error like this and log more concise error to the log for diagnostics >>>bug
path format error in file input result in cryptic exception no implicit conversion from nil to integer get the error only when running the etc init logstash but do not get this error when running it from the cli bin logstash config file is also at the bottom but since it works one way would imagine the file is correct timestamp 2015 03 25t23 29 51 406000 0400 message org jruby rubystring java 3690 in file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby pathname rb 48 in `chop basename file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby pathname rb 222 in `relative opt logstash lib logstash inputs file rb 85 in `register org jruby rubyarray java 1613 in `each opt logstash lib logstash inputs file rb 84 in `register opt logstash lib logstash pipeline rb 135 in `start inputs org jruby rubyarray java 1613 in `each opt logstash lib logstash pipeline rb 134 in `start inputs opt logstash lib logstash pipeline rb 72 in `run opt logstash lib logstash agent rb 139 in `execute opt logstash lib logstash runner rb 168 in `run org jruby rubyproc java 271 in `call opt logstash vendor bundle jruby gems stud 17 lib stud task rb 12 in `initialize file logstash agent rb line 151 timestamp 2015 03 25t23 36 20 078000 0400 message using milestone input plugin file this plugin should be stable but if you see strange behavior please let us know for more information on plugin milestones see http logstash net docs modified plugin milestones level warn timestamp 2015 03 25t23 36 20 444000 0400 message using milestone input plugin exec this plugin should be stable but if you see strange behavior please let us know for more information on plugin milestones see http logstash net docs modified plugin milestones level warn timestamp 2015 03 25t23 36 20 580000 0400 message using milestone output plugin redis this plugin should be stable but if you see strange behavior please let us know for more information on plugin milestones see http logstash net docs modified plugin milestones level warn timestamp 2015 03 25t23 36 22 675000 0400 message an unexpected error occurred this is probably bug you can find help with this problem in few places chat logstash irc channel on freenode irc irc via the web http goo gl ti4ro email logstash users googlegroups com bug system https logstash jira com nthe error reported is no implicit conversion from nil to integer config file root rftwawebp01 ls etc logstash conf sort while read line do cat etc logstash conf line done input file path opt ibm websphere appserver profiles hbc stg solr logs updateivtappforprofile log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs wc dataimport buildindex log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 bin stagingprop log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 instances hbc solr httplogs access act log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 instances hbc solr httplogs error act log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 instances hbc stg httplogs trace log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 instances hbc stg logs createinstanceant log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 instances hbc stg logs sdo log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 logs acpload log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 logs config ant log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg getpath log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 logs config log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 logs stagingprop log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 logs wc dataimport buildindex log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 logs wc dataimport preprocess log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 logs wcnonroot log type stg wcs logs exclude gz input file path opt ibm websphere commerceserver70 logs wc seo url load log type stg wcs logs exclude gz input file path opt ibm websphere plugins logs solrwebserver http plugin log type stg wcs logs exclude gz input file path opt ibm websphere plugins logs webserver1 http plugin log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg hamanager config log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg importconfigarchive log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg keygeneration log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg setsecurity log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg sibdefinechains log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg sibgenericdeployras log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr amjrte config log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr collect metadata log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr copyfiles log type stg wcs logs exclude gz input file path opt ibmihs logs access log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr create log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr createshortcutforprofile log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr generateprofilekey log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr getpath log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr hamanager config log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr importconfigarchive log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr keygeneration log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr setsecurity log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr sibdefinechains log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr sibgenericdeployras log type stg wcs logs exclude gz input file path opt ibmihs logs error log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg solr wsadminlistener log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg wsadminlistener log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles listprofiles log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles validateregistry log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs modifycloudscapepermission log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs product startmenu log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs update updateconfigcim log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs update updateconfig log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs update updateperftemplate log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs wc dataimport buildindex log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs executeupdateprofileivtapp log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs activity log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs addnode log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs backupconfig log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs ffdc nodeagent exception log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs ffdc prstghbcserver1 exception log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs iscinstall log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs nodeagent native stderr log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs nodeagent native stdout log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs nodeagent startserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs nodeagent stopserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg amjrte config log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs nodeagent systemerr log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs nodeagent systemout 15 03 22 22 28 52 log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs nodeagent systemout log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 native stderr log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 native stdout log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 out log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 serverstatus log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 ssl log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 startserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 stopserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg collect metadata log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 stopserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 systemerr log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 systemout log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 trace2 log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs prstghbcserver1 trace log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs removenode log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs server1 native stderr log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs server1 native stdout log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs server1 serverstatus log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs server1 startserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg copyfiles log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs server1 stopserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs server1 systemerr log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs server1 systemout log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs serverstatus log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs syncnode log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs update76692 log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg logs wc dataimport buildindex log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs activity log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs addnode log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs ffdc solrserver exception log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg create log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs hbc stg solr startserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs iscinstall log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs nodeagent native stderr log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs nodeagent native stdout log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs nodeagent startserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs nodeagent stopserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs nodeagent systemerr log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs nodeagent systemout log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs removenode log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs solrserver native stderr log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg createshortcutforprofile log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs solrserver native stdout log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs solrserver startserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs solrserver stopserver log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs solrserver systemerr log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs solrserver systemout log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs solrserver trace app log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs solrserver trace d1 log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs solrserver trace log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs syncnode log type stg wcs logs exclude gz input file path opt ibm websphere appserver profiles hbc stg solr logs update76692 log type stg wcs logs exclude gz input file path opt ibm websphere appserver logs manageprofiles hbc stg generateprofilekey log type stg wcs logs exclude gz input exec command echo heartbeat interval 1800 type heartbeat tags heartbeat input exec command ps user pid ppid pcpu pmem time vsz rss args interval 300 type os stats tags ps codec line input exec command usr bin sar interval 300 type os stats tags sar codec line filter grok match path greedydata greedydata filename if filename trace log or filename systemout log or filename systemerr log or filename native stderr log multiline pattern negate true what previous grok break on match false match message syslog5424sd message syslog5424sd javaclass message syslog5424sd javaclass grok break on match false match message lat long add tag longlat if lat mutate rename latitude geoip location lat longitude geoip location lon mutate add field geoip location long mutate merge tmplat into location merge geoip location lat mutate convert our new array of strings back to float convert geoip location float add tag geoip else if filename hudsonbay log multiline pattern negate true what previous if host rftwwapp mutate add tag website else if host rftwwebp mutate add tag apache website else if host rftmappp mutate add tag mobile mutate add tag apache mobile else if host rftwawebp01 mutate add tag stage mutate add tag apache staging else if host rftwaappp01 mutate add tag stage filter if path access grok match message commonapachelog data referrer data agent data domain data true client ip data jsessionid data was data cached response data redirect if path http plugin log grok match message serversetfailoverstatus server data node pendingrequests failedrequests affinityrequests totalrequests message stats ws server group servergroupcheckserverstatus checking status of data node ignoreweights markeddown retrynow retryinsec wlballows reachedmaxconnectionslimit if ps in tags grok match ps user pid ppid pcpu pmem time vsz rss args message data uid number pid int number ppid int number pcpu float number pmem float notspace time number vsz int number rss int data cmd filter if sar in tags grok match sar 17 47 35 cpu user nice system iowait steal idle 17 42 26 all 01 18 01 00 00 88 80 message time sartime data average data rowtype number pctuser float number pctnice float number pctsystem float number pctiowait float number pctsteal float number pctidle float output if debugme in tags stdout codec rubydebug redis batch true boolean optional default false batch events 50 number optional default 50 batch timeout 60 number optional default codec plain codec optional default plain congestion interval number optional default congestion threshold number optional default data type list string one of list channel optional db number optional default host xxxxxxxx array optional default 127 key dsg string optional password password optional port number optional default 6379 reconnect interval number optional default shuffle hosts boolean optional default true timeout number optional default workers number optional default >>>enhancement needs_details v1.5.0
program is not recognized error when running rc2 on windows my folder structure looks something like this my `java home` is `c program files java jdk1 31` when try to run with this command things work as want but if try to run rc2 get the following error >>>bug windows
populate lookup table on the fly we use logstash to collect web trafic logs among other things our application produces two kinds of logs the trafic logs contain an application id and an user readable application name and the other logs only refer to the application id the app id isn persistent mean that if we restart the server the app id changes as we use kibana to produce dashboards we would like to add field to the non trafic logs containing the application name not only the application id it would be easy if the application ids were persistent using the translate filter however as they often change we need to build lookup table on the fly from application mappings found in the trafic logs do you think it possible maybe with custom ruby code >>>enhancement
add configcheck to init and make sure to check config before trying to start using the deb package 5rc2 when using service to start logstash it will tell you that it started correctly if you have an invalid configuration java did logstash started but exited immediately because the config is invalid so this patch add an option to check the config and it also makes sure to check the config before starting only tested logstash sysv >>>enhancement packaging
installing plugins that have already been installed currently if you install plugin that has already been installed it will return the following as if it is actually installing something the first time certainly plugin update` is the way to go for updating installed plugins it may be nice though to have different message when someone attempts to use plugin install` to update the plugin maybe something along the lines of plugin name is already installed if you are updating the plugin please use the plugin update plugin name` command instead >>>enhancement plugin_manager
vs kafka output performance regression am creating this issue here so we can better track it for the release process if we conclude that this is in fact plugin only regression then we ll move it to the proper logstash kafka repo we got reports of performance drop with the kafka output between logstash and rc2 the user reported using the logstash kafka plugins with logstash was in fact able to reproduce with logstash logstash kafka https github com joekiller logstash kafka archive v0 tar gz kafka https archive apache org dist kafka kafka tgz jruby kafka https rubygems org gems jruby kafka versions java vs logstash logstash kafka latest https rubygems org gems logstash kafka versions java with codec backport tweak remove sprinf jruby kafka latest https rubygems org gems jruby kafka versions java vs logstash fix perf regression branch logstash output kafka https rubygems org gems logstash output kafka versions using the following config using this command version rate 86mib 01 50 26 6kib 26 6kib 86mib 02 22 20 5kib 20 5kib 86mib 02 23 20 4kib 20 4kib we see that the regression actually occurs between version and in logstash joekiller talevy can you confirm this thoughts if we agree this regression is somewhere in the plugin we can move this issue in the proper repo >>>performance-regression
changes with grok matched fields in rc2 hello when testing `1 rc2` `grok` is now including unmatched typed subpatterns which it previously didn and believe it still shouldn using the same test configuration the additional empty `duration` field is added with `1 rc2` logstash bin logstash config testcase conf message test message test 24 8ms duration 24 rc2 logstash rc2 bin logstash config testcase conf message test duration message test 24 8ms duration 24 the following sample configuration was used as `testcase conf` it includes commented out approach for backward compatibility that we re able to use for the short term input generator lines test test 24 8ms count filter grok match message test base10num duration float ms backward compatible grok match message test base10num duration ms mutate convert duration float mutate remove field version timestamp host sequence output stdout codec json lines this issue affects us because we have conditionals relying on the presence of `duration` for later filter directives this is an unexpected change to us can find references to it in `changelog` or in existing issues referencing `grok` so assume it is some sort of bug appreciate confirmation about this assessment though to know if this is actually bug or if just missing something else thanks for your time >>>blocker bug v1.5.0
logstash rc2 stops after while processing we have about 300 events per second and while was working perfectly for weeks rc2 stops after an unpredictable time mostly some hours sometimes even less even fewer times longer like day have set logstash to verbose but there are no indicators in the err als log files how can help to track this down please advise when logstash is not processing any more no events in kibana its still in ram top pid user pr ni virt res shr cpu mem time command 27559 logstash 20 17 569g 782g 65136 15 225 48 94 java ps aux logstash 27559 122 15 18422824 1871384 pts sl 10 36 225 49 usr bin java djava io tmpdir var lib logstash xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xmx6g xss2048k djffi boot library path opt logstash vendor jruby lib jni djava io tmpdir var lib logstash xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xbootclasspath opt logstash vendor jruby lib jruby jar classpath djruby home opt logstash vendor jruby djruby lib opt logstash vendor jruby lib djruby script jruby djruby shell bin sh org jruby main opt logstash lib logstash runner rb agent etc logstash conf var log logstash logstash log verbose >>>bug needs_details
submitting an output for new relic insights hi logstash team ve written an output for logstash that sends events into new relic insights would like to know how to go about getting this output contributed to the logstash project output https github com sschwartzman logstash output newrelic new relic insights https docs newrelic com docs insights new relic insights understanding insights new relic insights thanks in advance seth>>>new-plugin
0rc2 file descriptors are leaked when using http is it really gone guys hi just posted on closed issue https github com elastic logstash issues 1604 it looks like there is still something wrong about the tcp input am afraid regards andrei>>>needs_details
logstash hangs with multiple sqs inputs logstash logstash seems stable with with single sqs input but hangs after short time if add two or more to my config there is nothing written to the logs when this occurs the cpu gets pegged at 100 and messages are no longer picked up from the sqs queue was told in passing by an engineer at elasticon that lowering the number of threads on the sqs input could help but that had no effect ve set threads as high as with single sqs input and things seemed stable the problem only seems to occur if add more than two sqs inputs one other configuration of note is that had to disable the sqs checksum validation in order to get around an issue there see issue 2190 should also note that am running two central logstash servers with this config have not yet tried this with logstash here is my logstash config input sqs region us west queue logstash app1 access key id myaccessid secret access key myaccesskey threads use ssl false sqs region us west queue logstash app2 access key id myaccessid secret access key myaccesskey threads use ssl false sqs region us west queue logstash app3 access key id myaccessid secret access key myaccesskey threads use ssl false sqs region us west queue logstash app4 access key id myaccessid secret access key myaccesskey threads use ssl false filter if type app1 or app2 or app3 or app4 mutate gsub message grok match message timestamp iso8601 timestamp loglevel level int line greedydata msg add tag grokked date match timestamp iso8601 remove field timestamp add tag dated output elasticsearch cluster es metrics host localhost workers document id uuid >>>bug
docs installing latest plugins available in rubygems on installing plugins available on rubygems org in ls is not straightforward we should make this easier for example see https github com joekiller logstash kafka rubygems logstash kafka install on logstash 142 >>>docs enhancement
file input windows stops acceppting new files hi am using file input with logstash 5rc2 under windows to watch directory of xml logs our app is writing to the file system 20 to approx 1000k per xml file the files are written by our app after the request has been processed and never changed again logstash is picking up the file parses its filename and its multiline content and sends it off to elasticsearch for indexing parsing indexing of couple of files works fine however after couple of files have been processed file input all of sudden stops picking up any more files when try to shutdown logstash get lots and lots of sincedb write rename synch failed error messages just an example sincedb write rename sync failed level warn 0m sincedb write rename sync failed level warn sincedb write rename sync failed level warn sincedb write rename sync failed level warn 0m sincedb write rename sync failed level warn 0m any idea what is going wrong here >>>bug v1.5.0 windows
how to figure out what charset to use received an event that has different character encoding than you configured text u0000 u0005 u0000 u00005 xc0 u0012 u0000 expected charset utf level warn if receive this warning and unable to get the text how do figure out what to set the charset to codec plain charset iso 8859 all my machines are running ubuntu>>>enhancement
remove deprecation notices when output workers when workers is set to new plugin instances are created using params hash that contains both the user specified config parameters and the default ones this causes deprecation notices to be printed even though the user never specified deprecated config setting thus new workers should be created using only the original set of config parameters fixes 2865>>>reviewing
why manual installation failed this is the installation log >>>bug
refactor filter plugin filter method contract to improve performance simplify pipeline worker flow and prepare for bulk events processing the filter plugin `filter` method should be refactored to accept an event list and return the resulting events list instead of yielding new events to the passed block this yielding strategy adds unnecessary closure invokations which only serves the purpose of aggregating resulting new event relates to 2869 2870 >>>enhancement
logstash 5rc2 fails to stop if redis input is used when use redis as input it fails to stop using service logstash stop which sends kill term pid when debugging here is what get when sending sigterm to the process not started with service and it waits forever doing nothing can send more sigterm and more of those appear on the screen additionally noticed the following few lines above when it was logging and don know if it related or not here is the first config file know it could be simplified and some stuff in there do not make much sense but was testing logstash and that the config had when the bug happened and you can reproduce the bug every single time with this config here is the second config file another side note is that it seems that the redis plugin only works for the first few minutes just changed lines in the configuration file for redis from the package install on ubuntu 14 04 lts 64 bit let me know if you need the redis config file >>>bug v1.5.0
performance regressions this is master issue to track performance regression and proposed fixes will add measurements between rc2 and the fixes in 2869 relates to 2859 >>>blocker discuss performance-regression v1.5.0
performance regression fixes performance fixes to the pipeline and filters and output code generation this is also the `fix perf regression` share branch https github com elastic logstash tree fix perf regression >>>blocker enhancement performance-regression v1.5.0 work_in_progress
apache common log format bytes should be int in experimenting with kibana tried to do histogram using the mean value of the apache combined log bytes value however got this error classcastexception org elasticsearch index fielddata plain pagedbytesindexfielddata cannot be cast to org elasticsearch index fielddata indexnumericfielddata further searching reveals that perhaps this field should be cast to an int or should add filter to copy this value to say bytes int and then build the histogram on that >>>enhancement
unexpected log output from logstash in 5rc2 the relevant logstash config the unexpected and suspicious log output for unused deprecated elasticsearch settings >>>bug
docs make it easy to provide doc fixes from elastic co reference doc generation in logstash today uses an intermediate repository https github com elastic logstash docs this is used to consolidate all the generated docs from plugins and the static docs from this repo it is then converted from asciidoc to html and pushed to elastic co reference there is an icon to directly edit the docs but it points to the logstash docs repo and frustrates the user we need to make this better see https github com elastic logstash docs pull 66 issuecomment 83341750>>>docs v2.0.0
wrong shutdown event object handling in plugins while working on performance issues discovered what is probably the source of the pipeline shutdown stalling regression in we ve been seeing the plugins are checking for logstash shutdown that is initialized as the shutdown` symbol while the pipeline pushes `logstash shutdownevent new` so the plugins never see the shutdown event the fix is currently in this commit https github com elastic logstash commit c07368cc25d977bbda9fe0d7b2c41e0608a414f4 which is part of the fix perf regression shared branch https github com elastic logstash tree fix perf regression once we merge that branch we ll have to release new logstash core version >>>blocker v1.5.0
simple pipeline config is slower on 5rc2 than config get 220kb throughput on and 140kb on when measuring using `pv` tool>>>performance-regression v1.5.0
is it possible to configure logstash stop parsing logs under certain conditions hi guys is there any chance to allow logstash stop parsing specific log when it reaches eof my application might generate gb of logs so would like to remove them once those are parsed if it is not possible it would be great to have this feature in future version thanks alessio>>>enhancement
artifact acceptance test fails intermittently building remotely on ubuntu 14 64 metal metal pool in workspace home jenkins workspace logstash zip acceptance logstash zip acceptance bin bash tmp hudson7772960963634781229 sh 2015 03 19 02 12 29 url https s3 eu west amazonaws com build eu elasticsearch org logstash nightly jdk7 logstash latest snapshot zip 96174045 96174045 logstash latest snapshot zip timestamp 2015 03 19t02 12 40 871000 0100 message could not start tcp server address in use host port 2000 level error the error reported is address already in use bind address already in use tmp hudson7772960963634781229 sh line 38 kill 5981 no such process port test failed build step execute shell marked build as failure>>>bug tests-infra
reconnection threshold ability to configure how many times to try reconnection currently it tries forever and if the app is writing logs to network socket brings down the app this way logstash receiver can die and not bring down the app >>>missing_cla
create automated release acceptance test we need jenkins job that verifies the release artifacts and it needs to have more coverage than our existing package acceptance tests this should have tests for plugin cli file inputs and test the existence of jars vendor directories etc test plan `bin logstash version` list current version `bin logstash` with json input and check if parsing is successful `bin plugin list` should list all plugins installed by default assert the count currently 103 `bin plugin list verbose` should list version info assert for stdin plugin `bin plugin list stdin` should list logstash input stdin `bin plugin uninstall logstash input stdin` should uninstall check for exit code `bin plugin uninstall localgem` should uninstall check for exit code `bin plugin list stdin` should not list plugin `bin plugin install logstash input wmi` `bin plugin list verbose wmi` should show current version assert after getting from rubygems api `bin plugin update` mass update install locally built gem `bin plugin install no verify` `bin plugin update` try mass update after installing local gem test es integration with geo grok and useragent filter with apache logs send 50 apache logs and check exact fields after doing search on es do this test on node http and transport protocol kafka input output test bring up kafka send events through logstash producer and receive through logstash consumer talevy has the scripts for these file input test follow test file with known number of events and assert if the events are received test `start position beginning and also test tailing option file input test follow test file with known number of events and assert if the events are received test test tailing option check for bundled jars `find name jar wc l` should be 155 add `http proxy` test for installing plugins this should be run on all supported platforms >>>tests-infra
add proxy support for jar dependencies from the discussion in this issue https github com elastic logstash issues 2557 jar dependencies does not work with http proxy environment variable and needs code change this existed before in beta1 and needs to be reinstated >>>bug v1.5.0
regression syntax error with if on multiple lines just tried rc2 and got syntax error with my configuration file worked fine in here is the culprit block from the configuration file `filter` section workaround put all or conditions on the same line >>>bug v1.5.1
logstash randomly stops sending access log events to elasticsearch hi guys since few days ago ve noticed weird issue with logstash we re using it with the file input for java app running on tomcat we have few custom logfiles configured that have worked fine for months but we recently added tomcat access log with file input and it randomly fails there are no errors in the logfiles as far as can tell but have noticed that removing the sincedb file for the access log temporarily resolves the problem we re using logrotate with the copytruncate option to rotate the logs but the issue doesn seem to be linked to the log rotation any ideas what could be going wrong >>>needs_details
logstash stalled blocked 0rc2 hello devs have been facing persistent issue ve been seeing logstash receivers stalling regularly every 15min the process will stop receiving input and all threads look blocked the process never recovers logstash inputs become in closed wait status and the process is rendered useless from my understanding of the event pipeline if the output may become busy the pipeline can get blocked but will recover in this case it doesnt recover setup details 20 logstash forwarders logstash receivers performing multiline redis logstash indexers performing filters elasticsearch redis often elasticsearch is indexing around 9k sec total thread dump from one of the blocked processes can be found here wasn sure how to attach txt file www outtalimits com au jstack out after alot of reading this issue looks potentially related https github com elastic logstash issues 2130 let me know if you require any further debugging info >>>needs_details pipeline-stalls
how to warn user on input ouput not supporting codec there are several plugins like http output or file output that do not use codecs but the configuration allows user to define it but having an open issue is not enough visibility for users should method similar to `workers not supported` be added to the base rb class ad called from the register method of the plugins lacking codec support or do you see another way >>>enhancement
delete batch files from deb and rpm packages noticed on my linux system when using the package that it is also installing bat files for windows along with the bash scripts to run the script here is patch that should take care of removing them before building the package untested >>>bug packaging
lumberjack protocol seems to strip fields doing some kind of log collector using logstash not the forwarder since we won collect logs from files and forwarding all the logs to central location for analysis am using logstash 5rc2 from the debian package on ubuntu 14 04 lts 64 bit on both sides here is the configuration of the log collector this is test system hence why it only has single input and here is one log message get from that output log file and we can see that it is parsed correctly and the location field has been added on the other side on the central system fields from that log entry are stripped here is the config from that central system based on discussion had on irc in logstash it sounds like lumberjack stripping all those fields is bug >>>bug
logstash deb package fails to uninstall it happened on one system only and it was happened every single time it was uninstalled using apt get remove logstash wasn able to reproduce the issue on another install that was test system ubuntu server 14 04 lts with logstash elasticsearch and kibana so it has been wiped now however you might be able to figure out where it fails based on the error message >>>needs_details
clarify default protocol for es output plugin in the beginning paragraphs of http www elastic co guide en logstash current plugins outputs elasticsearch html plugins outputs elasticsearch we specify that `node` is the default protocol with the default protocol setting node this plugin will join your elasticsearch cluster as client node so it will show up in elasticsearchs cluster status but later on in the `protocol` section http www elastic co guide en logstash current plugins outputs elasticsearch html plugins outputs elasticsearch protocol it gets more fuzzy it specifies that there is no default value for the setting protocol value can be any of node transport http there is no default value for this setting and then there is this statement the default protocol setting under java jruby is node the default protocol on non java rubies is http since es output plugin is jruby implementation the default in this case will be node it seems like we don actually need the jruby vs non java rubies statement here maybe change there is no default value for this setting to specify the default to be node and remove the statement on jruby vs non java rubies >>>enhancement
add classpath flag option to logstash agent for custom java class loading motives custom serializer classes in kafka plugins and any other custom java libraries needed for future plugins that provide options for specifying custom java classes example >>>enhancement reviewing
new plugin logstash input mongodb ve create an input plugin for mongodb and would like to contribute it to the plugin repository it currently fits my needs and working with couple of interested parties that found my plugin on github to make it usable for them and ideally anyone else that would want to move log data or any data from mongodb through logstash like for it to be reviewed in it current state and to gather input will begin to write tests for it shortly also curious about the use of jruby which the jdbc sqlite3 gem requires does logstash always run on jruby or should bother making this run in any ruby repo https github com phutchins logstash input mongodb>>>adoptme needs_review new-plugin
update documentation etc for the company name change main task is to change links and email addresses from elasticsearch org elastic co the name mentioned in copyright doesn change don think kevinkluge can you confirm todo items update logstash plugins org repos to reflect new elastic co` contact info add appropriate elastic co` emails for gem owners so we can `gem push >>>bug v1.5.0-rc3
logstash filter units plugin hi ve created new filter for logstash and would like to contribute it to the logstash plugins organization it is called logstash filter units https github com thenewflesh logstash filter units it performs unit conversions on specified fields thanks al>>>needs_review new-plugin
performance comparison beta1 and rc2 we have been running logstash beta1 for while now with very good indexing rates compared to today have tried the rc2 version and it seems get an indexing rate drop by approx the test system is identical input to the indexers is redis plugin the redis queue is full to allow max indexing rates the output is elasticsearch as filters use xml date grok mutate use filterworkers and outputworker and two parallel processes each process has heap of 13gb mem java version 2015 03 16 13 03 01 logstash comp https cloud githubusercontent com assets 1506610 6666044 ac6cb1ac cbe0 11e4 9d81 fadabd1ad028 png the picture shows the indexing rate where first run rc2 and then beta1 any ideas what is going on can remember that the indexing rates at the time of were about the same as rc2 now >>>bug performance-regression v1.5.0
test coverage going down dramatically recently as you can see in the screenshot test coverage has gone down lot recently we should keep an eye what is happening here screen shot 2015 03 13 at 10 59 59 https cloud githubusercontent com assets 68540 6644401 aef5550e c970 11e4 8a3a a5388f5bd7f2 png >>>bug tests-infra
issues in specifying path of indexer file in logstash command tried to specify path to the indexer file location when running the logstash bat command the problem is that the path contains space and when try to run logstash get an exception that no such command found so far have tried the following commands and none of them work program files logstash bin logstash bat agent latest configs logstash indexer conf program files logstash bin logstash bat agent latest configs logstash indexer conf program files logstash bin logstash bat agent latest configs logstash indexer conf program files logstash bin logstash bat agent latest configs logstash indexer conf everytime get an error like no such command as configs or configs defs not defined at this point >>>windows
logstash 2225 replace chroot with su another attempt at fixing logstash 2225 by using su rather than chroot the environment is properly set up home user logname shell and the group set primarily this allows adding the logstash user to the groups it may need to gain access to log files >>>missing_cla
performance drop since v1 ve developed logstash plugin to filter data using java code performance of this plugin reduced by 30 since logstash v1 what might be the reason >>>performance-regression windows
remove the elasticsearch http plugins we have deprecated the `elasticsearch http` plugin in it was replaced with the elasticsearch output using the http protocol to do the deprecation we have created dummy plugin with the release we should remove this plugin the deprecation was done in https github com elasticsearch logstash issues 1757>>>breaking-compatibility v2.0.0
v1 rc2 keeps stopping on ubuntu 14 04 logstash v1 rc2 keeps stopping assume this is memory related issue because when manually edit etc init logstash and change ls heap size 500m to something else like ls heap size 5g it stays up however still stops answering and accepting connections after while all log files are clean cannot find the reason anywhere ve been running and previous versions on these machines for more than year now no issues please let me know what debug options should switch on to resolve this thanks >>>bug v1.5.0
service fails to stop v1 rc2 bash sudo service logstash stop killing logstash pid 10236 with sigterm waiting logstash pid 10236 to die waiting logstash pid 10236 to die waiting logstash pid 10236 to die waiting logstash pid 10236 to die waiting logstash pid 10236 to die logstash stop failed still running bash sudo opt logstash bin logstash agent version debug verbose logstash rc2 jruby 17 3p392 2014 12 09 fafd1a7 on openjdk 64 bit server vm 75 b13 jit linux amd64 java 75 oracle corporation jvm openjdk 64 bit server vm 24 75 b04 elasticsearch version build 3042293 2014 12 16t13 59 32z jvm 75 gem addressable gem atomic 99 gem avl tree gem awesome print gem json gem nokogiri gem aws sdk v1 61 gem aws sdk 61 gem thread safe gem descendants tracker gem ice nine 11 gem axiom types gem backports gem bindata gem buftok gem bundler gem cabin gem cinch gem clamp gem coderay gem coercible gem concurrent ruby gem edn gem multi json 11 gem elasticsearch api gem multipart post gem faraday gem elasticsearch transport gem elasticsearch gem equalizer gem ffi gem ffi rzmq gem minitar gem file dependencies gem filesize gem filewatch gem http parser rb gem ftw 42 gem gelf gem gelfd gem geoip gem gmetric gem hitimes gem http gem i18n gem jar dependencies gem jls grok 11 gem jls lumberjack 22 gem jrjackson gem jruby httpclient gem virtus gem maven tools gem ruby maven libs gem ruby maven gem jruby kafka gem jruby win32ole gem mime types gem method source gem slop gem spoon gem pry 10 gem rack gem rack protection gem tilt gem sinatra gem stud 19 gem polyglot gem treetop 15 gem logstash core rc2 gem logstash codec collectd gem logstash codec dots gem logstash codec edn gem logstash codec line gem logstash codec edn lines gem logstash codec es bulk gem msgpack jruby gem logstash codec fluent gem logstash codec graphite gem logstash codec json gem logstash codec json lines gem logstash codec msgpack gem logstash patterns core gem logstash codec multiline gem logstash codec netflow gem logstash codec oldlogstashjson gem logstash codec plain gem logstash codec rubydebug gem murmurhash3 gem logstash filter anonymize gem logstash filter checksum gem logstash filter clone gem logstash filter csv gem logstash input generator gem logstash output null gem logstash filter date gem logstash filter dns gem logstash filter drop gem logstash filter fingerprint gem logstash filter geoip gem logstash filter grok gem logstash filter json gem logstash filter kv gem metriks gem logstash filter metrics gem logstash filter mutate gem logstash filter multiline gem logstash filter ruby gem logstash filter sleep gem logstash filter split gem logstash filter syslog pri gem logstash filter throttle gem logstash filter urldecode gem user agent parser gem logstash filter useragent gem logstash filter uuid gem xml simple gem logstash filter xml gem logstash input couchdb changes gem logstash input elasticsearch gem logstash input eventlog gem logstash input exec gem logstash input file gem logstash input ganglia gem logstash input gelf gem logstash input tcp gem logstash input graphite gem mail gem logstash input imap gem logstash input irc gem logstash input kafka 11 gem logstash input log4j gem logstash input lumberjack gem logstash input pipe gem march hare gem logstash input rabbitmq gem redis gem logstash input redis gem logstash mixin aws gem logstash input s3 gem snmp gem logstash input snmptrap gem logstash input sqs gem logstash input stdin gem logstash input syslog gem memoizable gem naught gem simple oauth gem twitter 12 gem logstash input twitter gem logstash input udp gem logstash input unix gem xmpp4r gem logstash input xmpp gem logstash input zeromq gem tzinfo gem rufus scheduler 24 gem logstash output cloudwatch gem logstash output file gem logstash output csv gem manticore gem logstash output elasticsearch 18 gem logstash output email gem logstash output exec gem logstash output ganglia gem logstash output gelf gem logstash output graphite gem logstash output hipchat gem logstash output http gem logstash output irc gem logstash output juggernaut gem logstash output kafka gem logstash output lumberjack gem logstash output nagios gem logstash output nagios nsca gem logstash output opentsdb gem logstash output pagerduty gem logstash output pipe gem logstash output rabbitmq gem logstash output redis gem logstash output s3 gem logstash output sns gem logstash output sqs gem statsd ruby gem logstash output statsd gem logstash output stdout gem logstash output tcp gem logstash output udp gem logstash output xmpp gem logstash output zeromq bash sudo strace service logstash stop execve usr sbin service service logstash stop 21 vars brk 0x2419000 access etc ld so nohwcap ok enoent no such file or directory mmap null 8192 prot read prot write map private map anonymous 0x7f6c9e625000 access etc ld so preload ok enoent no such file or directory open etc ld so cache rdonly cloexec fstat st mode ifreg 0644 st size 35317 mmap null 35317 prot read map private 0x7f6c9e61c000 close access etc ld so nohwcap ok enoent no such file or directory open lib x86 64 linux gnu libc so rdonly cloexec read 177elf 200 30 832 832 fstat st mode ifreg 0755 st size 1811128 mmap null 3925176 prot read prot exec map private map denywrite 0x7f6c9e046000 mprotect 0x7f6c9e1fa000 2097152 prot none mmap 0x7f6c9e3fa000 24576 prot read prot write map private map fixed map denywrite 0x1b4000 0x7f6c9e3fa000 mmap 0x7f6c9e400000 17592 prot read prot write map private map fixed map anonymous 0x7f6c9e400000 close mmap null 4096 prot read prot write map private map anonymous 0x7f6c9e61b000 mmap null 4096 prot read prot write map private map anonymous 0x7f6c9e61a000 mmap null 4096 prot read prot write map private map anonymous 0x7f6c9e619000 arch prctl arch set fs 0x7f6c9e61a700 mprotect 0x7f6c9e3fa000 16384 prot read mprotect 0x619000 4096 prot read mprotect 0x7f6c9e627000 4096 prot read munmap 0x7f6c9e61c000 35317 getpid 22456 rt sigaction sigchld 0x40f100 rtmin rt sa restorer 0x7f6c9e07c150 null geteuid brk 0x2419000 brk 0x243a000 0x243a000 getppid 22455 getcwd home smueller 4096 15 open usr sbin service rdonly fcntl dupfd 10 10 close fcntl 10 setfd fd cloexec rt sigaction sigint null sig dfl rt sigaction sigint 0x40f100 rtmin rt sa restorer 0x7f6c9e07c150 null rt sigaction sigquit null sig dfl rt sigaction sigquit sig dfl rtmin rt sa restorer 0x7f6c9e07c150 null rt sigaction sigterm null sig dfl rt sigaction sigterm sig dfl rtmin rt sa restorer 0x7f6c9e07c150 null read 10 bin sh 8192 4768 pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7f6c9e61a9d0 22457 close read service 128 read 128 close wait4 wifexited wexitstatus null 22457 sigchld child exited rt sigreturn 0x11 22457 pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7f6c9e61a9d0 22458 close read service 128 read 128 close wait4 wifexited wexitstatus null 22458 sigchld child exited rt sigreturn 0x11 22458 chdir faccessat at fdcwd etc init logstash conf ok enoent no such file or directory geteuid stat etc init logstash st mode ifreg 0755 st size 3462 faccessat at fdcwd etc init logstash ok execve usr local sbin env env lang en us utf path usr local sbin usr local term xterm 256color etc init logstash stop 23 vars enoent no such file or directory execve usr local bin env env lang en us utf path usr local sbin usr local term xterm 256color etc init logstash stop 23 vars enoent no such file or directory execve usr sbin env env lang en us utf path usr local sbin usr local term xterm 256color etc init logstash stop 23 vars enoent no such file or directory execve usr bin env env lang en us utf path usr local sbin usr local term xterm 256color etc init logstash stop 23 vars brk 0x19ec000 access etc ld so nohwcap ok enoent no such file or directory mmap null 8192 prot read prot write map private map anonymous 0x7fa930e84000 access etc ld so preload ok enoent no such file or directory open etc ld so cache rdonly cloexec fstat st mode ifreg 0644 st size 35317 mmap null 35317 prot read map private 0x7fa930e7b000 close access etc ld so nohwcap ok enoent no such file or directory open lib x86 64 linux gnu libc so rdonly cloexec read 177elf 200 30 832 832 fstat st mode ifreg 0755 st size 1811128 mmap null 3925176 prot read prot exec map private map denywrite 0x7fa9308a5000 mprotect 0x7fa930a59000 2097152 prot none mmap 0x7fa930c59000 24576 prot read prot write map private map fixed map denywrite 0x1b4000 0x7fa930c59000 mmap 0x7fa930c5f000 17592 prot read prot write map private map fixed map anonymous 0x7fa930c5f000 close mmap null 4096 prot read prot write map private map anonymous 0x7fa930e7a000 mmap null 4096 prot read prot write map private map anonymous 0x7fa930e79000 mmap null 4096 prot read prot write map private map anonymous 0x7fa930e78000 arch prctl arch set fs 0x7fa930e79700 mprotect 0x7fa930c59000 16384 prot read mprotect 0x605000 4096 prot read mprotect 0x7fa930e86000 4096 prot read munmap 0x7fa930e7b000 35317 brk 0x19ec000 brk 0x1a0d000 0x1a0d000 open usr lib locale locale archive rdonly cloexec fstat st mode ifreg 0644 st size 3165552 mmap null 3165552 prot read map private 0x7fa9305a0000 close execve etc init logstash etc init logstash stop vars brk 0x204a000 access etc ld so nohwcap ok enoent no such file or directory mmap null 8192 prot read prot write map private map anonymous 0x7fe707ea8000 access etc ld so preload ok enoent no such file or directory open etc ld so cache rdonly cloexec fstat st mode ifreg 0644 st size 35317 mmap null 35317 prot read map private 0x7fe707e9f000 close access etc ld so nohwcap ok enoent no such file or directory open lib x86 64 linux gnu libc so rdonly cloexec read 177elf 200 30 832 832 fstat st mode ifreg 0755 st size 1811128 mmap null 3925176 prot read prot exec map private map denywrite 0x7fe7078c9000 mprotect 0x7fe707a7d000 2097152 prot none mmap 0x7fe707c7d000 24576 prot read prot write map private map fixed map denywrite 0x1b4000 0x7fe707c7d000 mmap 0x7fe707c83000 17592 prot read prot write map private map fixed map anonymous 0x7fe707c83000 close mmap null 4096 prot read prot write map private map anonymous 0x7fe707e9e000 mmap null 4096 prot read prot write map private map anonymous 0x7fe707e9d000 mmap null 4096 prot read prot write map private map anonymous 0x7fe707e9c000 arch prctl arch set fs 0x7fe707e9d700 mprotect 0x7fe707c7d000 16384 prot read mprotect 0x619000 4096 prot read mprotect 0x7fe707eaa000 4096 prot read munmap 0x7fe707e9f000 35317 getpid 22456 rt sigaction sigchld 0x40f100 rtmin rt sa restorer 0x7fe7078ff150 null geteuid brk 0x204a000 brk 0x206b000 0x206b000 getppid 22455 getcwd 4096 open etc init logstash rdonly fcntl dupfd 10 10 close fcntl 10 setfd fd cloexec rt sigaction sigint null sig dfl rt sigaction sigint 0x40f100 rtmin rt sa restorer 0x7fe7078ff150 null rt sigaction sigquit null sig dfl rt sigaction sigquit sig dfl rtmin rt sa restorer 0x7fe7078ff150 null rt sigaction sigterm null sig dfl rt sigaction sigterm sig dfl rtmin rt sa restorer 0x7fe7078ff150 null read 10 bin sh init script for logs 8192 3462 pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22459 close read 128 read 128 close wait4 wifexited wexitstatus null 22459 sigchld child exited rt sigreturn 0x11 22459 faccessat at fdcwd etc default logstash ok open etc default logstash rdonly fcntl dupfd 10 11 close fcntl 11 setfd fd cloexec read 11 8192 779 read 11 8192 close 11 faccessat at fdcwd etc sysconfig logstash ok enoent no such file or directory stat var run logstash pid st mode ifreg 0644 st size pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22460 close read 21877 128 read 128 close wait4 wifexited wexitstatus null 22460 sigchld child exited rt sigreturn 0x11 22460 open dev null wronly creat trunc 0666 fcntl dupfd 10 11 close fcntl 11 setfd fd cloexec dup2 close open dev null wronly creat trunc 0666 fcntl dupfd 10 12 close fcntl 12 setfd fd cloexec dup2 close kill 21877 sig dup2 11 close 11 dup2 12 close 12 pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22461 close read 21877 128 read 128 close wait4 wifexited wexitstatus null 22461 sigchld child exited rt sigreturn 0x11 22461 write killing logstash pid 21877 wit 42killing logstash pid 21877 with sigterm 42 kill 21877 sigterm write waiting logstash pid 21877 to 39waiting logstash pid 21877 to die 39 stat var run logstash pid st mode ifreg 0644 st size pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22463 close read 21877 128 read 128 close wait4 wifexited wexitstatus null 22463 sigchld child exited rt sigreturn 0x11 22463 open dev null wronly creat trunc 0666 fcntl dupfd 10 11 close fcntl 11 setfd fd cloexec dup2 close open dev null wronly creat trunc 0666 fcntl dupfd 10 12 close fcntl 12 setfd fd cloexec dup2 close kill 21877 sig dup2 11 close 11 dup2 12 close 12 stat sbin sleep 0x7fffea40fae0 enoent no such file or directory stat usr sbin sleep 0x7fffea40fae0 enoent no such file or directory stat bin sleep st mode ifreg 0755 st size 27024 clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22464 wait4 wifexited wexitstatus null 22464 sigchld child exited rt sigreturn 0x11 22464 write waiting logstash pid 21877 to 39waiting logstash pid 21877 to die 39 stat var run logstash pid st mode ifreg 0644 st size pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22477 close read 21877 128 read 128 close wait4 wifexited wexitstatus null 22477 sigchld child exited rt sigreturn 0x11 22477 open dev null wronly creat trunc 0666 fcntl dupfd 10 11 close fcntl 11 setfd fd cloexec dup2 close open dev null wronly creat trunc 0666 fcntl dupfd 10 12 close fcntl 12 setfd fd cloexec dup2 close kill 21877 sig dup2 11 close 11 dup2 12 close 12 clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22478 wait4 wifexited wexitstatus null 22478 sigchld child exited rt sigreturn 0x11 22478 write waiting logstash pid 21877 to 39waiting logstash pid 21877 to die 39 stat var run logstash pid st mode ifreg 0644 st size pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22567 close read 21877 128 read 128 close wait4 wifexited wexitstatus null 22567 sigchld child exited rt sigreturn 0x11 22567 open dev null wronly creat trunc 0666 fcntl dupfd 10 11 close fcntl 11 setfd fd cloexec dup2 close open dev null wronly creat trunc 0666 fcntl dupfd 10 12 close fcntl 12 setfd fd cloexec dup2 close kill 21877 sig dup2 11 close 11 dup2 12 close 12 clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22568 wait4 wifexited wexitstatus null 22568 sigchld child exited rt sigreturn 0x11 22568 write waiting logstash pid 21877 to 39waiting logstash pid 21877 to die 39 stat var run logstash pid st mode ifreg 0644 st size pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22625 close read 21877 128 read 128 close wait4 wifexited wexitstatus null 22625 sigchld child exited rt sigreturn 0x11 22625 open dev null wronly creat trunc 0666 fcntl dupfd 10 11 close fcntl 11 setfd fd cloexec dup2 close open dev null wronly creat trunc 0666 fcntl dupfd 10 12 close fcntl 12 setfd fd cloexec dup2 close kill 21877 sig dup2 11 close 11 dup2 12 close 12 clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22626 wait4 wifexited wexitstatus null 22626 sigchld child exited rt sigreturn 0x11 22626 write waiting logstash pid 21877 to 39waiting logstash pid 21877 to die 39 stat var run logstash pid st mode ifreg 0644 st size pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22702 close read 21877 128 read 128 close wait4 wifexited wexitstatus null 22702 sigchld child exited rt sigreturn 0x11 22702 open dev null wronly creat trunc 0666 fcntl dupfd 10 11 close fcntl 11 setfd fd cloexec dup2 close open dev null wronly creat trunc 0666 fcntl dupfd 10 12 close fcntl 12 setfd fd cloexec dup2 close kill 21877 sig dup2 11 close 11 dup2 12 close 12 clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22703 wait4 wifexited wexitstatus null 22703 sigchld child exited rt sigreturn 0x11 22703 stat var run logstash pid st mode ifreg 0644 st size pipe clone child stack flags clone child cleartid clone child settid sigchld child tidptr 0x7fe707e9d9d0 22749 close read 21877 128 read 128 close wait4 wifexited wexitstatus null 22749 sigchld child exited rt sigreturn 0x11 22749 open dev null wronly creat trunc 0666 fcntl dupfd 10 11 close fcntl 11 setfd fd cloexec dup2 close open dev null wronly creat trunc 0666 fcntl dupfd 10 12 close fcntl 12 setfd fd cloexec dup2 close kill 21877 sig dup2 11 close 11 dup2 12 close 12 write logstash stop failed still runn 37logstash stop failed still running 37 exit group >>>bug v1.5.0
logstash benchmark the latest changelog says where can find this benchmark >>>tests-infra
logstash package acceptance is false positive http build eu 00 elasticsearch org view ls 201 job logstash package acceptance is currently green it shouldn be green at minimum because of 2780>>>tests-infra v1.5.0
error starting logstash 0rc1 with elasticsearch output node and transport currently experimenting with an elk stack so this may be user error have setup elasticsearch and logstash in docker containers with very basic configuration when using logstash everything is working fine my current configuration is split into files in directory file file empty file when startup logstash get the java version on both boxes >>>blocker bug v1.5.0
support installing local plugins gem files info https gist github com tebriel f58980f662ca17dc2ded this gemfile worked in beta1 but not rc1>>>blocker bundler v1.5.0
permissions issue on the bundler config` this was reported by electrical on hipchat install logstash from any packages this is done as root start logstash as root this will create bundle config` with root permission start logstash as logstash user this will fail because it will try to write to the `bundler config` and the user doesn have the right permission possible fix might be this pr https github com elasticsearch logstash pull 2701 to have stateless bundler this pr wasn extensively tested >>>bug v1.5.0
generated packages include spec files generated packages currently still include the spec directory should not need those >>>discuss
jenkins regression tests fail periodically while pushing packages to s3 publish artifacts to s3 bucket bucket build eu elasticsearch org logstash nightly jdk7 file logstash rc1 all deb region eu west upload from slave false managed false error failed to upload files java io ioexception put destination bucketname build eu elasticsearch org objectname logstash nightly jdk7 logstash rc1 all deb com amazonaws amazonclientexception encountered an exception and couldn reset the stream to retry at hudson plugins s3 s3profile upload s3profile java 140 at hudson plugins s3 s3bucketpublisher perform s3bucketpublisher java 174 at hudson tasks buildstepmonitor perform buildstepmonitor java 32 at hudson model abstractbuild abstractbuildexecution perform abstractbuild java 770 at hudson model abstractbuild abstractbuildexecution performallbuildsteps abstractbuild java 734 at hudson model build buildexecution post2 build java 183 at hudson model abstractbuild abstractbuildexecution post abstractbuild java 683 at hudson model run execute run java 1784 >>>tests-infra
add jenkins jobs to use the plugins master branch right now if we want to do an integration testing we need to publish the plugins we should add job that use the master branch of each plugins for testing >>>v1.5.0
jenkins create all plugins tests for master we have test for published plugins but we also need to create one for tip of the master add task to install the gems with `gem test install all master` add task to install the gems with `gem test install default master` create task `rake test plugins master` to use the checked repository >>>tests-infra
jenkins green even if there are failures in all plugins tests http build eu 00 elasticsearch org view ls 201 job logstash all plugins test 222 console >>>blocker tests-infra v1.5.0
password value` not working first mentioned in https github com logstash plugins logstash output redis issues the password value` statement should show the plain text stored in password` but is instead showing new password class >>>blocker bug v1.5.0-rc1
escape tilde in doc tilde in conditional operator was not rendering since it wasn escaped per asciidoc syntax>>>docs
jar dependencies not working with gemfile having plugin references with the way we handle dependencies right now and the way jar dependencies expect us to work having gemfile with plugins on it like does not work when having files that depend on jar dependencies or also with files that might have also file dependencies this problems arises when we do rake artifact tar but also if with gemfile like the previous one you run rake bootstrap after some thoughts we think it is because the jar dependency is not properly installed and activated before we get into installing the plugin that need it this is why with gemfile without plugins and then executing rake install plugin default works solution to have this fix would be have jar dependencies loaded and activated before we get into installing the plugins related to 2757>>>bug bundler v1.5.0
error building tar and zip file tried building artifacts on does not work this is seen in our jenkins too and issue 2756 >>>blocker bug v1.5.0-rc1
problems when running the all plugins test when running the all plugins test in jenkins it shows this error having shown up beforehand some other errors related to jars fetching >>>blocker bug v1.5.0-rc1
refactored all gem bundler code into logstash bundler rb and moved patches into logstash patches>>>enhancement
gemfile and lock with default plugins `gemfile` and `gemfile jruby lock` with fixes 2733 >>>blocker v1.5.0-rc1
bin logstash rspec does not work without adding development dependencies in logstash user was able to run bin logstash rspec without running any other command but in logstash end user need to add development dependencies to run that command if you re into logstash and aim to run the test you should keep in mind to run the bin plugin install development before you can run the tests logstash should inform the user properly then trying to run the tests without having the dependencies or might be throw the readme >>>docs enhancement v1.5.0
logstash running on linux ppc64 crashes on startup when run logstash on linux ppc64 machine as follows it crashes with searching the web we find that the suggested solution is to point the java io tmpdir to something other than tmp the assumption being that tmp was mounted noexec as follows doing that produced the exact same error we are running rhel6 on power ppc74 machine has log stash been demonstrated to work on this combination of distribution operating system and architecture >>>bug v1.5.1
error with running artifact tar task plugin install default installing default plugins installing logstash output zeromq logstash codec collectd logstash output xmpp logstash codec dots logstash codec edn logstash codec edn lines logstash codec fluent logstash codec es bulk logstash codec graphite logstash codec json logstash codec json lines logstash codec line logstash codec msgpack logstash codec multiline logstash codec netflow logstash codec oldlogstashjson logstash codec plain logstash codec rubydebug logstash filter anonymize logstash filter checksum logstash filter clone logstash filter csv logstash filter date logstash filter dns logstash filter drop logstash filter fingerprint logstash filter geoip logstash filter grok logstash filter json logstash filter kv logstash filter metrics logstash filter multiline logstash filter mutate logstash filter ruby logstash filter sleep logstash filter split logstash filter syslog pri logstash filter throttle logstash filter urldecode logstash filter useragent logstash filter uuid logstash filter xml logstash input couchdb changes logstash input elasticsearch logstash input eventlog logstash input exec logstash input file logstash input ganglia logstash input gelf logstash input generator logstash input graphite logstash input imap logstash input irc logstash input kafka logstash input log4j logstash input lumberjack logstash input pipe logstash input rabbitmq logstash input redis logstash input s3 logstash input snmptrap logstash input sqs logstash input stdin logstash input syslog logstash input tcp logstash input twitter logstash input udp logstash input unix logstash input xmpp logstash input zeromq logstash output cloudwatch logstash output csv logstash output elasticsearch logstash output email logstash output exec logstash output file logstash output ganglia logstash output gelf logstash output graphite logstash output hipchat logstash output http logstash output irc logstash output juggernaut logstash output kafka logstash output lumberjack logstash output nagios logstash output nagios nsca logstash output null logstash output opentsdb logstash output pagerduty logstash output pipe logstash output rabbitmq logstash output redis logstash output s3 logstash output sns logstash output sqs logstash output statsd logstash output stdout logstash output tcp logstash output udp installation successful errno ebadf bad file descriptor bad file descriptor rewind at org jruby rubyio java 1886 save at home jenkins workspace logstash regression 15 jdk jdk7 label metal pool lib logstash gemfile rb 32 close at home jenkins workspace logstash regression 15 jdk jdk7 label metal pool lib logstash gemfile rb 62 execute at home jenkins workspace logstash regression 15 jdk jdk7 label metal pool lib logstash pluginmanager install rb 90 run at home jenkins workspace logstash regression 15 jdk jdk7 label metal pool vendor bundle jruby gems clamp lib clamp command rb 67 execute at home jenkins workspace logstash regression 15 jdk jdk7 label metal pool vendor bundle jruby gems clamp lib clamp subcommand execution rb 11 run at home jenkins workspace logstash regression 15 jdk jdk7 label metal pool vendor bundle jruby gems clamp lib clamp command rb 67 run at home jenkins workspace logstash regression 15 jdk jdk7 label metal pool vendor bundle jruby gems clamp lib clamp command rb 132 root at home jenkins workspace logstash regression 15 jdk jdk7 label metal pool lib logstash pluginmanager rb 12 rake aborted home jenkins workspace logstash regression 15 jdk jdk7 label metal pool rakelib plugin rake in `install plugins home jenkins workspace logstash regression 15 jdk jdk7 label metal pool rakelib plugin rake 27 in root org jruby rubyproc java 271 in `call org jruby rubyarray java 1613 in `each org jruby rubyarray java 1613 in `each org jruby rubyarray java 1613 in `each org jruby rubyarray java 1613 in `each org jruby rubykernel java 1087 in `load tasks top artifact tar artifact prepare plugin install default see full trace by running task with trace invoking bundler install your gemfile lists the gem logstash devutils more than once you should probably keep only one of them while it not problem now it could cause errors if you change the version of just one of them later >>>bug v1.5.0
list updated plugins upon completion of bin plugin update fixes 2625 with this the new behaviour is any local plugin gem can be updated not just the one in the gemfile so any plugin showing in `bin plugin list` can be updated all updated plugins will display if the update process triggers the installation of new plugin it will show otherwise if nothing gets installed or updated it will show >>>enhancement v1.5.0-rc1
use warn level instead of error level when plugin is using the milestone method in the plugin uses `warn` instead of `error` when plugin is using defining version with the milestone method >>>v1.5.0-rc1
fix failing package acceptance tests>>>tests-infra v1.5.0-rc1
gemfile gemfile jruby lock for rc1 should contain default plugins make sure rc1 branch tag contains gemfile gemfile jruby lock with all packaged plugins this is really important to be able to recreate the package with the correct plugins versions originally included in the released package >>>blocker v1.5.0-rc1
mass update all plugins with rc1 version of logstash core dependent on https github com elasticsearch logstash issues 2709>>>blocker v1.5.0-rc1
bundler interface to the user hi as we re now modeling our plugin behaviour versus bundler we should decide how do we want to handle the interaction with it for now we re following the same notation as the one in bundler settings with things like the without option used to exclude groups would like us to think if we like negated apis or positive ones bundler is also having some positive interface for example the one used by bundler setup when activating groups in my case always found more nice to express what want and not what don want as you never know what can he not being excluded http www rubydoc info github carlhuda bundler bundler settings https github com bundler bundler blob master lib bundler rb l114 looking forward to know what do you think on that >>>design enhancement question
possible to install different version of the same plugin the plugin manager does not take into account then version when installing plugin making possible to end up with version and of the same plugin installed the expected behaviour for me would be to keep the latest installed version of the plugin example in my opinion the semantics of the commands can be confusing because in this case we ve two version of the same plugin installed running the last one but no command to tell that guess bundler will remove for us many of the possible dependency issues but we might still want to keep our dependencies clean >>>bug bundler design discuss enhancement
development dependencies not properly installed by the ci helper scripts hi found that this set of commands miss the development dependencies from logstash they are installed but not available at runtime this is regression bug as this set of commands where working as expected since last friday trying to scope when the problem was introduced might be related with 2631 explanation for 2718 >>>blocker bug bundler v1.5.0-rc1
duplicate events when using and cr before output parentesis abonuccelli w530 opt elk test logstash bin logstash input stdin filter output stdout codec rubydebug oneevent message oneevent version timestamp 2015 03 02t09 53 35 873z host w530 abonuccelli w530 opt elk test logstash bin logstash input stdin filter output stdout codec rubydebug onevent message onevent version timestamp 2015 03 02t09 53 48 442z host w530 message onevent version timestamp 2015 03 02t09 53 48 442z host w530 >>>bug
geoip filter errors using rpm build of logstash after installing version via rpm using both my build and suyograo the geoip filter did not run and logstash exited looks like an issue with ls not being able to find the maxmind db file to recreate on fresh rhel7 install also fedora21 and centos7 smoke test will run successfully but using the geoip filter fails the error using debug` which indicates this is failing https github com logstash plugins logstash filter geoip blob master lib logstash filters geoip rb l66>>>blocker v1.5.0-rc1
fix failing jenkins tests http build eu 00 elasticsearch org job logstash regression 15 jdk jdk7 label metal pool 180 consolefull >>>tests-infra v1.5.0-rc1
unable to run rake test install all on mac stacktrace >>>blocker v1.5.0
release package does not work from outside of the installed directory installed the deb package which was created from another machine on to clean machine but with going inside the directory and running it from there it works >>>blocker bug v1.5.0-rc1
release the rc1 version of logstash core gem when we are ready for rc1 we need to release the latest logstash core gem and mass update plugins>>>blocker v1.5.0-rc1
allow prune to remove nil values allow to easily and dynamically remove nil values remove all fields containing nil 	prune blacklist values nil >>>enhancement
test not having deterministic behaviour there are some test like in the input file or input gelf that fail randomly because the test conditions are not deterministic example from input gelf >>>bug tests-infra
logstash core working as an standalone gem hi during some tests and fix of our beloved jenkins encounter with the requirement by some gems aka the filter grok to use the patterns directory and this raised question do we want the logstash core gem to work as an standalone gem mean if someone require the logstash core gem for example plugin is he expected to have directories like the patterns one or are the artifacts delivered with logstash the ones who are supposed to have them my take is more on the side of allowing logstash core to work as an standalone gem so including the patterns directory on it but probably making sure to have this directory on the root of the importing project and not in the gemset path what do you think is the best way to go >>>discuss enhancement v1.5.0
fix call update clean colinsurprenant bin plugin update abc doesn leave an older version installed >>>v1.5.0
make bundler to never save `bundler config` make sure our logstash application is stateless and doesn write on disk the bundler configuration >>>bug v1.5.1
packaged install fails to run with bundler invalidoption running logstash with rpm install from master fails with the following this was introduced with commit 647042c3f924b09e2310fb37f60cf45060070371>>>blocker bug v1.5.0-rc1
logstash beta1 version bump to beta2 easy and simple as this >>>v1.5.0
locally installed plugins do not show in bin plugin list after adding my plugin to the logstash gemfile and installing it do not see it listed when calling `bin plugin list` but can still use it and it has been installed correctly >>>bundler v1.5.0-rc1
update readme with the right rake task to setup development environment using the `rake bootstrap` command doesn correctly setup development environment updating the doc with the new `rake test install core` fixes https github com elasticsearch logstash issues 2688>>>v1.5.0
bin plugin uninstall fails from fresh rpm install which was built from master run bin plugin uninstall get the following generic error just use hipchat as an example this occurs for all the others too extremely verbose `debug true` output http pastebin com qvlp73gg >>>blocker bundler v1.5.0-rc1
rake test broken after running `rake bootstrap` off master then try to run `rake test` and get the following here is the full trace >>>docs v1.5.0-rc1
minor error in getting started docs http logstash net docs tutorials getting started with logstash there small error the text contains but its easy enough to watch both the access log and the error log actually any file matching log and right below in the code block the configuration from the code block would only match logs ending with log with an underscore and not log like the text suggests bit further down in the text as well and other random files which end with log >>>docs
always set bundle without fixes 2681 relates to 2674 >>>blocker v1.5.0-rc1
verify rubygems versions before monkeypatching fixes 2675 relates to 2556 2664 >>>blocker v1.5.0-rc1
use en dash instead of hyphen in license between years english grammar states that an en dash should be used not hyphen between two years examples of each em dash en dash hyphen em dash an em dash is typically used as stand in for comma or parenthesis to separate out phrasesor even just wordin sentence for various reasons an appositive examples where an em dash should be used school is based on the three rsreading writing and rithmetic against all odds petethe unluckiest man alivewon the lottery sense something presence ve not felt since en dash an en dash is used to connect values in range or that are related good rule is to use it when you re expressing to relationship examples where an en dash should be used in years 19391945 pages 3132 may be relevant new york beat los angeles 9895 when american english would use an em dash following british and canadian conventions hyphen hyphen is used to join words in compound construction or separate syllables of word like during line break or self evidently hyphenated name pro american cruelty free eggs em dash it pronounced hos pi tal it tee olivia newton john>>>v1.5.0
bundler gemfilenotfound thrown when bin logstash isn run from logstash root directory if you invoke logstash outside the root directory which it resides either from source or when installed you get the following result if `cd` into tmp logstash` where have master checked out and then run the command it works fine the problem is that https github com elasticsearch logstash blob 9561ade0353c4f12b3ba39edfd43a1d75e1a7748 lib logstash environment rb l91 detects that logstash root bundle config` exists however there isn ever an entry for `bundle gemfile` so unless you are in `logstash root` bundler cannot find `gemfile` this can be fixed by moving `env bundle gemfile logstash environment gemfile path` outside the `unless` it hard for me to tell being unfamiliar with bundler as much where bundle gemfile would be written to the config file >>>blocker bundler v1.5.0-rc1
make sure we expand the path to make dir glob work on windows if we provide relative file like hello irb main 005 dir glob test conf irb main 006 dir glob file expand path test conf users administrator test conf >>>v1.5.0
logstash web debian init script fails install logstash on ubuntu 12 from debian packages try to start with etc init logstash web start` expected service starts actual `>>>v1.5.0-rc1
create logstash core gem that can be published simple change as this only the change from logstash gemspec to be using logstash core gemspec supersedes 2629 >>>v1.5.0
pin gem specification reset monkey patch to specific version of rubygems this monkey patch is modification of code from rubygems v2 we have seen that this monkey patch will not load and crash with on earlier versions of rubygems have seen it crash on v1 either we only load it after the environement is relauched under vendored jruby in which case we know the rubygems version and or we check for correct rubygems version before applying this problem has also been reported by hinnerk in 2664 and relates to 2556 >>>blocker v1.5.0-rc1
nameerror when installing plugins trying to install any plugin and getting the following error get the `error reading plugin file caused by nameerror` for any plugin try to install tips >>>bug v1.5.0-rc1
add logstash roadmap to logstash static docs chatted with suyograo and with clintongormley about next steps for adding the logstash roadmap to the guide modeled this file after the resiliency page it is separate book which should be built as single page it lives within the logstash static docs in its own folder to build locally run the command with toc single otherwise this is controlled in the conf yaml file after this pr is merged suyograo will take care of ensuring this is copied over to the elasticsearch logstash docs and we ll create pr against the elasticsearch docs repo to modify conf yaml which clintongormley will review and approve >>>v1.5.0
proper bundler environment updated file dependencies and logstash devutils 10 setup bundler env if there no bundle config`>>>blocker v1.5.0-rc1
revisit require calls in logstash core code devutils and plugins requiring of agent rb pipeline rb environment rb and other non core files like patches should be cleaned across the project questions what is the minimal require call needed to get logstash agent running what is the minimal require call needed to test plugins >>>discuss internal-cleanup
group patches and load after environment setup groups all patches under lib logstash patches and requires them at the bottom of the lib logstash environment rb file solves 2613 >>>enhancement reviewing v1.5.0
netflow codec and cannot find serializer for class issue use lastest logstash beta1 and elasticsearch have an issue when using netflow codec here my logstash config https gist github com tomarch d824d5781a725cf68a10 ve got an error when use elasticsearch or file output got error to send bulk of actions to elasticsearch server at localhost cannot find serializer for class org jruby rubyobject level error the complete error log for the elasticsearch output https gist github com tomarch 3f16b02100717681242d the stdout seems fine https gist github com tomarch dc3f0561b473d0542dcd >>>v1.5.0
ensure all strings pulled out of env are utf8 on windows strings assigned to logstash event fields must be utf and since most windows aren utf by default we must intercept all get operations and convert the strings to utf issue surfaces in logstash filter environment for example fixes https github com logstash plugins logstash filter environment issues 1>>>bug reviewing v1.5.0 windows
rspec test does not work in all plugins if you run the recommended commands to execute the tests in plugin they don work having an error that looks like or this error gets solved if you add gem rspec group development to your gemfile or spec add development dependency rspec to your plugin gemspec file all plugins are affected >>>blocker bug tests-infra v1.5.0-rc1
concurrent ruby dependency error was unable to run `bin logstash docgen` >>>blocker bug v1.5.0
first pass at cleaning out logstash web all internal references flags kibana vendor everything must go if it referenced kibana or logstash web it is deprecated and removed operators are standing by >>>v1.5.0
fix 2643 this addresses some configuration documentation issues raised in 2643 >>>v1.5.0
added changes to address 2658 first draft >>>v1.5.0
clarify the guidelines for accepting plugins in the how to write plugin guide we need to make it clear in the how to http www elasticsearch org guide en logstash current how to write logstash input plugin html what the guidelines are for accepting plugin source code into logstash plugins https github com logstash plugins repo moving to repo is not mandatory contributors can continue to keep the source code in their repo and host the plugins on rubygems org for others to consume guidelines tests this is must to get accepted we will help contributors write specs code quality must be reviewed by the community also we should list the benefits of moving the repo to logstash plugins automated tests infra docs generation etc>>>docs new-plugin v1.5.0
adding an unpublished plugin to logstash plugins breaks test install all example with the latest logstash output logentries plugin the workaround is adding the plugin to the skip list in `rakelib default plugins rake`>>>bug
fallback to local configuration if the parsing for remote relatives path on windows fails to pass the `uri parse` method as fix suggest we fallback to local configuration fixes https github com elasticsearch logstash issues 2504>>>v1.5.0
test and update plugins with the release of the logstash core gem before moving forward with the release of the logstash core gem we should test and update accordingly all plugins that goes with logstash this is actually blocker for tasks easy the transition from the current way of doing things to the new logstash core gem one test installation and run to see everything works as expected publish good logstash core gem for update the plugins used in testing making sure they work with both systems gemspec and logstash core test installation and run to see everything works as expected now with plugins using logstash core prepare for the update of all plugins to using the logstash core gem including readme and example plugins merge 2677 to master and taking care current plugins works still release logstash core gem for beta2 pending until we have working newer version update all plugins to require logstash core if everything works as expected close this issue this related to the pr 2677 >>>v1.5.0
some of the plugins have their vendored files in their gem currently the gem that requires vendored files doesn use the `file dependencies` plugin because have released version of the gem by mistake with the disabled install hook it doesnt impact the current rc1 because the gems with the vendored files already include the files see the `collectd` the `useragent` gem and the geoip gem >>>bug
remove unnecessary bundle directory from the artifact in release the bundle config has bundle path setting that can interfere by misleading the plugin manager into not seeing the vendor bundle path >>>blocker bug
refactor bat scripts>>>enhancement windows
bin plugin list raises an exception when there are no plugins installed simple there are no plugins installed message should be enough >>>bug v1.5.0
doc explain why conditionals and sprintf format cannot be used in inputs 2642 is only the most recent example of someone presuming that conditionals and sprintf format and field references can be used in an input block our documentation for these does not reflect this limitation and should be updated to explain this better >>>docs enhancement
running bin plugin list on newly unpacked release on windows fails generated new release of logstash with rake artifact tar and moved it to windows unpacked and ran this is because bundle config contains the bundle path used during the generation of the release fix proposal before generating the artifact modify bundle config to have relative path for bundle path edit alternative fix is to not include the bundle config file in the release>>>blocker bug windows
use shell scripts to setup in an easy way our ci jobs this is basically doing the same as in 2639 but for the bundler move branch copy here the description for the other pr so it stays as reference try in this change to wrap up some easy changes in the way we aim to run our ci jobs that will allow us to have an easiest way for everyone including jenkins to run the different test jobs for logstash add common non changing interface that developers and machines aka jenkins could rely not to change have way to document in code the necessary steps to setup and run the test suites for logstash if we apply this change sample jenkins configuration could end up being as simple as ci setup sh takes care of setting up all the general environment to run the logstash test ci test sh takes care of runnig the test this script accepts parameter that setup and run core or all plugins tests by doing this we could simplify the transition process for changes like 2634 as the naming changes would be scope under common interface >>>tests-infra v1.5.0
use shell scripts to setup in an easy way our ci jobs try in this change to wrap up some easy changes in the way we aim to run our ci jobs that will allow us to have an easiest way for everyone including jenkins to run the different test jobs for logstash add common non changing interface that developers and machines aka jenkins could rely not to change have way to document in code the necessary steps to setup and run the test suites for logstash if we apply this change sample jenkins configuration could end up being as simple as ci setup sh takes care of setting up all the general environment to run the logstash test ci test sh takes care of runnig the test this script accepts parameter that setup and run core or all plugins tests by doing this we could simplify the transition process for changes like 2634 as the naming changes would be scope under common interface >>>tests-infra v1.5.0
bundler move branch having two gemspec declarations while trying to apply the 2629 pr in the 2475 bundler refactor branch noticed something that raised question on me created two gemspec files there one for logstash and another for logstash core the first one has dependencies for the main project while the second one has core and testing dependencies in the 2475 codebase there is an explicit check for having only one gemspec declaration https github com elasticsearch logstash blob wip bundler move lib logstash gemfile rb l156 do we ve any especific reason for that why we can not have more than one thanks >>>bundler v1.5.0-rc1
update jenkins to latest rake tasks after the bundler refactor in 2475 as part of the major bundler refactoring effort we added new rake tasks the current jenkins jobs use the old way of testing so they need to be updated after the merge rake tasks to install default plugins and their dev dependencies to test them >>>blocker bug tests-infra v1.5.0-rc1
provide load balancing and high availability features to logstash cluster in 2632 we introduced the concept of logstash cluster longer term this provides us the ability to dynamically balance jobs on failure to different instance in the cluster currently if specific instance of logstash becomes unavailable it may result in an outage until the problem is resolved unless dedicated load balancer is in use similarly if one instance of logstash is under heavy load the user needs an external mechanism to monitor this and re balance the load in clustered deployment we have the option of automatically distributing the load between instances based on the latest state of the cluster tags in clustered setup we can also introduce concept of tags where each instance is marked with specific role for example we could tag certain instances to be only running grok filter this could also be used to run multiple pipelines on the same cluster tags can also help simplify large configuration shared by the cluster when an update is made we could only reload specific components of the pipeline failover and dynamic load balancing are advanced features of the logstash cluster and can be achieved by using the building blocks introduced in 2632 >>>enhancement manageability roadmap
add support for clustering logstash instances today each logstash instance is full pipeline inputs filters and outputs stages in large scale logstash deployments users run multiple instances of logstash in order to horizontally scale event processing this requires manual management of individual configuration files or custom 3rd party configuration automation tools such as puppet or chef we plan to introduce concept of logstash cluster where instances can be controlled as whole on cluster level instead of being separate parts this would entail the following features provide an option to centrally store logstash config which is shared across all the instances in the cluster this would be the single source of truth for all the instances provide apis to control the cluster dynamically to change configuration see 2612 provide apis to monitor instances at the cluster level see 2611 logstash can still be started in single instance non clustered mode file based configuration will continue to work clustering instances will also provide the necessary groundwork for potential long term enhancements like automatic load balancing failover running multiple pipelines and so on >>>enhancement manageability roadmap
bin plugin install development should be sticky currently after doing to install development dependencies if we do any other plugin installation like then the development dependencies are not available anymore and any rspec run will fail once `bin plugin install development` has been executed development dependencies should always be installed visible at least until `bin plugin install no development` is called >>>bundler enhancement
logstash core gem add an option to generate logstash core gem including some deduplication of dependencies so are most of them just loaded from the core fixes 2474>>>v1.5.0-rc1
use cabin for error logging in plugin manager per https github com elasticsearch logstash pull 2475 discussion r24647763 >>>bundler enhancement
dry the gemfile handling and make sure we close the file handlers there repeated code like related to 2475 >>>bundler enhancement
bin plugin update should list updated plugins upon completion it currently silently updates plugins but does not show what was or was not updated to support this we should gather the plugin specs prior and after the update compare and report >>>bundler enhancement v1.5.0-rc1
see if we can refactor reuse rubygems classes `lib logstash gemfile rb` has basic minimal `gemfile` parser tailored to our own needs maybe we could actually reuse rubygems code for this >>>bundler enhancement
refactor logstash bundler bundler arguments this method could benefit refactoring see 2475 discussion >>>bundler enhancement v1.5.0-rc1
add file locking to prevent concurrent access to gemfile from plugin manager in `lib logstash gemfile rb` per 2475 discussion>>>bundler enhancement
beta1 on aix fails with errno enoent enoent vendor bundle jruby gems activesupport lib i18n ve been using logstash on aix and hoping to get beta1 going but hitting the same problem others have reported on solaris freebsd bash bin logstash config basic conf errno enoent enoent home kafka logstash beta1 vendor bundle jruby gems activesupport lib i18n file at org jruby rubyfiletest java 131 contains requirable file at home kafka logstash beta1 vendor jruby lib ruby shared rubygems basic specification rb 46 any at org jruby rubyenumerable java 1473 contains requirable file at home kafka logstash beta1 vendor jruby lib ruby shared rubygems basic specification rb 46 any at org jruby rubyenumerable java 1473 contains requirable file at home kafka logstash beta1 vendor jruby lib ruby shared rubygems basic specification rb 44 find inactive by path at home kafka logstash beta1 vendor jruby lib ruby shared rubygems specification rb 898 find at org jruby rubyenumerable java 592 find inactive by path at home kafka logstash beta1 vendor jruby lib ruby shared rubygems specification rb 897 try activate at home kafka logstash beta1 vendor jruby lib ruby shared rubygems rb 183 require at home kafka logstash beta1 vendor jruby lib ruby shared rubygems core ext kernel require rb 132 load locale at home kafka logstash beta1 lib logstash environment rb 111 root at home kafka logstash beta1 lib logstash runner rb 10 using the latest ibm jdk which again seems fine with logstash bash java version java version java tm se runtime environment build pap6470 27sr2fp10 20141218 02 sr2 fp10 ibm j9 vm build jre aix ppc64 64 compressed references 20141215 227395 jit enabled aot enabled j9vm r27 java727 sr2 20141215 1631 b227395 jit tr r13 java 20141003 74587 07 gc r27 java727 sr2 20141215 1631 b227395 cmprss j9cl 20141215 227395 jcl 20141217 01 based on oracle jdk7u75 b12 ve read folks suggesting this isn logstash problem but rather jruby problem but since it seems to be cropping up on multiple platforms wondering if there will be logstash fix or at least blessed workaround for logstash jruby or not if folks using logstash can upgrade it seems like regression of sorts for logstash >>>needs_details
use i18n for new gemfile header this is post 2475 use i18n for header text locales en yml >>>bundler enhancement
move all patches in lib logstash patches isolate any monkey patches into special directory structure so we can more easily understand what patches we have enabled this is post 2475 issue >>>enhancement v1.5.0
provide apis to manage pipeline currently whenever logstash configuration needs to be modified you have to edit configuration file and restart the logstash process this process requires the user to either temporarily halt the pipeline or accept the fact that an interruption in processing will occur while file based configuration works well especially with puppet chef it becomes increasing difficult to deploy logstash instances we plan to add rest based logstash management api to make it easier to interact with logstash this will allow dynamic configuration updates without the need to restart the process to be clear at this time we are not looking to change the existing configuration syntax also file based configuration will continue to be supported important manageability functions for this end point are reload restarts paused pipeline instance with new config and instantiates all the plugins add add specific parts of the pipeline dynamically for example we may want to add file input to follow new file destroy sends shutdown signal to all plugins and eventually stops status include pipeline state list of plugins the config itself pause pauses the pipeline unpause resumes the paused pipeline when interacting with the manageability apis care should be taken to not drop in flight messages >>>enhancement manageability roadmap v3.0.0
provide apis to monitor pipeline today most logstash monitoring functions are accomplished by tailing logs or outputting debug messages users typically send specially tagged tracer events to check the health of the system these special events are also used to measure the latency of the pipeline this is definitely not straightforward and it becomes hard to administer large scale logstash cluster we plan to introduce logstash monitoring api endpoint which will provide visibility into the pipeline some important metrics are health number of events processed latency metrics average percentile etc size of the persistent queues 2606 number of errors success medium term we should provide plugin level granularity for example it would be great to know how long on average an event spends on grok filters geo ip filters etc this would help users drill in to the expensive parts of the pipeline care should be taken to make sure metrics collection do not add additional stress on the pipeline and affect the latency and throughput of the events >>>enhancement metrics roadmap v3.0.0
write rubocop to detect multiple behavior methods example such code is an obvious candidate for splitting into two methods one for each conditional block >>>ruby_style_guide
reliability improvements for message delivery logstash currently does not provide end to end delivery guarantees when plugin fails to process an event it does not signal to an earlier stage in the pipeline that an error has occurred also on successful message delivery there is no acknowledgement to previous stages in the longer term we plan to introduce optional mechanism for such notifications to give users an easier way to keep track events as the flow through the pipeline additionally these acks will provide complete event resiliency from source to destination when used with message brokers like apache kafka and rabbitmq for example we should track when an event enters logstash and ack only when it successfully reaches destination otherwise the message is replayed by the source >>>enhancement resiliency roadmap v2.0.0
random bad file descriptor on windows when installing all the plugins when you try to install the plugin you are getting those kind of errors when installing plugins that have some `jar dependencies` our retry block could leave some gems in an inconsistent state it tries to install the `logstash input kafka` and failed and in the next loop tried to install the next plugin if you look at the `bundle` folder the kafka plugin is installed without the gems stacktrace >>>bug bundler v1.5.0-rc1 windows
add general purpose dead letter queue to pipeline today when logstash cannot process an event due to an error it has two choices drop or retry if the condition is temporary the next stage in the pipeline is temporarily overloaded intermittent network failues retrying is good approach otherwise if the failure is permanent bad encoding elasticsearch mapping error retrying could cause an indefinite stall in processing by creating poison messages in this scenario dropping the event is preferred so we can unblock the pipeline as third option we plan to introduce dead letter queue dlq which can be used to store any event that was not successfully sent to its destination we can also shunt events which have the potential of bringing down the pipeline dlq could also receive events that abuse the grok filter runaway regular expressions which cause expensive backtracking failures in grok patterns date filters and so on having separate queue allows the administrator to examine these events and resolve problems later while keeping the streaming nature of the pipeline additionally dead letter queues also allows users to further process clean the events before resending to its original destination we plan to add an input plugin that can read from the dlq >>>enhancement resiliency roadmap v3.0.0
provide option to have variable size internal queues which are persisted as mentioned in 2605 logstash uses in memory bounded queues between pipeline stages input to filter filter to output to buffer events the size of the queue is restricted to 20 and is non configurable this works well in practice because provides efficient streaming of messages between stages to reduce overall latency not so large as to cause memory pressure and gc activity not so large that crashing would cause devastating loss of events by count see 2605 in logstash deployments which require high throughput and resiliency users typically deploy message brokers such as redis rabbitmq or apache kafka essentially this breaks the pipeline into two stages shipping stage the application will ship logs to local logstash instance without any filters this logstash instance will forward events to an external message broker to buffer them indexing filter stage second group of logstash instances will pull off the queue apply the filters and output to destinations like elasticsearch pager duty amazon s3 this helps cases when there is mismatch in cadence between the shipping and the relatively expensive processing stage the queue buffers events outside of the application machines and does not add back pressure to the source building on the work of persistent queues 1939 we plan to offer built in alternative to an external message broker by adding variable queueing option to logstash which is persisted to disk we will provide an option to remove the dependency on external queues this will make it operationally easier to deploy and maintain logstash instances we will provide apis to monitor and interact with the queues >>>enhancement resiliency roadmap
add queue persistence to make pipeline resilient to crashes and restarts currently logstash uses in memory bounded queues between pipeline stages input to filter filter to output to buffer events see documentation http www elasticsearch org guide en logstash current pipeline html fault tolerance for more information currently the size of the queue is fixed to 20 and is not configurable it is possible to lose any queued events if logstash is terminated unsafely to prevent event loss in these scenarios we plan to persist these queues to disk >>>enhancement resiliency roadmap v3.0.0
remove stale jenkins configuration files this pr remove stale jenkins configuration files guess used long time ago to create and manage jobs in the ci environment if still valid something that guess not as the configuration looks old this files should be delivered throw another repository more suited to the business of dealing with the ci env >>>v1.5.0
elasticsearch with logstash was wondering what is the reason of having elasticsearch in vendor jar when logstash works with elasticsearch this generated an error with kibana and had to replace it with elasticsearch to get kibana to work >>>question
map disappearing im using logstash elasticsearch and kibana4 this is my conf logstash file input stdin filter geoip source ip output elasticsearch host localhost when check the elasticsearch head plugin can see that the logs have indexed which are logs are now stored in the index logstash date and that index contains documents however cannot view these documents on kibana furthermore when create tile map and then choose the coordinates to be geoip location choose this field which exists which probably tells me that the logs are indexed properly because logstash had managed to create that field from the ip address and after hit apply the map disappears no points are returned not even map is this an issue with logstash kibana or elasticsearch what am doing wrong please note that have indexed from mongodb some logs into elasticsearch and successfully viewed them in kibana so maybe the problem is with logstash thank you >>>question
dry lib logstash util filetools rb and rakelib fetch rake once the `wip bundler move` branch is merged>>>bundler enhancement
monkey patch for bugs isn applied when testing plugin from its repo since https github com elasticsearch logstash pull 2507 loads the monkeypatches for bugs rb file in the runner rb when testing plugin spec file from its repo the runner is never loaded hence the patch isn applied proposal require the monkeypatch from pipeline rb event rb or plugin rb>>>bug v1.5.0-rc1
make sure we freeze ruby maven maven tools and jar dependencies version fix the maven gems to their latest known working version >>>v1.5.0
latest version of ruby maven makes the `bundle install` fails currently there is blocking issue with the latest version of `ruby maven` and installing jars dependencies if you are declaring gem in gemfile using the github option it will make the bundle install crash before upgrading this gem you need to test the version with any plugins that require jars related issue and the stracktrace in https github com logstash plugins logstash input kafka issues 21>>>bug bundler v1.5.0-rc1
grok overwrite not working for empty strings so when have this input input 2015 02 11t17 49 29z logspout dev ziservice asdf message is asdf if have this input 2015 02 11t17 49 29z logspout dev ziservice or this 2015 02 11t17 49 29z logspout dev ziservice the message is not or like displayed in http grokdebug herokuapp com >>>bug
mem leak in lumberjack input logstash beta1 hi am experiencing an increasing mem usage and thread count some info on setup 15 20 logstash forwarders connection directly to logstash the logstash has outputs elasticsearch and to redis and all run on the same server there is pic from jconsole https cloud githubusercontent com assets 10955247 6143899 2a57f198 b20b 11e4 9309 0e211fe92925 png the high majority of the threads are associated with lumberjack have the stacktrace from one of these threads also have threaddump from the whole process http www outtalimits com au stack http www outtalimits com au heap dmp 729m let me know if you need any more info on this cheers >>>bug
the fix copy paste error >>>v1.5.0
feature request setting up highly available ha pipeline with logstash nodes as kibana user watching transactional data would like to configure logstash pipeline with strong guarantees that events are not lost so that can use elk as forensic analysis tool in logstash the pipeline currently reads off connection and acks as soon as it made it into memory this is problem if the underlying software or the hardware were to fail while logstash is processing message some examples of software failure operating system stability codec stacktrace on edge case network outages on virtualised switches vm hypervisor failure scope this change will extend the life of an event in logstash extend the lumberjack input with needs ha option extend the elasticsearch output with provides ha option opt in both needs ha and provides ha should be opt in as it will likely have performance hit out of scope existing inputs and outputs plugins should still operate without code changes setting up clustering technologies to be highly available ha requirements the pipeline should only allow one ha output to simplify when an ack is ready to be sent the pipeline should allow one or more inputs to ack on delivery to an ha output outputs labeled provides ha should only write when all events have been processed from the input spooled batch input labeled needs ha should only ack spooled event batches when all events have been written to the ha output clients who have not received an ack should resend if disconnect happens before they re acked most clients which implement ack already do this events should be cancelled as soon as possible when an input disconnects to stop them writing to an output cancelled events from drop should not block other events being written acked cloned events should only ack on delivery of both messages to an ha output configuration example >>>discuss enhancement reviewing roadmap
issue using metric filter with if conditionals using logstash version the problem am seeing is when am trying to use the metric filter inside conditional if loop logstash doesnt seem to apply the metric filter however if there is no if loop and use the metric filter directly logstash recognises the filter my sample configs are as follows config not working grok and date filter are matched and can see the changes but not metric filter filter if type catalog logs grok match message xxxxxx ghas response as field metrics meter http shankcatalog response add tag metric date match time mm yy hh mm ss sss target timestamp working config filter grok match message xxxxxx has response as field metrics meter http catalog shanklatest response add tag metric date match time mm yy hh mm ss sss target timestamp >>>bug needs_details v1.5.0
rename message can you test this please to trigger jenkins build today we can manually trigger new jenkins build for commit using the message can you test this please this is confusing to the contributors reviewers we should qualify that this message is for jenkins something like jenkins retest or something on those lines >>>tests-infra
remove the message can one of the admins verify this patch don know what the reason for having this message is it is just confusing https github com elasticsearch logstash pull 2572 issuecomment 73779643>>>tests-infra
ungz was named incorrectly if your `vendor json` specifies file that is just gzipped such as `lcg json gz` then the file cannot be extracted properly because the function is misnamed example error https gist github com tebriel f8a15eb5e1250249b2ea>>>v1.5.0
error messages when no permission to read config file accidently made made config files not readable by the logstash user account this resulted in the following error messages timestamp 2015 02 10t20 07 58 723000 0000 message error expected one of input filter output at line column byte after file logstash agent rb line 140 timestamp 2015 02 10t20 07 58 744000 0000 message you may be interested in the configtest flag which you can nuse to validate logstash configuration before you choose nto rest art running system file logstash agent rb line 142 suggest that the system gives more descriptive error than the current one >>>enhancement
style preferences on usage of return proposal reject use of single explicit return if method uses multiple returns then all returns must be explicit example and the multiple return questions should we allow returns from conditional in the above case what is returned is not really obvious especially if have style that doesn have an `else` then the `if implicit return is nil >>>ruby_style_guide
require on method calls with arguments>>>ruby_style_guide
unconditional logger info and debug use rubocop to catch unconditional logger info and debug https github com elasticsearch logstash blob master lib logstash runner rb l13 l46>>>ruby_style_guide
do not accept the use of tempfile in the code use rubocop to detect the use of the tempfile>>>ruby_style_guide
install plugins message messing with bundler warning messaging problem hi if you install plugin it outputs the next message it would be great if we can hide somehow this bundler gemspec warnings they don really provide relevant message to the issue of installing the plugin here might be misleading for some people >>>bundler
exception in filterworker illegalaccessexception no such method every now and then when we restart logstash all our workers or just some of them die with the stacktrace below we re running admittedly with few patches from pull requests to fix issues on jdk 20 b26 as not that comfortable with or probably you testing it pasting our whole 1k loc config here are the basics input tcp filters date environment filter grep grok json metrics mutate throttle outputs exec elasticsearch graphite soap https github com stockholmuniversity logstash soap stacktrace >>>bug
testing individual plugins fails with homebrew jruby after cloning plugin repository and running jruby bundle install successfully >>>bug
bin plugin install is not working on fresh git clone steps `git clone logstash` `rake bootstrap` errors out `bundle install` succeeds am guessing this is related to `rake bootstrap` not working 2558 >>>blocker bug bundler v1.5.0-rc1
rake bootstrap does not work in bundler move branch `git clone logstash` `rake bootstrap` if this is the new workflow we should update the readme >>>blocker bug bundler v1.5.0-rc1
document http proxy support for installing plugins `bin plugin install` and other commands should be able to work when using http proxy we should simply document the standard way of using proxy support with rubygems org >>>bundler docs v1.5.0
warn unresolved specs during gem specification reset ffi filed upstream with rubygems https github com rubygems rubygems issues 1070>>>bundler enhancement
add code coverage to the all plugins jenkins job we now have jenkins job to install all plugins and run specs on them we should add code coverage for this run >>>tests-infra
doc plugins installed from beta1 are not recognised by the new bundler solution had plugins installed using `bin plugin install` from beta1 release switched branches to test the https github com elasticsearch logstash tree wip bundler move and tried to uninstall an existing plugin plugins were not recognised because they are not listed in `gemfile` users upgrading from beta1 to rc1 will hit this issue too>>>blocker bug bundler docs v1.5.0-rc1
outputs can crash silently locking up entire pipeline migrated from https logstash jira com browse logstash 1749 if an output plugin encounters an exception such as logstash 1504 et al the output crashes silently the exception is printed to stdout and never reaches the log this causes that output sizedqueue to no longer be consumed and eventually filter workers and then input workers block on sizedqueue pushes logstash appears to cease processing messages without warning or explanation the only way was able to debug this was to run logstash in screen and watch the output ran it with vv because had no idea why it was locking up and set my scrollback to 100000 lines at this point was able to see my output thread elasticsearch river crash although had to scroll ways back to find this exception since the other threads continued on for awhile here the exception from my output thread it irrelevant why my output thread is crashing but for those curious our vulnerability scanner sent garbage bytes to the syslog port and logstash happily ate them until it tried to convert the message to utf in the json codec would set the priority of this to critical if could almost dropped logstash because this issue made it inexplicably unreliable at least logging the exception would have given me clue as to how to proceed >>>jira-migrated
logstash crashes on windows am getting the following message on the console timer expired abort fatal error has been detected by the java runtime environment exception access violation 0xc0000005 at pc 0x000007feef3a1aa4 pid 7956 tid 6536 jre version java tm se runtime environment 40 b43 build 40 b43 java vm java hotspot tm 64 bit server vm 24 b56 mixed mode windows amd64 compressed oops problematic frame migrated from https logstash jira com browse logstash 2076>>>jira-migrated
do not update sincedb if the data is not accepted by elasticsearch am using elasticsearch with logstash and am currently in process of parsing 2b documents across 18 indices at times due to various reasons probably bug in ls see these errors the problem vanishes after restart the logstash process anyway the major problem is that even though the write has failed logstash updates sincedb and doesn retry the loglines this has caused large pain as one has to constantly monitor and restart if such errors are found so far have lost over 100m documents and no idea how to get them back migrated from https logstash jira com browse logstash 2203>>>jira-migrated
add http input plugin migrate from https logstash jira com browse logstash 871 it is important to note that community plugin exists here https github com moshen logstash http input>>>new-plugin
elasticsearch output ability to send failed messages to dead letter queue as user of logstash we experience lost messages when logstash elasticsearch output is not configured correctly for elastisearch cluster index or type message to be output to elasticsearch cannot be indexed due to be malformed and elasticsearch errors on the index request not related to elasticsearch cluster availability see retry method has been added in other ticket this is only for messages that will never be able to be indexed until further changes are made either to message we would like the ability to configure dead letter type queue that either can send message directly to message queue rabbitmq or possibly write to local log file that can be configured as failed log input to logstash and handled with additional filters and outputs in logstash config to ensure these messages are not lost an alternative from user perspective not sure how technically feasible this is based on how logstash operates would be to not acknowledge the message from message queue on input pulling from rabbitmq until the message has been successfully indexed into elasticsearch >>>enhancement resiliency roadmap
string field expansion thingy should support default if no value present migrated from https logstash jira com browse logstash 268 currently if you use foo and there is no such field it leaves foo literally in many cases you probably want to specify default value bourne shells let you do this by saying foo default value maybe permit folks to do foo bar and also foo baz fizz and such >>>bug enhancement jira-migrated
logstash api logstash current lack of metrics visibility to its internal state and inability to manipulate running pipeline calls for much needed api this should be implemented alongside the current logstash conf` feature and not replace it logstash should expose resources such as itself or logstash agent the pipeline and plugins logstash instance single logstash instance started with `bin logstash that runs or more pipelines url `http localhost 9400` pipeline `logstash pipeline` instance with stages input filter and output url `http localhost 9400 pipeline stage one of three stages of pipeline containing an ordered list of or more plugin instances url `http localhost 9400 input` plugin instance one instance of plugin `mutate` `stdin` `tcp` etc url `http localhost 9400 filter this would then allow one to start an empty ls instance and post configuration to it creating new pipeline `curl post http newnode 9400 or updating configuration through `curl put http node 9400 pipeline name each resource would also have state or status api that included metrics migrated from https logstash jira com browse logstash 85>>>discuss enhancement jira-migrated roadmap v2.0.0
create exec filter migrated from https logstash jira com browse logstash 119 would be useful to pipe arbitrary fields through command to modify them here an example that would anonymize hostnames or something filter exec command sed re loggly com anonymizedhost example com fields message hostname source host the default would use only the `message` to parse the protocol between logstash and the exec filter must be strict something like for every line emitted one line must be emitted as the new line if no changes are made simply print it unmodified deleting the field can be done by printing blank line we exec the process once and use stdin for sending data stdout for reading responses if it dies some retries should occur>>>jira-migrated new-plugin
add ability to set all fieldnames to lowercase migrated from https logstash jira com browse logstash 732 text >>>discuss enhancement jira-migrated
ipfix input plugin migrated from https logstash jira com browse logstash 799 info on ipfix http en wikipedia org wiki ip flow information export related >>>jira-migrated new-plugin
sflow input migrated from https logstash jira com browse logstash 800>>>jira-migrated new-plugin
ldap search input plugin migrated from https logstash jira com browse logstash 1772 >>>jira-migrated needs_review new-plugin
logstash is loosing lines events when it terminates got logdata json file that contains log events believe this bug is generic and doesn depend on the input file format tested this behaviour again with logstash beta1 and oracle java 31 b13 64 bit however believe it does not depend on the java version also noticed similar logstash behaviour in version and believe it the same problem count the events the of the input file with wc logdata json then check the number of imported documents in elasticsearch with index search cat logdata json logstash counting events after the import notice that there are some 1000 events documents missing if am using more than one worker more documents get lost one worker is the best case logstash cat logdata json ncat localhost 10000 counting events after the import the number of lines in the json file is identical to the number of events in elasticsearch it is possible to use multiple workers also it is possible to use redis input plug in all events make it suspected reason bug when we use stdin as input logstash terminates immediately after the input file is fully read when we use tcp or redis as input logstash reads all available events but does not terminate until it gets killed http www elasticsearch com guide en logstash current plugins outputs elasticsearch html describes the options flush size and idle flush time that means by default each elasticsearch output worker maintains queue of up to 5000 elements however it will be flushed or written to elasticsearch after second of inactivity that makes the difference between logstash terminating immediately or continuing to listen for input questions does the elasticsearch output flush it queue when logstash terminates does stdin input terminate logstash without the possibility to flush event queues feel that question describes the reason for this logstash behavior however it would be good to investigate other output plugins as well >>>v1.5.0-rc1
logstash is crashed every day setup standalone elk on single server but each day logstash is crashed with following msg >>>logging_improvements
add asciidoc note for community supported plugins this should read the list of logstash shipped plugins from the default plugins rb file and add an asciidoc note admonition to signify that it is community supported >>>v1.5.0
output file doesn work correctly on logstash beta1 this is my configuration in output conf output file path var log test yyyy mm dd log but it hasn created valid file with the above time format need rotation log it created test filepath failures this configuration was still used normally in logstash format of timestamp 2015 02 05t17 19 27 456z >>>bug v1.5.0
elasticsearch output doesn restart after failure we have couple of web frontends that have stopped reporting logs the last note in the logstash log mentions manticore failure talking to elasticsearch and then nothing else https gist github com drewr 0ef6a4ca02c32131400c our config looks bit like this >>>bug
update to documentation templates this update presents alternate text if no configuration options exist for plugin it even hides the details section if there are no configuration parameters >>>v1.5.0
docs do not generate the details section if there are no configurations if you see http www elasticsearch org guide en logstash current plugins codecs es bulk html there is details section which is empty for instance it says this plugin supports the following configuration options but then nothing follows if there are no configuration options maybe we should just say there are no configuration options for this plugin and get rid of the details header after which there are no details >>>docs v1.5.0
update to fix logstash docs 42 see https github com elasticsearch logstash docs issues 42 the teardown method is in the base class now so it commented out >>>v1.5.0
fix encoding issue on windows jruby when getting data from the socket stdlib either through socket gethostname socket peeraddr or others windows will produce string with windows 1525 encoding when plugin tries to do `event field string` event validate value will raise exception since the string isn utf encoded this is temporary fix until jruby fixes https github com jruby jruby issues 2558 fixes at least https github com logstash plugins logstash input tcp issues https github com logstash plugins logstash input syslog issues https github com logstash plugins logstash input pipe issues https github com logstash plugins logstash input generator issues https github com logstash plugins logstash input file issues https github com logstash plugins logstash filter metrics issues >>>v1.5.0
cannot start logstash beta1 on windows os windows server 2012 r2 standard 64 bit logstash bin logstash bat agent vv config logstash conf please download the jruby complete jar from http jruby org download to log stash vendor jar and re run this command press any key to continue then copied the jruby from https s3 amazonaws com jruby org downloads 19 jruby complete 19 jar to logstash vendor jar logstash java version java version 75 java tm se runtime environment build 75 b13 java hotspot tm 64 bit server vm build 24 75 b04 mixed mode logstash bin logstash bat agent vv config logstash conf io console not supported tty will not be manipulated the error reported is bad uri is not uri logstash conf logstash vendor jar jruby complete 19 jar meta inf jruby home lib ruby uri common rb 176 in `split logstash vendor jar jruby complete 19 jar meta inf jruby home lib ruby uri common rb 210 in `parse logstash vendor jar jruby complete 19 jar meta inf jruby home lib ruby uri common rb 747 in `parse logstash lib logstash agent rb 291 in `load config logstash lib logstash agent rb 101 in `execute logstash lib logstash runner rb 166 in `run org jruby rubyproc java 271 in `call logstash lib logstash runner rb 171 in `run org jruby rubyproc java 271 in `call logstash vendor bundle jruby gems stud 18 lib stud task rb 12 in `initialize >>>blocker v1.5.0-rc1 windows
make sure mixin type of plugins cannot be installed we use mixin plugin to share common code between multiple plugins to dry for example the aws s3 input and output plugins use logstash mixin aws https github com logstash plugins logstash mixin aws which is gem but not logstash plugin we need to enforce that `bin plugin install` cannot actually install this as plugin this should only be installed as dependency when installing `logstash input s3` >>>v1.5.0
add vendor json and jar dependency info this adds information about `vendor json` and jar dependencies in the gemspec file >>>v1.5.0
update package acceptance tests use environment var ls branch to select which packages to use from which branch >>>v1.5.0
logstash keeps creating temporary files like jffi7147932261595358903 tmp logstash keeps creating temporary files like jffi7147932261595358903 tmp in windows temp directory and not cleaning them up this files created by logstash at start up time because of ffi library found bug in jruby https github com jruby jruby issues 1237 upgrading to new jruby version should fix the issue >>>bug windows
actually push out changes facepalm merge >>>v1.5.0
removing deprecated docs updating other this change now reflects the changes for including that contrib is going away as are milestones the new doc is not extending logstash but contributing to >>>v1.5.0
retire `bin logstash web` when kibana is released related https github com elasticsearch kibana pull 2574 the kibana backend is now in nodejs given that kibana now uses backend supported by the nice folks on the kibana team don think we need to ship with `bin logstash web` anymore >>>enhancement v1.5.0-rc1
windows test results ph and are working on fixing logstash bugs on windows in the `wip bundler move` branch confusingly name know it mix of work in there had to disable some plugins because they were causing rspec to crash not test failure rspec would raise exception and abort execution the full test output is here https gist github com jordansissel 622db419dc1b284794bd will file bugs on individual repos as result but this ticket tracks the study >>>windows
document the use of metadata feature we added metadata` syntax to the event class which helps store arbitrary data while an event flows through the pipeline stages this helps certain configs like in data filter to avoid creating intermediate fields we should document the use of this functionality with examples configs with and without metadata see https github com elasticsearch logstash pull 1836>>>blocker docs v1.5.0
update readme to current dev environment fixes 2112 1527>>>v1.5.0
fix some url evaluation due to monospace quoting the url evaluations happened because monospace quoting does that before monospacing this resulted in urls which were formerly all typed out being shortened >>>v1.5.0
fix few missed passthroughs>>>v1.5.0
removed nested inline passthrough errors it less pretty but it won break build docs pl >>>v1.5.0
plugin patches fix docbook xml render failures by adding float before section headings >>>v1.5.0
shutdown semantics exception handling in the pipeline related issues prs https github com elasticsearch logstash pull 1373 https github com elasticsearch logstash issues 1250 https github com elasticsearch logstash issues 2130 https github com elasticsearch logstash issues 2152 the pipeline is composed of input filter output workers https github com elasticsearch logstash blob master lib logstash pipeline rb l171 l241 that execute the plugins code and take care of uncaught exceptions that may occur during their execution these workers should tolerate hopefully transient exceptions and not allow the pipeline to crash also known fatal exceptions should abort the pipeline execution and terminate logstash therefore workers should have the following behaviour input workers have long running method call `run` filters and output workers continuously pop from queue what is transientexception fatalexception we have no way of knowing what the plugin considers transient fatal exception two possible choices treat all standarderror derived exceptions as transient those derived from exception as fatal provide logstash transientexception as parent exception for transient exceptions logstash fatalexception for fatal ones plugins would only throw descendants of these classes questions should transient failure call some setup teardown behavior on the plugin current code for the input plugin https github com elasticsearch logstash blob master lib logstash pipeline rb l171 l196 calls teardown and then retries but at that point the plugin instance might no longer be usable for filters and outputs the shutdown is done through shutdownevent however if plugin is very slow executing sleep 100000 it will never pop the shutdownevent from the queue and execute teardown should there be pipeline shutdown force true on some situations thread naming problem related issues https github com elasticsearch logstash issues 2462 https github com elasticsearch logstash issues 2425 best practices when developing plugins exception handling recommendations which kind of exceptions should reach the worker what happens if plugin misbehaves throws top level exception hangs >>>design discuss v2.3.0
feature request jdbc output input plugins this issue is here to throw the idea in the air this could possibly include other rdbms systems generic database output plugin but being selfish focusing on postgres first >>>new-plugin
plugins bundler refactor>>>blocker bundler v1.5.0-rc1
create logstash core gem the plugins need to have way to define their dependencies on logstash right now we are solving this by creating virtual `gemspec` and adding it to the `gemspec` database if we create and publish real `logstash core` gem we will be able to remove this hack >>>bundler v1.5.0-rc1
remove the gem bundler hacks remove all the bundler gemspec hacks in logstash the only thing remaining should be the lock` file hack and maybe this could be removed if we use platform` option when we require gem `set load path should use the `bundler setup >>>blocker bundler v1.5.0-rc1
file dependencies and the gem hook the plugin manager actually invoke the `gem hook` of the plugin to download the vendor files know we did some experimentation to remove the need for this call but do not recall the blocker on this want to know if we can be closer to the jar dependencies behaviour and make it work like magic if we cannot make it work like the jar dependencies we will have to rely on rake task after installing the gems with bundler >>>bundler v1.5.0-rc1
create simple wrapper around the gemfile we are currently using two different projects to manage the plugins and dependencies bundler and rubygems let try to create simple command wrapper around the `gemfile` to add remove and update plugins we will need to do some house keeping on the installed gems we can read the `gemfile` and use `instance eval` to generate the current database things to check we will probably have to use `bundle update` and the `bundle clean` calls bundle package will move all the gem needed for the project in `vendor cache` directory this could allow offline installation of plugins think this behaviour requires to move the lock with the gems we can use the same interface of the pluginmanager to achieve this >>>blocker bundler v1.5.0-rc1
jenkins install all plugins on logstash and run all specs>>>tests-infra v1.5.0-rc1
add package testing to branch at present it appears we only have job to do package testing for master we need to do >>>tests-infra v1.5.0-rc1
add monitoring to critical jenkins jobs as noted in https github com elasticsearch logstash issues 2465 we haven been running plugin tests in at least months we need monitoring to alert us when this kind of thing occurs we should be paged if jenkins isn running tests >>>tests-infra v1.5.0
add windows testing to jenkins currently jenkins doesn test logstash on windows this needs to be changed >>>tests-infra windows work_in_progress
improve the package tests to test the tar and zip artifacts at present the package acceptance tests only appear to test the deb and rpm we need to also test the tar gz and zip >>>tests-infra v1.5.0-rc1
all plugins need to be tested automatically at present it appears that none of the plugin tests are being run by jenkins here sample screenshot showing that the last months we haven run set of filter tests this pattern repeats for nearly all plugin jobs in jenkins screen shot 2015 01 28 at 58 01 am https cloud githubusercontent com assets 131818 5942363 dc19a8ea a6cb 11e4 9000 f3f7b43e70ff png >>>tests-infra v1.5.0-rc1
the package acceptance test falsely reports passing when build the artifacts tar zip etc they are nonfunctional due to gem problems jenkins claims the tests pass cannot see how at this time but this is signal that the acceptance tests are not correctly testing the packaging >>>tests-infra v1.5.0-rc1
all output fail if one of many outputs fails we have an issue in logstash when our elasticsearch cluster slows down essentially we use logstash with multiple outputs elasticsearch graphite and hdfs if any of the above outputs have issues all outputs will fail it would be great if only the output the issue failed and didn impact the others >>>enhancement
rpm deb make pre releases sort lower than ga releases the current replacement works for rc and dev versions but is ineffective for stuff like alpha and beta we take more generic method whenever we get dot followed by an alphabetic character we replace the by for in dev beta2 dev do echo echo sed alpha done dev dev beta2 dev beta2 dev>>>packaging
build artifacts are unusable ps users jls documents github logstash build logstash beta1 logstash beta1 bin logstash version bundler gemfilenotfound users jls documents github logstash build logstash beta1 logstash beta1 tools emfile not found build at users jls documents github logstash build logstash beta1 logstash beta1 vendor bundle jruby gems bundler 11 lib bundler definition rb 22 definition at users jls documents github logstash build logstash beta1 logstash beta1 vendor bundle jruby gems bundler 11 lib bundler rb 155 setup at users jls documents github logstash build logstash beta1 logstash beta1 vendor bundle jruby gems bundler 11 lib bundler rb 118 set gem paths at users jls documents github logstash build logstash beta1 logstash beta1 lib logstash environment rb 65 root at users jls documents github logstash build logstash beta1 logstash beta1 lib logstash runner rb 8>>>blocker bundler v1.5.0-rc1
delete the zipfile before building it if we don do this zip file new and despite the zip file create flag will reopen an existing zip file instead of writing new one the error you get without this patch is rake aborted add failed entry logstash dev license already exists users jls projects logstash vendor bundle jruby gems rubyzip lib zip file rb 392 in `check entry exists >>>v1.5.0-rc1
update bundler gemfile lock>>>v1.5.0-rc1
rake artifact tar error installing murmurhash3 trying to run `rake artifact tar` after successful `rake bootstrap` installing logstash codec rubydebug with native extensions gem installer extensionbuilderror error failed to build gem native extension logstash vendor jruby bin jruby exe extconf rb make make is not recognized as an internal or external command operable program or batch file gem files will remain installed in logstash vendor bundle jruby gems murm urhash3 for inspection results logged to logstash vendor bundle jruby gems murmurhash3 ext murmurhash3 gem make out an error occurred while installing murmurhash3 and bundler cannot conti nue make sure that `gem install murmurhash3 succeeds before bundling retrying vendor gems upon exception bundler installerror fetching source index from https rubygems org >>>needs_details unconfirmed windows
skip some plugins for install all skip the examples` and jms` plugins for now>>>v1.5.0
make sure file input works correctly on windows>>>v1.5.0-rc1 windows
add bin plugin bat which just invokes bin logstash plugin fixes 2287>>>v1.5.0
allow uninstalling gems with rubygems and skip bundler in this case do not use bundler to uninstall gems >>>v1.5.0
set bundle path env to overwrite any bundler config and fix bundler setup will fix 2400 >>>v1.5.0
plugin design streamline event submission by an input plugin currently all input plugins contains more or less the following lines decorate is handling the add field add tag and with 2390 it could use sprintf syntax and already manipulate event fields set by the input plugin so it should be enforced that decorate is called after the event is filled by the specific input the idea would be to dry this into inputs base rb it would avoid plugin implementor to forget or misplace the call to decorate thoughts here is the list of inputs not complying with the proposed rule exec file ganglia generator heroku irc kafka log4j lumberjack relp s3 snmptrap sqlite sqs stdin syslog udp unix varnishlog wmi xmpp zenoss>>>breaking-compatibility discuss v3.0.0
windows plugin upgrade fails users jls documents github logstash windows bin plugin bin plugin install logstash output elasticsearch validating logstash output elasticsearch valid logstash plugin continuing removing existing plugin before installation successfully uninstalled logstash output elasticsearch java nomethoderror undefined method `delete for remove spec at users jls documents github logstash vendor jruby lib ruby shared rubygems specification rb 1089>>>v1.5.0-rc1 windows
update jar dependencies update jar dependencies to and added dsl element to jar dependencies language to allow using custom maven repository in plugin jar dependencies>>>v1.5.0
make jenkins run the full test suite again>>>tests-infra v1.5.0-rc1
release all new plugin changes for rc1>>>v1.5.0-rc1
typo fix for the rake task>>>v1.5.0
logstash stuck on sending bulk of actions to client multiline issues in logstash 0beta in logstash 0beta when there are several filters configured have grok filters multiline and json filters logstash gets stuck when sending bulk to elasticsearch tried playing with the amount of filters to see if that what causes the issue only multiline and json filters configured all works well only grok filters configured all works well but when combining them all together logstash starts to work but just gets stuck at very early point on sending bulk of actions to client when remove only the multiline filter all works well using logstash 0beta and es thanks >>>needs_details
fix the coveralls badge if there is no branch selected the coveralls badge show the coverage level as unknown this is not nice so change it to use the master one and get the avg number >>>v1.5.0
provide common code for zeromq filter and output logstash filter zeromq and logstash output zeromq are using utils zeromq rb https github com logstash plugins logstash filter zeromq blob master lib logstash util zeromq rb file which was duplicated during beta1 as part of https github com elasticsearch logstash issues 2055 previously before the plugin separation they shared the same file we know have to dry this up to new plugin like https github com logstash plugins logstash mixin aws which has common utils code for ec2 input and output >>>bug
cmd exe bin logstash complains about git not being found users jls documents github logstash bin logstash hello world fizzle fangle bundler gemspecerror there was errno enoent while loading logstash gemspec no such file or directory git from users jls documents github logstash logstash gemspec 12 in `eval gemspec eval gemspec at users jls documents github logstash vendor bundle jruby gems bundler 12 lib bundler rb 394 instance eval at org jruby rubybasicobject java 1545 eval gemfile at users jls documents github logstash vendor bundle jruby gems bundler 12 lib bundler dsl rb 32 evaluate at users jls documents github logstash vendor bundle jruby gems bundler 12 lib bundler dsl rb 10 build at users jls documents github logstash vendor bundle jruby gems bundler 12 lib bundler definition rb 25 definition at users jls documents github logstash vendor bundle jruby gems bundler 12 lib bundler rb 155 setup at users jls documents github logstash vendor bundle jruby gems bundler 12 lib bundler rb 118 set gem paths at users jls documents github logstash lib logstash nvironment rb 65 root at users jls documents github logstash lib logstash unner rb >>>blocker v1.5.0-rc1 windows
make log4j setup more explicit which appender to append to>>>v1.5.0
plugin bundler nomethoderror during uninstallation bin plugin uninstall logstash output kafka validating removal of logstash output kafka uninstalling plugin logstash output kafka with version successfully uninstalled logstash output kafka nomethoderror undefined method `delete for remove spec at users tal code es talevy logstash vendor jruby lib ruby shared rubygems specification rb 1089 remove at users tal code es talevy logstash vendor jruby lib ruby shared rubygems uninstaller rb 274 uninstall gem at users tal code es talevy logstash vendor jruby lib ruby shared rubygems uninstaller rb 158 uninstall at users tal code es talevy logstash vendor jruby lib ruby shared rubygems uninstaller rb 136 execute at users tal code es talevy logstash lib logstash pluginmanager uninstall rb 26 run at users tal code es talevy logstash vendor bundle jruby gems clamp lib clamp command rb 67 execute at users tal code es talevy logstash vendor bundle jruby gems clamp lib clamp subcommand execution rb 11 run at users tal code es talevy logstash lib logstash runner rb 144 call at org jruby rubyproc java 271 run at users tal code es talevy logstash lib logstash runner rb 171 call at org jruby rubyproc java 271 initialize at users tal code es talevy logstash vendor bundle jruby gems stud 18 lib stud task rb 12>>>blocker v1.5.0-rc1
use the info level when printing the version notice for the plugin fixes https github com elasticsearch logstash issues 1570>>>v1.5.0
allow logstash rpm to require either jre or jdk we re unable to use puppet to install the logstash rpm because it requires the jre package while we use the jdk on many of our systems >>>v1.5.0
switch to use gem ftw version 42 instead 39 in version 39 in lib ftw dns dns rb https github com jordansissel ruby ftw blob master lib ftw dns dns rb bug in unpacking ipv6 address >>>v1.5.0
filter and output threads arent named correctly naming thread will help us debug problematic plugins https github com elasticsearch logstash blob master lib logstash pipeline rb l196>>>enhancement
make configurable the filter flush opportunity interval this exposes previously constant setting as the filter flush opportunity interval flag the default value is the previous default of seconds this will not be common setting for users to change also cleaned up bit of the pipeline settings to make the configuration keys into constants fixes 1231>>>needs_tests
document jruby oom behavior and how to address from 1496 when ls runs out of memory it writes out the following message error your application used more memory than the safety cap of 500m specify xmx to increase it cap size in mb specify for full outofmemoryerror stack trace this can be confusing to the end user given that is the flag for specifying worker threads in ls this behavior should be documented in some form of troubleshooting logstash page along with steps which can be taken to address the situation >>>docs
redis rabbitmq output input with multiple hosts for silent fail over given cluster of rabbitmq redis nodes it would be desirable that ls silently fail over in case rabbitmq redis node pointed by ls dies this should be true for input and output >>>enhancement resiliency
test coverage reenabled the motivation of this pr is basically to enable the opportunity to get coverage report from logstash this basically enable developers to get coverage report when the env variable coverage evaluate to true so for example >>>v1.5.0
add some feedback when stdout is present as requested in 2163 added two logger calls that report when logstash is up and running and then it shutdown hand merge dependencies to be able to merge this pr we need to update and release https github com jordansissel ruby cabin with the pr that adds this method https github com jordansissel ruby cabin pull 25 >>>v1.5.0
provide our own ssl certs on windows ruby this fixes bug where windows ruby ships with insufficient ssl certificate information and this causes gem installations to fail this patch is only applied under windows ruby because jruby is not affected by it fixes 2402>>>v1.5.0
`rake bootstrap` on windows ruby cannot gem install minitar bootstrapping goes download jruby unpack jruby relaunch under jruby however with the windows ruby installer it ships with broken rubygems configuration such that `gem install` cannot work due to ssl cert trust problems the recommended workaround for each user is this https gist github com luislavena f064211759ee0f806c88 however think this is bad workaround it requires every dev on windows to do this hunt for the ruby directory download this random cert file and hope you did it right want to automate the workaround but am at present unable to find solution https gist github com jordansissel 76b47be00509c5b6f5a0>>>windows
`rake bootstrap` on windows says it can find java neat >>>docs v1.5.0 windows
unable to run bin logstash no gem found error on some environments am unable to successfully run `bin logstash` after running `rake bootstrap` with clean vendor dir here is the current error encounter https gist github com talevy 0cd47c1dfe9c7f918e79>>>blocker v1.5.0
fix logstash event gemspec for jruby and mri closes 1582 >>>v1.5.0
filter xml ignore namespace hi need to remove namespace from the input xml before applying xpath expressions in the xml filter changing the filter to achieve this is easy but it would be nice to have this feature included as an attribute in the configuration of the xml filter and also part of the standard release adding the following line after the xml creation doc nokogiri xml value will remove the namespace doc remove namespaces >>>v1.5.0
harmonize add field and add tag behavior in inputs and filters introduce util decorator for common event manipulation like add field or add tag potentially could also be reused in filters needing tag on failure fix for 2354>>>v1.5.2
add couchdb and es bulk to default plugins>>>v1.5.0
normalize the exception behaviour for inputs outputs and filters right now an exception on an input plugin will cause it to restart indefinitely while an exception in an output plugin halts logstash immediately edited taking jordansissel comments into account this pull request makes all plugins have the same behaviour if plugin raises standarderror worker catches and retries the method an exception makes logstash crash this might not be the desired behaviour we want so this pr is more wip aiming at consistent behaviour across plugins also this adds tests to the pipeline for this behaviour issues related to this problem https github com elasticsearch logstash issues 2152 https github com elasticsearch logstash issues 2130 https github com elasticsearch logstash issues 1250 https github com elasticsearch logstash issues 1373 fixes https github com elasticsearch logstash issues 2477>>>reviewing work_in_progress
mutate check for nil before attempting to remove fixes 2379 tests are here https github com logstash plugins logstash filter mutate pull this used to work as unintended side effect until https github com elasticsearch logstash commit b7ba48d393f9d17a8a4f377d8739af4fdf9c0343 was merged>>>v1.5.0
update readme to reflect plugin split to repositories>>>v1.5.0
packaging as single jar to run in aws elastic beanstalk have cases where we run logstash in vm completely independent of any inputs and outputs for example using an s3 input and an elasticsearch output in these cases we care very little about the local machine and file system so deploying configuring and monitoring full vm just to run logstash is pain would just prefer to run jar in aws elastic beanstalk this would require packaging logstash and any custom plugins in an executable jar or jar in jar >>>discuss enhancement
support for draft ietf json text sequence logstash should ingest json data in this form https datatracker ietf org doc draft ietf json text sequence basically that means `rs json lf` since log stash already handles `json lf` trivial parser could simply delete the leading rs character smarter one would use this to detect truncated json text and recover the following record as described in the spec >>>discuss
rspec style refactor in this pr use the old conditionals spec in order to perform an rspec style refactoring it would be awesome if you guys can share here your opinions and points of view of what are best practices for writing tests for you >>>tests-infra
mutate with non existent field throws an error `bin logstash filter mutate remove foo bar logstash ok logstash 0beta1 ok logstash snapshot c95cc001b532906bfcaf3ea6808a63f7a8e4ae5e fail >>>bug v1.5.0
operational concern offline plugin installation user story ish thing as an person deploying logstash may operate within an air gapped datacenter or otherwise not internet connected facility would like to install and upgrade logstash plugins without requiring internet connectivity at installation time let gather some options for providing plugin installation in the above situation ideally the solution chosen should be one which is least painful for users and operators of logstash proposals this will be updated as discussion progresses on this topic the user could locally mirror rubygems org and sonatype maven and use this as the installation source we could periodically publish full resolved build artifact that includes all known plugins and dependencies this artifact could be unpacked on local machine and used as source for plugin installation >>>enhancement
allow to define gem in the gemfile with the path option this patch use bundler to generate the virtual specs when you use gem blah path something fix 2351 if you want to test it it wont be in the vendor disclaimer git github options doesn work right now not sure why need to test if the package exist in vendor and we try to redeclare it in the gem to see which one bundler will take >>>v1.5.0
add way to run all plugin test from rake command added rake task to run all test plus fix dependency for octokit >>>v1.5.0
logstash multiline filter throws exception and logstash freezes am running logstash1 node with single thread it receives via tcp input parses the message according to syslog rfc5424 format and it has multiline filter on it the multiline filter is throwing this exception at this point the logstash freezes and stops processing incoming logs my configuration looks like this if remove the grok parsing it still throws the same exception debugging the messages sending they all look correct whenever send single line message it works great when send multiline messages each line after the first starts with as you can see in the multiline pattern defined >>>bug v1.5.0
workaround rake task that add development dependencies for testing into gemfile rake task that source the currently installed dependencies and updated gemfile so they can be installed and available for testing while not necessary very optimal solution this helps to run all specs coming from plugins all at once with given logstash version workflow example rake plugin install all rake vendor append development dependencies tools gemfile plugins all rake plugin install all will basically add all the plugins then append the development dependencies to the gemfile plugins all and run again the plugin install all note for now rake plugin install all is also installing the development dependencies in order to adapt it to the comments coming from electrical we should decide on one way and remove the other so this workflow for now is doing something else too >>>v1.5.0
rough draft first commit of new plugin howto docs this includes small plugintype asciidoc files which are little more than macro placeholders the real document is singular at `include pluginbody asciidoc` and has many `ifdef` blocks to include code or `ifndef`blocks to exclude code as needed be warned viewing the `pluginbody asciidoc` file as github may interpret it will omit most of these blocks because of the `ifdef` statements >>>docs v1.5.0-rc1 work_in_progress
split pipeline overview and config file examples out of getting started changed the heading of the event lifecycle topic to logstash processing pipeline and changed the config file format topic to configuring logstash merged the topics removed from getting started into those two files think the order of the topics should be tweaked so it getting started with logstash logstash processing pipeline configuring logstash command line flags extending logstash adding sample filter to logstash input plugins output plugins filter plugins codec plugins not sure how to do that >>>docs v1.5.0
add ability to have multiple index templates currently when using elasticsearch output you can configure elasticsearch mapping template for single index it would be useful to use multiple templates to for example treat logdata for one type different than another instead of choosing one size fits all strategy for all log data for example in our case we gather some log data that is high volume but low priority collectd as well as low frequency volume data related to application logs in this case it would be nice to be able to have different indicices with different shard counts replica settings etc as well as custom mappings so that we can treat it differently >>>question
testing style refactoring tests to permit `it` and more focused tests today filter specs usually do something like this problems with this `config` is not implemented in way that is usable properly in rspec `sample` implies `it` and other oddities doing this more closely aligning with rspec norms using `let` and `subject` to setup our testing inputs and using `it` to test the behaviors additionally would propose instead of using logstash config strings we could just use the plugin objects themselves for example instead of we would use we can add helpers to abstract event processing such as having an `event` helper take an `input` value via `let` or similar trick or something similar it hopefully will make our tests easier to read write maintain >>>tests-infra
editing cleanup pass through the logstash docs changes from my review of the logstash docs fixed some bad links did some light editing and reorganized the config file topic bit >>>v1.5.0
timestamp is converted to local tz offset when logstash reads message event with an existing timestamp field the timestamp value is converted to the local timezone offset for example timestamp with value of 2015 01 14t15 51 55 310z prior to the logstash input will get converted to 2015 01 14 08 51 55 310 0700 in my case after the output this format differs from the output of the date filter my understanding from the documentation is the timestamp should always be in utc this may be fixed in but still thought it was worth noting believe the issue is in the time addon rb where the parse iso8601 creates new time with the local tz with the following code could that be changed to the following >>>bug
plugins to install also the plugins development dependencies while testing plugin installation are expected for now to have also their development dependencies installed this is like this because the way we do testing right now actually this problem raised when testing https github com logstash plugins logstash output email blob master logstash output email gemspec l28 as the rumbster dependency was not installed to do that change in the plugin manager is easy as we can see in this pr but to do that using bundler is really no possible or at less was not able to see the way there is also subtle change here that the introduction of an event variable so we are able to install plugins while testing with dev deps but not while in production released status >>>v1.5.0
noop tests are randomly failing finished in 91 seconds 229 examples 25 failures failed examples 25 logstash filters noop remove tag type noop tags t1 t2 when processed failure error let pipeline logstash pipeline new config gem loaderror could not find logstash filter noop among 70 total gem lib logstash config mixin rb 214 in `plugin version lib logstash config mixin rb 227 in `print version notice lib logstash config mixin rb 204 in `validate lib logstash config mixin rb 100 in `config init lib logstash filters base rb 134 in `initialize lib logstash pipeline rb 268 in `plugin eval in `initialize lib logstash pipeline rb 32 in `initialize spec filters base spec rb 173 in root spec filters base spec rb 173 in root lib logstash runner rb 58 in `run lib logstash runner rb 113 in `run lib logstash runner rb 171 in `run randomized with seed 16474>>>bug v1.5.0
defining development gem in the gemfile and specifying the path doesn add it to the loadpath logstash use the `gemfile` to install gems but doesn use it to modify the load path of the application so if you add this line to your gemfile useful to test an unreleased gems the es logstash lib` wont be added to the application load path` and the tests will fail with the git` option might fail too >>>blocker v1.5.0
colon char in install path causes load error we are trying to run logstash in mesos sandbox which creates paths with colon character which cause the following error on starting logstash error could not find or load main class org jruby main>>>adoptme docs unconfirmed
add back kafka to default packaging was removed in 2320 with 2320 kafka was removed from the default install list to save 30mb from the ls release package we had discussion internally and arguments were made for having kafka included back to make it consistent with the other packaged plugins moving forward post v1 the idea is to have logstash ship with small list of plugins by default to reduce the install size this would also allow users to only install plugins which are needed for their use case this is made easier by the recent plugin management infrastructure which can add remove plugins at any time once we have more data on which plugins are popular we will open an issue to only include those in the default package until then kafka stays>>>v1.5.0
add example as an exclude pattern when installing all plugins so we can run the all plugins install without issues >>>v1.5.0
sync type tags filtering in filters and outputs starting from 2332 and scratching the surface found out that filters base still reference `include any` and `exclude any` configuration in the documentation but they aren used at all cleaning the doc filters outputs filtering by tags was describe as matching all but was matching any use the same logic as in filters base filters outputs filtering by exclude tags was broken because exclude method is nil use the same logic as in filters base bonus using hash syntax in the log >>>v1.5.0
update all occurrences of license to reflect 2015 it isn 2014 anymore >>>blocker v1.5.0
add logstash codec cef to the plugins all exclude the plugin logstash codec cef is still not released to rubygems so when the install plugin all command need to have this into his exclude filter otherwise is not possible to fetch all plugins at once as expected >>>v1.5.0
use the gem specification from the plugin to display the version notice to the user we will need to update all the plugins to remove the milestone option and adjust the version in the gemspec>>>reviewing v1.5.0
plans for supported ruby jruby in sure you are aware of this but out of curiosity could you please share your thoughs about your plans for upgrading supported ruby version in logstash jruby 9mode jruby 0mode jruby 9000 or faith jump to jruby 9000 with test test test because the mri disclaimer seems scary as as one month of support left meaning that jruby 9mode will also be frozen with alignment with mri ruby is now in the security maintenance phase this means that we never fix bugs except for security issues and at this time the end of the maintenance of has been scheduled for february next year we recommend that users of ruby should migrate to newer version as soon as possible just bumped into this because asked this naive question to jruby https github com jruby jruby issues 2411 regarding the timeout configuration caveat described in dns filter https github com logstash plugins logstash filter dns blob master lib logstash filters dns rb l25 >>>discuss v2.0.0
logstash configtest does not properly verify date filter an invalid `date` filter passes logstash configtest function logstash configtest misses this filter rule `date match timestamp see below for console output >>>bug v1.4.0
output fix use of `exclude tags` in output plugins for people still using `exclude tags` in their output configuration logstash stops with an exception `typeerror can convert nil into string` fix that by fixing the reference to exclude tags` >>>v1.5.0
add support for bytes validation to config fixes issue https github com elasticsearch logstash issues 1921 allows for friendlier config option for specifying file sizes currently uses the filesize https github com dominikh filesize rubygem to parse validate the input this supports both iec binary and si units for more context on the different units https wiki ubuntu com unitspolicy >>>v1.5.0
remove kafka input and output from default plugins packaging with kafka plugin can easily be installed using `bin plugin install losgtash input kafka` this will shave 30mb from the ls release package see 2137 >>>v1.5.0
refactor the insist usage within the logstash specs the motivation of this pr is to refactor the insist usage so we only use one way of expressing conditions and this is the most common within the rspec ruby community by using the rspec3 matchers we can archive good detail and expressiveness having good way to express the tests within logstash for clarity did not refactor in here the matchers usage this is scope for later refactoring note it relates to https github com elasticsearch logstash devutils pull 15 that adds insists as runtime dependency there so the usage of insist throw requireing devutils spec helper is still possibility for example for many plugins testing notes to test this you need to use https github com elasticsearch logstash devutils pull 15 as your devutils so jenkins is expected to fail another step within the spec refactoring check 2318 for context >>>tests-infra v1.5.0 v2.0.0
update to use rspec3 as test runner the motivation of this pr is to upgrade the test runner in place to rspec branch so we can leverage all the nice features it has related prs https github com elastic logstash devutils pull 29 https github com logstash plugins logstash input s3 pull 43 upstream issue https github com rspec rspec mocks issues 964 created because of the jrjackson error when using the and call original expectations in rspec3 >>>enhancement tests-infra v1.5.1
automatically install plugin on failed plugin lookup implements 4588 >>>enhancement plugin_manager reviewing v3.0.0
support locale for date parsing in sprintf format when parsing date with `sprintf` we use by default the local `locale` for example could produce something different when running on french computer than on an english computer `14 dc 2014 00 13 42 0000` vs `14 dec 2014 00 13 42 0000` it could be nice to specify for date the locale we want to use whatever is set on the computer locale date format such as >>>adoptme enhancement
use of unset scriptname variable in init scripts files pkg logstash web sysv redhat pkg logstash sysv redhat pkg logstash web sysv pkg logstash sysv contain but scriptname is never set it probably should be set with something like >>>bug packaging
wrong in metrics docs trying to do the example from http logstash net docs filters metrics this codeblock gives me running logstash 2c0f5a1 >>>docs
cleanup agent execute method work towards decoupling the agent from the pipeline by moving config handling and pipeline setup to separate methods>>>enhancement reviewing
if directory structure has rspec in the name it fails to startup logstash to make sure we don startup logstash when running checks via rspec we do check at https github com elasticsearch logstash blob master lib logstash runner rb l200 this however also catches anything that has rspec in any part of the path of the file in my case have rspec in one of the directory names we should improve the check >>>bug
document if file input support inotify on this old jira entry seems that file input plugin support inotify since version https logstash jira com browse logstash 39 but looking at the docs http logstash net docs inputs file it not mentioned and the following option really sounds like polling source stat interval how often we stat files to see if they have been modified increasing this interval will decrease the number of system calls we make but increase the time to detect new log lines >>>docs
adjust help output to match actual searched paths for plugins the help text of pluginpath for the agent doesn match what the code actually searches for as per https github com elasticsearch logstash blob master lib logstash agent rb l276>>>v1.5.0
time difference calculation in logstash in the scenario where you can to calculate difference between two timestamps in an event for example to calculate the elapsed time there are no filters or options within logstash to do it except of using very simple ruby filter for example as this is expected to be common operation it would be easier to have this integrated within the flow there are some options to implement this as new filter within the mutate filter as new option within the filter base so we can use it within add field option present in every filter for example so what option is the one you like the most >>>discuss enhancement
update accessors get does not mutate store this fixes accessors so that when one `get`s field reference it does not inject an empty path into the original store before there were side effects >>>v1.5.0
logstash parsed message do not put in fields with logstash the parsed message do not put in fields is that an evolution or an issue >>>question
elasticsearch recommended version is very vunerable by default suggested note for the documentation the recommended version of elastic search is vulnerable to remote exploit cve 2014 3120 suggest modifying the documentation to highlight the fact that security needs to be applied by default on this version kibana needs direct access to the elastic search endpoint it is obviously quite out of scope for you to be concerned with production grade operations especially with third party packages but as logstash is part of the elasticsearch family it is relevant have had system running on vm for just hours to evaluate the logstash kibana before it was shut down by the cloud provider for being part of ddos exploited by the elasticsearch vulnerability not being an expert user in logstash elasticsearch had no idea the recommended version is actually woefully out of date in terms of security patches is there chance of friendly nudge on the geting started page by the way is the recommended version the minimum or can we upgrade happily to rob >>>bug docs
add support of the cef format can you add support of cef format as input and output in logstash to be able to support different scenario to send data from arcsight esm or any device that support cef format logstash elasticsearch from elasticsearch logstash arcsight esm >>>enhancement
dns filter not doing what expected hi have this dns filter filter dns reverse source action replace from which expected that it will reverse dns the source field and then replace it with the new value dns name but it puts the dns new in new field called logsource why is that >>>needs_details
possible to export to plain hi want to use logstash to get logs out of rabbitmq and back in to plain text files it is working but it is placing everything in json in the file can get only the full message field without json in my output file >>>question
bin plugin does not work on windows>>>blocker v1.5.0-rc1 windows
multiple field patterns for message hi need to extract all fields from the events any fields that may not be or may be in different order examples cef stonesoft ips 271281 http sls successful status code spt 60494 deviceexternalid ips 1030 moff sensor dmac e4 c7 22 a4 17 e4 dst 192 168 requestmethod get cat protocol information requesturl www ttttt org app http rt dec 17 2014 20 18 49 act permit proto dpt 80 src 172 16 dvc 172 16 dvchost 172 16 smac 90 e2 ba 19 a1 1b cs1label ruleid cs1 100 try some configuration like at grok match message dpt int dst port message dst ip dst ip message src ip src ip message rt stonegate date event time message devicefacility data message src ip src ip message dst ip dst ip and other format grok match message dpt int dst port dst ip dst ip src ip src ip with fail result what is the correct syntax try this config with logstash dev beta1 also create full string patterns for this type message check on https grokdebug herokuapp com and try parse events at grok first try break on match false except in match message patern from patterns grok next try not work match message patern from patterns thank you for help >>>discuss v2.0.0
strip support for non used jruby versions and unused code aka rdocs with the aim to reduce unnecessary space this pr fix some of this problems like strips support from the vendorized jruby for and libs it makes sure that logstash is run under the mode remove unused gems like rdocs removed specs from logstash plugins fits some points from 2137 >>>v1.5.0
memory leak hi all use logstash and run into memory leak on my server this is graph from zabbix logstash https cloud githubusercontent com assets 8733909 5536355 77bf0ae8 8aa1 11e4 8ea2 f6ac2d09e50c png 15 12 logstash has been restarted manually server config ubuntu 14 04 lts java version 25 java tm se runtime environment build 25 b17 java hotspot tm 64 bit server vm build 25 25 b02 mixed mode logstash cmd usr bin java djava io tmpdir var lib logstash dcom sun management jmxremote dcom sun management jmxremote port 10961 dcom sun management jmxremote authenticate false dcom sun management jmxremote ssl false xmx1024m xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly xx printgcdetails xx printgctimestamps xx printclasshistogram xx printtenuringdistribution xx printgcapplicationstoppedtime xloggc logstash gc log jar opt logstash vendor jar jruby complete 11 jar opt logstash lib opt logstash lib logstash runner rb agent etc logstash conf var log logstash logstash log logstash config also have no suspicious events at any logs average messages rate 4000 per minute >>>question
fix nologin path run the command then it return sh usr sbin nologin>>>bug v1.5.0
multiline matching woes having hardtime understanding how to make logstash match my given input the log file looks like this though it may have multiple indented lines like storage job etc the input is very irregular which makes this even harder but my config looks like however this results in only parsing of the second part should perhaps have some logic in the filter block to switch on `multiline in tags or could have both in single `type bacula my regex is sane according to grokdebug as given single line of input it correctly shows all the right fields but something goes wrong when it multilined >>>needs_details question
adding validate method on the hash to check for the uniqueness of the keys we are validating keys in the hash to make sure they are unique without enforcing validation the last value of the key will be used config will show to the user this fix also check for deep nested hash fixes 2197>>>reviewing v1.5.0
default plugins that depend on murmurhash3 fail to install on my windows mingw couldn install all default plugins because murmurhash3 native ext code failed to compile more details in https github com funny falcon murmurhash3 ruby pull the fix in this environment requires new release of murmurhash3>>>bug windows
bin logstash file conf should work like it does in nix in nix environments it possible to run logstash with just `bin logstash file conf` or `bin logstash config string on windows both of these generate `no such command it necessary to use the `agent` option this interface should be as similar as possible in all environments >>>enhancement windows
wip rspec improvements and upgrade to rspec this is working progress pr initially started with the motivation in mind to provide clarity to the logstash tests and to upgrade them to this is an wip pr that is mainly open so we can reach common point on how do we want to have our test looking like if you have any question or doubt about why something is like it is fire comment smile purbon>>>work_in_progress
quotes being escaped hi am running elk stack setup udp input logstash elasticsearch am using the udp input method on port 514 to get the syslog messages switched from syslog input to udp input because one of the major appliance barracuda waf is not using standard syslog format that the syslog input in logstash can understand the problem am facing is quite odd some of the log messages very randomly and very few out of 10k received from the waf would appear to have their quoutes escaped in the message at first thought its the waf doing this however watched the tcpdump traffic and noticed that the original packet message for these messages the ones having their quotes escaped were fine apparently its the logstash adding the escaped characters here is my logstash filter for the waf http pastebin com raw php sv7qpg6s here are few incidents that show you the tcpdump message and the corresponding logstash mesage http pastebin com raw php zavy9efq really thank you in advance for any help hints you can provide me to debug this problem thanks khizer>>>needs_details
cleaning gems dependencies from the logstash gemspec cleaning unused dependencies in `logstash gemspec` regenerating the lock files tested with >>>v1.5.0
logstash date plugin what wrong provided two date format but only one seems to work despite all three lines are being matched briefly here is my config input stdin type defacetimestamp filter grok match message datestamp defacetimestamp timestamp iso8601 defacetimestamp date match defacetimestamp dd mm yyyy hh mm ss yyyy mm dd hh mm ss timezone utc if grokparsefailure in tags mutate remove field host version id type else if type defacetimestamp mutate add field malware type shd drone type remove field host version id type message output stdout codec rubydebug here is my input 09 03 2014 08 36 00 08 03 2014 05 44 00 2014 01 03 13 47 24 here is the output timestamp 2014 03 09t08 36 00 000z type defacetimestamp defacetimestamp 09 03 2014 08 36 00 timestamp 2014 03 08t05 44 00 000z type defacetimestamp defacetimestamp 08 03 2014 05 44 00 timestamp 0014 01 03t13 47 24 000z weird type defacetimestamp defacetimestamp 14 01 03 13 47 24 thanks>>>needs_details
cleanup the main repository before ga cleanup the repository bit gembag rb is not used anymore the download of the vendored files moved to their own specific gems >>>v1.5.0
grok should ignore tilde backup files when processing patterns dir this comes from the discussion of 2244 when testing config using grok and custom patterns user will often be editing pattern definition files in `patterns dir` between run attempts many most linux ey text editors create backup files named as the original filename plus suffix in the same location as the original even though they aren hidden these are often invisible by default in file browsers when dealing with multiple pattern definition files and especially when renaming them it possible to have lot of these tilde files lying around after while `grok` currently reads everything in `patterns dir` including any tilde backups it quite reasonably doesn define the order in which it reads them and it doesn warn if the definition of `mypattern` in stale `patterns or `previousfilename backup file overrides the definition of `mypattern` in `patterns` hilarity ensues also hair tearing teeth gnashing bad language and various other undesirable outcomes propose that `grok` should ignore any files in `patterns dir` ending in there may be other things it be beneficial to blacklist too but this seems like good start >>>enhancement
clean up integration test as they are now in separated gem this pr cleans up old integration testing code that is now living in their own gem https github com elasticsearch logstash integration testing in case you want to run integration testing you should import and run the previous gem into given installation fix 2168>>>v1.5.0
specify in doc and validate if config item allows sprintf format rework of 1517 for here is an idea following discussion on logstash user groups where someone tried to dynamicly set the host parameter of elasticsearch http output from event field this proposal tag the config items that can or cannot use dynamic value aka sprintf under the hood example done on the base filter and output>>>reviewing
mutate convert option is creating an extra field bin logstash filter mutate convert geoip coordinates float hello world message hello world version timestamp 2014 10 02t05 58 40 365z type stdin host oh my geoip >>>bug v1.5.0
logstash email smtp options documentation needs work the documentation around custom smtp connections on the outbound email connector is inadequate and inaccurate it appears it is cut and past from the ruby mail documentation and following does not result in working config more specifically the options block is listed as an hash but when using hash the options are ignored if however you encode those options as an array they do seem to work but there is no example in the documentation that suggests this is the case what is there suggests it should be hash documentation suggests that this works options smtpiporhost gmail com it does not however this does work options smtpiporhost gmail com also some of the older versions of this documentation are worse and don even state the config value name correctly instead refer to address while the code clearly references smtpiporhost this was tested using 2>>>docs
fix start exit value for logstash web init script without this fix the init script does not exit cleanly when start succeeds looks like it the same fix that was applied to logstash sysv earlier this year >>>missing_cla
developing plugins for logstash v1 since the new plugin mechanism with v1 where the plugins are fetched from rubygems for development what would be the proper way running debugging my own plugin without posting to rubygems for every change >>>docs v1.5.0
any plan to eval merge outstanding contrib plugin pull requests before starting yet another project after reading this http www elasticsearch org blog plugin ecosystem changes see that there is now yet another copy of the plugins projects and there are still 25 issues and 70 outstanding pull requests from the old logstash contrib project https github com elasticsearch logstash contrib why not merge these in before starting yet this second version of the plugins isn this going to lead to more confusion with everyone fixes contributions that will now be orphaned >>>question
first steps out of synch with release first line in getting started guide is bin logstash input stdin output stdout that does not work because the commands have changed the documentation does not reflect that >>>needs_details
filter multiline moving https logstash jira com browse logstash 631 to github rails production log has two empty lines in between each event my multiline filter with pattern is not matching and know for sure have two newlines here is the filter tried which isn working with typical rails production log multiline type rails prod log pattern negate true what previous the following works but isn quite what want multiline type rails prod log pattern negate true what previous the reason sometimes an event stacktrace has broken single empty line with one newline character in it in between the stacktrace wouldn want to split that stacktrace into two separate events so need to match on two newlines ie appreciate work around for now until version comes out thanks navid confirmed still occuring in >>>question
logstash1 removing tag in filter fails with undefined method delete upgraded to 5beta1 to test out functionality attempting to remove tag fails below is snippet from my configuration filter configuration filter if program services monitor and message current memory used by supervisor grok patterns dir etc logstash patterns dellpatterns match message current memory used by supervisor data data process number memusedkb int remove tag logs add tag state failure message exception in filterworker exception backtrace opt logstash lib logstash filters base rb 198 in `filter matched org jruby rubyarray java 1613 in `each opt logstash lib logstash filters base rb 193 in `filter matched opt logstash vendor bundle jruby gems logstash filter grok lib logstash filters grok rb 287 in `filter eval 187175 in `initialize org jruby rubyarray java 1613 in `each org jruby rubyenumerable java 805 in `flat map eval 187171 in `initialize org jruby rubyarray java 1613 in `each org jruby rubyenumerable java 805 in `flat map eval 187168 in `initialize org jruby rubyarray java 1613 in `each org jruby rubyenumerable java 805 in `flat map eval 187129 in `initialize org jruby rubyproc java 271 in `call opt logstash lib logstash pipeline rb 268 in `filter opt logstash lib logstash pipeline rb 206 in `filterworker opt logstash lib logstash pipeline rb 150 in `start filters level error thank you >>>blocker bug v1.5.0
logstash stops working if pagerduty output encounters errors our logstash environment has been taken down couple times this week due to misconfiguration in one of our config files with the pagerduty output it took us long time to identify the issue wondering if there is any way to prevent this going forward or at least an easier way to pinpoint what is causing the issue in the future we typically process 000 000 msgs per hour we use the pagerduty output pretty heavily but always use the throttle filter to make sure we are not sending too many messages to pd pd has rate limiting which will start rejecting requests if you send it more that 60 in minute we misconfigured the throttle config in one of our files which resulted in us trying to send large number of requests to pd really quickly it appears this is what crippled our environment and took us down to 000 msgs per hour we are assuming pagerduty started rejecting requests from our pagerduty output which resulted in the logstash queue getting filled up which stopped us from grabbing messages from redis for processing is there way to configure the pagerduty output to prevent this type of issue also is it possible to view the status of the logstash queues or even see which messages are currently in the queue this would have allowed us to identify and solve the issue much more quickly thanks>>>design v2.0.0
refactor doc generation use generic task for installing all plugins use refactored bundle install task>>>v1.5.0
add doc generation tasks to logstash this is required for the automated asciidoc generation job in jenkins rake docs generation generates all the documentation and index files for the plugins >>>v1.5.0
dependency rake tasks run twice and take too long wrapped the task call with `puts time now` and two things are not right prints occur the task is executed twice the task itself takes seconds while the execution is 14 seconds long >>>bug needs_details
failed to deserialize exception response from streamrepeat log4j 2014 12 17t17 36 26 739 warn org elasticsearch discovery zen ping unicast growing man failed to send ping to zen unicast inet 127 9300 org elasticsearch transport remotetransportexception failed to deserialize exception response from stream caused by org elasticsearch transport transportserializationexception failed to deserialize exception response from stream 	at org elasticsearch transport netty messagechannelhandler handlerresponseerror messagechannelhandler java 168 	at org elasticsearch transport netty messagechannelhandler messagereceived messagechannelhandler java 122 	at org elasticsearch common netty channel simplechannelupstreamhandler handleupstream simplechannelupstreamhandler java 70 	at org elasticsearch common netty channel defaultchannelpipeline sendupstream defaultchannelpipeline java 564 	at org elasticsearch common netty channel defaultchannelpipeline defaultchannelhandlercontext sendupstream defaultchannelpipeline java 791 	at org elasticsearch common netty channel channels firemessagereceived channels java 296 	at org elasticsearch common netty handler codec frame framedecoder unfoldandfiremessagereceived framedecoder java 462 	at org elasticsearch common netty handler codec frame framedecoder calldecode framedecoder java 443 	at org elasticsearch common netty handler codec frame framedecoder messagereceived framedecoder java 303 	at org elasticsearch common netty channel simplechannelupstreamhandler handleupstream simplechannelupstreamhandler java 70 	at org elasticsearch common netty channel defaultchannelpipeline sendupstream defaultchannelpipeline java 564 	at org elasticsearch common netty channel defaultchannelpipeline sendupstream defaultchannelpipeline java 559 	at org elasticsearch common netty channel channels firemessagereceived channels java 268 	at org elasticsearch common netty channel channels firemessagereceived channels java 255 	at org elasticsearch common netty channel socket nio nioworker read nioworker java 88 	at org elasticsearch common netty channel socket nio abstractnioworker process abstractnioworker java 109 	at org elasticsearch common netty channel socket nio abstractnioselector run abstractnioselector java 312 	at org elasticsearch common netty channel socket nio abstractnioworker run abstractnioworker java 90 	at org elasticsearch common netty channel socket nio nioworker run nioworker java 178 	at org elasticsearch common netty util threadrenamingrunnable run threadrenamingrunnable java 108 	at org elasticsearch common netty util internal deadlockproofworker run deadlockproofworker java 42 	at java util concurrent threadpoolexecutor runworker threadpoolexecutor java 1145 	at java util concurrent threadpoolexecutor worker run threadpoolexecutor java 615 	at java lang thread run thread java 745 caused by java io invalidclassexception failed to read class descriptor 	at java io objectinputstream readnonproxydesc objectinputstream java 1603 	at java io objectinputstream readclassdesc objectinputstream java 1517 	at java io objectinputstream readnonproxydesc objectinputstream java 1622 	at java io objectinputstream readclassdesc objectinputstream java 1517 	at java io objectinputstream readnonproxydesc objectinputstream java 1622 	at java io objectinputstream readclassdesc objectinputstream java 1517 	at java io objectinputstream readnonproxydesc objectinputstream java 1622 	at java io objectinputstream readclassdesc objectinputstream java 1517 	at java io objectinputstream readordinaryobject objectinputstream java 1771 	at java io objectinputstream readobject0 objectinputstream java 1350 	at java io objectinputstream readobject objectinputstream java 370 	at org elasticsearch transport netty messagechannelhandler handlerresponseerror messagechannelhandler java 166 23 more caused by java lang classnotfoundexception org elasticsearch elasticsearchexception 	at java net urlclassloader run urlclassloader java 366 	at java net urlclassloader run urlclassloader java 355 	at java security accesscontroller doprivileged native method 	at java net urlclassloader findclass urlclassloader java 354 	at org jruby util jrubyclassloader findclass jrubyclassloader java 92 	at java lang classloader loadclass classloader java 425 	at java lang classloader loadclass classloader java 358 	at org elasticsearch common io throwableobjectinputstream loadclass throwableobjectinputstream java 93 	at org elasticsearch common io throwableobjectinputstream readclassdescriptor throwableobjectinputstream java 67 	at java io objectinputstream readnonproxydesc objectinputstream java 1601 34 more elasticsearch lucene logstash java version 55>>>needs_details
bug whitelist name in prune filter hi everyone have problem with the whitelist of prune filter don know if this filter has some bug want to insert some fields in elasticsearch and the logstash insert more fields thanks>>>needs_details v1.5.0
the bin plugin is not working due to version inconsistency tried to do bin plugin install contrib it downloaded byte file logstash contrib modified tar gz the file name was based on the string pulled from lib logstash version rb which is logstash version modified this needs to be logstash version the error is in the logstash 2c0f5a1 all packages >>>v1.4.3
fix docgen with correct path to gem s>>>blocker docs reviewing v1.5.0
email output plugin keeps only last options have this config for logstash output section as it happens logstash tries to send all messages to smsgateway addr lz it looks as if only the last config override of the plugin is kept how can use different mail server for different conditions thank you >>>bug
issue with elasticsearch input plugin for logstash hello all am running into an issue when using the elasticsearch input plugin for logstash would like to retrieve information on various node statistics so in the input plugin specify the index to be nodes local stats however this causes an error plugin had an unrecoverable error will restart this plugin plugin xx xx 228 80 index nodes local stats query scroll 1m error undefined method `bytesize for nil nilclass exception nomethoderror stack opt logstash vendor bundle jruby gems ftw 39 lib ftw http message rb 65 in `body opt logstash vendor bundle jruby gems ftw 39 lib ftw agent rb 298 in `request opt logstash vendor bundle jruby gems ftw 39 lib ftw agent rb 217 in `post opt logstash lib logstash inputs elasticsearch rb 97 in `run opt logstash lib logstash pipeline rb 163 in `inputworker opt logstash lib logstash pipeline rb 157 in `start input level error file logstash pipeline rb line 168 believe the issue is because the input plugin always adds the search field at the end of the url possible solution to this issue could be to make the search field an optional parameter for instance could specify search false in the input file and it would omit the search parameter from the url in the plugin there may also be other checks in the plugin that does not allow for this type of querying so other changes may have to be made to support this use case >>>question
logstash does not properly pick up the last position in file on restart symptom logstash misses log events when using the file input if the logstash process is restarted or stops unexpectedly and is restarted it appears that the sincedb file is not being utilized on startup utilizing start from beginning will result in duplicate data and is not the intended behavior it should pick up the log from the last read position when re starting logstash version reproduction input file path tmp log sincedb path tmp logstash sincedb start logstash append data to multiple logs in the directories being scanned stop logstash append additional data to logs this data will be missing including all data appended to the logs while logstash is starting start logstash append additional data to logs eventually the logs will be read from the end again >>>bug
move vendor part to file dependencies gem>>>blocker v1.5.0
updates docs to fix 2240 package urls in docs now use https to fix 2240 >>>missing_cla v1.5.0
ensure at least one semantic is there way to ensure at least one semantic in logstash want to be sure that no events are lost between input and output typical example is in input take message from queue send it to filters and output if output succeeds let say post message via http and success is 200 response then remove message from queue so message is removed from queue only if output successfully delivers this message and if something terrible happens logstash crashes destination for output is not available or behaves weird will never lose any data need to deliver >>>design enhancement v2.0.0
logstash problem message failed to flush outgoing items since couple of months ago experiencing problem with logstash in the logs have several error like the following have elasticsearch and logstash and the configuration for logstash is like this what is wrong is there any bug in logstash should upgrade it thanks in advance >>>needs_details
migrate life of an event to asciidoc>>>docs
install test plugin dependencies throw bundler every time we run the test there is test task named test prep that install the plugins throw the logstash command this makes the test slow because every new run it installs again the plugins this pr does this installation throw bundler like the others dependencies so each time we run the test we just pick the previous installation if is the case it also include an small refactoring having now only one task to run the bundler install command making things mode simple >>>v1.5.0
update jruby dependency to create workable build for openbsd jruby 17 includes several fixes which are needed in order to run on openbsd with 64 bit time openbsd and later there is still the issue of logstash 665 that also affecting openbsd but manually patching the files as suggested by aldian works around it >>>enhancement
fix running rake test after bootstrap the first time rake tasks can not find plugins installed throw the test prep task the first time it run by clearing the gem paths this pr fix 2219 so the rspec can find everything >>>bug v1.5.0
auto install missing plugins since contrib package will not be used with logstash would be nice to have logstash auto install any missing plugins that exist in the config >>>enhancement v2.0.0
dry the gem installation rake tasks both `vendor rake` and `plugin rake` use the same code logic for installing gems this should be dry ed up >>>enhancement v1.5.0
add bundler reset method which fixes the lock file updates this fixes the lock file updating upon running the rake tasks which install the gem dependencies>>>bug v1.5.0
create getting started template example input filter output plugins we should provide example input filter output plugins developers can start with to bootstrap their dev environment >>>enhancement
exclude rake files from artifacts addresses https github com elasticsearch logstash issues 2220>>>enhancement reviewing v1.5.0
removes the patterns from patterns dir the core patterns are now provided by the logstash patterns core gem this empty folder can be used for custom patterns after https github com logstash plugins logstash filter grok pull is merged in the logstash filter grok plugin this also fixes 2225>>>enhancement reviewing v1.5.0
the logstash ruby plugin documentation is incomplete the ruby plugin documentation http www elasticsearch org guide en logstash current plugins filters ruby html is incomplete and only documents the basic configuration option details specifically the code configuration option is the most important part of the configuration options but it is one of the least documented options issues there are no links to documentation or logstash code that describes what the event variable is or even what type of variable it is we can assume it some sort of hash or object based on the single example but other than that there are no details what attributes or methods are available is it immutable can you alter the contents of other fields what constraints are placed on ruby code used with this plugin are there any special keywords that can not be used limits on methods used or any particular characters that need special escaping what happens when ruby code throws an exception does logstash silently drop the event or does the filter just fail simple link to the description of the event variable or wider range of examples may help solve several of these issues >>>docs v2.0.0
logstash plugin documentation renders very badly on mobile platforms the logstash plugin documenation http www elasticsearch org guide en logstash current filter plugins html in the newly released beta guide http www elasticsearch org guide en logstash current index html renders very badly on mobile platforms the lists in the middle and right side of the page overlap and are impossible to read and it very difficult to find and click the link you are looking for this happens for all plugins output filter and codec please won someone think of the mobile children >>>docs
logstash 50b1 custom patterns not read in at startup had to explicitly add in the patterns dir opt logstash150b1 patterns setting in all of my multiline and grok filters in order for my patterns to be read in during start up even though they were in the default patterns directory these were the errors seen in debug the error reported is pattern latimestamp not defined opt logstash150b1 vendor bundle jruby gems jls grok 11 lib grok pure rb 121 in `compile org jruby rubykernel java 1501 in `loop opt logstash150b1 vendor bundle jruby gems jls grok 11 lib grok pure rb 91 in `compile opt logstash150b1 vendor bundle jruby gems logstash filter multiline lib logstash filters multiline rb 150 in org jruby rubyarray java 1613 in `each opt logstash150b1 lib logstash pipeline rb 148 in `start filters opt logstash150b1 lib logstash pipeline rb 78 in `run opt logstash150b1 lib logstash agent rb 141 in `execute opt logstash150b1 lib logstash runner rb 166 in `run org jruby rubyproc java 271 in `call opt logstash150b1 lib logstash runner rb 171 in `run org jruby rubyproc java 271 in `call opt logstash150b1 vendor bundle jruby gems stud 18 lib stud task rb 12 in `initialize >>>bug v1.5.0
add newer than option to file input trying to use the logstash file input to ingest logs the directory structure is as follows logs yyyy mm dd it would be nice to be able to have newer than option in order to limit what files are ingested either by the file date timestamp or via an expression to parse out the date timestamp from the file name it would also be nice if it could handle relative dates as in 5d for anything new in the last days etc thanks >>>enhancement v2.0.0
forced to kill logstash process hi trying to parse 500 lines csv file there must be something wrong in my file because everytime launch the logstash script to parse the process stops working and gets stuck indefinitely if press ctrl it still holds in the same status the only way to stop the process is the inglourious kill below pasted two different debug outputs had on two different runs any help thanks regards marco first debug output message is not truncated bd connection count batch timeout force true final nil level debug file stud buffer rb line 207 cinterrupt received shutting down the pipeline level warn file logstash agent rb line 119 sending shutdown signal to input thread thread level info file logstash pipeline rb line 236 second debug output path message 2014 06 22 14 19 48 55905 12874 us california mountain view 	google public dns google com zeus dga get 80 yhdyhyjkjtgxnjucylremxwsto com version timestamp 2014 12 12t08 25 24 626z type botnet drone host marco path home marco csv drone path data message 2014 06 22 14 19 48 55905 12874 us california mountain view google public dns google com zeus dga get 80 yhdyhyjkjtgxnjucylremxwsto com version timestamp 2014 12 12t08 25 24 626z type botnet drone host marco path home marco csv drone cancelled false level debug file logstash filters grok rb line 280 log4j java properties setup log4j level debug level debug file logstash logging rb line 87 log4j 2014 12 12t09 25 26 431 info org elasticsearch node logstash marco 4561 4024 version pid 4561 build f1585f0 2014 04 16t14 27 12z log4j 2014 12 12t09 25 26 432 info org elasticsearch node logstash marco 4561 4024 initializing log4j 2014 12 12t09 25 26 432 debug org elasticsearch node logstash marco 4561 4024 using home home marco logstash bin config home marco logstash bin config data home marco logstash bin data logs home marco logstash bin logs work home marco logstash bin work plugins home marco logstash bin plugins log4j 2014 12 12t09 25 26 485 debug org elasticsearch plugins logstash marco 4561 4024 home marco logstash bin plugins directory does not exist log4j 2014 12 12t09 25 26 486 info org elasticsearch plugins logstash marco 4561 4024 loaded sites log4j 2014 12 12t09 25 26 548 debug org elasticsearch common compress lzf using unsafechunkdecoder decoder log4j 2014 12 12t09 25 30 601 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool generic type cached keep alive 30s log4j 2014 12 12t09 25 30 624 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool index type fixed size queue size 200 log4j 2014 12 12t09 25 30 640 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool bulk type fixed size queue size 50 log4j 2014 12 12t09 25 30 640 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool get type fixed size queue size 1k log4j 2014 12 12t09 25 30 641 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool search type fixed size queue size 1k log4j 2014 12 12t09 25 30 641 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool suggest type fixed size queue size 1k log4j 2014 12 12t09 25 30 641 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool percolate type fixed size queue size 1k log4j 2014 12 12t09 25 30 641 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool management type scaling min size keep alive 5m log4j 2014 12 12t09 25 30 642 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool flush type scaling min size keep alive 5m log4j 2014 12 12t09 25 30 647 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool merge type scaling min size keep alive 5m log4j 2014 12 12t09 25 30 647 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool refresh type scaling min size keep alive 5m log4j 2014 12 12t09 25 30 648 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool warmer type scaling min size keep alive 5m log4j 2014 12 12t09 25 30 648 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool snapshot type scaling min size keep alive 5m log4j 2014 12 12t09 25 30 648 debug org elasticsearch threadpool logstash marco 4561 4024 creating thread pool optimize type fixed size queue size null log4j 2014 12 12t09 25 30 755 debug org elasticsearch transport netty logstash marco 4561 4024 using worker count port 9300 9400 bind host null publish host null compress false connect timeout 30s connections per node receive predictor 512kb 512kb log4j 2014 12 12t09 25 30 779 debug org elasticsearch discovery zen ping unicast logstash marco 4561 4024 using initial hosts localhost 9300 localhost 9301 localhost 9302 localhost 9303 localhost 9304 localhost 9305 with concurrent connects 10 log4j 2014 12 12t09 25 30 795 debug org elasticsearch discovery zen logstash marco 4561 4024 using ping timeout 3s master election filter client true master election filter data false log4j 2014 12 12t09 25 30 800 debug org elasticsearch discovery zen elect logstash marco 4561 4024 using minimum master nodes log4j 2014 12 12t09 25 30 802 debug org elasticsearch discovery zen fd logstash marco 4561 4024 master uses ping interval 1s ping timeout 30s ping retries log4j 2014 12 12t09 25 30 855 debug org elasticsearch discovery zen fd logstash marco 4561 4024 node uses ping interval 1s ping timeout 30s ping retries log4j 2014 12 12t09 25 30 957 debug org elasticsearch monitor jvm logstash marco 4561 4024 enabled true last gc enabled false interval 1s gc threshold old gcthreshold name old warnthreshold 10000 infothreshold 5000 debugthreshold 2000 default gcthreshold name default warnthreshold 10000 infothreshold 5000 debugthreshold 2000 young gcthreshold name young warnthreshold 1000 infothreshold 700 debugthreshold 400 log4j 2014 12 12t09 25 30 963 debug org elasticsearch monitor os logstash marco 4561 4024 using probe org elasticsearch monitor os jmxosprobe 36963f with refresh interval 1s log4j 2014 12 12t09 25 30 965 debug org elasticsearch monitor process logstash marco 4561 4024 using probe org elasticsearch monitor process jmxprocessprobe 3417cc with refresh interval 1s log4j 2014 12 12t09 25 30 980 debug org elasticsearch monitor jvm logstash marco 4561 4024 using refresh interval 1s log4j 2014 12 12t09 25 30 981 debug org elasticsearch monitor network logstash marco 4561 4024 using probe org elasticsearch monitor network jmxnetworkprobe 822e10 with refresh interval 5s log4j 2014 12 12t09 25 30 995 debug org elasticsearch monitor network logstash marco 4561 4024 net info host marco eth0	display name eth0 		address fe80 a00 27ff fede 497a 10 24 32 29 		mtu 1500 multicast true ptp false loopback false up true virtual false lo	display name lo 		address 127 		mtu 16436 multicast false ptp false loopback true up true virtual false log4j 2014 12 12t09 25 31 003 debug org elasticsearch monitor fs logstash marco 4561 4024 using probe org elasticsearch monitor fs jmxfsprobe 1c27e82 with refresh interval 1s log4j 2014 12 12t09 25 31 772 debug org elasticsearch indices store logstash marco 4561 4024 using indices store throttle type merge with index store throttle max bytes per sec 20mb log4j 2014 12 12t09 25 31 809 debug org elasticsearch script logstash marco 4561 4024 using script cache with max size 500 expire null log4j 2014 12 12t09 25 31 824 debug org elasticsearch cluster routing allocation decider logstash marco 4561 4024 using node concurrent recoveries node initial primaries recoveries log4j 2014 12 12t09 25 31 832 debug org elasticsearch cluster routing allocation decider logstash marco 4561 4024 using cluster routing allocation allow rebalance with indices all active log4j 2014 12 12t09 25 31 836 debug org elasticsearch cluster routing allocation decider logstash marco 4561 4024 using cluster concurrent rebalance with log4j 2014 12 12t09 25 31 842 debug org elasticsearch gateway local logstash marco 4561 4024 using initial shards quorum list timeout 30s log4j 2014 12 12t09 25 31 944 debug org elasticsearch indices recovery logstash marco 4561 4024 using max bytes per sec 20mb concurrent streams file chunk size 512kb translog size 512kb translog ops 1000 and compress true log4j 2014 12 12t09 25 32 671 debug org elasticsearch indices memory logstash marco 4561 4024 using index buffer size 49 3mb with min shard index buffer size 4mb max shard index buffer size 512mb shard inactive time 30m log4j 2014 12 12t09 25 32 692 debug org elasticsearch indices cache filter logstash marco 4561 4024 using node weighted filter cache with size 20 actual size 98 7mb expire null clean interval 1m log4j 2014 12 12t09 25 32 706 debug org elasticsearch indices fielddata cache logstash marco 4561 4024 using size 1b expire null log4j 2014 12 12t09 25 32 797 debug org elasticsearch gateway local state meta logstash marco 4561 4024 using gateway local auto import dangled yes with gateway local dangling timeout 2h log4j 2014 12 12t09 25 32 807 debug org elasticsearch bulk udp logstash marco 4561 4024 using enabled false host null port 9700 9800 bulk actions 1000 bulk size 5mb flush interval 5s concurrent requests log4j 2014 12 12t09 25 32 813 debug org elasticsearch cluster routing allocation decider logstash marco 4561 4024 using node concurrent recoveries node initial primaries recoveries log4j 2014 12 12t09 25 32 819 debug org elasticsearch cluster routing allocation decider logstash marco 4561 4024 using cluster routing allocation allow rebalance with indices all active log4j 2014 12 12t09 25 32 819 debug org elasticsearch cluster routing allocation decider logstash marco 4561 4024 using cluster concurrent rebalance with log4j 2014 12 12t09 25 32 820 debug org elasticsearch cluster routing allocation decider logstash marco 4561 4024 using node concurrent recoveries node initial primaries recoveries log4j 2014 12 12t09 25 32 820 debug org elasticsearch cluster routing allocation decider logstash marco 4561 4024 using cluster routing allocation allow rebalance with indices all active log4j 2014 12 12t09 25 32 821 debug org elasticsearch cluster routing allocation decider logstash marco 4561 4024 using cluster concurrent rebalance with log4j 2014 12 12t09 25 32 855 info org elasticsearch node logstash marco 4561 4024 initialized log4j 2014 12 12t09 25 32 856 info org elasticsearch node logstash marco 4561 4024 starting log4j 2014 12 12t09 25 32 914 debug org elasticsearch netty channel socket nio selectorutil using select timeout of 500 log4j 2014 12 12t09 25 32 925 debug org elasticsearch netty channel socket nio selectorutil epoll bug workaround enabled false log4j 2014 12 12t09 25 33 105 debug org elasticsearch transport netty logstash marco 4561 4024 bound to address 9301 log4j 2014 12 12t09 25 33 108 info org elasticsearch transport logstash marco 4561 4024 bound address inet 9301 publish address inet 10 24 32 29 9301 log4j 2014 12 12t09 25 33 205 debug org elasticsearch transport netty logstash marco 4561 4024 connected to node zen unicast marco inet localhost 127 9301 log4j 2014 12 12t09 25 33 205 debug org elasticsearch transport netty logstash marco 4561 4024 connected to node zen unicast marco inet localhost 127 9300 log4j 2014 12 12t09 25 36 170 debug org elasticsearch transport netty logstash marco 4561 4024 disconnected from zen unicast marco inet localhost 127 9300 log4j 2014 12 12t09 25 36 172 debug org elasticsearch transport netty logstash marco 4561 4024 disconnected from zen unicast marco inet localhost 127 9301 log4j 2014 12 12t09 25 36 180 debug org elasticsearch discovery zen logstash marco 4561 4024 filtered ping responses filter client true filter data false target james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 master james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 log4j 2014 12 12t09 25 36 194 debug org elasticsearch transport netty logstash marco 4561 4024 connected to node james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 log4j 2014 12 12t09 25 36 375 debug org elasticsearch discovery zen fd logstash marco 4561 4024 master starting fault detection against master james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 reason initial join log4j 2014 12 12t09 25 36 424 debug org elasticsearch discovery zen publish logstash marco 4561 4024 received cluster state version 159 log4j 2014 12 12t09 25 36 428 debug org elasticsearch discovery zen logstash marco 4561 4024 received cluster state from james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 which is also master but with cluster name cluster elasticsearch log4j 2014 12 12t09 25 36 459 debug org elasticsearch cluster service logstash marco 4561 4024 processing zen disco receive from master james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 execute log4j 2014 12 12t09 25 36 481 debug org elasticsearch cluster service logstash marco 4561 4024 got first state from fresh master rn d53m5tpmvozkaac6gtg log4j 2014 12 12t09 25 36 482 debug org elasticsearch cluster service logstash marco 4561 4024 cluster state updated version 159 source zen disco receive from master james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 log4j 2014 12 12t09 25 36 483 info org elasticsearch cluster service logstash marco 4561 4024 detected master james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 added james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 reason zen disco receive from master james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 log4j 2014 12 12t09 25 36 483 debug org elasticsearch cluster service logstash marco 4561 4024 set local cluster state to version 159 log4j 2014 12 12t09 25 36 503 info org elasticsearch discovery logstash marco 4561 4024 elasticsearch xs94rcqhqta31uy3 opbqq log4j 2014 12 12t09 25 36 508 debug org elasticsearch cluster service logstash marco 4561 4024 processing zen disco receive from master james rhodes rn d53m5tpmvozkaac6gtg marco inet 10 24 32 29 9300 done applying updated cluster state version 159 log4j 2014 12 12t09 25 36 508 debug org elasticsearch cluster service logstash marco 4561 4024 processing updating local node id execute log4j 2014 12 12t09 25 36 508 debug org elasticsearch cluster service logstash marco 4561 4024 cluster state updated version 159 source updating local node id log4j 2014 12 12t09 25 36 508 debug org elasticsearch cluster service logstash marco 4561 4024 set local cluster state to version 159 log4j 2014 12 12t09 25 36 510 info org elasticsearch node logstash marco 4561 4024 started log4j 2014 12 12t09 25 36 514 debug org elasticsearch cluster service logstash marco 4561 4024 processing updating local node id done applying updated cluster state version 159 new elasticsearch output cluster nil host localhost port 9300 9305 embedded false protocol node level info file logstash outputs elasticsearch rb line 252 automatic template management enabled manage template true level info file logstash outputs elasticsearch rb line 258 using mapping template template type geo point level info file logstash outputs elasticsearch rb line 278 cinterrupt received shutting down the pipeline level warn file logstash agent rb line 119 sending shutdown signal to input thread thread level info file logstash pipeline rb line 236 caller requested sincedb write level debug file filewatch tail rb line 185 caller requested sincedb write level debug file filewatch tail rb line 185 >>>needs_details
dry logstash util zeromq rb in zeromq output and filter plugins both plugins have copy of the same `logstash util zeromq rb` file >>>enhancement
add creation of zipfile for the artifacts>>>enhancement v1.5.0
running rake on generated tarball invokes vendor jruby `rake t` should list available rake tasks but instead executes `vendor jruby` which downloads jruby >>>blocker bug needs_details v1.5.0
rake test can find plugins on the first run running `rake bootstrap rake test` will install the plugins but the spec run will complain about the plugins missing running `rake test` again will reinstall all plugins and then tests pass >>>bug
expand attributes in listingblocks sync to logstash docs version asciidoc requires special configuration in order to expand attributes version numbers within listingblocks in addition this will sync the version of this doc to be the same as the version in the logstash docs repo sigh >>>v1.5.0
rabbitmq queues get deleted no matter what on shutdown hi as much as we love logstash elasticsearch shipping with logstash forwarder logstash has proven to be quite unreliable logstash getting overwhelmed quickly and some race condition bounding connections logs lost today we tested moving messages though beaver rabbitmq logstash the latter approach in theory should let us to process any number of logs horizontally scaling on aws and remove spof idea is to have beavers ship to rabbitmq cluster another dynamic logstash cluster would consume the messages and ship to yet another elasticsearch cluster when any one thing gets to small we can always adjust it by simply adding machines the problem we found is that the logs from the rabbitmq input vanish into thin air error message that we get when we kill logstash perhaps not relevant configuration is following another problem is that the messages have been set to ack but seam to be vanishing into thin air not word in the logs but getting acked before being shipped of anywhere the same logstash agent is working with several lumberjack inputs that are moving logs to elasticsearch just fine and the format is the same as am testing on machine that normally has logstash forwarder running on it on side note logstash is restarting lot without any log entry or apparent cause please advise >>>needs_details v1.5.0
rabbitmq input output default codec in your documentation the default codec is `plain` but in your code it `json` >>>bug
s3 input nomethoderror using with s3 input and the following configuration my config input s3 bucket mybucket withadirectory credentials id key codec json output stdout codec rubydebug bucket contents s3cmd ls s3 mybucket withdirectory 2014 11 24 21 43 s3 mybucket withdirectory 2014 12 08 07 45 729126 s3 mybucket withdirectory samplefilefortesting gz error pipeline started level info file logstash pipeline rb line 78 plugin had an unrecoverable error will restart this plugin plugin mybucket withdirectory credentials xyz zyx region endpoint us west error undefined method `common prefixes for hash exception nomethoderror stack home test logstash vendor bundle jruby gems aws sdk 35 lib aws core data rb 101 in `method missing home test logstash vendor bundle jruby gems aws sdk 35 lib aws core data rb 121 in `method missing home test logstash vendor bundle jruby gems aws sdk 35 lib aws core response rb 184 in `method missing home test logstash vendor bundle jruby gems aws sdk 35 lib aws s3 prefix and delimiter collection rb 31 in `each member in page home test logstash vendor bundle jruby gems aws sdk 35 lib aws s3 object collection rb 288 in `each member in page home test logstash vendor bundle jruby gems aws sdk 35 lib aws s3 paginated collection rb 31 in each item home test logstash vendor bundle jruby gems aws sdk 35 lib aws core collection with limit and next token rb 54 in each batch home test logstash vendor bundle jruby gems aws sdk 35 lib aws core collection rb 80 in `each batch home test logstash vendor bundle jruby gems aws sdk 35 lib aws core collection rb 47 in `each home test logstash vendor bundle jruby gems aws sdk 35 lib aws s3 object collection rb 282 in `each home test logstash lib logstash inputs s3 rb 168 in `list new home test logstash lib logstash inputs s3 rb 150 in `process new home test logstash lib logstash inputs s3 rb 137 in `run org jruby rubykernel java 1521 in `loop home test logstash lib logstash inputs s3 rb 136 in `run home test logstash lib logstash pipeline rb 163 in `inputworker home test logstash lib logstash pipeline rb 157 in `start input level error file logstash pipeline rb line 168 >>>bug
gem paths fixes and refactor this is based on ph pr 2200 this has been tested using jruby as the default interpreter with this has not been tested with mri as the default interpreter >>>v1.5.0
missing `artifact zip` rake target >>>enhancement v1.5.0
jsonparsefailure being added to messages that seem to be parsed correctly have json input configured like this the json message itself looks like this when this message is sent to logstash it is being parsed correctly but the tag jsonparsefailure` is still being added here screenshot from kibana kibana response codes https cloud githubusercontent com assets 79502 5345672 3a0d1274 7f22 11e4 933f 7bc7b8df8ff0 png >>>bug
warning about overriding patterns when using hash syntax in grok filter as grok filter match can now use hash syntax switched from filter grok match message pattern1 message pattern2 message pattern3 to no comma paradise filter grok match message pattern1 message pattern2 message pattern3 however this is internally interpreted as hash so it only keeps the last pattern in the final config either it is bug or friendly warning in grok is required for dummies>>>docs enhancement v2.0.0
logstash and monolog formatter am using the monolog logstashformater to create my logs than want to insert it in to my logstash here is an example of log created by monolog timestamp 2014 12 08t09 07 54 810335 00 00 source devserver fields channel orderlogger level 100 ctxt site roulette ctxt country uk ctxt type virtual message order tags orderlogger type core it is built good for logstash now load the logstash with this config input stdin output stdout codec rubydebug but now try to paste the created log from monolog and get this message channel orderlogger level 100 ctxt site roulette ctxt country uk ctxt type virtual message order tags orderlogger type core version timestamp 2014 12 08t09 08 24 800z host logstash so as you can see logstash didn parse it right it simply place all the string inside the message any ideas >>>needs_details
gems installed via `rake bootstrap` are not available during pipeline runtime gems installed during `rake bootstrap` process end up in ls home build bootstrap gems` and are not available when running ls pipeline see >>>blocker v1.5.0
date filter issues could not use log date date filter did not work for me on netscreen firewall logs and this is my config input tcp type ns5400 port 3333 filter if type ns5400 grok match message netscreensessionlog date match date mmm dd hh mm ss timezone asia riyadh locale en sa output stdout codec rubydebug elasticsearch embedded true >>>needs_details
unexplained behaviour without debug command line argument am using logstash elasticsearch kibana with input from nxlog on windows computer my configuration is such that nxlog is communicating to logstash on tcpip channels output om tcp hence my logstash config is listening on tcp servers my logstash filter is broken into sections via if type xxxx sections all sections are rather complex output is to elasticsearch stdout rubydebug codec and to file during testing it was observed that processing of input would stop after some time and data was not being inserted into elasticsearch further testing revealed that output to elasticsearch was failing halted yet output to file would continue as long as input was being provided this behaviour was found to be true for one of the logstash inputs for what it worth the filter uses the xml filter after further testing it has been determined that running logstash with the debug argument does not cause any issues note have not run tests to determine whether or not the issue is true with the other inputs perhaps the issue is caused by the xml filter don know this yet any feedback is greatly appreciated >>>unconfirmed
missing unit in documentation for discover interval file input plugin documentation for the file input plugin does not specify what unit discover interval is in http logstash net docs inputs file discover interval value type is number default value is 15 how often we expand globs to discover new files to watch sincedb write interval does specify unit in second stat interval does not >>>docs v1.5.0
create empty etc logstash conf directory fixes 2188 >>>v1.5.0
using logstash with elasticsearch percolators it would be awesome if there were way to feed logstash events into the elasticsearch percolator envision this as being filter the filter would feed events to the percolator and then could use the responses which include both the matching query and the document with conditionals to tag events and or inject new events into the logstash pipeline >>>discuss enhancement
abort artifact if plugin installation fails closes 2174 uses the same strategy as https github com elasticsearch logstash blob master rakelib vendor rake l254>>>v1.5.0
reinstate standalone flag and remove bundle in vendor task the standalone flag during rake bootstrap is needed to generate the bundler setup rb flag however that generates tools bundle config file that sets the bundle path and will later mess with `rake plugin install defaults` forcing all plugins to be installed in vendor bundle instead of vendor plugins setting path in `rake plugin install defaults` isn an option because then gems from vendor bundle will not be reused generating many duplication and some installation errors the only option could find was to remove the bundle dir after running `rake vendor` bundle install closes 2183 >>>v1.5.0
loaderror no such file to load error while running rake artifact tar plugin installing plugin logstash filter clone loaderror no such file to load var lib jenkins workspace logstash vendor bundle bundler setup require at org jruby rubykernel java 1065 require at var lib jenkins workspace logstash vendor jruby lib ruby shared rubygems core ext kernel require rb 55 set gem paths at var lib jenkins workspace logstash lib logstash environment rb 42 root at var lib jenkins workspace logstash lib logstash runner rb rake aborted >>>blocker reviewing v1.5.0
add beta1 changelog this replaces https github com elasticsearch logstash pull 2161>>>blocker v1.5.0
update pipeline to call teardown of output workers when workers fixes https github com elasticsearch logstash issues 2178>>>reviewing v1.5.0
timestamp performance improvement the `timestamp to json` method was very very slow this fix improves json serialization performance also added cleanup and performance improvement to `event to s`>>>v1.5.0
output workers do not gracefully teardown tearing down an output plugin worker does not tear down any worker threads it spawned to further parallelize its outputing>>>enhancement v1.5.0
add generic support for retrying events in output plugins currently there is no general supported way to effect retry policy in an output plugin this is being done in https github com logstash plugins logstash output elasticsearch pull it would be nice if there was general retry buffer for plugins to insert into and call to flush upon their own retry policy for each specific use case >>>design enhancement
let maven tools get latest fixes in present the latest release of maven tools fixes regression where some of our java dependent plugins would fail to build because of our naming convention for the apache license string silly now that the fix for this regression is present in rubygems no need to lock the version to 5>>>v1.5.0
`rake artifact tar` succeeds even if an internal `bundle install` fails >>>bug reviewing v1.5.0
tcp output not adding lf 0x0a at the end of line tring to use tcp output logstash but even if the documentation says each event json is separated by newline it seems that lf is not added looking at the code it seems that the part is commented out am doing something wrong >>>bug v1.5.0
frequent broken pipe exceptions while using tcp or syslog inputs the plugins seem to break down frequently and then recover even if only client is accessing them at any time furthermore even when logstash is started it does not show up as listening in the netstat all tcp command strangely enough udp does have not been able to find documentation as to how to enable some logging for logstash so can provide more useful information >>>bug
fix bootstrap process duplicate gems and maven issue during `rake bootstrap` or `rake artifact tar` gems were being installed more than once since the gem path environment variable wasn set to cover all sources of gem directories pinning maven tools to works around https github com torquebox maven tools pull move plugins gemfile to `tools gemfile plugins`>>>bug enhancement v1.5.0
avoid use of and and or in ruby code this is an internal code quality improvement not feature for logstash itself the reason behind this is that and `and` similarily and `or` have very different orders of operations `and` is very late best to avoid >>>ruby_style_guide
remove test integration since it has been moved into elasticsearch logstash integration testing relates to 2150 2157 >>>enhancement v1.5.0
remove spool codec from default plugins this plugin is to be deleted and thus doesn make sense to have it installed by default more on why here https github com logstash plugins logstash codec spool issues 1>>>enhancement v1.5.0
fix acceptance>>>v1.5.0
please garbage collect few obsolete prs 1993 codec removed in 1099 already fixed in 1164 1232 makefile is dead 1234 obsolete with 1245 obsolete with 1027 obsolete with 1845 superseed by https github com logstash plugins logstash input pipe pull 1266 replaced by 2164 1457 already fixed and some obsolete duplicate issues 1265 issue related to 1266 covered by 2164 1464 fixed in by 769 1615 covered by https github com logstash plugins logstash filter date pull 1502 fixed by 1354 1602 inactive question 1659 inactive question 1662 duplicate of 1709 1733 answered 2057 covered by 2164 1917 answered 1862 anwered in googlegroups>>>question
doc correct links to plugin sources>>>v1.5.0
echo something to stdout when ls has successfully started for the first time in ages today called the logstash binary directly however it not clear when it has actually started unless you use the or vv flags eg only got response after hit enter it be good to have something echoed out saying logstash now running or whatever to let the user know it started similar to when it shuts down >>>enhancement v1.5.0
add missing var directories in rpm deb packages>>>v1.5.0
cant find var lib logstash when installing the debian package on ubuntu 14 04>>>blocker v1.5.0
add var log logstash as an empty directory testing deb package dpkg build logstash dev all deb grep var log logstash drwxrwxr 2014 12 01 22 29 var log logstash testing rpm package rpm qvlp build logstash dev noarch rpm grep var log logstash drwxrwxr root root dec 22 34 var log logstash fixes 2146>>>needs_tests reviewing v1.5.0 work_in_progress
file input throws exception when reading files with japanese file name hi it is logstash when configure the logstash to read file with japanese file name it throws error can anyone succeed to read file with non ascii file name by file input japanese content has no issue masashi nakane>>>v1.5.1
logstash metrics plugin in does metrics plugin actually work in cannot make it output any rates or count generator type generated filter metrics meter events add tag metric output stdout codec line format rate events count stdout codec rubydebug all get is rate events count message hello world version timestamp 2014 12 01t21 35 11 195z type generated host servername sequence 10 events tried both on windows and linux with no success >>>bug
logstash error hallo there getting the following error in the log file of logstash when kibana is trying to open connect with elasticsearch and for kibana get blank page adim suricata tail var log logstash logstash log at org elasticsearch common netty bootstrap clientbootstrap connect clientbootstrap java 229 at org elasticsearch common netty bootstrap clientbootstrap connect clientbootstrap java 182 at org elasticsearch transport netty nettytransport connecttochannelslight nettytransport java 680 at org elasticsearch transport netty nettytransport connecttonode nettytransport java 643 at org elasticsearch transport netty nettytransport connecttonodelight nettytransport java 610 at org elasticsearch transport transportservice connecttonodelight transportservice java 133 at org elasticsearch discovery zen ping unicast unicastzenping run unicastzenping java 279 at java util concurrent threadpoolexecutor runworker threadpoolexecutor java 1145 at java util concurrent threadpoolexecutor worker run threadpoolexecutor java 615 at java lang thread run thread java 745 log4j 2014 12 01t21 32 11 551 warn org elasticsearch transport netty logstash suricata 21556 4012 exception caught on transport layer id 0x95f6a5cf closing connection java nio channels unresolvedaddressexception at sun nio ch net checkaddress net java 127 at sun nio ch socketchannelimpl connect socketchannelimpl java 644 at org elasticsearch common netty channel socket nio nioclientsocketpipelinesink connect nioclientsocketpipelinesink java 108 at org elasticsearch common netty channel socket nio nioclientsocketpipelinesink eventsunk nioclientsocketpipelinesink java 70 at org elasticsearch common netty channel defaultchannelpipeline senddownstream defaultchannelpipeline java 574 at org elasticsearch common netty channel channels connect channels java 634 at org elasticsearch common netty channel abstractchannel connect abstractchannel java 207 at org elasticsearch common netty bootstrap clientbootstrap connect clientbootstrap java 229 at org elasticsearch common netty bootstrap clientbootstrap connect clientbootstrap java 182 at org elasticsearch transport netty nettytransport connecttochannelslight nettytransport java 680 at org elasticsearch transport netty nettytransport connecttonode nettytransport java 643 at org elasticsearch transport netty nettytransport connecttonodelight nettytransport java 610 at org elasticsearch transport transportservice connecttonodelight transportservice java 133 at org elasticsearch discovery zen ping unicast unicastzenping run unicastzenping java 279 at java util concurrent threadpoolexecutor runworker threadpoolexecutor java 1145 at java util concurrent threadpoolexecutor worker run threadpoolexecutor java 615 at java lang thread run thread java 745 log4j 2014 12 01t21 32 13 482 warn org elasticsearch monitor jvm fan boy gc young 324 691 duration 3s collections 6s total 3s 7m memory 78 8mb 77 3mb 491 6mb all pools young 8mb 68 2kb 66 5mb survivor 325 6kb 402 7kb 3mb old 76 7mb 76 9mb 416 8mb the version that using is logstash 2c0f5a1 all kibana elasticsearch plz help>>>needs_details
pipeline stops processing events because of exception in filterworker getting the following error in the logstash log and when it happens the pipeline stops processing events the error does not seems to be related to some specific input sometimes the log is generated but the pipeline processing continues some info about the environment command line my config >>>bug dead-letter-queue needs_details
plugins https ssl options inconsistencies we should probably look into using standard config option for using the `https` `ssl` protocol did little survey and this is what we currently use protocol http https logstash output elasticsearch ec2 ssl boolean logstash output elasticsearch ssl boolean logstash input rabbitmq proto http https logstash output loggly ssl enable boolean logstash input tcp ssl boolean logstash output redmine enable ssl boolean logstash output riak suggest we standardize on ssl >>>breaking-compatibility enhancement v3.0.0
add test to sprintf to cover metadata support was migrating config files to the new metadata feature after looking at the tests saw we did not have any test to cover metadata and sprintf interpolation >>>v1.5.0
packages missing creation of var log logstash currently the packages deb rpm don create the var log logstash directory which causes failures at startup >>>blocker v1.5.0
filter clone documentation optional option clones seems not to be optional treid the clone filter without giving the `clones` option and was hoping that it would create clones with the same type as the original event but no clones were created clone add tag cloned icinga alert using the following clones are created clone add tag cloned icinga alert clones clone maybe misread the documentation because both configurations get through the `configtest`of logstash but since the first example doesn do anything would have liked at least hint that it won do anything >>>docs v2.0.0
codec on event api change this pr patches only `lib logstash codecs base rb` the rest of the changes have been disseminated to individual plugin repos closes 1523 and replaces 1573>>>blocker reviewing v1.5.0
windows reload logstash agent on linux nodes logstash can read all configuration files under the conf directory there is no such option in windows limiting the configuration file to what specified when the agent is started if this problem is overcome how then do you tell the agent to reload the now multiple configuration file >>>enhancement windows
slim down the release artifacts unpacked tar of master branch at time of writing is pretty large this causes the package to be large 100mb unpacked size is 169mb comparatively v1 is 80mb duplicate files same checksum in package deduplication will shave 24mb see if we can ship release without dependency tests specifically spec and test directories in our dependency gems this accounts for about 10mb of data clean up large files there are more than 200 files over 50kb this accounts for 120mb of data strip ruby and support from jruby we only use ruby syntax for now strip code we don use like rdoc 9mb it also likely we can do platform specific cleanup on rpm and deb based systems we can probably assume it linux and as result don need to ship any windows or solaris artifacts ffi dll so files etc let find lots of things to clean up deduplication removing spec tests from gems lots of files larger than 50kb do we need them all example candidates include kibana which includes bootstrap `less` files which are unlikely to be needed in production the `twitter` gem changelog md is 76kb `simplecov html` includes 250kb of javascript that isn used by logstash stripping ruby and support in the jruby packaging strip unused code like rdoc estimate 10mb of saving if we strip and support needs testing >>>blocker v1.5.0
bin logstash rspec fails to load cabin after building and untarring the `artifact tar` result bin logstash rspec fails from that unpacked package common error is failing to load plugin the cabin gem is failing to be loaded this appears to be because `logstash environment set gem paths is only including the `plugins home` path in the gem path and we are relying on `bundler setup rb` to pretend the core gem dependencies aren gems but libraries this has the effect of hiding the presence of the cabin gem even though the library is present possible fixes review plugins it likely that no plugin really requires cabin because logstash simply provides the logger` setting as an interface and that no plugin really does `require cabin or `cabin channel whatever` alternately review our usage of bundler setup rb as understand it using bundler setup rb removing rubygems loading greatly improved logstash startup time so prefer not rejecting the bundler setup rb solution >>>blocker v1.5.0
rpm creates separate dir for pidfile but doesn use it hi confusing behavior of init script shipped with logstash rpm rpm contains empty dir var run logstash` which is then never used init script contains this simple line `pidfile var run name pid `>>>needs_details packaging
improve rabbitmq input and output plugin docs just minor improvement but when setting up an output to rabbitmq broker yesterday ran into an issue which was not immediately obvious given the socket connection errors returned by march hare the issue was that in my config had specified vhost including the leading forward slash the documentation only states that vhost entry should be string and that the default is it would be handy if this were amended to clarify non default vhost should not contain any leading slash >>>docs
logstash file input didn collect update in files on the same nfs mount point if ask them to listen on each file it can always detect the updates the input reading thread is doing does this mean its stuck somewhere file daemon prio 10 tid 0x00007fc22001a000 nid 0x6ee3 runnable 0x00007fc242f92000 java lang thread state runnable at sun nio ch filedispatcherimpl read0 native method at sun nio ch filedispatcherimpl read filedispatcherimpl java 46 at sun nio ch ioutil readintonativebuffer ioutil java 223 at sun nio ch ioutil read ioutil java 197 at sun nio ch filechannelimpl read filechannelimpl java 149 locked java lang object at org jruby util io channeldescriptor read channeldescriptor java 604 at org jruby util io channeldescriptor read channeldescriptor java 574 at org jruby rubyio sysread rubyio java 2998 at org jruby rubyio invoker sysread call rubyio invoker sysread gen at org jruby internal runtime methods javamethod javamethodn call javamethod java 665 at org jruby internal runtime methods dynamicmethod call dynamicmethod java 206 at org jruby runtime callsite cachingcallsite call cachingcallsite java 168 at org jruby ast calloneargnode interpret calloneargnode java 57 at org jruby ast dasgnnode interpret dasgnnode java 110 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby ast blocknode interpret blocknode java 71 at org jruby ast rescuenode executebody rescuenode java 221 at org jruby ast rescuenode interpret rescuenode java 116 at org jruby ast beginnode interpret beginnode java 83 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby evaluator astinterpreter interpret block astinterpreter java 112 at org jruby runtime interpreted19block evalblockbody interpreted19block java 206 at org jruby runtime interpreted19block yield interpreted19block java 157 at org jruby runtime interpreted19block yieldspecific interpreted19block java 130 at org jruby runtime block yieldspecific block java 111 at org jruby rubykernel loop rubykernel java 1521 at org jruby rubykernel invoker loop call rubykernel invoker loop gen at org jruby runtime callsite cachingcallsite callblock cachingcallsite java 143 at org jruby runtime callsite cachingcallsite calliter cachingcallsite java 154 at org jruby ast fcallnoargblocknode interpret fcallnoargblocknode java 32 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby ast blocknode interpret blocknode java 71 at org jruby evaluator astinterpreter interpret method astinterpreter java 74 at org jruby internal runtime methods interpretedmethod call interpretedmethod java 204 at org jruby internal runtime methods defaultmethod call defaultmethod java 206 at org jruby runtime callsite cachingcallsite callblock cachingcallsite java 177 at org jruby runtime callsite cachingcallsite call cachingcallsite java 183 at org jruby ast fcalloneargblockpassnode interpret fcalloneargblockpassnode java 32 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby ast ifnode interpret ifnode java 118 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby ast whenoneargnode when whenoneargnode java 49 at org jruby ast casenode interpret casenode java 133 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby evaluator astinterpreter interpret block astinterpreter java 112 at org jruby runtime interpreted19block evalblockbody interpreted19block java 206 at org jruby runtime interpreted19block yield interpreted19block java 194 at org jruby runtime interpreted19block yield interpreted19block java 177 at org jruby runtime interpreted19block yieldspecific interpreted19block java 140 at org jruby runtime block yieldspecific block java 129 at rubyjit filewatch watch each d9daf52dbd4f215d0c0e159875f0d2ade6f334d11663791523 block ruby file var tmp logstash vendor bundle jruby gems filewatch lib filewatch watc at rubyjit filewatch watch each d9daf52dbd4f215d0c0e159875f0d2ade6f334d11663791523 block ruby file call rubyjit filewatch watch each d9daf52dbd4f215d0c0e159875f0d2ade6f334d11663791523 block ruby file at org jruby runtime compiledblock19 yield compiledblock19 java 135 at org jruby runtime block yield block java 142 at org jruby rubyarray eachcommon rubyarray java 1606 at org jruby rubyarray each rubyarray java 1613 at org jruby rubyarray invoker each call rubyarray invoker each gen at org jruby runtime callsite cachingcallsite callblock cachingcallsite java 143 at org jruby runtime callsite cachingcallsite calliter cachingcallsite java 154 at rubyjit filewatch watch each d9daf52dbd4f215d0c0e159875f0d2ade6f334d11663791523 file var tmp logstash vendor bundle jruby gems filewatch lib filewatch watch rb 60 at rubyjit filewatch watch each d9daf52dbd4f215d0c0e159875f0d2ade6f334d11663791523 file var tmp logstash vendor bundle jruby gems filewatch lib filewatch watch rb at org jruby internal runtime methods jittedmethod call jittedmethod java 161 at org jruby runtime callsite cachingcallsite callblock cachingcallsite java 143 at org jruby runtime callsite cachingcallsite call cachingcallsite java 149 at org jruby ast fcallnoargblockpassnode interpret fcallnoargblockpassnode java 27 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby ast blocknode interpret blocknode java 71 at org jruby ast whilenode interpret whilenode java 131 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby ast blocknode interpret blocknode java 71 at org jruby evaluator astinterpreter interpret method astinterpreter java 74 at org jruby internal runtime methods interpretedmethod call interpretedmethod java 247 at org jruby internal runtime methods defaultmethod call defaultmethod java 222 at org jruby runtime callsite cachingcallsite cacheandcall cachingcallsite java 356 at org jruby runtime callsite cachingcallsite callblock cachingcallsite java 213 at org jruby runtime callsite cachingcallsite calliter cachingcallsite java 222 at org jruby ast calltwoargblocknode interpret calltwoargblocknode java 62 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby evaluator astinterpreter interpret method astinterpreter java 74 at org jruby internal runtime methods interpretedmethod call interpretedmethod java 161 at org jruby internal runtime methods defaultmethod call defaultmethod java 190 at org jruby runtime callsite cachingcallsite cacheandcall cachingcallsite java 316 at org jruby runtime callsite cachingcallsite callblock cachingcallsite java 145 at org jruby runtime callsite cachingcallsite calliter cachingcallsite java 154 at org jruby ast callnoargblocknode interpret callnoargblocknode java 64 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby ast blocknode interpret blocknode java 71 at org jruby evaluator astinterpreter interpret method astinterpreter java 74 at org jruby internal runtime methods interpretedmethod call interpretedmethod java 182 at org jruby internal runtime methods defaultmethod call defaultmethod java 198 at org jruby runtime callsite cachingcallsite cacheandcall cachingcallsite java 326 at org jruby runtime callsite cachingcallsite call cachingcallsite java 170 at org jruby ast calloneargnode interpret calloneargnode java 57 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby ast rescuenode executebody rescuenode java 221 at org jruby ast rescuenode interpret rescuenode java 116 at org jruby ast beginnode interpret beginnode java 83 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby ast blocknode interpret blocknode java 71 at org jruby ast rescuenode executebody rescuenode java 221 at org jruby ast rescuenode interpret rescuenode java 116 at org jruby ast ensurenode interpret ensurenode java 96 at org jruby evaluator astinterpreter interpret method astinterpreter java 74 at org jruby internal runtime methods interpretedmethod call interpretedmethod java 182 at org jruby internal runtime methods defaultmethod call defaultmethod java 198 at org jruby runtime callsite cachingcallsite cacheandcall cachingcallsite java 326 at org jruby runtime callsite cachingcallsite call cachingcallsite java 170 at org jruby ast fcalloneargnode interpret fcalloneargnode java 36 at org jruby ast newlinenode interpret newlinenode java 105 at org jruby evaluator astinterpreter interpret block astinterpreter java 112 at org jruby runtime interpreted19block evalblockbody interpreted19block java 206 at org jruby runtime interpreted19block yield interpreted19block java 194 at org jruby runtime interpreted19block call interpreted19block java 125 at org jruby runtime block call block java 101 at org jruby rubyproc call rubyproc java 290 at org jruby rubyproc call rubyproc java 228 at org jruby internal runtime rubyrunnable run rubyrunnable java 99 at java lang thread run thread java 745 >>>needs_details unconfirmed
exception in output thread silently locks up logstash copying this from the logstash jira because ve run into it yet again this is pretty serious problem and ve wasted lot of time debugging it if an output plugin encounters an exception such as logstash 1504 et al the output crashes silently the exception is printed to stdout and never reaches the log this causes that output sizedqueue to no longer be consumed and eventually filter workers and then input workers block on sizedqueue pushes logstash appears to cease processing messages without warning or explanation the only way was able to debug this was to run logstash in screen and watch the output ran it with vv because had no idea why it was locking up and set my scrollback to 100000 lines at this point was able to see my output thread elasticsearch river crash although had to scroll ways back to find this exception since the other threads continued on for awhile here the exception from my output thread org jruby exceptions raiseexception invalidbytesequenceerror xb9 on ascii 8bit at org jruby rubystring encode org jruby rubystring java 7599 at json ext generatormethods rbhash to json json ext generatormethods java 71 at logstash event to json file opt logstash logstash jar logstash event rb 157 at logstash outputs elasticsearchriver receive file opt logstash logstash jar logstash outputs elasticsearch river rb 212 at logstash outputs base handle file opt logstash logstash jar logstash outputs base rb 86 at ruby initialize eval 247 date filter looking for field type syslog field timestamp level debug file opt logstash logstash jar logstash filters date rb line 197 at org jruby rubyproc call org jruby rubyproc java 271 at logstash pipeline output file opt logstash logstash jar logstash pipeline rb 259 at ruby outputworker file opt logstash logstash jar logstash pipeline rb 218 at ruby start outputs file opt logstash logstash jar logstash pipeline rb 145 it irrelevant why my output thread is crashing but for those curious our vulnerability scanner sent garbage bytes to the syslog port and logstash happily ate them until it tried to convert the message to utf in the json codec would set the priority of this to critical if could almost dropped logstash because this issue made it inexplicably unreliable at least logging the exception would have given me clue as to how to proceed better solution would be to drop log the offending message and restart the output exceptions in inputs are handled by logging the exception and restarting the input worker exceptions in filters are handled by logging the exception and shutting down the filter worker at least in either of these cases the sysadmin has some clue about what went wrong >>>bug pipeline-stalls
conditional in operator ignores first string of the list using logstash config file output but gives `>>>bug
sensu codec for rabbitmq output originally reported by brian preston at https logstash jira com browse logstash 2116 trying to get matching ingested logs to fire sensu alert one way see to do this is have logstash output matching logs into rabbitmq using the output already written however the message would need to be formatted into the format sensu uses which implies codec history the google group logstash users mentioned need for this in nov 2013 but it looks like no one has implemented it yet the original thread https groups google com forum searchin logstash users sensu logstash users pzkbl7xoteg pfcierpxri4j it probably would not need specific codec if the existing rabbitmq plugin supported customizing the payload >>>new-plugin
add new parameter or change pattern to function like grok match need to be able to control what field the multiline filter is applying its logic too similar to how grok match parameter works >>>enhancement
logstash different character hi all is it possible that logstash stops working after getting similar warning like this after this logstash doesn ships logs to elastic search and it stops working at all while truncate the log file it watches don know if it bug or normal behavior but would be great to find an answer google doesn answer much about this >>>needs_details
added apache logs changed description and now computes top 20 fix missing commit 30d323>>>v1.5.0
update gemfile for package testing missing commit from 5>>>v1.5.0
use logstash devutils>>>v1.5.0
add code climate badge hi everyone took the liberty of adding logstash to code climate https codeclimate com it service analyzing the code quality of projects checking metrics such as method length complexity cyclomatic code complexity believe duplication and others the service is free for open source you can check out the logstash site at code climate here https codeclimate com github elasticsearch logstash logstash does really well with an overall score of out of the badge added shows off that score as another note code climate also supports test coverage reporting regarding issue 2113 we use both over at shoes4 as they seem to have other problems but overall work code climate test coverage is really easy to configure with travis ci you seem to be using another internal ci server dunno how easy that is to set up but that rather another issue and just nice to know here signed the cla cheers tobi >>>v1.5.0
coveralls not working see that logstash has development dependency on coveralls and also seems to have it set up alright in the spec helper https github com elasticsearch logstash blob master spec spec helper rb l5 l17 but it doesn seem to report coverage to the coveralls web https coveralls io elasticsearch logstash my guess would be that the ci server misses the coverage environment variable or somehow the results aren getting sent over there suggest removing coveralls or getting it reporting maybe the results are also private and just see them in that case carry on but love to have those public for oss projects ve had my fair share of troubles with coveralls so using another service might also be an option cheers tobi>>>bug tests-infra v2.0.0
logstash init script does not respect the logstash user groups fix included have experienced the issue that logstash when started as service does not read log files unless they are world readable or owned by the logstash user itself have added the logstash user to the user group of the files in my case apache user group and that did not work then found solution to the problem here http serverfault com questions 632079 logstash not reading logs unless world readable>>>v1.5.3
fixing documentation inconsistencies this pull request fix some inconsistencies found in the documentation like the ones listed below confusing message in the getting started tutorial vs the logstash output elasticsearch pages might be good idea to drop link here to this page but sure how to do that issue 2098 references to logstash net what should be move to elasticsearch site wip >>>v1.5.0
install default plugins via bundler you know for speed this is an attempt to speed `rake artifact` tasks one of the major factors slowing the process is the gem dependencyinstaller install method called for each plugin this method will check the dependencies for the gem meaning dependencies are checked 100 times during the rake task an alternative is to hand out all the gems to bundler and have it figure out dependencies and install order in go the approach also removes the 100 system calls to bin plugin install each spawns jvm instance this reduces the run time by 60 in my tests before 36 minutes now 12 minutes not sure if there any negative impact on this approach please review >>>enhancement reviewing v1.5.0
there aren any configuration files hi when installing logstash via debian repo and setup multiple configfiles under etc logstash conf like this 01 lumberjack input conf 10 syslog conf 30 lumberjack output conf the init script etc init logstash web fails with the following error there aren any configuration files etc init logstash web restart there aren any configuration files in etc logstash conf failed test too many arguments if manually trigger test can confirm this test etc logstash conf conf bash test too many arguments as workaround changed if test conf dir conf then to if ls conf dir conf then and it is starting fine now >>>unconfirmed
allow opt space between device id and colon fix elasticsearch logstash 2101>>>missing_cla
logstash docs contradictory es version statements in the getting started part there is note that says this tutorial specifies running logstash with elasticsearch each release of logstash has recommended version of elasticsearch to pair with make sure the versions match based on the logstash version youre running link http www elasticsearch org guide en logstash current logstash reference html however in the output plugins there is contradictory reference version note your elasticsearch cluster must be running elasticsearch or later link http www elasticsearch org guide en logstash current plugins outputs elasticsearch html this could lead to some miss interpretation >>>docs v1.5.0
logstash docs add disclaimer at the top of community maintained plugins right now on logstash net for plugins that are provided in the contrib package there is note at the top saying this is community contributed plugin it does not ship with logstash by default but it is easy to install to use this you must have installed the contrib plugins package as we migrate the docs to org we should maintain this type of notice on plugins that are not shipped by default with logstash otherwise users may think something is wrong when they dont see them available in the download proposed wording for org documentation this is community maintained plugin it does not ship with logstash by default but it is easy to install by running `bin plugin install plugin name >>>docs v1.5.0
refactored ex noop filter specs into filter base specs the noop filter is now dynamically defined class into the `spec filters base spec rb` and the plugin lookup method has been adjusted to support dynamically defined plugins >>>enhancement v1.5.0
failing plugins on jenkins logstash codec cloudfront commit logstash codec collectd commit logstash codec compress spooler commit logstash codec es bulk commit logstash codec gzip lines commit logstash codec s3plain commit logstash filter metaevent commit logstash filter zeromq commit logstash input couchdb changes commit logstash input drupal dblog commit logstash input gemfire commit logstash input github commit logstash input meetup commit logstash input rss commit logstash nightly logstash package acceptance puppet logstash acceptance commit puppet logstash acceptance main puppet logstash docs puppet logstash rspec >>>blocker
add offending input file name line number to the error generation when getting an error such as timestamp 2014 11 10t15 05 13 345000 0500 message received an event that has different character encoding than you configured text xc2h x81 expected charset utf level warn add the offending input file name line number to this entry such that it could look like timestamp 2014 11 10t15 05 13 345000 0500 message received an event that has different character encoding than you configured text xc2h x81 expected charset utf level warn file my input conf line 32 makes it easy to trap down misconfigurations >>>enhancement low_hanging_fruit
mutate filter gsub not working when fieldname contains period when trying to do mutate gsub on field in which the fieldname contains period netflow protocol gsub is not working if use field that has no period in the name it works fine current config https gist github com clay584 a45871a73e911ff0ccbd sample data showing that the field is not updated https gist github com clay584 cac6126aee96ce85b26a>>>bug needs_details
mass update of plugins update gemspec with info elasticsearch com update link gemspec with http www elasticsearch org guide en logstash current index html description with link dont use without logstash summary with link dont use without logstash bump version logstash group add development dependency launch jenkins rebuild of all plugins see example pr for https github com logstash plugins logstash output elasticsearch pull 18 files>>>blocker v1.5.0
make it easier to ingest csv files csv files are fairly common and almost always include header line with name of fields right now logstash requires to somehow skip the header by doing messy match drop specify manually the columns to understand the rest of files it would be really awesome if ls would just grab the field names from 1st line and then discard it maybe controlled by header line option understand that it may not be easy to do if filters have no control over the input and also when resuming load it would have to read the header line 1st but it could be pretty powerful if the input could be controlled by the filter or just add more input options to generally handle the concept of header and feed it to the filter >>>enhancement
windows rewrite bin logstash bat in powershell powershell is for me much easier to read and write and maintain it also been available for 10 years so most windows systems that are supported should have access to it >>>windows
update for windows to execute rake bootstrap and bin logstash bat with the switch to minitar the rake bootstrap command was broken in windows accessing file in binary mode resolves the issue also cleaned up the logstash bat script to mimic more the logstash shell script remove deps command and use ruby envvar also update jruby to security release 16 >>>v1.5.0
java gem runtime dependencies not installed and missing platform setting this relates to logstash plugins logstash output elasticsearch 15 the problem is currently generalized to all java runtime dependencies in the beta1 package all currently installed java plugins are missing their java dependencies logstash input eventlog missing jruby win32ole logstash input rabbitmq missing march hare logstash output rabbitmq missing march hare logstash output elasticsearch missing manticore all for the exception of `logstash codec fluent java` which has its `msgpack jruby` dependency think the `msgpack jruby` gem was actually installed by the `logstash codec msgpack` which looks like is the only plugin that still has dual gemspec setup haven analyzed the plugin manager code but suspect this is probably related to the single dual gemspecs since the only correctly installed dependency has been done from plugin with the dual gemspecs also note that the following plugins logstash input rabbitmq logstash output rabbitmq logstash output elasticsearch are all missing the platform setting in the gemspec >>>blocker bug v1.5.0
pluginmanager group option does not work bin plugin list group output logstash output elasticsearch bin plugin list group input no plugins found bin plugin list group filter no plugins found bin plugin list wc 101>>>blocker v1.5.0
integration and unit tests for plugin manager there should be test suite for the plugin manager created so we can track there issued with the behaviour of this important components what happen when installing stuff removing updating etc >>>enhancement tests-infra
rename logstash logstash in all classes we should rename all the constants from logstash to logstash for backwards compatibility we can have logstash logstash but the code should look like `class logstash agent lowercase >>>breaking-compatibility v2.0.0
bump version to beta1>>>v1.5.0
separate runtime dependencies and development dependencies in all the plugins gemspec all the dependencies for the plugins are declared as runtime dependencies but in reality some of the dependencies are only used to make the test run one of the gem with the problem is the ruby filter https github com logstash plugins logstash filter ruby >>>internal-cleanup plugin_manager
internal gemify plugin boilerplate the new plugin ecosystem aims to allow anyone to create and publish their own logstash plugins at present all the plugins we ship have bunch of boilerplate in gemspecs rake etc like to reduce boilerplate so we can reduce maintenance costs and reduce copy paste problems things to do based on reviewing few plugins rakelib is all boilerplate move it to single library and publish as gem gemfile is some boilerplate we can move the dependencies into the gem in the above point include any test harness helpers like `spec helper rb` from logstash update all plugins to remove the boilerplate and use the library the above two points implement update all plugins gemspecs to put the correct dev runtime deps>>>v1.5.0
configtest misses invalid grok pattern have deployment setup where run logstash with configtest before commit deploy the configuration today however it tripped me up because ran the config test deployed and half an hour later noticed that all the logstash agents had started but then exited because of an invalid grok pattern typo in grok pattern nospace rather than notspace caused it to exit when parsing the first event which hit that rule the error reported is nospace das key value not defined assume now that logstash configtest only actually checks if the configuration is syntactically correct but not if it will work would it be possible to allow plugins to test their own configurations for configuration errors configtest would first test whether the config file as whole is syntactically correct and following delegate each input filter output section to be tested by their respective plugins >>>enhancement known_issue
plugin cannot allocate memory am dealing with huge amount of logs and encountered this issue the error log shows like this or is there an argument can specify the memery size >>>needs_details
grok assigns the wrong names to captures under some conditions description composing grok patterns that share named captures will result in names to bind to the wrong capture in the context of the composition reproduction steps setup the following patterns file etc logstash patterns general test patterns` run the patterns file using the following logstash config will print the following to standard out expected output field should exist called `failure` which captures the text failed password the field `username` should contain the text magicaluser >>>reviewing v2.0.0
elasticsearch input causing illegalargument error hello it seems as though the elasticsearch input have in my logstash is causing me some errors here is the conf file for logstash actually apologies upon trying to isolate the issue have found this has to do with logstash elasticsearch plugin where should place this question my logstash config file is as follows the above posted stack trace however is inside of elasticsearch which is leading me to beleive it is on elasticsearches execution being enacted by the logstash plugin apologies for the lack of understanding of the issue previous to now input stdin elasticsearch host 10 14 157 port 9200 index core42 query license error output file path users username desktop logfile txt email from logstash alert nowhere com subject testing to someone somewhere com via smtp body here is the event line that occured core log htmlbody alert you have been automatically alerted about the following event core log options smtpiporhost smtp gmail com port 587 domain gmail com username somemail gmail com password somepass starttls true authenticationtype login now when run this get the following errors in elasticsearch these only occur when run logstash so don beleive it is an issue with the jdbc river 14 11 12 10 12 31 996 error river jdbc bulknodeclient bulk 29 failed with failed items failure message failure in bulk execution 58 index core42 type jdbc id 103756 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 62 index core42 type jdbc id 103760 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 147 index core42 type jdbc id 103767 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 12 32 061 error river jdbc bulknodeclient bulk 29 failed with failed items failure message failure in bulk execution 38 index core42 type jdbc id 103756 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 42 index core42 type jdbc id 103760 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 127 index core42 type jdbc id 103767 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 13 12 003 error river jdbc bulknodeclient bulk 37 failed with failed items failure message failure in bulk execution 99 index core42 type jdbc id 103747 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 13 12 077 error river jdbc bulknodeclient bulk 37 failed with failed items failure message failure in bulk execution 71 index core42 type jdbc id 103747 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 13 31 618 error river jdbc bulknodeclient bulk 29 failed with failed items failure message failure in bulk execution 29 index core42 type jdbc id 103756 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 33 index core42 type jdbc id 103760 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 118 index core42 type jdbc id 103767 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 13 31 660 error river jdbc bulknodeclient bulk 29 failed with failed items failure message failure in bulk execution 60 index core42 type jdbc id 103756 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 64 index core42 type jdbc id 103760 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 13 36 665 error river jdbc bulknodeclient bulk 30 failed with failed items failure message failure in bulk execution index core42 type jdbc id 103767 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 14 11 633 error river jdbc bulknodeclient bulk 37 failed with failed items failure message failure in bulk execution 59 index core42 type jdbc id 103747 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 14 11 710 error river jdbc bulknodeclient bulk 37 failed with failed items failure message failure in bulk execution 91 index core42 type jdbc id 103747 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 14 30 195 error river jdbc bulknodeclient bulk 29 failed with failed items failure message failure in bulk execution 45 index core42 type jdbc id 103756 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 49 index core42 type jdbc id 103760 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 134 index core42 type jdbc id 103767 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 14 30 256 error river jdbc bulknodeclient bulk 29 failed with failed items failure message failure in bulk execution 55 index core42 type jdbc id 103756 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 59 index core42 type jdbc id 103760 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 144 index core42 type jdbc id 103767 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 15 10 204 error river jdbc bulknodeclient bulk 37 failed with failed items failure message failure in bulk execution 82 index core42 type jdbc id 103747 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 15 10 280 error river jdbc bulknodeclient bulk 37 failed with failed items failure message failure in bulk execution 94 index core42 type jdbc id 103747 message mapperparsingexception failed to parse core log nested elasticsearchillegalargumentexception unknown property 2014 11 12 10 15 58 523 error river jdbc riverthread interrupted while shutdownjava io ioexception interrupted while shutdown at org xbib elasticsearch plugin jdbc pipeline executor simplepipelineexecutor shutdown simplepipelineexecutor java 145 at org xbib elasticsearch plugin jdbc riverthread afterpipelineexecutions riverthread java 140 at org xbib elasticsearch plugin jdbc riverthread run riverthread java 130 at java lang thread run unknown source at java util concurrent executors runnableadapter call unknown source at java util concurrent futuretask run unknown source at java util concurrent scheduledthreadpoolexecutor scheduledfuturetask access 201 unknown source at java util concurrent scheduledthreadpoolexecutor scheduledfuturetask run unknown source at java util concurrent threadpoolexecutor runworker unknown source at java util concurrent threadpoolexecutor worker run unknown source at java lang thread run unknown source 2014 11 12 10 15 58 525 error river jdbc riverthread interrupted while shutdownjava io ioexception interrupted while shutdown at org xbib elasticsearch plugin jdbc pipeline executor simplepipelineexecutor shutdown simplepipelineexecutor java 145 at org xbib elasticsearch plugin jdbc riverthread afterpipelineexecutions riverthread java 140 at org xbib elasticsearch plugin jdbc riverthread run riverthread java 130 at java lang thread run unknown source at java util concurrent executors runnableadapter call unknown source at java util concurrent futuretask run unknown source at java util concurrent scheduledthreadpoolexecutor scheduledfuturetask access 201 unknown source at java util concurrent scheduledthreadpoolexecutor scheduledfuturetask run unknown source at java util concurrent threadpoolexecutor runworker unknown source at java util concurrent threadpoolexecutor worker run unknown source at java lang thread run unknown source 2014 11 12 10 15 58 524 error river jdbc riverthread interrupted while shutdownjava io ioexception interrupted while shutdown at org xbib elasticsearch plugin jdbc pipeline executor simplepipelineexecutor shutdown simplepipelineexecutor java 145 at org xbib elasticsearch plugin jdbc riverthread afterpipelineexecutions riverthread java 140 at org xbib elasticsearch plugin jdbc riverthread run riverthread java 130 at java lang thread run unknown source at java util concurrent executors runnableadapter call unknown source at java util concurrent futuretask run unknown source at java util concurrent scheduledthreadpoolexecutor scheduledfuturetask access 201 unknown source at java util concurrent scheduledthreadpoolexecutor scheduledfuturetask run unknown source at java util concurrent threadpoolexecutor runworker unknown source at java util concurrent threadpoolexecutor worker run unknown source at java lang thread run unknown source 2014 11 12 10 15 58 523 error river jdbc riverthread interrupted while shutdownjava io ioexception interrupted while shutdown at org xbib elasticsearch plugin jdbc pipeline executor simplepipelineexecutor shutdown simplepipelineexecutor java 145 at org xbib elasticsearch plugin jdbc riverthread afterpipelineexecutions riverthread java 140 at org xbib elasticsearch plugin jdbc riverthread run riverthread java 130 and finally here is the mapping on the index as my research is showing me this has something to do with the issue however strict mapping to string should have fixed it as far as can see have tried strict and false dynamic mapping both create the same results put core42 mapping jdbc jdbc dynamic false properties class type string core level type string core log type string core user type string customer type string datetime type date format dateoptionaltime server name type string webapp type string again am posting here because this error occurs when am using logstash to reparse the logs which are in elasticsearch and give me email alerts using an elasticsearch input to indexes that were fed by river >>>reviewing
add how where to install logstash notice in plugins gems descriptions currently searching for logstash in rubygems yields large amount of results for all plugins each plugin description should say how where to install logstash and install use the plugin >>>docs v1.5.0
modify the way we fetch the installed version of the plugin fixes 2025>>>v1.5.0
logstash on windows crash outofmemory for some reasons java process does not honor these settings in logstash bat if ls min mem set ls min mem 2g if ls max mem set ls max mem 2g java process core dumps when memory is 1gb is this known issue we use java update 25 64 bit >>>windows
allow binary operators and comparable on timestamp object closes 2052 implement the comparable mixin and use standard binary operators on timestamp object closes 2052>>>reviewing v1.5.0
move util zeromq to common library gem for all zeromq related plugins>>>internal-cleanup low_hanging_fruit
contrib plugin filters zeromq rb has not be transitioned into logstash plugins contrib filters zeromq rb is missing in the logstash plugins repo once done ping me need to refactor the json stuff in it >>>v1.5.0
contrib plugin filters metaevent rb has not be transitioned into logstash plugins contrib `filters metaevent rb` is missing in the logstash plugins repo >>>blocker v1.5.0
add support for operators in timestamp this should be as easy as adding new delegators to the underlying time object see https github com logstash plugins logstash filter collate blob master lib logstash filters collate rb l94>>>reviewing
fix for handling accessor sets on array elements previously filters like mutate would throw an exception when attempting to convert an element within an array to specific type this was raising an error because the index in the field reference was being treated as string instead of an integer representing the index of the field to convert now plugins like mutate can access and convert elements within arrays to specific types or updating their values related issue https github com elasticsearch logstash issues 1401>>>v1.5.0
non plugin logstash gems should not be installable by the plugin manager non plugin gems like logstash mixin aws https github com logstash plugins logstash mixin aws should not be installable by the new plugin manager not sure if we can just unset the logstash plugin property https github com logstash plugins logstash mixin aws blob master logstash mixin aws gemspec l19 or add new installable property >>>enhancement low_hanging_fruit plugin_manager
example in pagerduty `details` field has syntax error for the pagerduty plugin put the `details` example in details hash optional default timestamp timestamp message message got this error message error expected one of at line 44 column 51 don think you need the comma in between the two fields >>>docs v1.5.0
some plugin generation fixes ensure empty lines in some places only print the table if we actually have items to put in there always use inspect function when printing out the defaults>>>blocker docs work_in_progress
added blank line between description and synopsis this fixes the bug where synopsis was not rendered properly >>>blocker docs v1.5.0
document plugin development workflow in all plugins readme should be something like dev loop clone repo optionally edit `gemfile` to specify alternate logstash core source local path or git ref bundle install` bundle exec rake vendor` code bundle exec rspec` run in logstash using plugin manager install build gem with gem build plugin gemspec` in logstash bin plugin install path to plugin gem` test config relates to 2039 2042>>>blocker enhancement v1.5.0
publish logstash core gem and cleanup gemspec dependencies to support running tests specs in plugins per 2039 we will need to publish logstash core gem so that it can be included as dependency in the plugin to allow running specs from within that plugin and not having to install the plugin in logstash to be able to run the specs this gem will essentially be used when developing plugins should we rename the gem to `logstash core` while at it we should review all remaining dependencies in the gemspec and correctly assign runtime and development dependencies and remove unused ones like `msgpack` which have now been move as specific dependencies in the relevant plugins >>>enhancement v1.5.0
proposal allow per plugin log level configuration hello thinking of the new plugin system that will hopefully build community of plugins someone somewhere is going to need to debug plugin and to turn debugging on for logstash can produce thousands of entries seconds on some installations it would be great to have the ability to configure specific plugin for debug logging guess the implementation would be something like implement in input filter output base the new configuration option log level like the codec and add field etc when the input filter output base inits if log level is set it uses logger clone` and logger level to create new logger with same outputs but different level if log level wasn set it simply leaves the current logger alone jordansissel might need to confirm clone is safe on the cabin channel and maybe there better way to do this but think it ll definitely be worthwhile without this kind of feature plugin developers would end up having to avoid debug level entirely as it causes logstash to print all events so we essentially reduce the granularity for plugin logging and without it there always going to be more noise than necessary when you only want to debug single plugin let me know what you think thanks >>>discuss logging_improvements
support running specs tests in plugins we should be able to run specs from within plugin directory without having to install it >>>blocker enhancement v1.5.0
website should recommend other elasticsearch version than because of cve 2014 3120 ve had couple of digital ocean droplets locked because of vulnerability in es think lot of people are suffering this too the current getting started docs give the link for the download of http logstash net docs tutorials getting started with logstash maybe later version should be suggested other sources http www cve mitre org cgi bin cvename cgi name 2014 3120 http bouk co blog elasticsearch rce >>>bug docs
force the uninstall of plugin at install or update time it can happen we want to update plugin that is dependency for an other plugin which will result in warning and manual action at uninstall phase of the install update tasks since we are 100 sure in these cases that the plugin will be installed again we can force the uninstall part not to alert us about it this solves the issue we otherwise would get gem dependencyremovalexception uninstallation aborted due to dependent gem >>>bug
rabbitmq input deletes queue on exit if shut down logstash with enabled rabbitmq input the queue on rabbitmq server is deleted have activated passive true so logstash dos nt need to know the whole configuration of the queue but there is bad line in march hare rb 69 delete unless durable in this line also the passive flag should be taken into account the queue should only be deleted if it not durable and logstash is not operating passive as workaround you have to define durable true >>>bug
platform check in plugins gemspec is not evaluated correctly in some gemspecs we have this gemname is arbitrary at this moment the `if` statement is evaluated at gem build time instead of gem install time this causes the normal ruby gem to be installed instead of the jruby specific dependency the only solution can think of so far is building gems one for normal ruby other for jruby >>>blocker discuss v1.5.0
update license>>>v1.5.0
verify extracted plugins are the last version from master had an issue with an extracted plugins dns filter not containing the latest version from master maybe it is the case for other plugins we will need to verify all of them same issue with json filter >>>blocker v1.5.0
fix some bugs under mri `bin plugin install` works now most specs pass the only specs that don pass are ones that are broken under mri due to 2024 not being fixed fixes 2022 and 2023>>>mri_support reviewing v2.0.0
mri support need joda time formatting support joda got lovely date format syntax we ll need to support this ourselves under mri >>>mri_support
plugin install tool should accept multiple plugins to install as user it would be lovely if could install multiple plugins the same time with `bin plugin install plugin1 plugin2 plugin3 `>>>enhancement plugin_manager
include list of plugins by default this plugin set should be the same as the ones included in core in logstash so users should experience no negative impact of this >>>blocker v1.5.0 work_in_progress
pluginmanager wrap bin logstash plugin to bin plugin closes 1969>>>enhancement
plugins error while listing all plugins installed suyog machine ws logstash bin logstash plugin list logstash output redis typeerror cannot convert instance of class org jruby rubyarray to int exit at users suyog ws logstash lib logstash program rb 10 main at users suyog ws logstash lib logstash runner rb 86 root at users suyog ws logstash lib logstash runner rb 210>>>bug
some documentation generation fixes add docgen command to use internal libraries fix loading of base files due to plugin path changes fix loading of jar dependency files remove kramdown gem and actions cleanup the generated synopsis bit>>>v1.5.0
logstash threads not being cleaned up hi guys have an elk installation with logstash and elasticsearch there is problem with the threads what can see is that total number of threads are constantly increasing and are not being cleaned up when they are finished at some point then get java outofmemory and it crashes have installed this fix suggested from this discussion https github com elasticsearch logstash forwarder issues 212 and since then dont get outofmemory in the logs anymore but still the same behaviour here is screenshot from jvisualvm which shows this you can see that the gc activity almost dies and the gc graph looks different after that logstash1 https cloud githubusercontent com assets 9476606 4880761 13fa58b0 6340 11e4 96be efa7c9ed0ecc png when look at the threads can see lots of finished threads which are not being cleaned up and clog the moemory logstash2 https cloud githubusercontent com assets 9476606 4880800 796c5072 6340 11e4 8f6a ddedaae423dd png can anyone help me shed some light on this and figure out whats happening >>>needs_details
lumberjack input not handling tags parameter either completely misunderstood the lumberjack input or it doesn add the tags specify in the tags parameter my config would expect that each event reaching logstash through this lumberjack input should be tagged with lumberjack in fact it isn it only uses the tags supplied on logstash forwarder on the other side >>>needs_details
add script which builds all generated plugin docs maybe incorrectly this will leverage electrical work to generate asciidoc for every plugin listed in the file would need manual updating with this method >>>blocker enhancement v1.5.0
update elasticsearch output plugin to retry bulk some actions may fail within the es client bulk call now some messages specifically errors 429 and 503s will be retried up to times if there are still actions that are unsuccessfully indexed stud buffer will continue its current behavior to retry indefinitely stud buffer will replay all events it first attempted to flush to elasticsearch this means duplicate events may find themselves in elasticsearch mostly fixes 1631>>>blocker enhancement reviewing v1.5.0
add http auth and ssl to the es input plugin now that es output will support basic auth and ssl https github com elasticsearch logstash pull 1777 we should add this enhancement to es input plugin too>>>blocker v1.5.0
fix removing field with reference to array items specs fixes 1988 >>>bug v1.5.0
chain codecs in input and output plugins there no good reason not to support codec chains for example receiving json messages encoded in msgpack format this requires some tweaking of the config syntax and the ast generation code >>>discuss enhancement
mutate remove field doesn support deleting an array item from someone in electrical gws failing test for spec util accessors spec rb >>>bug v1.5.0
add comment for locale in date filter for non english environment the date filter don parse correctly the month name see http stackoverflow com questions 26653490 logstash date filter failed parsing>>>v1.5.0
add slack output filter this adds basic way for the output to send data to the slack api basic http get call requiring the token and channel to post to >>>new-plugin
the generated tar from the new build system doesn follow directory structure of previous versions have downloaded the version from https download elasticsearch org logstash logstash logstash tar gz ``tar xzf logstash tar gz`` extracts the fles to ``logstash 2`` directory the tgz file created from the artefact tar ``tar xzf logstash dev tar gz`` extracts the files to the current directory>>>v1.5.0
refactor sincedb implementation few plugins need to keep information about the current state of the plugin like `what is the lastest file have read` `which id` each plugins implement their own datastore and often use the current file system ref https github com elasticsearch logstash blob master lib logstash inputs s3 rb l257 logstash should provide pluggable backend for plugins developers to store this kind of information simple persistent key value store would cover most cases >>>enhancement
make new external kafka plugin compatible with logstash currently there are few compile time issues with building logstash input kafka https github com logstash plugins logstash input kafka link to jenkins run http build eu elasticsearch org view ls 20inputs job logstash input kafka commit console electrical is working with the jar dependencies library author to see if there is way to resolve this here https github com mkristian jar dependencies issues if kafka vendor related jars are still going to be managed by logstash one solution is to include those jars and the plugins can leverage that otherwise these jar dependencies conflict fix will fix all things >>>blocker bug v1.5.0
add es bulk codec add codec to parse an elasticsearch bulk index stream>>>blocker reviewing v1.5.0
feature add logstash directory in rspec feel free to delete it it was test after messing with my vimscripts was wondering why we did not have logstash folder inside the spec folder there is lot of editing tools or plugins ruby vim textmate ruby that allow easy navigation to the alternate version of the current file code file vs spec file if both directories have the same structure and naming convention also am it remove the need of the core directory >>>question
fix refactor file output this will need reviews it used similar behavior on failure than the grok filter >>>blocker reviewing v1.5.0
pluginmanager wrap bin logstash plugin to bin plugin it would be nice to wrap bin logstash plugin to more convenient bin plugin script >>>blocker enhancement v1.5.0
flat internal event representation an idea worth exploring is to move from an internal `hash` hierarchical event representation to simpler flat representation this is really some early brainstorming please contribute ideas thoughts comments overall goals the logstash event object supports nested structures and special syntax for accessing nested field `field references` internally the object json representation is basically the same as the object itself can be hash of hash of hash or whatever from memory usage perspective this can consume lots of object references from serialization point of view visiting all the objects can be costly we are interested in exploring some internal representation improvements that should improve per event memory usage and event serialization costs basically instead of having an internal object hierarchy representation like we could have something like or using the logstash path convention this could be done while preserving the current `event` api making this backward compatible pros we could get rid of the whole `accessors` class which caches fields path to inner objects values this would become essentially lookup it would speed up lookups and remove the `accessors` complexity event serialization for persistence would become simpler and certainly faster cons json input codec would need to change to use the jackson streaming api and convert json object to flat representation same idea for json output codec we need to produce json object from flat representation we need to verify all usage of `event to hash` and probably have to perform flat hierarchical conversion to create proper hash representation of the `event` thoughts >>>design
make filter failure logging more verbose to indicate affected input currently logstash when filter fails to match pattern logstash will output something akin to the below in its log this is of limited use when the filter in question is used on multiple inputs and targeting the same field on each input in the above case the date filter is used against the message field on most inputs in our logstash configurations this leads to scenario where the most effective debugging method is to restart logstash multiple times removing single input from the configuration each time until upon restart the failure notification is no longer written to the logs although logstash concatenates all includes into monolithic configuration at runtime it would be very useful if the logging aspect would verbosely specify the last input called before the failing filter or in the case of the filter being called from conditional statement the condition that the filter was called from this would significantly reduce the time required for effective debugging of this type of error >>>enhancement
broken file input doc reference to configuration array the path argument of the file input documentation https github com elasticsearch logstash blob master lib logstash inputs file rb l29 uses logstash configuration page configuration array to reference `http logstash net docs configuration array` but since the plugin is in `inputs` the doc reference expands to `http logstash net docs inputs configuration array` instead making an explicit reference like logstash configuration page http logstash net docs latest configuration array does not work since the redirect removes the array` notation is it possible to do something like logstash configuration page configuration array >>>bug docs
regarding stop logstash automaticaly hi used time out option in pipeline rb and integrated with groovy grail application but here logstash is stopping but they are giving call to grail groovy application context for stopping so complete application is down please check my code from pipeline rb def filterworker logstash util set thread name worker begin while true	 timeout timeout 10 do event input to filter pop if event logstash shutdownsignal input to filter push event 		 break end todo sissel we can avoid the extra array creation here if we don guarantee ordering of origin vs created events origin event is one that comes in naturally to the filter worker created events are emitted by filters like split or metrics 		events event filter event do newevent events newevent end events each do event 		 next if event cancelled filter to output push event 		 end	 end end	 rescue e		 shutdown outputs	 wait outputs	 shutdown filters wait filters logger error exception in filterworker exception backtrace backtrace end	 filters each teardown end def filterworker>>>needs_details
opensuse logstash udp input not listening no errors opensuse 11 10 21 default logstash modified runas user root installation rpm try to setup an udp input for logstash but cannot get it to work the stdout is not showing any errors the following command returns nothing `netstat tapen grep 11000 conf startup could someone please advise how to proceed >>>bug unconfirmed
use open3 popen3 to fix hanging io in jruby 9k>>>bug v1.5.0
tcp input ssl chain ca configuration issues at the moment the ssl configuration options of the tcp input are fairly limited and some are even useless the following issues exist it is not possible to specify `extra chain cert` for the server certificate thus if certificate chain is necessary this can only come from the ca store the ca store system store or specified file is only activated if `ssl verify true` requiring client verification so without client verification it is not possible to send proper certificate chain the system store is always included if `ssl verify true` making client certificate validation useless since client can send any certificate from any recognised ca for any name propose the following changes allow `extra chain cert` to be set to specify certificate chain extra property allow the certificate store to be initialised from the system store even when not using client certificates extra property `ssl set default paths` or something like that and moving couple of lines of code do not use the system store for client certs by default make the previous property `false` by default this may break existing configurations but in these cases the peer verification was probably useless anyway >>>enhancement
add option to use local jruby version instead of the vendored one if we want to test against custom jruby versions we need to ensure we use the correct jruby binary like what we can do with use ruby bin logstash to use the local ruby binary we can do the same with the rake bootstrap job>>>bug v1.5.0
added rake vendor force gems option for forcing bundle install useful when updating gemspec dependencies or gemfile to force dependencies update without having to manually delete in `vendor >>>v1.5.0
isolate gems into build dependencies do not use any system gems fixes having bundler installed in the rubies and gem installer not finding the bundler bin in build dependencies bin >>>bug v1.5.0
if check mutate plugin misbehave when looking up value in hash but an array is present instead given this input field properties is an array of hashes which is kind of evil in it self and using if check for different values of properties logstash will act in rather unexpected way while am fully aware that one should not input an json array and try to access it as hash this is rather unexpected behaviour this is workaround but seems like rather akward to use it also worth noting that besides the unexpected behaviour logstash slowsdowns quite bit when it hits this issue also note that this is was triggered by bug in our json logger of writing an array of hashes instead of simple hash with multiple values which is now fixed but as this can throw people off when hitting this same issue it seems to be like it should be addressed anyhow >>>enhancement
provide an example of expected pri format previously the pri docs linked users to the rfc for log formats although this is sufficient for getting the required information it is not very convenient understanding the correct format is required for using this filter so this information should be included as part of the documentation this patch adds that explanation along with an example >>>missing_cla
support aws sts in the aws config mixins the aws config currently support s3 keys from config env keys and iam roles for authentification it would be nice to add support to the sts http docs aws amazon com sts latest apireference welcome html it already available in the aws sdk http docs aws amazon com awsrubysdk latest aws core credentialproviders assumeroleprovider html see discussion from https github com elasticsearch logstash issues 1778 issuecomment 58659807 >>>enhancement
adding round robin failover for rabbitmq module this hack makes the rabbitmq output failover to multiple rabbitmq servers ports in round robin fashion it is fully backwards compatible but ve failed to entirely stop the dropping of messages whilst failing over >>>needs_tests
fix some bugs in the new rake build process>>>v1.5.0
wip feature persistent queue make sure to run `rake bootstrap` first when you run logstash the following queue files will be created `filter to output queue` is the metadata file and `filter to output queue 0` is the paged data file for now most of the code lives in https github com colinsurprenant jruby mmap https github com colinsurprenant jruby mmap queues >>>work_in_progress
fix metadata testing failures this bug was introduced in the recent metadata patch the problem was caused by testing specific monkeypatch on logstash event fixed this by moving the strict set input validation from logstash util accessors to logstash event as class method then monkeypatched the event to invoke validation before doing the set operation this now makes it call the original method and should help keep future breakages from happening >>>v1.5.0
feature recursive pattern for grok hi didn arrived to use recursivity inside grok custom patterns think this could be an awesome feature benoit description grok pattern matching the two following lines 2014 07 11 18 26 21 335 info 1712933 text2 2014 07 11 18 26 21 335 info 1712933 text3 want to match both of the lines and extract data like this custom date loglevel posint ama values list data custom date year monthnum monthday hour minute second custom value custom list value custom value custom values list complex custom list value custom list value complex custom list value what would like to get >>>enhancement
output plugins stop if one fails testing conditional with two output plugins if the jira output plugin fails logstash does not continue and process the email plugin if move the email plugin before the jira plugin the email gets sent and it fails on the jira plugin >>>resiliency
tests elasticsearch remove the rescue so we can see what errors we get es indices delete index will not fail if there are no indices see it will only fail if we have genuine issue like error elasticsearchillegalargumentexception wildcard expressions or all indices are not allowed status 400 which would be good to surface than just failing the test >>>bug v1.5.0
include stud try module to elasticsearch spec test previously few elasticsearch integration tests relied on this module but the module could not be found to test this change started up an elasticsearch instance with the following config change to allow wildcard deletion of indices for testing purposes as well as running the rspec test with elasticsearch tag included >>>v1.5.0
fix typo>>>v1.5.0
documentation issue tail 0a there is in my opinion typo on the page http logstash net docs tutorials getting started with logstash the line reads from file on the filesystem much like the unix command tail 0a should actually read reads from file on the filesystem much like the unix command tail 0f there is as far as know no option to tail thanks alex>>>v1.5.0
date filter truncates rather than rounds input use syslogbase2 to parse the start of an rsyslog event filter to get the date stamp from the original event date match timestamp8601 iso8601 example output in es timestamp8601 2014 10 21t11 48 21 646972 01 00 timestamp 2014 10 21t10 48 21 646z 646972 has been truncated to 646 rather than rounded to 647>>>bug
update en yml word spelling concatonated to concatenated>>>docs v1.5.0
unable to delete old log files since logstash does not close active connections on them hi currently am parsing only last days of iis http logs using logstash shipper windows am trying to delete the log files which are older than days but am unable to delete the old log files while logstash service is running is there way to close the active connections on old files without stopping the service so that could delete them >>>windows
new config option validate bytes from discussion with jordansissel and me adding validate bytes to allow users to from config say size file 10mb and it just works and under the hood we still get the base units 10mb 10485760 but improves user input probably done when parsing the config file could also work with timed based configuration 1m related to the s3 output and the file rotation on size >>>enhancement v2.0.0
add elasticsearch spec tag to exclude on external es dependency problem introduced in 1791 >>>v1.5.0
workers s3 output plugin no such file or directory ph electrical more review from my testings refers to pr 1913 it appears the file exists >>>bug
s3 ouput friendlier error when you dont have the permission on your s3 bucket access denied return or raise at opt logstash vendor bundle jruby gems aws sdk v1 56 lib aws core client rb 375 client request at opt logstash vendor bundle jruby gems aws sdk v1 56 lib aws core client rb 476 put object at eval write with put object at opt logstash vendor bundle jruby gems aws sdk v1 56 lib aws s3 s3 object rb 1760 write at opt logstash vendor bundle jruby gems aws sdk v1 56 lib aws s3 s3 object rb 612 write on bucket at opt logstash lib logstash outputs s3 rb 158 move file to bucket at opt logstash lib logstash outputs s3 rb 223 configure periodic uploader at opt logstash lib logstash outputs s3 rb 238 time alert at opt logstash lib logstash outputs s3 rb 139 loop at org jruby rubykernel java 1501 time alert at opt logstash lib logstash outputs s3 rb 137>>>bug
fix s3 input output with codec this prs includes lot of changes merged jsvd documentation improvement and added more documentation on new attributes fix 1340 ruby code cleanup following the style md it now use the aws config mixing support iam roles fix 1778 fix 1575 the plugin also use standard codec added new codec s3 plain to support previous version refactoring of the code to improve clarity and allow easier testing created initial test suite for it added simple tests to the aws config mixin fixed bug causing events to be dropped when using the size file option and the file rotation fixed bug when the tags were nil in the plain text format fix 1626 fixed bug when specifying the file size the doc says kb but the condition was on bytes added the option to specify temporary directory for the working files fix 1860 cloudfront is now codec fix 1630 gzip decode is now codec initial work for 1895 s3 output issue when working with multiple workers added threaded uploader fix 1915 s3 output when the codec is started it will try to create simple file on your bucket to test the permissions fix 1914 cc electrical >>>reviewing
fixed mutate merge bug 1911 and added merge specs fixes 1911 and also fixes the source field that was mutated into an array >>>bug
mutate filter merge prepends nil when using mutate merge with an non existing target field the target array has nil value prepended reproduction the `list` target field contains nil foo `>>>bug v1.5.0
logstash skipping lines when moving between files in windows the two log files below are to be processed by the conf also below the first file app1 log is read in and processed just fine the second file is then processed but the first three lines are skipped entirely the second file typically starts at identified listener it does this every single time this appears to only happen on windows platform and happens on ls and ls have tried all sorts of combinations and have now virtually given up would deeply appreciate any insights into what may be going on as this problem is seriously damaging to our uptake of the elk stack thanks the text below is app1 log 2014 09 09 00 00 00 000 0100 starting 2014 09 09 00 00 01 000 0100 started 2014 09 09 00 00 02 000 0100 listening 2014 09 09 01 00 00 000 0100 command received shutdown 2014 09 09 01 00 01 000 0100 shutting down the text below is app2 log 2014 09 09 00 00 00 000 0100 starting initialization 2014 09 09 00 00 01 000 0100 initialization completed successfully 2014 09 09 00 00 02 000 0100 scanning for listeners 2014 09 09 00 00 03 000 0100 identified listener 2014 09 09 00 00 04 000 0100 registering listeners 2014 09 09 00 00 05 000 0100 registered listeners 2014 09 09 00 00 06 000 0100 registration complete successfully here is the conf very simple input file path elk app1 log elk app2 log start position beginning sincedb path elk sincedb filter grok match message if grokparsefailure not in tags date match datetime yyyy mm dd hh mm ss sssz output stdout codec rubydebug >>>v1.5.0-rc1 windows
rabbitmq use bunny >>>enhancement v1.5.0
rspec helper for configuration inputs outputs filters every plugins use some sort of configuration it will help create the minimal tests for each plugin to have some sort of helpers to test them we could take https github com thoughtbot shoulda matchers as an inspiration this will complete the pipeline helpers help us with the deprecated config>>>enhancement tests-infra
fix cleaning s3 input cleaning the s3 input little took the work from danielredoak as starting point added few tests around the new list new logic >>>reviewing
regex grok patterns grok patterns are pretty fundamental utility for getting information out of many logs and are regularly combined with conditionals in the filter phase it would be useful to generalize grok patterns to the entire system say by relabelling them regex patterns and being able to access them in all places where applicable for example something like this if stuff pattern2 and other stuff grok match pattern1 p1 pattern2 p2 pattern3 p3 not sure what the correct syntax would be but the above tripped off the keyboard my example is bit artificial >>>enhancement
nameerror uninitialized constant i18n config set when try to start dev agent built out of the repository on rhel5 get nameerror uninitialized constant i18n config set const missing at org jruby rubymodule java 2690 available locales set at opt logstash vendor bundle jruby gems i18n 11 lib i18n config rb 47 locale available at opt logstash vendor bundle jruby gems i18n 11 lib i18n rb 277 enforce available locales at opt logstash vendor bundle jruby gems i18n 11 lib i18n rb 285 translate at opt logstash vendor bundle jruby gems i18n 11 lib i18n rb 150 agent at opt logstash lib logstash agent rb root at opt logstash lib logstash agent rb require at org jruby rubykernel java 1085 root at file usr opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby shared rubygems core ext kernel require rb run at opt logstash lib logstash runner rb 138 call at org jruby rubyproc java 271 run at opt logstash lib logstash runner rb 158 call at org jruby rubyproc java 271 require at file usr opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby shared rubygems core ext kernel require rb 55 >>>needs_details
dns filter spec should always mock the call to the resolv library fix always mock rspec resolv calls for this filter the integration test could use the real dns server 1875>>>enhancement v1.5.0
logstash filters dns dns reverse lookup sometime fails some dns spec are failing investigate if its better to just stub the call or rely on the localhost logstash filters dns dns reverse lookup replace on field foo 199 192 228 250 when processed failure error unable to find matching line from backtrace insist failure expected carrera databits net but got carrerra databits net spec filters dns spec rb 36 in root lib logstash runner rb 61 in `run lib logstash runner rb 116 in `run lib logstash runner rb 158 in `run >>>bug v1.5.0
accept file and http uri in f>>>enhancement
multiline removes lines when we try to index some xml with multiline all identic lines are not saved image https cloud githubusercontent com assets 2175602 4591547 8a14f030 506e 11e4 9f71 e5dd1ea7fde9 png >>>bug
zeromq input not compatible with libzmq hello getting an error when trying to run logstash with zeromq input have version of zeromq installed libzmq support was added to ffi rzmq in v2 https github com chuckremes ffi rzmq commit d556e0482eee159b117a718e5d6f94796027d58a guessing the gemspec file dictates which version is linked at build https github com elasticsearch logstash search utf8 e2 9c 93 ffi rzmq type code >>>reviewing v1.5.0
conditionals no way to check if boolean field exists in the logstash config language can determine any way to check if boolean field exists using this conditional `if myfield exists else doesn exist the results from testing this conditional statement are ve asked the question here as well to reach out and see if someone else knows way to check for boolean existence http stackoverflow com questions 26287082 logstash config check if boolean field exists>>>enhancement
logstash not using etc default logstash environment variables installed logstash from official deb repository set custom java jre in etc default logstash javacmd opt jre bin java logstash init script launch logstash without the proper javacmd value it seems chroot exec command doesn forward the environment properties fixed it adding in opt logstash bin logstash etc default logstash >>>bug packaging
logstash grok filter have this pattern monthday montdayjava month monthjava year yearjava time timejava loglevel notspace threadid host httpdate timestamp word verb notspace request http number httpversion word channel notspace channelurl number requesttime notspace requesttimeunit and the problem is in word verb notspace request http number httpversion logstash get this error expected one of at line 13 column 174 byte 363 after filter if type apache access grok 	match message monthday montdayjava month monthjava year yearjava time timejava loglevel notspace threadid host httpdate timestamp you may be interested in the configtest flag which you can use to validate logstash configuration before you choose to restart running system can some one help me please >>>question
update email rb the explanation how to use the options part of the configuration is confusing especially the part explaining the defaults adding an example on how the change the defaults to other value should help >>>missing_cla
s3 output use an hardcorded path for tmp and fail creating directories when you are using the s3 output plugin and the opt logstash s3 temp doesnt exist it will try to create the s3 temp but it wont do it recursively also there is no way to specify custom directory it should be new option in the config file >>>bug
grok maybe allow defining the type in the pattern definition problem many users do things like number bytes in grok and then are confused why elasticsearch fails to do statistics or other numeric aggregations on it the cause is that grok only does strings by default and elasticsearch is sent string and maps bytes to string and this is confusing tired of users tripping over this problem would be willing to add feature to grok that allowed you to define the type of pattern inside the pattern definition background in grok patterns file you can define pattern with `name pattern` syntax name of pattern space the regexp pattern proposal allow the type to accompany the name by way of example if we were to fix this number problem permanently we would define the new pattern like this the new syntax is `name type regexp` and is backwards compatible with the old syntax the type` is made optional and defaults to string if not provided this would allow us to more reasonably define the patterns with their respective types such that this will be captured as numeric type in elasticsearch number bytes it not clear if this will solve everything though since in some cases like bytes the value is never fractional so users doing number bytes and seeing float may be confused because they wanted to see long type in elasticsearch thoughts >>>enhancement
add message id debug line so we know what email killed ls lot of the time we don know what email caused an error in parsing thus as soon as we start parsing an email lets debug log the message id so we can identify and remediate >>>enhancement
how to stop logstash automaticaly hi whenever my file reading is completed then automatically logstash is requiered to stop so where required to do configuration waiting for reply>>>question
sns plugin nullpointer bug https github com elasticsearch logstash blob master lib logstash outputs sns rb l117 the call to join is not guarded so if your event has no tags the plugin nullpointer except at this line and kills the whole logstash process >>>bug
config logic is broken if type in syslog fails looked at the debug output it turns syslog into field reference this fails if type in syslog this works if type in foobar imadethisupanddonotwantthisvariable this works if type foobar >>>bug
grok pattern in file should trim ending spaces put grok patterns in file didn realized there was space at the end it resulted not match took me quite some time to figure out that the problem need to use rubydebug to tell there parsing error even didn tell since leading spaces do not matter ending space should not either also think it common mistake >>>bug v2.0.0
refactor filters base periodic flush option as discussed in 1545 and 1805 the periodic flush should not be user configurable >>>enhancement v2.3.0
fix broken link to page with configuration examples>>>bug docs
allow metadata to an event that is not sent on output originally from https logstash jira com browse logstash 1798 it would be great to have arbitrary metadata for an event which isn passed through the output and specifically not made available to the encoding serialization phase example use case fields like index name which are derived by filter and used by the elasticsearch output but probably shouldn be part of the event sent to elasticsearch proposed syntax is simply fieldref namespace metadata anything under this is considered metadata and not show up normally through json or other serialization example use once https github com elasticsearch logstash pull 1644 is merged >>>enhancement v1.5.0
feature request collectd codec also on output would be nice to use when sending metrics to collectd >>>enhancement new-plugin
feature request load config pattern if deemed valuable to others would it be possible for someone with ruby experience to update the globbing of configs to be conf might be just as simple as changing line 288 of agent rb this would allow you to also keep backups of old configs or move configs out of the way if you want to piecemeal during testing which configs are live luckily the added bonus even with is that private directories like git aren sourced so the entire logstash conf can be under version control >>>discuss
respect default values specified via `default` the existing documentation generator doesn take into consideration defaults declared like so default codec json this fixes issue 1827 >>>v1.4.0
create split array rb filter to yield events from an array>>>missing_cla needs_tests
documented default codec for redis input is incorrect the documentation says it plain but looking at the code reveals that it json >>>v1.4.0
commit history cleanup can someone remove this from the commit history 2c5a955fc89df67e6aac08bfddac4db723ff222d 69535125 debian debian logstash war git filter branch prune empty index filter git rm rf cached ignore unmatch debian debian logstash war tag name filter cat all>>>internal-cleanup
gem bundling refactor gem bundling now uses the standalone mechanism to generate setup rb file which add each individual gem into the load path this considerably speeds up the logstash boot time my tests shows it almost cut load time in half got rid of the custom gemfile specs loading which did not work when trying to use local unpublished gem after applying this you must >>>enhancement
user agent no target specified the filter is supposed to place name os os name device in the root of the event if target isn specified without specified none of the fields are created by changing to have target of ua it creates the fields but removing that target line results in no fields being written out even though cs useragent in this case contains content also could wrap this with conditional if cs useragent but would think the filter should be updated to state if source value is or then don populate ua fields with other >>>needs_details
documentation issue on the web page logstash net going to docs and then getting started with logstash when we want to see the logs on elasticsearch the code should be logstash input stdin output elasticsearch host localhost protocol http port 9200 otherwise an exception is thrown org elasticsearch discovery masternotdiscoveredexception waited for 30s if you can guide me about how to update this can do it thanks>>>docs needs_details
filter metrics fix flushing in metrics filter as discovered in 1805 metrics filter is not correctly flushing events the current spec was calling flush manually not relying on the pipeline periodic flusher threads here is proposal test case using the full agent to cover this case fix to metrics filter based on the changed done to other flushing filters multiline spool in 1545 >>>bug
add general purpose gzip codec add gzip codec or file input option for gzipped files edit add general purpose gzip codec which can be used in inputs and outputs>>>new-plugin
logstash web upstart driven daemon doesn run properly on ubuntu 14 04 trusty right after you install the `logstash 2c0f5a1` package from the official repository you would see that the `logstash web` process consumes enormous amount of cpu then dies if you dig and try to run the exact command it executes you would see gem home opt logstash vendor bundle jruby usr bin java djava io tmpdir var lib logstash xmx500m xx useparnewgc xx useconcmarksweepgc djava awt headless true xx cmsinitiatingoccupancyfraction 75 xx usecmsinitiatingoccupancyonly jar opt logstash vendor jar jruby complete 11 jar opt logstash lib opt logstash lib logstash runner rb web var log logstash logstash log optionparser invalidoption invalid option complete at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby optparse rb 1542 catch at org jruby rubykernel java 1284 complete at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby optparse rb 1540 parse in order at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby optparse rb 1380 catch at org jruby rubykernel java 1284 parse in order at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby optparse rb 1347 order at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby optparse rb 1341 permute at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby optparse rb 1432 parse at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby optparse rb 1453 parse at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby optparse rb 1443 run at opt logstash lib logstash kibana rb 83 run at opt logstash lib logstash runner rb 126 call at org jruby rubyproc java 271 run at opt logstash lib logstash runner rb 175 main at opt logstash lib logstash runner rb 92 root at opt logstash lib logstash runner rb 215 if you run it without the last l` parameter it runs fine may be relevant to https github com elasticsearch logstash issues 1809 ps the `logstash agent` meanwhile starts fine>>>v1.5.0
not binding to ports when running as regular user wanted to bring back https logstash jira com browse logstash 840 since running as logstash user can open ports 1024 is there any documented work around for this would be nice for logstash to ingest 514 for central syslog but not have to run as root to do so >>>needs_details
add dot slash to tutorial per the direction above it we re running the local copy not anything in the path>>>needs_details
tiny typo in docs dupe word>>>bug docs missing_cla
conditional regex does not match numbers https logstash jira com browse logstash 1474>>>adoptme enhancement
logstash using 100 cpu while installing logstash on ubuntu 14 04 01 saw after starting logstash that java started using 100 of the cpu this was using java openjdk 67 and logstash after comparing with centos and the same config saw that logstash stopped if there was no config in the etc logstash conf directory the same was not true on ubuntu after putting bogus config file in the directory on the ubuntu machine the cpu usage dropped back to normal >>>needs_details
multiline needs to be more clear on not thread safe multiline documentation should be clearer that it not thread safe and that one needs to be careful to ensure the events pass though the same logstash instance to ensure the log lines can be processed by the same handler >>>docs
metrics filter not working with current master hello tried to do some benchmarking yesterday with the latest master but metrics plugin is not working with that release used various config settings one of them was also the one suggested in metrics rb plugin file input generator type generated filter if type generated metrics meter events add tag metric output only emit events with the metric tag if metric in tags stdout codec line format rate events rate 1m generator is generating event so input works also added mutate add tag before if sentence and between metrics and get new tags so it looks like it does go through filter section but metrics plugin somehow doesn produce output can anyone confirm is my syntax wrong >>>bug
filter xml fix for logstash 2246 extract non ascii content with xpath copied from 1790 as reported in logstash 2246 https logstash jira com browse logstash 2246 xml filter xpath fails with non ascii content here is test case and fix it is due to nokogiri to http nokogiri org nokogiri xml node html method to calling to xhml or to xml without encoding parameters using the to str method extract the content differently hidden in the or java implementation and do not suffer encoding issue>>>bug
issue connecting logstash with elasticsearch was following the getting started guide http logstash net docs tutorials getting started with logstash and couldn test the trivial case with elasticsearch even when was using the recommended versions openjdk 7u65 es and logstash all of this in ubuntu 14 04 installation you propose to start it this way but get this error and nothing was stored on the server was able to get it to work this way so is there an error in the documentation am doing something wrong what the correct way to connect logstash with an elasticsearch server thanks >>>needs_details question
add additional functions to irc input adding the ability to catch all events this includes privmsg to logstash quit join parts add the ability to send number of users per channel stats into the logstash pipeline on intervals >>>enhancement
feature request allow field to be set to analyzed or not analyzed from within logstash think it would be nice if we could set field to be not analyzed or analyzed in elasticsearch from logstash configuration have no idea how easy or difficult this kind of thing would be to implement but figured might as well throw it out there >>>enhancement
remove logstash web init script there no need to launch kibana on all logstash installations and the current way we ship init scripts doesn work well anyway >>>v1.5.0
avoid static file corruption small png on windows when using `logstash web` on windows the kibana logo on the dashboard is broken this is because it will return small png with 479 instead of 480 bytes removing 0x0d >>>missing_cla v1.5.0
patterns grok patterns should not be executable>>>bug
elasticsearch output plugin to support multiple hosts and enhance stability elasticsearch output plugin to support multiple hosts and enhance stability make elasticsearch output plugin to support mutiple hosts and round robin balance which will help lot to balance the resource and performance of whole elasticsearch cluster improve stability by handling exception and retry with left servers while flushing bulk which will reduce the possibility of data loss largely >>>enhancement missing_cla
filter xml fix for logstash 2246 extract non ascii content with xpath as reported in logstash 2246 https logstash jira com browse logstash 2246 xml filter xpath fails with non ascii content here is test case and fix it is due to nokogiri to http nokogiri org nokogiri xml node html method to calling to xhml or to xml without encoding parameters using the to str method extract the content differently hidden in the or java implementation and do not suffer encoding issue >>>bug
dns filter add tag adds tags even if filter was unsuccessful noop add field hostname ip address dns action replace reverse hostname add tag reverse dns successful even if reverse dns doesn resolve the reverse dns successful tag gets added was hoping to use conditional on this tag in order to remove my duplicated hostname field if it still contains an ip address >>>bug
remove redis input list listener custom lua the custom lua script used for batching items from list could be replaced with so basically doing lrange fetches batch of items without deleting them ltrim deletes them wrapped in multi to make this atomic and wrapped in pipeline to avoid multiple network roundtrips >>>enhancement
redis input plugin blocks logstash pipeline shutdown tested against mac os 10 and centos x86 64 with logstash to reproduce download and extract the precompiled logstash archive https download elasticsearch org logstash logstash logstash tar gz run logstash with the below configuration barebones with only redis input input redis host 127 data type list key test filter output stdout attempt to shutdown logstash using ctrl observe that logstash does not halt using ctrl prints interrupt received shutting down the pipeline level warn but also does not shut down using ctrl number of times after will continue to print the same pipeline shutdown message but has no effect otherwise >>>bug unconfirmed v1.5.0
s3 input do not require aws credentials fallback to iam roles using the s3 input to pull some logs from s3 and didn configure the `credentials` part since have configured the instance with iam roles unfortunately found out that the credentials are required searched bit and found out that aws sdk works with iam roles seamlessly http docs aws amazon com awssdkdocsruby latest developerguide ruby dg roles html so suppose that it going to be trivial to let it use that if it appears to be trivial we can adopt this for all aws related input outputs unfortunately my ruby skills are limited to some chefing so hesitate to go on and fix it but if you could provide some guidance and feedback could give it shot ps the s3 input has no tests right >>>enhancement
add http auth and ssl to the es output plugin the typical use case is the placement of transparent proxy in front of es this pr enables basic auth and https to be configured independently while the ssl configurations only allow the validation of the server certificate and specification of the ca cert it easy to add the necessary options to send the client certificate also this patch removes the use of ftw in the output plugin sticking only to the elasticsearch ruby client if performance is an issue faster alternative to the faraday transport in es ruby could be implemented >>>blocker reviewing v1.5.0
sqs input plugin won restart logstash stops reading from sqs but is still running error message says plugin is restarting but nothing actually happen message plugin had an unrecoverable error will restart this plugin plugin elb credentials region endpoint eu west tags s3 error socket closed level error >>>bug
add msgpack feed unpacker codec for use with tcp or pipe inputs could be refactored to be an option within the msgpack codec my ruby could also be rusty >>>new-plugin
wip integration tests this is wip pr on the feature integration tests shared branch the idea is to provide tooling for real logstash integration tests both for performance measurement purpose and for correctness each test should invoke logstash in an external process as opposed to use mocked test harness as with specs >>>enhancement v1.5.0
fix 1771 fix for issue 1771 added bonus is new spec for the ruby filter >>>enhancement
fix to json methods to accept arguments for json gem compatibility following the json refactor the `timestamp` class implements `to json` which breaks if to json is called from json gem context the fix is to change the method signature to accept arbritary arguments which can be ignored >>>bug v1.5.0
plugins format vs message format config inconsistencies most codecs and some plugins use the `format` config but not file output juggernaut output nagios nsca output pipe output tcp output which use `message format` shouldn we just use `format` everywhere >>>breaking-compatibility enhancement v3.0.0
pipeline shutdown can be blocked by stdin input for whatever reason can figure out how to close stdin in jruby and interrupt any currently blocked reads on stdin this confuses users and is generally annoying the symptom is that should terminate logstash cleanly but stdin never really stops so the pipeline stays up until you close stdin as user via related 1767 >>>enhancement v3.0.0
conditionals for output are broken in master as stated in super documented and explored logstash 2288 https logstash jira com browse logstash 2288 by danielredoak current master fails when using conditionals in output block here is simple testcase and fix proposal jordansissel can you please review>>>bug
specify ctrl to halt pipeline kinda confusing to new users `ctrl d` is better than `ctrl c` >>>bug
random lumberjack input causing logstash to crash was wondering if someone could point me in the right direction with weird error seeing with logstash and lumberjack input have logstash doing some event filtering and sending logs to another logstash server using the lumberjack output input it been working great with my nginx and syslog data but today ve enabled new application that sends json data to logstash it looks like it sending some events that are crashing one of my logstash instances have tried running logstash in debug mode but can see anything useful in there >>>bug
refactor rspec first step of the rspec refactoring for 1737 >>>enhancement reviewing
elasticsearch http plugin should be deprecated since the `elasticsearch` output plugin has supported `protocol http` this makes the `elasticsearch http` now mostly duplicate and not needed anymore let mark it deprecated and provide users helpful message for how to convert for example showing full configuration example based on exactly their output config to convert it to elasticserach output the message should be warning and non fatal >>>blocker docs v1.5.0
can split strings with in mutate plugin have multiline message php slow log and had already grok part of it into new field stack but can split the new field string into an array by `mutate split stack there is no error warning messages but just put all data into new field try to use filters ruby to write `event stack event stack split and got what want so is there anything specially in filters mutate >>>known_issue
use defaultencoder as default message serializer as specified by the kafka documentation for producers http kafka apache org documentation html>>>bug
rfc remove ability to run multiple subcommands from bin logstash today users can do `bin logstash agent something conf web` and they ll get single process with an agent and web thingy don think anyone uses this and it mostly confuses users for clarity am proposing removing the ability to run multiple subcommands simultaneously bin logstash web is staying because it is really useful for first time users demos and proof of concepts work like to remove this function multiple subprocesses and in doing so clean up whole bunch of nasty code in `lib logstash runner rb` if you depend on this feature please let me know >>>breaking-compatibility v1.5.0
move docs into asciidoc format adding asciidoc generation for plugin s>>>v1.5.0
kafka output unknown configuration key topic id topic id topic id shouldn be passed to the producer config object >>>bug v1.4.0 v1.5.0
refactor logstash rspec testing along the way logstash rspec testing system has grown into an abomination this ticket is to list things that we need to fix in the first iteration move to rspec move all helper functions into their own modules and extend rspec implement docker support for testing against services re factor rspec files into correct naming convention and structure>>>enhancement tests-infra
win32ole failing running most current rpms on rhel commands to install yum localinstall https download elasticsearch org elasticsearch elasticsearch elasticsearch noarch rpm yum localinstall https download elasticsearch org logstash logstash packages centos logstash 2c0f5a1 noarch rpm yum localinstall https download elasticsearch org logstash logstash packages centos logstash contrib efd53ef noarch rpm 10 history grep localins root ip 10 64 16 25 logstash tail logstash err loaderror load error win32ole win32ole java lang unsatisfiedlinkerror opt logstash vendor bundle jruby gems jruby win32ole lib racob x64 dll opt logstash vendor bundle jruby gems jruby win32ole lib racob x64 dll invalid elf header possible cause endianness mismatch require at org jruby rubykernel java 1085 require at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby shared rubygems core ext kernel require rb 55 require at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby shared rubygems core ext kernel require rb 53 require at opt logstash vendor bundle jruby gems polyglot lib polyglot rb 65 root at opt logstash vendor bundle jruby gems jruby win32ole lib jruby win32ole rb 10 require at org jruby rubykernel java 1085 require at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby shared rubygems core ext kernel require rb 135 require at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby shared rubygems core ext kernel require rb 133 require at file opt logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby shared rubygems core ext kernel require rb 124 require at opt logstash vendor bundle jruby gems polyglot lib polyglot rb 65 root at opt logstash lib logstash inputs eventlog rb register at opt logstash lib logstash inputs eventlog rb 36 each at org jruby rubyarray java 1613 start inputs at opt logstash lib logstash pipeline rb 135 start inputs at opt logstash lib logstash pipeline rb 134 run at opt logstash lib logstash pipeline rb 72 run at opt logstash lib logstash runner rb 168 call at org jruby rubyproc java 271 execute at opt logstash lib logstash agent rb 139>>>reviewing
support for redis sentinel in redis input and output redis supports failover through separate service called sentinel http redis io topics sentinel added support for it to the output and input modules using the redis sentinel wrapper library https github com flyerhzm redis sentinel >>>missing_cla
add journald input requested at fossetcon during untergeek talk by folks from red hat coreos api docs here http www freedesktop org software systemd man sd journal html journal api seems fairly stable over the past few years though any help understanding exactly which apis are known stable and if that api is available in the systemd shipped in rhel fedora etc either way systemd is popular and streaming the journal into logstash seems like pretty great win for users >>>needs_review new-plugin
support amqp protocol requested at fossetcon during untergeek talk by folks from red hat coreos >>>enhancement
don open an extra log subscriber to stdout on hup currently sending hup signal to logstash when logging to stdout adds and it as subscriber again resulting in extra log messages for each hup signal sent which is very confusing >>>missing_cla
make grok pattern prog bit more flexible this small patch makes logstash correctly interpret ansible ansible progname atm it failes with grok parse error generally any characters are allowed except and colon needed because sometimes pid isn used tests pass >>>bug
dns rb socketerror gethostbyname name or service not known socketerror gethostbyname name or service not known gethostbyname at org jruby ext socket rubysocket java 286 resolve at opt logstash vendor bundle jruby gems ftw 39 lib ftw dns dns rb 13 resolve at opt logstash vendor bundle jruby gems ftw 39 lib ftw dns rb 38 each at org jruby rubyarray java 1613 inject at org jruby rubyenumerable java 865 resolve at opt logstash vendor bundle jruby gems ftw 39 lib ftw dns rb 37 connect at opt logstash vendor bundle jruby gems ftw 39 lib ftw connection rb 137 connect at opt logstash vendor bundle jruby gems ftw 39 lib ftw agent rb 406 call at org jruby rubyproc java 271 fetch at opt logstash vendor bundle jruby gems ftw 39 lib ftw pool rb 48 connect at opt logstash vendor bundle jruby gems ftw 39 lib ftw agent rb 403 execute at opt logstash vendor bundle jruby gems ftw 39 lib ftw agent rb 319 get at opt logstash vendor bundle jruby gems ftw 39 lib ftw agent rb 217 register at opt logstash lib logstash outputs elasticsearch http rb 117 each at org jruby rubyarray java 1613 outputworker at opt logstash lib logstash pipeline rb 220 start outputs at opt logstash lib logstash pipeline rb 152>>>bug
move logstash gemspec loading into environment module previously the loading of the logstash gemspec was limited to the plugin manager after more tests we need the gemspec to be loaded for any action with the plugins moving it to the environment module makes it available for more generic loading>>>v1.4.0
improvements to plugin manager use better installer method to avoid documentation installation with the previous method it would install the documentation which didn exist create fake gemspec info for logstash to help dependency management for plugins previously we would create real gem and install it to aid in dependency management for plugins and logstash now we create fake gemspec on the fly with the real version of logstash avoiding having to build it every time >>>enhancement
kv filter issue with kv on repeated key values pairs duplicate values emitted using logstash kv trim include keys tradeid now the message has tradeid 123 etc etc tradeid 123 but now my tradeid 123 123 would be nice if it removed duplicates in the mean time is there work around >>>enhancement v1.5.0
added grok pattern for google app engine logs parsing ve added this grok pattern that allows users to parse google app engine logs there were lot of commits in august because started working with the previous gae format that changed on 27th of august see my issue opened https code google com googleappengine issues detail id 11251 >>>enhancement
require usr bin which for wrapper script >>>missing_cla
kafka do not delete zk offset when auto offset reset is set to smallest wait for upstream issue https github com joekiller jruby kafka issues 7>>>bug
failed parsing date from field invalid format in logstash this bug was reported on irc by finaltry finaltry reported that it was happening on jdk 67 from oracle java website using suse 11 sp2 and on windows have confirmed that it happens on windows with jdk 40 could not reproduce on centos using jdk 32 or 65 but not confident that was really using jruby there since have rvm set up with ruby on my path tried running logstash with `use jruby 1` at the beginning of the command line but not sure whether it really did it or not summary it looks like it java error from joda time but doesn seem to be occurring on all platforms details simple conf invocation input on stdin output >>>bug
kafka allow sprintf for topic id see https github com joekiller logstash kafka issues 19 allowing the logstash sprintf call on the topic id would allow routing events to different topics without multiple conditionals and producers in my use case like to send events on few different topics logs system logs app metrics app with sprintf on the event could tag each input with type and use that to dispatch to matching topic does this sound feasible >>>enhancement v2.0.0
flag to enable async replication on elasticsearch output see https logstash jira com browse logstash 333>>>enhancement v1.4.0
logstash hangs after invalid byte sequence in utf exception in filterworker gsub after urldecode in the logs with logstash running with see followed by many many plugin is finished log lines including this one which guess is the cause of the exception that message came from tcp input that has ``codec line charset utf `` set but that another issue and then nothing logstash has hung >>>bug v1.5.0
elasticsearch update api support it could be nice if logstash could interact with elasticsearch update api the api specification http www elasticsearch org guide en elasticsearch reference current docs update html >>>enhancement
prevents event sprintf from converting floats to sci notation this allows sprintf to correctly print floats up to 15 decimal places which should be enough for most without this very big or very small floats will be converted to scientific notation fixes 1670>>>bug
docs for conditionals aren clear about what constitutes true or false value for example given `if foo the docs don make it clear when that expression will be false presume it ll be false if there no field of that name but the doc don actually say that will it be false if the field contains an empty string or numeric or string or an undefined nil value other clarifications are needed as well there no mention of operator precedence or associativity the `in` operator has no documentation other than list of examples but they don make it clear how `in` actually behaves when one side or the other is an array or string some operators will cause exceptions if the value they re applied to is of the wrong type string instead of int or vice versa others silently fail to work that last point has caused me hours of difficulty few months ago continue to have hard time with these basic issues and not newbie >>>docs
logstash kafka do not decorate kafka metadata by default in input plugin kafka input adds metadata for every event read like kafka msg size 288 topic test demo1 consumer group logstash this can be controlled by the setting `decorate events false` the default is true today but feel it should be turned off by default this behavior is also consistent with other plugins like es it can be turned on optionally>>>bug v1.5.0
getting discover file glob error message in logstash1 console output while trying to process vmstat output following is the logstash conf file which am using the log file input for it is generated based on redirecting vmstat command output till yesterday it was working fine but suddenly it started giving discover file glob error earlier was using and upgraded to but the issue is same output is send to elasticsearch in local machine can you please let us know if there is any issue in the setup could cause this issue made sure the lnput file has proper permission logstash conf input file discover interval 60 path logstash testlogs vmstat log filter grok match message number int space space number int space space number swapd int space space number free int space space number buff int space space number cache int space space number si int space space number so int space space number bi int space space number bo int space space number in int space space number cs int space space number us int space space number sy int space space number id int space space number wa int output elasticsearch input log file content 7535996 72612 232184 19 35 100 7535988 72612 232188 283 532 100 7535988 72620 232188 279 533 100 7535988 72620 232188 275 530 100 7536020 72628 232188 284 535 100 logstash console log log4j 2014 08 25t19 05 46 201 debug org elasticsearch cluster service logstash genieacs vm1 23844 4010 set local cluster state to version 20 log4j 2014 08 25t19 05 46 201 debug org elasticsearch cluster service logstash genieacs vm1 23844 4010 processing updating local node id done applying updated cluster state version 20 log4j 2014 08 25t19 05 46 201 info org elasticsearch node logstash genieacs vm1 23844 4010 started new elasticsearch output cluster nil host nil port 9300 9305 embedded false protocol node level info file logstash outputs elasticsearch rb line 252 automatic template management enabled manage template true level info file logstash outputs elasticsearch rb line 258 using mapping template template type geo point level info file logstash outputs elasticsearch rb line 278 discover file glob logstash testlogs vmstat log glob is logstash testlogs vmstat log level debug file filewatch watch rb line 117 discover file glob logstash testlogs vmstat log glob is logstash testlogs vmstat log level debug file filewatch watch rb line 117 >>>reviewing
allow dynamic parsing of the timezone parameter to date filter using beaver to ship nginx error log to logstash and it has an additional field with the timezone information from the server like to use the specified timezone to parse the timestamp properly >>>enhancement
typo in getting started tutorial string has to be enclosed in double quotes this typo made me waste quite lot of time while trying the getting started tutorial blush >>>bug docs v1.4.0
how to remove the fields that used in the output want to set index according to the file name and don want the index has some useless fields such as file name output elasticsearch host 192 168 10 cluster ky esearch index file dir file name index type file time like above don want index has the fields file dir file name file time but if remove them from the object event won get them in the output how to do it >>>v1.5.0
filter date fallback to en locale better failure logging and tag on failure some more improvments to date filter use fallback parser with english locale when platform default is non english logstash 785 improve register error report with invalid pattern logstash 1487 improve date parsing final failure log add the config tag on failure logic logstash 777 logstash 915 >>>bug
add parallel download to s3 default parallel files file from s3 too slow this patch speedup logstash for parallel processing s3 files>>>enhancement
file input doc update update docs to mention the fileinput filter requires stable inode numbers there are number of logstash user posts where users have stumbled on this >>>docs
file input buffering causing duplicate messages on logstash restart symptom restarting logstash while it is reading large file will cause it to duplicate some messages cause think it is the buffering in tail rb read file from ruby filewatch tail rb reads the file in 16kb chunks but doesn update it in memory sincedb until all 16kb have been sent to logstash and presumably processed don yet understand how file rb is wired in possible fix slow reading in smaller chunks using 25 byte buffer caused no messages to be duplicate but few to be dropped possible fix faster update the in memory sincedb hash after yielding each line sincedb inode filepos line length not sure how multi byte character encodings are handled in ruby and or logstash any thoughts be willing to work on fix with some direction >>>bug needs_details
parse failure slows down entire agent when logstash fails to parse large log file with large grok parse template it slows down the entire agent performance significantly on the other hand when the parsing succeeds logstash is orders of magnitude faster maybe it has something to do with exception handling >>>needs_details
suspicious logstash mulitline behaviour hello all we use logstash forwarder and logstash from the elasticsearch repo we crashed on very weird case with the following log line 2014 08 28 11 55 05 112 ganeti masterd pid 4426 clientreq7 info received job poll request for 799610 the line has no newline inside it and we wonder what injected the newline in the middle of the request string in the message field lsf or logstash is there some parameter that we should take into consideration several similar logs events come and go and are parsed correctly it seems that logstash received the event once as mulitline event timestamp 2014 08 28t11 55 12 199000 0300 message filter received event logstash event 0x68d28bf2 cancelled false data message 2014 08 28 11 55 05 112 ganeti masterd pid 4426 clientreq7 info received job poll requ version timestamp 2014 08 28t08 55 12 145z type ganeti file var log ganeti master daemon log host gnt 03 offset 5291945 log type ganeti master log level info timestamp 2014 08 28t11 55 12 209000 0300 message filter received event logstash event 0x14423fb0 cancelled false data message est for 799610 version timestamp 2014 08 28t08 55 12 151z type ganeti file var log ganeti master daemon log host gnt 03 offset 5292033 log type ganeti master log level info timestamp 2014 08 28t11 55 12 230000 0300 message output received event logstash event 0x18dafb1a cancelled false data message 2014 08 28 11 55 05 112 ganeti masterd pid 4426 clientreq7 info received job poll requ nest for 799610 version timestamp 2014 08 28t11 55 05 112 03 00 type ganeti file var log ganeti master daemon log host gnt 03 offset 5291945 5292033 log type ganeti master log tags multiline grokked multilinegrokparsefailure dated ganeti unknown log timestamp 2014 08 28 11 55 05 112 proc name ganeti masterd proc pid 4426 ganeti thread clientreq7 error level info ganeti message received job poll requ received at 2014 08 28 08 55 12 utc level info and once more after several minutes as single line event timestamp 2014 08 28t11 59 01 897000 0300 message filter received event logstash event 0x6736458d cancelled false data message 2014 08 28 11 55 05 112 ganeti masterd pid 4426 clientreq7 info received job poll request for 799610 version timestamp 2014 08 28t08 59 01 824z type ganeti file var log ganeti master daemon log host gnt 03 offset 5291945 log type ganeti master log level info timestamp 2014 08 28t11 59 01 931000 0300 message output received event logstash event 0x3041084c cancelled false data message 2014 08 28 11 55 05 112 ganeti masterd pid 4426 clientreq7 info received job poll request for 799610 version timestamp 2014 08 28t11 55 05 112 03 00 type ganeti file var log ganeti master daemon log host gnt 03 offset 5291945 log type ganeti master log proc name ganeti masterd proc pid 4426 ganeti thread clientreq7 error level info received at 2014 08 28 08 59 01 utc tags grokked dated level info kindly kostis>>>needs_details
gracefully shutdown the agent on sigterm fixes 1675 tested on ubuntu precise fixes github issue 1675 >>>v1.5.0
duplicate events on service restart with file input symptom logstash re reads files when the logstash service is restarted ubuntu logstash installed with apt get cause logstash does not trap sigterm sent by upstart so file input does not get chance to flush any sincedb changes to disk to reproduce create files with message each sudo service logstash start wait for logstash to process the files sudo service logstash restart wait for logstash to process the files expected after the restart logstash will not output any events actual logstash outputs duplicate events here is vagrantfile to reproduce https github com brianlow logstash dupe mailing list discussion https groups google com forum topic logstash users wrwx99ar2qo >>>bug missing_cla
eventlog input doesn shutdown when asked user on irc reported that eventlog input windows prevents logstash from terminating cleanly and appears to get stuck or at least ignores the shutdown request >>>v1.5.0 windows
statsd output is converting very small float numbers to scientific notation before sending to statsd we ve been seeing lot of these messages in our statsd log `27 aug 13 12 41 debug bad line 3e 05 ms in msg proxy varnish time taken 3e 05 ms the numbers are coming out of the varnishncsa log as very small floats like 000093 but after it comes out of logstash it in the scientific notation checked by running tcpdump to see exactly what was going into logstash and then what was coming out is there any way to stop this from happening >>>bug v1.5.0
useragent plugin not parsing some strings correctly hi ve been using the useragent plugin of logstash and found it very useful but encountered problem with some user agents not being parsed properly useragent string like mozilla windows nt win64 x64 trident rv 11 like gecko will have the ua os field set to just windows while it should be windows the regexes yml file contains appropriate regexes as shown below and testing the string on http www whatsmyua info also identifies it correctly regex windows nt os replacement windows also could not figure out what the difference between ua os and ua os name is they seem to always contain the same values >>>bug needs_details
prevent overwrite of event host field in stdin>>>bug v1.4.0
support rfc5424 message format logstash has the syslog input http logstash net docs inputs syslog which only supports messages in rfc3164 with some modifications it would be useful to add codec which supports rfc5424 http www ietf org rfc rfc5424 txt messages which could be used with inputs like tcp with this support users would not have to use grok filter with `syslog5424line` pattern>>>enhancement
filter date fix locale config as discussed in 1279 date filter locale config setup is complex and buggy in this pr make use of java new factory method http docs oracle com javase docs api java util locale html forlanguagetag java lang string colinsurprenant feedback >>>bug
fix for nil s3 input credentials array configuration values never return nil if unspecified they return an empty array at least from my testing noticed some people brought this issue up on google groups as well so went ahead and modified the credentials parameter to default to an empty array and check for an empty array value if empty it defaults to using environment variables left the original nil check in though that could probably be removed as well lines 71 73 of the file merging in closes elasticsearch logstash 1619>>>bug missing_cla v1.4.0
minimal package installation hi looking to build an rpm based on rhel standards noticed that you bundle some unnecessary files into your current rpm myself will have kibana set in separate rpm for example can you please provide with with list of minimal essential directories needed by `logstash` for example is the vendor` directory needed for the application thank your for your suggestions while here please have look at axivo elasticsearch rpm https www axivo com resources 11 details >>>needs_details question
use optimized grok library tested using combinedapachelog grok format almost 3x throughput increase with grok version `0 10 12` with grok version `0 11 0` and associated ls changes ls config >>>enhancement
filter mutate raise configerror in register as reported in logstash 2003 valid types was an unknown local var and was raising an unexpected error this is fixed and now using the standard logstash configurationerror >>>bug
infinate hang when elasticsearch restarts logstash appears to go into infinite hang after events are processed after elasticsearch restarts tested with logstash elasticsearch on rhel by the following steps tested with file input also start elasticsearch from command line and wait for started message start logstash from command line as agent with following config file input stdin output stdout elasticsearch cluster elasticsearch send test events stdin stop elasticsearch send test events stdin start elasticsearch send test events stdin seems to recover successfully when no events sent before elasticsearch restarts step here is the entire console output exception occurs after test root lnx65 bin logstash agent verbose mdc stdin conf pipeline started level info log4j 2014 08 21t20 10 44 283 info org elasticsearch node logstash lnx65 localdomain 17807 2010 version pid 17807 build f1585f0 2014 04 16t14 27 12z log4j 2014 08 21t20 10 44 283 info org elasticsearch node logstash lnx65 localdomain 17807 2010 initializing log4j 2014 08 21t20 10 44 316 info org elasticsearch plugins logstash lnx65 localdomain 17807 2010 loaded sites log4j 2014 08 21t20 10 47 029 info org elasticsearch node logstash lnx65 localdomain 17807 2010 initialized log4j 2014 08 21t20 10 47 029 info org elasticsearch node logstash lnx65 localdomain 17807 2010 starting log4j 2014 08 21t20 10 47 141 info org elasticsearch transport logstash lnx65 localdomain 17807 2010 bound address inet 9301 publish address inet 10 15 9301 log4j 2014 08 21t20 10 50 358 info org elasticsearch cluster service logstash lnx65 localdomain 17807 2010 detected master lnx65 el3w2hxoqvqkviwo0ft4sg lnx65 localdomain inet 10 15 9300 added lnx65 el3w2hxoqvqkviwo0ft4sg lnx65 localdomain inet 10 15 9300 reason zen disco receive from master lnx65 el3w2hxoqvqkviwo0ft4sg lnx65 localdomain inet 10 15 9300 log4j 2014 08 21t20 10 50 368 info org elasticsearch discovery logstash lnx65 localdomain 17807 2010 elasticsearch sedbmuoztlq5dxxcnenasq log4j 2014 08 21t20 10 50 373 info org elasticsearch node logstash lnx65 localdomain 17807 2010 started new elasticsearch output cluster elasticsearch host nil port 9300 9305 embedded false protocol node level info automatic template management enabled manage template true level info using mapping template template type geo point level info 2014 08 21t18 10 53 394 0000 lnx65 localdomain test 2014 08 21t18 10 58 896 0000 lnx65 localdomain test test 2014 08 21t18 11 01 376 0000 lnx65 localdomain test log4j 2014 08 21t20 11 06 351 info org elasticsearch discovery zen logstash lnx65 localdomain 17807 2010 master left lnx65 el3w2hxoqvqkviwo0ft4sg lnx65 localdomain inet 10 15 9300 reason transport disconnected with verified connect log4j 2014 08 21t20 11 06 353 warn org elasticsearch discovery zen logstash lnx65 localdomain 17807 2010 master left and no other node elected to become master current nodes logstash lnx65 localdomain 17807 2010 sedbmuoztlq5dxxcnenasq lnx65 localdomain inet 10 15 9301 client true data false log4j 2014 08 21t20 11 06 354 info org elasticsearch cluster service logstash lnx65 localdomain 17807 2010 removed lnx65 el3w2hxoqvqkviwo0ft4sg lnx65 localdomain inet 10 15 9300 reason zen disco master failed lnx65 el3w2hxoqvqkviwo0ft4sg lnx65 localdomain inet 10 15 9300 2014 08 21t18 11 14 608 0000 lnx65 localdomain test test test exception in thread elasticsearch logstash lnx65 localdomain 17807 2010 generic org elasticsearch cluster block clusterblockexception blocked by service unavailable state not recovered initialized service unavailable no master 	at org elasticsearch cluster block clusterblocks globalblockedexception clusterblocks java 138 	at org elasticsearch cluster block clusterblocks globalblockedraiseexception clusterblocks java 128 	at org elasticsearch action bulk transportbulkaction executebulk transportbulkaction java 197 	at org elasticsearch action bulk transportbulkaction access 000 transportbulkaction java 65 	at org elasticsearch action bulk transportbulkaction onfailure transportbulkaction java 143 	at org elasticsearch action support transportaction threadedactionlistener run transportaction java 117 	at java util concurrent threadpoolexecutor runworker threadpoolexecutor java 1145 	at java util concurrent threadpoolexecutor worker run threadpoolexecutor java 615 	at java lang thread run thread java 744 log4j 2014 08 21t20 11 45 493 info org elasticsearch cluster service logstash lnx65 localdomain 17807 2010 detected master lnx65 7vpau211rhemhznw1u9eyq lnx65 localdomain inet 10 15 9300 added lnx65 7vpau211rhemhznw1u9eyq lnx65 localdomain inet 10 15 9300 reason zen disco receive from master lnx65 7vpau211rhemhznw1u9eyq lnx65 localdomain inet 10 15 9300 test test >>>reviewing
conflicting information in documentation the documentation for sincedb path in file input http logstash net docs inputs file sincedb path seems to be conflicting it says there is no default value for this setting and afterwards it says the default will write sincedb files to some path matching home sincedb or maybe just misunderstood in which case apologize >>>docs
tcp output plugin does not send newlines the tcp output plugin is supposed to send events separated by newline but the newline is not there tested using nc logstash config tried posting the events like this in other console ran nc the events arrived like this no newline between them >>>bug
tcp input host field contains source port fixes logstash 1849 https logstash jira com browse logstash 1849>>>v1.5.0
define quote escaping semantics this is requested numerous places but was reminded from https github com elasticsearch logstash pull 895 escaping quotes and control characters are impossible to do today in logstash config is literally backslash and lowercase is literally backslash and doublequote logstash supports single and double quoted text values and we should support escapes in both the same exact way proposal should be text with single quote as value should be text with single double quote as value because it is expected by users and should be single tab character as value ascii 09 because it is expected by users and should be single line feed character as value ascii 10 because of and we should also support and as single carriage return ascii 13 and should be text with single backslash unicode text is fully supported and does not need escaping >>>breaking-compatibility enhancement known_issue v3.0.0
hp procurve switch pattern created grok pattern for hp procurve switches>>>needs_details
make record offset available for file input logstash forwarder includes the file offset for generated events this is great to have when trying to identify duplicate events and it would be very useful if the `file` input plugin also provided the offset as part of the generated event >>>enhancement
use ruby for the build process this is major work in progress moving our building tools from make scripting to using ruby and rake >>>v1.5.0
plugin manager plugin manager for the new plugin structure install from rubygems latest specific version from gem file list installed plugins all specific name specific group uninstall plugin update single plugin to latest version single plugin to specific version all to latest version>>>enhancement reviewing work_in_progress
urldecode error encoding compatibilityerror incompatible encodings ascii 8bit and utf am parsing logs with urls and then trying to create an decoded field using the `urldecode` filter some urls have caused an error shown below where logstash throws an exception and hangs can only stop the process by killing it the url below is encoded with n` characters those show up when run the string through `uri unescape in an irb session that too is shown below not sure what is causing the errors logstash has consistently errored on the same log when have tried to run it through again after deleting the since` file this occurs in about 0001 of the logs 25m have don know what would cause this error the raw log has two urls both from amazon the first one is encoded and the second one is not the second url also has n` characters which is strange for url but that is auxiliary to the problem logstash reads the lines and tries to parse them as shown in the grok parsing error output logstash fails which is expected because am not expecting n` characters then the next output is the exception raw log grok parsing errors the log entry is not formed as expected the grok parsing errors are not what concered with included here to show that each line is read error this error hangs logstash exception in filterworker exception backtrace org jruby rubystring java 3041 in `gsub file home nsm logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby uri common rb 331 in `unescape file home nsm logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby uri common rb 649 in `unescape home nsm logstash lib logstash filters urldecode rb 44 in `urldecode home nsm logstash lib logstash filters urldecode rb 33 in `filter eval 225 in `initialize org jruby rubyproc java 271 in `call home nsm logstash lib logstash pipeline rb 262 in `filter home nsm logstash lib logstash pipeline rb 203 in `filterworker home nsm logstash lib logstash pipeline rb 143 in `start filters level error irb rest irb main value http fls na amazon com batch op atvpdkikx0der 180 6327007 2173202 1ss93xt5m0ga50yy9f7d uedata 2fdp 2fb00iaa5bss 2fref 3ddra sm hp ho it p1400 1000 2fuedata 2fnvp 2funsticky 2f180 6327007 2173202 2fdetail 2fntpoffrw 3fld 26v 3d0 811 26id 3d 0a 0a 0a00fjt63vj75hdw3fh6k0 0a 0a 0a 26ctb 3d1 26m 3d1 26sc 3db00lo3k0021 26af 3d2927 26cf 3d3031 26pc 3d3207 26ld 3d3207 26t 3d1408026513217 26csmtags 3daui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 7caui 7caui 3aajax 26pty 3ddetail 26spty 3dglance 26pti 3db00iaa5bss 26tid 3d1ss93xt5m0ga50yy9f7d 26aftb 3d1 38589 irb main 024 uri unescape value http fls na amazon com batch op atvpdkikx0der 180 6327007 2173202 1ss93xt5m0ga50yy9f7d uedata dp b00iaa5bss ref dra sm hp ho it p1400 1000 uedata nvp unsticky 180 6327007 2173202 detail ntpoffrw ld 811 id n00fjt63vj75hdw3fh6k0 ctb sc b00lo3k0021 af 2927 cf 3031 pc 3207 ld 3207 1408026513217 csmtags aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax aui aui ajax pty detail spty glance pti b00iaa5bss tid 1ss93xt5m0ga50yy9f7d aftb 38589 >>>bug v1.5.0-rc1
pipeline stops processing events because of exception in filterworker for nil nilclass getting this error in the logstash error log and when it happens the pipeline stops processing events the inputs are still able to receive events but no events get through to the output stage the error happens infrequently about every other day or so so unsure what exactly is causing it using the website deb of logstash on ubuntu 14 04 what other information do you need to debug this further >>>bug reviewing
snmptrap redis json encoding bug have simple logstash configuration that reads snmptraps and outputs them to redis which is json encoded some messages fail to make it to redis with the logstash log reporting failed to convert event to json invalid utf maybe looking at the code this appears to originate from within the redis output have tried without specifying codec as well as explicitly setting the charset to binary the snmp traps do contain some non ascii characters binary representations of mac addresses and ip addresses but they appear to be properly escaped with xhh style notation in the output log the only difference can spot between messages that make it to redis compared ones that fail is the mac address field an example of failing message has this field in the message part note it appears to be doubly escaped as this is from the error log which itself appears to be json encoded as well and the same value again as parsed by the mibs other mac addresses that start with fc f8 ae work so can only assume it is the latter half 3c 2e 18 that is breaking the encoding >>>bug
support dsl style queries in elasticsearch input plugin have use case in the field where es data have to be extracted from site and shipped to remote site for analysis the elasticsearch input plugin is great tool right now to be able to efficiently export data from an elasticsearch index currently this plugin supports only lucene style queries it will be nice to add dsl support for more query and caching flexibility eg perhaps allow the end user to define query in an external text file and reference the file and the plugin can simply read in the query etc >>>enhancement v1.5.0
handle connection issues better in ls elasticsearch input have es running on different port than the default 9200 but have not defined port parameter explicitly in the configuration the result is the following which is confusing error this can certainly be addressed by specifying port parameter for the non standard port would be nice for the plugin to throw more intuitive error message though >>>bug
elasticsearch output plugin rejected docs in bulk indexing partial failure are silently lost if the bulk indexing request returns 200 ok but contains partial failures these rejected doc are silently lost some documents in bulk request can fail indexing with esrejectedexecutionexception rejected execution queue capacity xx but the bulk request response still returns with 200 success heres such response example this could be handled with retry queue an exponential backoff plus time size limit where documents could be routed to rejections file output for example doing this would handle temporary hickups and would avoid loosing trace of rejected documents user could then easily re feed the rejected documents once the situation is resolved >>>bug v1.5.0
move cloudfront stuff from s3 input into codec the s3 input has partial support for cloudfront log format in this metadata thing in the code this kind of format specific concern belongs in codec for sure further moving it into codec would improve performance of the s3 input and reduce code complexity doing this change would fix the following bug https logstash jira com browse logstash 2220>>>v1.5.0
if there is no tags in the input part the s3 output plugin fails let say for example have such config file when run logstash and it starts to pipe the logs got this error >>>bug
upgrade twitter client version started working on this but aborted yak shave let upgrade twitter lib to the latest at time of writing 11 this will upgrade buftok and fix some bugs in the twitter input the yak shave was that twitter requires http parser newer than ftw requires and conflicts don expect any problems but this will require new release of ftw to compensate >>>enhancement v1.5.0
add sample endpoint support for twitter inputs now twitter input is only filter endpoint support that means we need keywords property want to use sample endpoint for collecting many tweet think we have two option for implementing change keywords to optional if we don specify keyword property twitter input use sample endpoint add sample property if we set sample property to true twitter input use sample endpoint >>>enhancement v2.0.0
s3 input config credentials never nil using logstash s3 input plugin environment variables for s3 not too sure if this is just my system but leaving credentials empty does not work amazon linux getting this error message made sure my config variables were set properly and even tried printing out their values in the s3 script they were available did bit of debugging printing out produces rb backup to dir argumenterror>>>v1.5.0
dynamic include keys and exclude keys for kv filter implementation for issue https github com elasticsearch logstash issues 1617 when specifying `include keys` and or `exclude keys` for use in the kv filter user can include dynamic key names for example if an event has `key` field and the user wants to parse out value using the kv filter the user should be able to say `include keys key the same goes for `exclude keys` >>>enhancement
tag on failure for the date filter the `grok` `tag on failure` option is really helpful think `date` filter should have it too it particularly hard to notice date failures because logstash will set the timestamp` attribute to something close even if it fails so you have to look carefully to see that it wrong >>>reviewing
bundle es bin plugin it would be nice if ls bundled es bin plugin many people use es as an output they are installing the aws plugin for example by hand because they want the features associated with their es output node bundling es bin plugin would make this install easier >>>enhancement
cleanup rabbitmq input output plugins pr 1607 had me review the plugin to discover some unused code at https github com elasticsearch logstash blob master lib logstash outputs rabbitmq bunny rb l103 l108 and https github com elasticsearch logstash blob master lib logstash outputs rabbitmq march hare rb l103 l108 don really like the coding style of the rabbitmq input output plugins they could be tidied up either remove this dead code or use it to log useful information bot input and output plugins should log in consistent way>>>enhancement
configtest doesn detect relative path problems my first attempt at logstash config file configtest says it okay but apparently it isn assume this is bug >>>discuss enhancement known_issue
fix typos elasticearch elasticsearch>>>docs
logstash 2276 fixed if else branch mixup in rabbitmq input>>>bug v1.4.0
kv filter support escaped quotes found https logstash jira com browse logstash 2272 via google and ran into the same issue could not sign up at jira so decided to open the issue here too we are currently unable to complete your sign up there are no available licenses for jira >>>reviewing
file descriptors are leaked when using http several of logstash input and output modules use http via the ftw gem https github com jordansissel ruby ftw from my experience with logstash this gem is leaking file descriptors and eventually causing logstash to essentially die by repeatedly trying and failing to open file descriptor for some task for example here is trace got after running logstash for couple of days in my setup this will repeat until restart the process after which logstash will run ok until it again eats up all available file descriptors on the system you can check the file descriptors in use by running sudo lsof grep java wc on busy system like mine logstash is leaking about 10 file descriptors minute the number goes up and down as some are released back into the wild but grows consistently over time this issue seems similar to https logstash jira com browse logstash 892 tl dr ftw is leaking file descriptors causing any and all http based plugins to eventually stall logstash note this error can also manifest as dns lookup failure but believe this is also fundamentally due to lack of available file descriptors >>>bug reviewing
starting logstash is not working as described on the how to when try to start my logstash following this guide logstash http logstash net docs tutorials getting started with logstash am using windows get logstash input stdin output stdout no such command usage logstash command args run command with the help flag to see the arguments for example logstash agent help available commands agent runs the logstash agent version emits version info about this logstash web runs the logstash web ui called kibana rspec runs tests>>>windows
provide option to suppress redis input errors for cold redis servers use case redis inputs defined in ls config one of the redis inputs is only used in the failover scenario will be intentionally stopped most of the time currently ls will process the redis input with the live redis server and throw repeated errors on the 2nd ls input something like the following ii would be nice to be able to suppress these errors for example perhaps add an input parameter configuration option allowing the user to specify redis input as cold and as result suppress the repeating connection errors >>>enhancement
google bigquery crashes after temp file roatation hi after investigating an major issue had with google bigquery plugin ve found the following every time file is being deleted using the google bigquery plugin logstash crushes with the error it can find the file to fix the issue ve added to the file delete filename statement in both google bigquery and google cloud storage ruby files the following change file delete filename if file exist filename it fixes the issue as files can be deleted in couple of statements prior to that roll out for more info https logstash jira com browse logstash 2247 please implement the change in the upcoming versions of the product thanks dave>>>bug question
lumberjack plugin doesn work with ssl key passphrase generated key using the instructions for the logstash forwarder readme md `openssl req x509 batch nodes newkey rsa 2048 keyout logstash forwarder key out logstash forwarder crt days 3650` then to test put the key and cert in place and started logstash successfully next set passphrase on the key using `openssl rsa aes256 in logstash forwarder key out logstash forwarder key new mv logstash forwarder key new logstash forwarder key` placed the passphrase so my config looks like started up logstash and receive the following error `the error reported is neither pub key nor priv key verified the passphrase works by decrypting it with `openssl rsa in logstash forwarder key out logstash forwarder key new` package versions my version of openssl is using ubuntu 12 04 java is logstash 2c0f5a1 an extensible logging pipeline logstash contrib efd53ef community supported plugins for logstash appreciate any suggestions thanks>>>needs_details
bugfix fingerprint timestamps this should resolve 1572>>>bug v1.4.0
added python logging timestamp pattern couldn find an appropriate pattern to match python logging time stamps with grok so added the following >>>needs_details
add unique tag for grok parser in module input how are syslog input tests executed and where because for the command make test the tests are excluded when executed them setting socket false get jruby exception exception in thread ruby thread 109 users simon workspaces logstash lib logstash inputs syslog rb 89 org jruby exceptions jumpexception breakjump added new tests for the tag and also improved little bit the old one >>>bug v1.4.0
issue 1590 multiline filter and additional worker threads do not work together simple documentation update to show this is limitation with the filter https github com elasticsearch logstash issues 1590>>>docs
conditionals string is allowed as conditional statement current grammar allows using string as conditionals statements like if fool noop add tag fool but as reported in logstash 1434 this could be confusing to non programmer distracted users that would write if field string1 or string2 and do not understand why the condition is always matched >>>design discuss enhancement
consumer output tearsdown before worker queue` is emptied have rabbitmq as input and custom buffered plugin as output my output teardown is called before worker queue` on the output is emptied order of events sigint rabbitmq closes connnection rabbitmq send the remaining events to output buffer output receieves sigint event output joins threads teardown is called in output std buffer calls finalflush events lost due the following code teardown does not wait for the threads to empty worker queue` and the events inside that buffer are lost so every instance would loose events in range of 20 using logstash bundled jruby rabbitmq std buffer>>>bug pipeline-lifecycle reviewing v2.3.0
avoid turning timestamp into json addresses 1583>>>needs_details
logstash event timestamp when using json serializer is hash master branch when doing event to json expect something more like timestamp 2014 07 31t09 05 58 710z but with the new cabin oj serializers see this timestamp time 2014 07 31t09 05 58 710z maybe it new standard not aware of but just noting it here still looking into it maybe json serialization for the logstash timestamp object is not the best approach for just this field >>>bug reviewing unconfirmed
need cabin oj gem for logstash event gemspec master branch copied from logstash gemspec gem add runtime dependency cabin apache license gem add runtime dependency oj mit style license >>>bug v1.5.0
fix init scripts so they use seperate log files for daemon and app so this is to address that firstly it be good to log the daemon log somewhere maybe secondly it be good if that log was separate from the jvm log because the init script log is owned by root because the daemon is started as root but the jvm is owned by logstash so it log will be owned by logstash and most importantly now logstash can actually start on first start with out hacking or configuration management to manage the ownership of log files >>>missing_cla
add size based index cut off today the index cut off for ls is time based it can create new index when the date changes some users would want to add size based cut off so when their current index reaches threshold new index is automatically created by ls >>>design discuss enhancement
zlib errors cause logstash to quit having multiple errors such as zlib dataerror invalid distance code and logstash zlib dataerror invalid block type that causes the logstash service to stop feeders to the service are from other logstash instances of them also running logstash and using the lumberjack protocol to send logs>>>v1.5.0
aws credentials are not needed if using iam roles when launching an ec2 instance with iam role id and secret key are not needed to interact with the aws api for this scenario error should not be raised if id and key are not present would it be acceptable to not raise an error if credentials are not provided this is how have run other applications another solution could be to specify in some way that credentials will be taken care of by the role >>>v1.5.0
logrotation of logstash logs in debian an aside tried to make an account on logstash jira com but atlassian claims jira has no more licenses available logstash 2c0f5a1 from logstash debian repository cron logrotate error error skipping var log logstash logstash log because parent directory has insecure permissions it world writable or writable by group which is not root set su directive in config file to tell logrotate which user group should be used for rotation added su logstash adm have logstash added to group adm on my system to etc logrotate logstash and the error disappears during execution of etc cron daily logrotate>>>discuss
fix codec encode context this fixes 1523 >>>enhancement v1.5.0
fingerprint filter doesn work with timestamp field here simple configuration that demonstrates the issue link at http sprunge us rufs mostly copy of combined apache conf input generator type generated message 127 11 dec 2013 00 01 45 0800 get xampp status php http 200 3891 http cadenza xampp navi php mozilla macintosh intel mac os 10 rv 25 gecko 20100101 firefox 25 count filter grok match message combinedapachelog date match timestamp dd mmm yyyy hh mm ss fingerprint filter don work with timestamp field fingerprint method sha1 key 0123 source timestamp fingerprint method murmur3 source timestamp checksum filter does work though checksum keys timestamp output stdout codec rubydebug don know what the reason why is and can easily surmise it from looking at `fingerprint rb` `checksum rb` was easier for me to follow >>>bug v1.5.0
internal logging return to json back in the day logstash used json for its log format however non utf problems and bad logging styles caused crashes in the logger so we moved to ruby `object inspect` now that we have better handle on utf problems and we have better handle on how to do logging it probably time to make cabin go back to emitting json >>>enhancement
initial patterns for mysql slow query log grok patterns to parse the mysql slow query log >>>enhancement
avro codec add support for the avro data serialization avro apache org >>>enhancement v2.0.0
in condition not working with arrays containing url or ip running logstash the following conditions are not working if data request referer in http example com route1 http example com route2 do stuff if data request client ip in 66 249 78 66 249 78 60 do stuff note that the fields shown in the left part of the above conditions are given as an example >>>needs_details
windows startup crash conditions windows java 7u45 jre jruby not explicity installed following startup directions in http logstash net docs tutorials getting started with logstash have elasticsearch kabana are they compatible they were all downloaded from the same page basically command line stdin output elasticsearch host localhost stack trace rubyio java 1468 in `fwrite java lang nullpointerexception from rubyio java 1408 in `write from rubyio invoker write gen in `call from rubyclass java 690 in `finvoke from helpers java 502 in `invoke from rubybasicobject java 363 in `callmethod from rubyio java 2486 in `write from rubyio java 2474 in `putssingle from rubyio java 2403 in `puts1 from rubyio java 2376 in `puts from rubyio invoker puts gen in `call from cachingcallsite java 326 in `cacheandcall from cachingcallsite java 170 in `call from program files elk logstash logstash lib logstash runner rb 182 in `method ruby run from 3a program 20 files elk logstash logstash minus dot dot lib logstash runner method ruby run in `call from 3a program 20 files elk logstash logstash minus dot dot lib logstash runner method ruby run in `call from cachingcallsite java 326 in `cacheandcall from cachingcallsite java 170 in `call from program files elk logstash logstash lib logstash runner rb 92 in `method ruby main from 3a program 20 files elk logstash logstash minus dot dot lib logstash runner method ruby main in `call from 3a program 20 files elk logstash logstash minus dot dot lib logstash runner method ruby main in `call from cachingcallsite java 326 in `cacheandcall from cachingcallsite java 170 in `call from program files elk logstash logstash lib logstash runner rb 215 in file from program files elk logstash logstash lib logstash runner rb in `load from ruby java 811 in `runscript from ruby java 804 in `runscript from ruby java 673 in `runnormally from ruby java 522 in `runfrommain from main java 395 in `dorunfrommain from main java 290 in `internalrun from main java 217 in `run from main java 197 in `main >>>v1.5.0-rc1 windows
error on nagios pattern on the nagios pattern there is missing closing curly bracket on the nagioslogline definition on line 108 col 565 nagios ec line disable host check to be replaced by nagios ec line disable host check >>>bug
logstash forwarder can not connect when running logstash under ibm java installed logstash on sles11sp2 and ibm java and logstash forwarder logstash forwader can not connect to logstash logstash forwarder throws this exceptoion server selected unsupported protocol version 300 downgraded java to everything works fine java java version java tm se runtime environment build pxa6470sr7 20140410 01 sr7 ibm j9 vm build jre linux amd64 64 compressed references 20140409 195732 jit enabled aot enabled j9vm r26 java726 sr7 20140409 1418 b195732 jit r11 b06 20140409 61252 gc r26 java726 sr7 20140409 1418 b195732 cmprss j9cl 20140409 195732 jcl 20140409 01 based on oracle 7u55 b13 openssl client java working fine new tlsv1 sslv3 cipher is edh rsa des cbc3 sha server public key is 2048 bit secure renegotiation is not supported compression none expansion none ssl session protocol tlsv1 cipher edh rsa des cbc3 sha session id 53ce4d8bfb8f9779a6edc6adbaba509aee87f278b93cb0f0e3c40c6eca8796f8 session id ctx master key 89758fc630bde376ffb7b930a17b40ad7bd3882c8628feb3a8a19c1439e50b1bca67cc394a48b923ebd598aa691c9f08 key arg none start time 1406029195 timeout 300 sec verify return code 18 self signed certificate openssl client java not working new tlsv1 sslv3 cipher is edh rsa des cbc3 sha server public key is 2048 bit secure renegotiation is supported compression none expansion none ssl session protocol sslv3 cipher edh rsa des cbc3 sha session id 53ce4e4a8bf4196a7517971cba92e059631a0e56878c9bce6ed271ca2cfe220d session id ctx master key 794c6a9f35d1d669647b4385f094e643537b3bc10bf489ff9b96f544fe23d5ce231596fef4f323a530d639f581bf8684 key arg none start time 1406029387 timeout 300 sec verify return code 18 self signed certificate >>>bug needs_details unconfirmed
init does not log to stdout and err version from the logstash repository had problem with read permissions on crt file which noticed when looked in var log logstash logstash log however the init script should create stdout and err which it does not the directory var log logstash is owned by the logstash user and as group root running ls on ubuntu 12 04 did not change anything in etc defaults logstash nor the init script >>>packaging
fix 1547 fix for break on match while evaluating grok patterns closes 1547 removed the use of `grok pile` and just used array of `grok grok` to make things simpler and allow to easily fix `break on match` behavior>>>bug v1.4.0
file locking in windows rolling logs etc https logstash jira com browse logstash 986 has fix for this been merged yet >>>v1.5.0-rc1 windows
catch exceptions during processing fix for 1553 >>>enhancement
xpath filter crashes when receiving invalid xml input if invalid xml is received by the xml filter with defined xpath expression it will crash the worker instead of marking the input with xmlparsefailure tag >>>bug reviewing
evaluate dynamic fields in event when used with gsub closes 1529>>>bug v1.4.0
added req rep pattern available to zmq input needed an alternative to push pull load balancing investigated req router and req rep already under consideration from what read in the comments in the code the req rep request reply pattern is essentially the same as req router request router from the req perspective there are use cases when you may want to swap out rep for router so this addition is to use req on the logstash side see http zguide zeromq org page all the load balancing pattern this is alternative to push pull in which the first pull connections may grab too many messages and not be truly load balanced >>>enhancement needs_tests reviewing
its 2014 >>>docs
alternative unique key prefix for metrics when we use the metrics filter in our logstash setup we intermittently experience slow startup times that can take several minutes our configuration is as follows after some debugging believe that one statement in particular is causing significant delay securerandom hex https github com elasticsearch logstash blob master lib logstash filters metrics rb l149 it also seems to take anywhere from 200 seconds to call securerandom hex from simple script that wrote see below so not sure if this is deeper problem with jruby java it is worth noting that often the first call to securerandom hex after restarting the system usually executes in less than second but all subsequent calls take increasing amounts of time since it seems that the only reason for calling securerandom is to prevent collisions between metric keys for separate metric filter objects see the commit message for https github com elasticsearch logstash commit de0bdacbf70ad9394adfce9d1e96ee63c118b8ca ve changed the prefix to simply be the id http ruby doc org core object html method object id of the metrics filter object which is guaranteed to be unique for all active ruby objects even if securerandom hex wasn taking such long time it does seem redundant to generate new random number when the unique object id already exists as trusted identifier >>>needs_details
filters clone conditionals bug am not sure what the source of this issue is but right now my brain is fried so ll post it here for others to look at it and when my brain is unfried ll work on it with this configurations type in any input foo for example clearly the 2nd event the clone did not correctly went through the `if type clone conditional >>>bug v1.5.0
grok break on match false option does not work logstash v1 testing on windows unless misunderstanding what meant to happen grok break on match false does not work correctly the second pattern is never matched when the first one is config file 	input stdin 	filter 		grok 			break on match false 			match 				 message greedydata name1 beard 				 message tree greedydata name2 			 		 	output stdout codec rubydebug input1 	treebranch output1 		 message treebranch 		 version 		 timestamp 2014 07 17t15 31 52 488z 			 host hostyhost 			 name2 branch verdict1 that was as expected the first pattern was not matched but the second one was so the field name2 is created input2 	bushbeard output2 		 message bushbeard 		 version 		 timestamp 2014 07 17t15 33 27 792z 			 host hostyhost 			 name1 bush verdict2 that was as expected the first pattern was matched but the second one was not so the field name1 is created input3 	treebeard output3 		 message treebeard 		 version 		 timestamp 2014 07 17t15 33 50 543z 			 host hostyhost 			 name1 tree verdict3 that was not as expected the first pattern was matched so name1 was created properly but then the second pattern was never attempted or failed so name2 is missing this is what was expected 		 message treebeard 		 version 		 timestamp 2014 07 17t15 33 50 543z 			 host hostyhost 			 name1 tree 			 name2 beard >>>bug v1.5.0
host is wrong off by one in some cases have elk setup with about 15 hosts running logstash forwarder connecting to the collecting logstash instance for some reason at some points in time the host that is reported isn correct it reporting to come from host while the logline in reality comes from host ve added screenshot of this in kibana to make this more clear image https cloud githubusercontent com assets 123280 3611768 eed1d3d8 0d9f 11e4 8fc1 523953e7e50c png everything that has ws be in the second column which is the application name parse from the logline should come from acc app orderrouter everything from systemtrader rest should come from acc app systrd host name in last column as you can see it is off by elk logstash config input lumberjack port 5043 type logs ssl certificate opt logstash ssl certs logstash forwarder crt ssl key opt logstash ssl private logstash forwarder key codec multiline pattern timestamp iso8601 negate true what previous if host acc mutate add field environment acc if type log4j grok match message timestamp iso8601 date space space data application space space loglevel level space space data thread space space greedydata output elasticsearch bind host 127 port 9200 protocol http logstash forwarder config network servers xxx xxx xxx xxx 5043 ssl certificate etc ssl certs logstash forwarder crt ssl key etc ssl private logstash forwarder key ssl ca etc ssl certs logstash forwarder crt timeout 15 files paths opt logs log fields type log4j this is logstash version and logstash forwarder git commit 66c29b5cb208c1be7a675707939a2335c2b66605 april 29 ps we forward the log4j files instead of directly connecting log4j because we have an older system in place now which relies on the current log4j config and files but aware we could sent json messages or connect log4j immediately to logstash >>>bug needs_details unconfirmed
feature filter flushing execution this pr from the shared branch will replace 1260 this should implement correct behaviour for filter flushes in the above if two emits an event periodically via flush then only three should receive it >>>enhancement v1.5.0
getting started section in readme is incorrect if you follow the readme you will be greeted with the following error to fix this had to use `export use ruby 1` or run the command like so `use ruby bin logstash deps` can updated the readme if you like but not sure if the scripts in bin should be updated instead >>>bug needs_details unconfirmed
adding delaycompress to logrotate to avoid issues like etc cron daily logrotate gzip stdin file size changed while zipping this change is harmless and will prevent errors like this one>>>bug reviewing
how to config timezone in china want rewrite timestamp it is only in utc but in china it must found it in but in version it not work how to tak it in server thanks very much my english is very bad bu good at chinese hehe >>>question reviewing
error your application used more memory than the safety cap of 500m get this error every day error your application used more memory than the safety cap of 500m specify xmx to increase it cap size in mb specify for full outofmemoryerror stack trace from where and how can specify this xmx variable >>>needs_details
add spec for the tcp output plugin per 1270 >>>enhancement
sincedb path needs to accept path not file discovered by coolacid in the irc chat today 15 14 https github com jordansissel ruby filewatch blob master lib filewatch tail rb l209 the input file filter sincedb path looks for file and not path couldn specify directory for sincedb files to go into and coolacid said this is why ideally like to see the ability to specify relative path with dynamic filename like sincedb path sincedb the output file filter path already works this way dynamically can grok the inputfilename and then beautifully do output file path output inputfilename out >>>needs_details
snmptrap handle shutdown previously when trying to shutdown logstash the snmptrap plugin would endlessly try to restart this change catches the shutdownsignal exception exits the listening thread and returns allowing logstash to shutdown >>>bug missing_cla
merge joekiller kafka plugin to logstash core closes 1472>>>enhancement
use bundler compatible ruby version string this fixes the invalid gem path with mri bundler uses inconsistent version number schemes across rubies for example jruby 11 will have `1 9` in its gem path while mri will have `2 0` in the 1437 refactor wrongly assumed the `major minor` scheme was used across all rubies >>>bug
xmpp input output chinese characters crashes logstash have an xmpp chat that use as input for logstash when tried to write chinese characters in the chat logstash crashes quitely command logstash bin logstash agent debug vf logstash simple conf value input to chat sorry forgot half longstash simple conf input xmpp password help rooms rat help xxx se rat helperman type user wrat helper6 xxx se output print each event to stdout stdout enabling rubydebug codec on the stdout output will make logstash pretty print the entire event as something similar to json representation codec rubydebug error message 2014 07 14t20 21 22 767000 618 debug processing beer kiss jabber message 2014 07 14t20 21 22 768000 618 debug trying stanzacbs 2014 07 14t20 21 22 769000 618 debug trying message iq presence cbs output received event message beer kiss version timestamp 2014 07 14t18 21 22 780z type room rat help xxx rat helperman from ewamagn level debug file eval line 16 2014 07 14t20 21 22 792000 618 warn exception rexml parseexception org jruby rubyregexp java 1697 in `match file home ewamagn programming search logstash2 logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby rexml source rb 210 in `match file home ewamagn programming search logstash2 logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby rexml parsers baseparser rb 419 in `pull event file home ewamagn programming search logstash2 logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby rexml parsers baseparser rb 183 in `pull file home ewamagn programming search logstash2 logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby rexml parsers sax2parser rb 92 in `parse home ewamagn programming search logstash2 logstash vendor bundle jruby gems xmpp4r lib xmpp4r streamparser rb 79 in `parse home ewamagn programming search logstash2 logstash vendor bundle jruby gems xmpp4r lib xmpp4r stream rb 75 in `start exception parsing line position last 80 unconsumed characters file home ewamagn programming search logstash2 logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby rexml parsers baseparser rb 435 in `pull event file home ewamagn programming search logstash2 logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby rexml parsers baseparser rb 183 in `pull file home ewamagn programming search logstash2 logstash vendor jar jruby complete 11 jar meta inf jruby home lib ruby rexml parsers sax2parser rb 92 in `parse home ewamagn programming search logstash2 logstash vendor bundle jruby gems xmpp4r lib xmpp4r streamparser rb 79 in `parse home ewamagn programming search logstash2 logstash vendor bundle jruby gems xmpp4r lib xmpp4r stream rb 75 in `start message beer kiss version timestamp 2014 07 14t18 21 22 780z type room rat help xxx se rat helperman from ewamagn 2014 07 14t20 21 23 260000 618 warn exception typeerror can convert rexml parseexception into string org jruby rubystring java 1159 in home ewamagn programming search logstash2 logstash vendor bundle jruby gems xmpp4r lib xmpp4r stream rb 136 in `parse failure home ewamagn programming search logstash2 logstash vendor bundle jruby gems xmpp4r lib xmpp4r streamparser rb 81 in `parse home ewamagn programming search logstash2 logstash vendor bundle jruby gems xmpp4r lib xmpp4r stream rb 75 in `start 2014 07 14t20 21 23 261000 618 warn exception caught in parser thread typeerror org jruby rubystring java 1159 in home ewamagn programming search logstash2 logstash vendor bundle jruby gems xmpp4r lib xmpp4r stream rb 136 in `parse failure home ewamagn programming search logstash2 logstash vendor bundle jruby gems xmpp4r lib xmpp4r streamparser rb 81 in `parse home ewamagn programming search logstash2 logstash vendor bundle jruby gems xmpp4r lib xmpp4r stream rb 75 in `start >>>bug crashes
tcp output ssl support this fixes and improves few things in and adds ssl support to the tcp output >>>enhancement
mutate gsub filter does not evaluate variables hi have requirement where need to strip some data out of the message body of the event thought that the mutate gsub filter would be ideal when using mutate gsub the find string does not appear to evaluate variables logtype and hostname are collected in an earlier grok pattern event sometype somehost com sun apr 27 19 20 44 2014 example mutate gsub message sometype somehost com gives message sun apr 27 19 20 44 2014 as desired where mutate gsub message logtype hostname gives the original message unaltered have confirmed that the variables are being filled by using the following mutate add field replace logtype hostname replace is then equal to sometype somehost com in the case of the example >>>bug v1.5.0
s3 output critical race condition problem fixed there was critical problem in the logstash s3 output plugin that can cause data loss and data corruption of old logs while rolling to the next file and uploading the last complete temp file into s3 output thread keeps writing to the file being uploaded it could cause having some data appended after upload completion which can cause data loss having some data appended even after the temp file has been deleted which can cause some corrupted small sized file with the same name if recovery flag is on after logstash restart the small corrupted file will be uploaded into s3 this process will overwrite the original backup ed files and cause the backup file loss our company has been heavily and pitifully affected by this we have written this patch which properly works with ruby file objects and use mutex properly while rolling to the next temp file >>>bug needs_tests reviewing
update doc for changes introduced in 1437 update developers documentation for changes introduced in 1437 >>>docs v1.5.0
multiline filter with what previous cuts off last line when using stdin input example seq 10 bin logstash agent test conf 2014 07 11t15 10 37 057 0000 lepus 2014 07 11t15 10 37 058 0000 lepus 2014 07 11t15 10 37 059 0000 lepus 2014 07 11t15 10 37 060 0000 lepus 2014 07 11t15 10 37 060 0000 lepus 2014 07 11t15 10 37 061 0000 lepus 2014 07 11t15 10 37 061 0000 lepus 2014 07 11t15 10 37 062 0000 lepus 2014 07 11t15 10 37 062 0000 lepus multiline buffers the current entry when run in previous mode so it should probably flush that buffer when the input is exhausted >>>bug v1.5.0
ouput rabbitmq march hare should allow dynamic key config item initially reported in https logstash jira com browse logstash 1786 march hare the jruby implementation of rabbitmq has been refactored to use codec internally during this refactoring was lost the possibility to use sprintf value for key like key origin bunny the ruby implementation still allow dynamic key but do not use codec comparing the receive method of each impl make it clear https github com elasticsearch logstash blob master lib logstash outputs rabbitmq march hare rb l31 https github com elasticsearch logstash blob master lib logstash outputs rabbitmq bunny rb l29 >>>blocker enhancement v1.5.0
inputs base copy the codec charset when switching includes tests>>>bug v1.4.0
codec line do charset conversion on flush also add tests to verify line codec does charset conversion on flush related bugs https logstash jira com browse logstash 1789 syslog input uses tcp input which defaults to line codec >>>bug v1.4.0
disambiguous between config using event sprintf and static ones here is an idea following discussion on logstash user groups where someone tried to dynamicly set the host parameter of elasticsearch http output from event field this proposal tag the config items that can or cannot use dynamic value aka sprintf under the hood example done on the elasticsearch http we can do the full scan afterwards hth ps silly dreamt that reaching the 200th pull request would trigger the next merge party on your side pretty please >>>reviewing
use the newer fieldname pattern for grok filters use the newer fieldname pattern for grok filters replace the older grok style match fieldname pattern with the newer one match fieldname pattern also see https github com elasticsearch logstash issues 1499 for more examples >>>docs
use better default values for workers pools buffers things to tune and or make default workers based on number of cpu cores review pool buffer sizes tests for performance change default protocol in es output from `node` to `http` https github com logstash plugins logstash output elasticsearch issues 150 audit existing defaults for kafka consumer https github com logstash plugins logstash input kafka issues 36 change the default bulk size to 500 instead of 5000 documents https github com logstash plugins logstash output elasticsearch issues 181 remove original temporary timestamp field by default https github com logstash plugins logstash filter date issues 24 specific to plugins redis use batch operations by default enable batch operations by default where possible specific issues will be updated as we file more individual issues against plugins>>>design discuss enhancement meta v2.0.0
tcp input connection threads tracking leak suspected tcp input leak and or overload condition this error message is returned gradually increasing over time to constant stream of this message plugin had an unrecoverable error will restart this plugin plugin raw syslog host mode server error closed stream level error rsyslog haproxy four logstash instances each with two tcp inputs tcp output to index search product jstack netstat na lsof and lsof output as requested available here https gist github com dougmcclure c5badc31dae31a50d647>>>bug v1.4.0 v1.5.0
plugin publishing etc we discussed this for an hour or so in june at the elasticsearch all hands in amsterdam for various reasons detailed below we want plugins to be distributed as individual packages with the goals of allowing for any given plugin that anyone can publish their own publically what is now core contrib now exists simply as individual plugins plugins could be versioned and released independently of logstash releases plugins could have their documentation presented easily online along with the rest of the logstash docs plugins could be found by users discovery of plugins features proposed users should be able to search for plugins users should be able to install plugins even older versions plugin maintainers should be able to publish their plugins independent of logstash releases docs for any plugin should be viewable online testing status for plugin should be visible this should encourage plugin maintainers to write tests and will help logstash developers understand the scope of breaking change something similar to in goal rubygems org or cpan but specific to logstash plugins only something similar to godoc org or rubydoc info but again specific to logstash plugins proposal for deep thinking it should be possible to extend this idea to to include more fully baked solutions such as plugins logstash configs and kibana dashboards specific to solving certain kind of problem >>>v1.5.0
new plugin structure we are considering new plugins structure which allows us to separate the plugins from the core project this allows us concentrate on the core project release plugins much faster when there are improvements bugs let other people contribute new plugins in much easier way without waiting on us the idea is to have the plugins available as rubygems here is proposed gemspec file so far https gist github com electrical d83086ad368202235312>>>enhancement
allow user hostname in commonapache log allow user hostname in the field userid so it is possible to parse 127 user identifier frank domain com 10 oct 2000 13 55 36 0700 get apache pb gif http 200 2326 with commonapachelog pattern >>>bug needs_details
error with grok filter match documentation is there something wrong with the example documentation of grok `match` here what it says in the logstash docs http logstash net docs filters grok value type is hash default value is hash of matchies field value filter grok match message duration number duration if value type is hash then why does the example show an array if you take look at the `overwrite` section it clearly states that the value is an `array` and the example also shows it as an array >>>docs
grokparsefailure on syslog input not sure if this is bug with logstash or problem on my end but have logstash instance running receiving input from syslog and on about 90 of my outputs get grokparsefailure ve tried running it with grok and even removing my grok filters and still get parse failure the few syslog messages that come through without failure tag ve also noticed have three more fields than the ones that do fail logsource timestamp not timestamp and program my assumption is that whatever default parsing logstash does to syslog inputs is trying to grab fields in the syslog messages that aren there has anyone else encountered this issue looking to confirm whether this bug fault with logstash or fault with my syslog >>>enhancement v1.5.0
added messages added asa 106100 asa 106102 asa 106103 syslog messages>>>missing_cla
new output unix output events to unix socket analog to the input unix but only with the client mode useful if you already have some tool that receives data via unix socket and knows how to deal with it >>>adoptme enhancement new-plugin
kv rb new features added option to parse value between brackets when spaces attached to value split ignore the spaces added new feature to drill down dig into value and extract more key value pairs automatically new test for this has been added and other tests has been changed as well to check the above changes >>>enhancement needs_tests reviewing
tcp input multiline codec won work correctly with huge ingress traffic the tcp input and the multiline codec interact really badly resulting in dropped and truncated messages the tcp input reads from socket via socket sysread 16384 this just reads the maximum data available on the socket it does not read single lines the multiline codec will fail hardly as it assumes it only has to decode single complete lines the default line codec is working correctly easy to test just push more than one line to the tcp input which can be read in single sysread call and use multiline filter ``nc localhost 9001 biglogfile log netcat does this very reliable for me ubuntu 12 04 `` do not know what the interface definition is but think the multiline codec needs fixing probably by just using the line codec followed by the multiline codec but this composition cannot be done via configuration >>>bug reviewing v1.5.0
bug lumberjack output accents hi am using lumberjack output to communicate with remote lumberjack input everything worked fine until some accents got into the messages version on both side my output configuration output lumberjack codec json hosts localhost port 5041 ssl certificate my input configuration input lumberjack codec json port 5041 ssl certificate ssl key when write push hello with the client get on the remove server message hello version timestamp 2014 06 27t15 54 45 900 02 00 type stdin host now if push hllo message message hllo version timestamp 2014 06 27t13 57 30 199z host version timestamp 2014 06 27t13 57 30 213z you can notice that the last brackets is missing on the second message which makes it impossible to interpret it as json object thank you by advance >>>bug
update cron action pattern here is the sample message the original pattern doesn parse cron info no mta installed discarding output this patch allows to parse these messages properly >>>needs_tests
rubydebug codec does not work for file input the documented example for rubydebug http logstash net docs codecs rubydebug which if understand correctly would be the correct way to import logstash log files into logstash does not work the problem is here https github com elasticsearch logstash blob e03b67dc7da0c3d654caef9ca1a144d1ab99e580 lib logstash codecs rubydebug rb l17 >>>docs v1.5.0
merge joekiller logstash kafka plugin into core https github com joekiller logstash kafka issues 5>>>enhancement v1.5.0
twitter input throws exception trying to fetch twitter metrics with the twitter input plugin http logstash net docs inputs twitter but when enable the `full tweet` option it stops working and the log fills up with exceptions when remove the `full tweet` line it works ok if your are missing information please let me know and ll provide it asap installed packages logstash conf var log logastash logstash log >>>bug v1.5.0
make throttle threadsafe the throttle module isn thread safe it also currently has bug in that it fails to alert the user when throttle is started with multiple worker threads this pr changes it to use thread safe cache the behavior remains the same but now uses the flush event to purge keys instead of tracking it internally making the code simpler >>>enhancement reviewing
validate config file encoding when it contains non ascii characters currently if config file contains non ascii characters but is not properly encoded one would get the unexpected error invalid byte sequence in utf this fix propose to check if the config file is correctly encoded otherwise throw more verbose error message hint to convert the failing file to utf related tickets https logstash jira com browse logstash 1103 https logstash jira com browse logstash 1531>>>v1.5.0
elasticsearch automatic alias creation the ability to create an alias on index is creation supported on es 1x limiting factor with kibana is searching large number of indexes using aliases would allow to greatly reduce the size and number of http posts and improve search time thanks example logstash config >>>enhancement
logstash s3 plugin error when use s3 plugin connects to s3 bucket has problem my bucket has lot of log files logstash wouldnt connect to s3 the error massage is timestamp 2014 06 20t12 45 34 024000 0800 message plugin had an unrecoverable error will restart this plugin plugin cloudfront bucket my bucket name credentials access key secret key region endpoint us east backup to dir data s3 error execution expired level error is someone knows this question how to resolve my logstash version is >>>needs_details
add ssl and authentication support for the http protocol of output elasticsearch should fix https github com elasticsearch logstash issues 1453 due to the faraday dependency it seems on some version of ruby faraday openssl and or your https backend the request will fail even though the response stream seems ok >>>enhancement needs_tests reviewing
fix for 1451 line codec was using an undefined variable which caused it to throw an exception fixed and added tests for line codecs closes 1451>>>bug
line codec when used throws an exception using logstash with line codec throws an exception when data is received `bin logstash input stdin output stdout codec line or `bin logstash input stdin output stdout >>>bug v1.5.0
twitter input plugin fixes all tweet hash keys should be strings not symbols add robustness rescue exceptions handle twitter rate limiting errors>>>bug
init script should kill ls if it fails to stop in time https github com elasticsearch logstash blob master pkg logstash sysv l73 l91 at the moment we just exit if ls doesn exit on time or not at all we might want to send kill after while >>>enhancement
logstash boot sequence cleanup drip support fix big cleanup of boot shell scripts fixed drip support works with both vendored jruby and using local jruby deprecated use jruby environment var added use ruby and use drip environment vars centralized gem path handling in logstash environment added `dripmain rb` file for good jvm warmup see https github com ninjudd drip wiki jruby and https github com jruby jruby blob master core src main java org jruby main dripmain java now vendored jruby mode is the default the `use ruby 1` environment var allows to use the local ruby interpreter whichever ruby it is inclusing jruby to use drip either set the `use drip 1` environment var or set `javacmd `which drip` in my environment the fastest dev setup for running tests and specs is having jruby locally installed personnaly use rbenv and launch logstash with `use ruby 1` to add drip use both `use ruby 1` and `use drip 1` one caveat with drip noticed is that unlike nailgun drip does not reuse the same jvm once your app quits drip will launch another jvm this means that if for example the jvm starup warming takes seconds it will take another five seconds after your app exited for the drip jvm to be ready this means that if you try to re run logstash right after it exited you might still have startup delay there check the drip bin in https github com ninjudd drip blob master bin drip and setting the `drip pool` var to actually works and spins multiple jvms but the initial startup time will take `drip pool` the jvm startup time `drip pool` is not externally settable you have to edit the shell script >>>enhancement
logstash would crash if timestamp is number line 231 in https github com elasticsearch logstash blob master lib logstash event rb is fixednumber so it has no property called tv sec this would cause logstash crashed directly without any log >>>bug v1.5.0
logstash as windows service hello looking in the documentation can not find an example to turn logstash as windows service there any way to do it it is possible to include an installer like elasticsearch thanks in advance http cookbook logstash net recipes windows service >>>question
config conditionals ignored for flushed filter events while working on custom filter for logstash version encountered an issue where events that are returned by the `flush` method are not verified against configuration conditionals have the following configuration that calls my toy `flush` filter the `flush` filter is simple implementation that caches the first event and releases it through the flush mechanism see code below after the filter if `impossible thing` is found in the `non existent field` add the tag `should not exist` this tag should never be added to the event to execute this configuration and allow the flusher to execute run the following command the output from this configuration includes the `should not exist` tag set the code for the `flush` filter is this >>>bug v1.5.0
filterworker fails with can add new key into hash during iteration full trace exception in filterworker exception backtrace org jruby rubyhash java 986 in users system sandbox logstash logstash lib logstash util accessors rb 60 in `store path org jruby rubyarray java 1613 in `each org jruby rubyenumerable java 865 in `inject users system sandbox logstash logstash lib logstash util accessors rb 60 in `store path users system sandbox logstash logstash lib logstash util accessors rb 55 in `lookup users system sandbox logstash logstash lib logstash util accessors rb 39 in `set users system sandbox logstash logstash lib logstash event rb 138 in users system sandbox logstash logstash lib logstash filters urldecode rb 29 in `filter org jruby rubyhash java 1339 in `each users system sandbox logstash logstash lib logstash filters urldecode rb 28 in `filter eval 232 in `initialize org jruby rubyproc java 271 in `call users system sandbox logstash logstash lib logstash pipeline rb 262 in `filter users system sandbox logstash logstash lib logstash pipeline rb 203 in `filterworker users system sandbox logstash logstash lib logstash pipeline rb 143 in `start filters level error file logstash pipeline rb line 212 >>>bug needs_details unconfirmed
issues with getting started on windows was challenged by jordansissel via twitter https twitter com jordansissel status 474925576805830656 to outline my experiences setting up logstash he asked me to create an issue first off suspect that most of my problems come from using windows was following directions http logstash net docs tutorials getting started with logstash cd logstash bin logstash input stdin output stdout no such command usage logstash command args run command with the help flag to see the arguments for example logstash agent help available commands agent runs the logstash agent version emits version info about this logstash web runs the logstash web ui called kibana rspec runs tests ok no problem think agent is what want bin logstash agent input stdin output stdout no such command hmm maybe there are quoting problems with windows let see if there is way to pass the config via file echo input stdin output stdout config txt bin logstash agent config txt well there no output but the getting started tells me can type into stdout and see messages cool but what about this kibana thing can do logstash bat web but it doesn tell me what port it running on receive suggestion that there one liner https twitter com jordansissel status 474941174634283008 to start everything cool bin elasticsearch embedded true web rubyio java 1468 in `fwrite java lang nullpointerexception from rubyio java 1408 in `write from rubyio invoker write gen in `call from rubyclass java 690 in `finvoke from helpers java 502 in `invoke from rubybasicobject java 363 in `callmethod from rubyio java 2486 in `write from rubyio java 2474 in `putssingle from rubyio java 2403 in `puts1 from rubyio java 2376 in `puts from rubyio invoker puts gen in `call from cachingcallsite java 326 in `cacheandcall from cachingcallsite java 170 in `call doh try all of the above steps with cygwin and don have any more luck >>>blocker bug v1.5.0-rc1 windows
move field merging details from filters json into event the field merging details do not belong into the json filter>>>enhancement v2.0.0
null pointer and logstash stops working hi guys im getting the following exception after some hours of running logstash couldnt find any information about this error on the internet and browsing the code doesnt give me any information at all im not worried about the error itself its not really important if one event is not succesfully parsed but its very very annoying as am not able to run logstash for long time the only way to get it alive is restarting it this is my config file simplified version any idea thanks lot in advance regards >>>bug needs_details unconfirmed
fix external command invocation>>>enhancement v1.4.0
new eventlog inputs no gem or win32ole required use win32 registry and ffi not use wmi memory leak in svchost exe because of security token optimized memory and fixed some memory leak more compatible with old version fix crash memory leak on build description fix crash on registry with null byte based on https github com djberg96 win32 eventlog >>>enhancement reviewing
s3 outputs filename prefix hi it doesn seem to be possible to add prefix to simulate directory on s3 output it can be nice feature best regards >>>enhancement
allow to configure pipe restart behaviour follow up of 942 logstash 1799 don always restart pipe commands colinsurprenant can you have final look at it please >>>enhancement
fix for logstash 1469 this will fix logstash 1469 by catching the exception thrown by the redis gem in the case of trying to unsubscribe or punsubscribe to not existent connection >>>missing_cla
sensu json codec bare bones minimal implementation this is an attempt to start the bridge to enable writing logstash event messages to the sensu infrastructure this codec may be used to encode via logstash outputs full json messages destined for sensu either directly through socket using tcp output and port 3030 on client or to the rabbitmq queue the logstash client would normally talk to at present the codec only formats the message and adds the default values for fields required by sensu if not already set the hash incoming to the encode method is read by the codec so if the fields are already set those values will not be overwritten >>>missing_cla new-plugin
replace time parse with time iso8601 noticed that the `logstash event` constructor calls `logstash time parse iso8601` in mri this calls `time parse` the comment says it all warning ruby time parse is really terrible and slow luckily ruby has an iso8601 parsing method built into the standard library `time iso8601` ran the event rspec benchmarks in mri ruby and here are the results before `event timestamp parse rate 30851 sec elapsed 32 413648s` after `event timestamp parse rate 71543 sec elapsed 13 977632s` so the rate more than doubled also created gist https gist github com dwbutler 51657198746c93103e08 benchmarking `time parse` vs `time iso8601` in mri and jruby vs the joda implementation in jruby >>>enhancement missing_cla mri_support
replace json parsers with jrjackson and oj did benchmarks for both typical event json document of 3kb and huge 45kb document for our big documents use cases 3kb json doc from 16k sec to 30k sec 45kb json doc from 850 sec to 5k sec my bechmark is using generator input config and tps measured using here are the changes summary new `logstash json` class as abstraction for everything json new `logstash timestamp` class to solve ruby time jrjackson serialization problem and cleanup everything timestamp related refactored cleanedup `logstash inputs elasticsearch` input and added basic spec>>>enhancement
docs make bit more clear that ls is waiting for input not hung in logstash 2219 the user thought ls was hung and waited minutes for ls todo something let make it bit more clear that it not hung just that ls is waiting for some input >>>docs
nested field notation for arrays in mutate broken example to reproduce input will error with so the problem has to do with the `accessors` class handling the key as string this was fixed for `accessors get` but not for `accessors set` have the correct fix in will submit pr for it shortly >>>bug v1.5.0
moved to contrib warning missing in doc maybe mistaken but it looks like there is no alter filter since release >>>docs
fix for chroot not getting supplemental groups linux chroot doesn get the supplemental groups before dropping privileges as such we need to pull it from etc group and tweak it so that we can send them to chroot original report came from spuder on irc here is his gist report https gist github com spuder a1c3c7d10ce129507858 spuder tested this and reported it working should work on other systems that use sysv init >>>bug packaging v1.5.3
add tests to cover codec autoswitch json json lines plain line tests for 1392>>>enhancement v1.4.0
automatically choose most correct codec for bytestream inputs now if you try to use `plain` or `json` codecs with either `stdin` or `tcp` inputs it will automatically select `line` or `json lines` codec respectively right now many users try to use json codec with tcp input this should work but due to technical limitations it does not to compensate we have always provided json lines codec to help parse streams of line delimited json which is what most folks seem to be handling these days haven found json library capable of processing byte stream jackson has one but it requires an input stream model which logstash does not currently expose future work will make this possible related 1391>>>enhancement v1.4.0
trying to parse cloudtrail logs using logstash hi guys just need little help in getting this working here my config file and output when try to run it https gist github com marianogg9 4ce7f551a0109076b3d4 it gets stuck and won do anything else is there any way to debug this any other way of getting info of what it doing thanks >>>needs_details unconfirmed
showstopper bugs on windows on win7 64 bit and possibly other windows versions logstash is currently useless for these reasons logstash locks logfiles when using file input this means that rolling logs doesn work at all even editing logfile monitored by logstash is impossible there are clearly line ending issues as get events with text and nothing more if there is something wrong with the config file such as specifying the wrong port number for an output ctrl doesn work the process must be killed manually >>>v1.4.0 v1.5.0 windows
tarball build do not include gitignore and spec reports in final tarball logstash tarball contains the spec reports folder with more than 600 xml files about test results suppose this is not intentionally part of the packaging >>>enhancement
fix stdin message handling specs fix for issue 1386>>>bug v1.4.0
input generator message stdin broken it does not read stdin but instead uses the stdin string >>>bug v1.5.0
initial spec for pipe input as discussed in 942 input pipe needs specs to evolve here is proposal of an initial version>>>enhancement v1.4.0
correct documentation of some config elements>>>docs
1321 add cest and cet timezone to tz>>>enhancement reviewing
fixing relative path issues left over from flatjar era this should save users from file not found type errors because of bad relative paths >>>enhancement v1.4.0
don install development gems for whatever reason the development group is installed by default via bundler this was not intentiona the effect is that we might be unintentionally violating dependency license term ansicolor is gpl2 by including it in our release definitely do not wish such things with this patch the next run of `bin logstash deps` shows all dev dependencies being removed removing coveralls removing docile removing kramdown removing rest client removing simplecov removing simplecov html removing term ansicolor removing thor 18 removing tins fixes 1372>>>bug v1.4.0
plugins dependent on relative paths to files may not work depending on where `bin logstash` was invoked from the path may be incomplete resulting in failure to find the file this is especially noticeable in the `elasticsearch` outputs where `template` is specified >>>bug
stop filterworker and outputworker from crashing when an exception is thrown during event processing logstash may stop accepting data or crash altogether cf logstash 1353 logstash 1440 or logstash 1872 have commited two changes that make logstash continue working after encountering an exception to test the patches you can use the following configs for the filterworker case for the outputworker case please consider including these patches in the next release thanks >>>jira-migrated
don distribute unnecessary packages with releases examples we ship coveralls which depends on term ansicolor and this 2nd gem is gpl2 licensed not sure what the legal ramifications are but frankly we don do it on purpose and we shouldn be shipping `coveralls` with our releases anyway since it is only used during testing not during production runs >>>bug v1.5.0
updating ffi rzmq when testing logstash with zeromq input plugin there was an incompatibility with libzmq version logstash agent input zeromq topology pubsub mode client address tcp output stdout using milestone input plugin zeromq this plugin should be stable but if you see strange behavior please let us know for more information on plugin milestones see http logstash net docs plugin milestones level warn loaderror the libzmq version is incompatible with ffi rzmq this issue makes it impossible to use logstash with newer versions of 0mq updating ffi rzmq gem to version which supports 0mq api seems to solve the problem with zeromq plugin >>>reviewing v1.5.0
fix unintended class level logger leak the `config mixin dsl validate` class method initializes logger` which end up being defined in the plugins at class level the symptom was to be able to call logger` from lambda defined at class level in codec which normally should not be possible since logger` normally should only exist in plugin instance https github com elasticsearch logstash blob master lib logstash config mixin rb l192 >>>bug needs_tests
collectd codec missing nan handling from collectd input in with the collectd input plugin there was handling for managing `nan` values this came after my fork for refactoring as codec so it was omitted unfortunately `nan` values are reality and way to handle them needs to be added back in >>>bug v1.5.0
update metrics rb example update the example because output doesn have the message parameter instead it should use codec also update the way how logstash is executed >>>docs
fix single element lists in config currently if you try and use list containing single element like foo in the configuration file logstash interprets that as access to field literally called foo in an event including the quotes by updating the selector element pattern in the grammar to not match either or in field names logstash now correctly interprets this as list updated the in not in operator tests to cover this fixes logstash 2201 https logstash jira com browse logstash 2201 >>>discuss enhancement
fix broken congestion interval congestion check seems to run for redis for every single even passing through or for every batch if using batches reproduced the issue on my platform and fixed it seems it didn affect me as much as was using large batches this was reported on the mailing list and here is the fix which ve tested on my platform >>>bug needs_tests reviewing
config option for hipchat server hipchat server beta is open this lets you specify an alternate server could also be done as the full api url comments welcome >>>enhancement reviewing
jira 2046 jira 2181 fix usage help>>>docs v1.5.0
monthday must not require leading zero for day of month 10 see also https logstash jira com browse logstash 2199>>>enhancement missing_cla
allow underscores in the hostname grok pattern while of course it is not conform the relevant rfcs reverse dns records tend to be out of one control and underscores start getting used more often see also ticket https logstash jira com browse logstash 2198>>>enhancement needs_tests reviewing
improve the unixpath grok pattern the ``unixpath`` grok pattern could be improved so that it also matches paths such as `` tmp valid directory `` and also syslog messages from for example clamd where the path is immediately followed by colon character see ticket https logstash jira com browse logstash 2197>>>enhancement needs_tests reviewing
fix ipv6 support for geoip simple fix to support the ipv6 databases in the filter fixes https logstash jira com browse logstash 1100 and partly https logstash jira com browse logstash 1124 https logstash jira com browse logstash 2163>>>enhancement reviewing
enhancement add array support for host parameter in elasticsearch output in an environment where multicast discovery is disabled `discovery zen ping multicast enabled false` it would be more robust to have `host` accept list of unicast adresses as it is possible in elasticsearch using `discovery zen ping unicast hosts host1 host2 >>>enhancement
inputs eventlog fix broken link syntax in doc>>>docs
codecs collectd missing errors module for doc generation doc generation crashes for codecs collectd because of missing require logstash errors >>>bug v1.4.0 v1.5.0
temp directory can now be modified in conf file related to https logstash jira com browse logstash 155 there is another pr that supposedly fixes this at https github com elasticsearch logstash pull 938 but contains much more than needed by this issue >>>enhancement reviewing
pass correct home env into chroot without this patch the logstash isn able to start on debian while using file input as both `home` and `sincedb dir` aren set in chroot simple `echo` claims that `home` isn set before the export at least on debian also `chroot userspec` doesn change the `home` env either >>>bug v1.4.0
avoid redirect in kopf start url by adding trailing >>>docs
jira 2046 jira 2181 fix usage help update default behavior to be aligned with agent rb and add missing configtest translation >>>docs
clean up s3 output docs see http logstash net docs outputs s3 it has lot of todos transitions to and from italics that don have reason that see and just needs some formatting improvements this bug is to clean up the look and put the todos in some constrained place so they don interrupt reading about what is present >>>docs v2.0.0
handle cases where logstash dies while decoding email headers this caused the plugin to crash with the following error plugin had an unrecoverable error will restart this plugin plugin foo acme com user johndoe tags imap content type text plain error undefined method `encode for nil nilclass level error >>>bug reviewing
add parsing of old event since last use using the same method as input file filewatch jira issue https logstash jira com browse logstash 1506>>>enhancement needs_tests reviewing
move csv to codec moving the csv output to codec for future use note file currently does not use codecs thus the csv output can be removed yet >>>enhancement needs_tests new-plugin reviewing
allow nested hashes and doc fix this commit allows the use of nested hashes in the mapping function it also allows the use of log stash variables in both the key and value of the map additionally updated the documentation so that it specifies the hash syntax as opposed to the array syntax the array syntax worked because it was silently converted to hash this fixes 1323>>>enhancement missing_cla needs_tests reviewing
add patterns for aws s3 elb access log add grok pattern to parse s3 access logs http docs aws amazon com amazons3 latest dev logformat html and elb access logs http docs aws amazon com elasticloadbalancing latest developerguide access log collection html >>>enhancement reviewing
support nested hashes in http output mapping would like the ability to have nested hashes when using the mapping function of the http output given `mapping metric test tags name help type please the current json output would be metric test tags name help type please what would expect would be metric test tags name help type please >>>enhancement reviewing
zeromq errors out upon logstash restart when restarting logstash when receiving input from zeromq logstash gives error as timestamp 2014 05 01t00 38 36 503000 0200 message zeromq error while in recv string error code level error error repeats for while before logstash has started up completely it functions fine afterwards though>>>bug unconfirmed
docs update irc input docs for password channels update the irc input documentation on how to connect to passworded channels issue logstash 2165 supported by chad barraford cbarraford on irc >>>docs v1.4.1
kv should always overwrite the target field in the event that kv has nothing to do it doesn write the target field if your source and target are the same this can be problem you expect the target to always be hash but when kv took no action it still string this in turn breaks inserting things into es if es is expecting an object >>>bug needs_tests reviewing
pattern for websense proxy this is the pattern to create fields in for websense proxy version for more details or if you need any help then please contact kamal bisht bisht7 gmail com >>>enhancement needs_tests reviewing
enable geoip file caching enable geoip file caching which increases performance by roughly 25 tested three scenarios no geoip lookups 1250 messages per second geoip lookups with setup no caching 1000 messages per second geoip lookups with caching as per this pr 1250 messages per second the fix is updating the geoip gem to set option preload to true see issue https logstash jira com browse logstash 2158>>>enhancement reviewing
fix gelf input for the logstash 1595 utf decoding issue this patch fixes the gelf input for https logstash jira com browse logstash 1595 by migrating it to the codec mechanism and reusing the json codec >>>enhancement needs_tests reviewing unconfirmed
update footer links for docs fix for logstash 2157 update the footer to link to the correct repo logstash vs elasticsearch and point contrib plugins to the correct contrib repo this should work however couldn get make docs to run to verify >>>docs reviewing
space in directory name breaks file discovery installing logstash in directory where the full path to the directory has space in it will cause file not found errors on config or other files the bin logstash start up script is suspect seen at training on april 25 2014 with >>>bug v1.4.1
logstash 2142 if data timestamp is an array take the first timestamp otherwise simply use the correct timestamp>>>missing_cla needs_details
logstash 2135 configurable port for xmpp output input based on https logstash jira com browse logstash 2135>>>enhancement reviewing
common solution for loading custom jars building on top of good work of colinsurprenant in 1233 logstash can now almost propose common solution for loading jars present under vendor jar working on jdbc related plugin input filter and this patch would permit me to load the required jar in one line in the register method like >>>enhancement reviewing
fixing bug that affect mostly centos deploy the nice call in the start script is missing so everything breaks>>>bug reviewing
improve windows first usage experience the current getting started guide makes heavy use of the flag and the fact that agent is supposed by the logstash sh script it was not the case in windows bat also suppose most windows user will easily replace bin logstash with bin logstash however using single quote on the doc for will never work for them would you mind switching to double quote at least in the getting started guide to ease the copy paste testing >>>enhancement reviewing v1.5.0
logstash is losing data with raw tcp input when using raw tcp for input have noticed that you can lose data this appears to happen when the input queue is overflowed how is this overflowed am not sure because there is no entry in the log file and am not ruby programmer but suspect it is when queue processing thread dies since there is no flow control the sending program might as well dump the data to dev null when this happens it would be nice if the socket was closed then the client can pause and reconnect >>>needs_details
pluginpath refactor with this patch pluginpath contrib dir path will correctly find the lib logstash dir and also find the contrib gems and add it to gem path it follows the same previous logic of prepending these paths so that plugin from pluginpath would overwrite one in the logstash distribution my concern with this is having multiple gem paths could cause gem conflicts did not test this yet am pushing this pr mainly to get feedback on this idea and maybe get some testing >>>enhancement needs_tests reviewing
logstash upstart script not working for some users var log upstart logstash log` only gives the following `sending logstash logs to var log logstash logstash log` sadly there no information in it so tried to run command that is executed as the `logstash` user it works if set gem home don know if that is the actual problem or if this is simply because am running the command differently compared to the upstart daemon if you have any more clues on how to dig into that will try>>>bug
fixes path to nologin in ubuntu at least in 12 04 it usr sbin nologin`>>>bug
remove the log parameter as web doesn allow it when run opt logstash bin logstash web h` is not one of the allowed parameters when it is started with it it fails and upstart keeps restarting and failing>>>bug reviewing v1.4.0
making the option multivalued changing the flag to be multivalued it super useful when you want to package custom logstash configurations with your services example bin logstash etc logstash conf services logstash conf >>>enhancement needs_tests reviewing
documentation missing in grok example simple doc fix>>>docs v1.4.1
allow spaces in directory names bash launch scripts first crack at fix for logstash 1983 two possible issues this might break dev using ruby since we be introducing an extra variable if someone does an inplace upgrade with an extra version of jruby getting the jar file will break maybe check for more then one item and error or find more elegant way to pick the jar file for the record can pass the into the exec as it won be expanded correctly >>>bug needs_details
documentation fix generator example logstash 2129 just moved the lines into the correct spot in the comments >>>docs v1.4.1
adding locale parameter to syslog input so it can be propagated to the date filter used in the syslog input that will allow users of the syslog input to specify the locale that should be used to parse the date when the locales of the origin and destination are not the same related jira issue https logstash jira com browse logstash 1998>>>enhancement needs_tests reviewing
undefined local variable or method `org at event rb 218 missing require perhaps this works with jruby but fails on ruby1 >>>mri_support
synchronize access to client threads in logstash outputs tcp logstash was consistently failing with the following error when client connected to tcp output logstash at the time was receiving heavy stream of events so this is likely the result of race condition accessing client threads` which is not thread safe so this change synchronizes access to it across threads >>>bug needs_tests
feature filter flushing execution this patch should implement correct behavior for filter flushes in the above if two emits an event periodically via flush then only three should receive it >>>enhancement needs_tests reviewing
multiline filter still breaking after the fix in 1211 nightly build still crashes only the filter though the multiline filter crashes with exception >>>bug v1.4.1
filter date reject invalid unix timestamp when using the date filter with unix or unix ms format if an invalid value is given like not resolved sprintf mytimestamp it is evaluated to zero thanks string to and thus reset timestamp to epoch time root cause of 1236 and also mentionned in logstash 1597 bugfix spec >>>enhancement reviewing
working to bring the netflow codec to higher milestone status the netflow codec is pretty awesome but the code could use some refactoring since it didn have any tests figured that the first place to start was to add some tests that document its current behavior before making any changes the hand coded fixtures are mostly verified against real netflow traffic from cisco catalyst layer switch except that took guess at what some of the complex data would look like because not collecting that kind of stuff in my environment today planning to add some more details but wanted to get this first set of passing tests out there in case there more interest in the community >>>reviewing tests-infra v2.0.0
add robustness to avoid crashing on unexepected input this is followup from issue 1240 where pre multiline tv sec fix shippers were paired with post multiline tv sec fix indexers using redis the indexer was crashing on the tv sec error because the shipper malformed the event should we add robustness to avoid crashing in such condition >>>enhancement resiliency
evaluate if better robustness is required to avoid crashing on unexepected input this is followup from issue 1240 where pre multiline tv sec fix shippers were paired with post multiline tv sec fix indexers using redis the indexer was crashing on the tv sec error because the shipper malformed the event should we >>>enhancement needs_details v1.5.0
nomethoderror undefined method `tv sec in outputs elasticsearch copied bug report from pr 1211 comment by thuck seems to happen with post multiline tv sec fix to validate >>>bug v1.4.1
option to set up permissions for unix socket unix server socket is created with default permissions 755 it practically useless to have such mode as it allows only user under which logstash is running to write into socket whether logstash is running under root or unprivileged user other unprivileged processes aren able to write data into it >>>enhancement reviewing
remove field in date filter removes even if filter fails adding the remove field argument in date filter removes the named field even if the date does not match successfully >>>needs_details
filter date format unix defaults to 1970 01 01 example date filter which am currently using this causes great confusion because if the timestamp field does not match any of the date formats it always matches on unix even if it is obviously not unix timestamp does not match regexp and so creates events at 1970 01 01 would it be possible to confirm that the date could be unix timestamp before forcing failed conversion cheers robin >>>enhancement reviewing v1.5.0
rabbitmq bunny >>>enhancement
filter flushes should be relative to timestamp and configurable filters are flushed every seconds this should be configurable desirably it should be associated to the timestamp read from log events therefore it would allow the reprocessing of batch of logs considering the correct time that the events happened >>>enhancement
debian init script fails for debian at the moment the debian init script fails for debian will send pr for fixing it >>>bug v1.4.1
cleanup checks for jar context execution in many places there are checks for jar context execution like https github com elasticsearch logstash blob master lib logstash inputs log4j rb l46 these are not required anymore since logstash is not executed from flatjar anymore >>>enhancement
basic http input plugin implemented basic version of an http input plugin test code included for some basic verification this implements fix for jira issue logstash 871 although not polling the http server to read the logs it instead provides access for clients to push events to the server by posting them to the logstash instance >>>new-plugin
add tilde to unixpath tilde is valid character in unixpaths >>>bug v1.4.0
elasticsearch bulk codec this pr implements an elasticsearch bulk codec and should hopefully fix logstash 1445 https logstash jira com browse logstash 1445 and by association logstash 928 https logstash jira com browse logstash 928 logstash 1117 https logstash jira com browse logstash 1117 for decode it only supports the index and create bulk operations and just picks out the document that follows those commands so the index type and id fields are lost all other bulk operations are ignored decode tested by nc ing some bulk data to something like for encode the index index type and document id options are supported same as the other elasticsearch based outputs encode tested with an elasticsearch cluster with river set up pointing to the same rabbitmq successfully indexes the queue once this is deemed usable guess the elasticsearch http and elasticsearch river outputs are made obselete >>>needs_tests
feature json timespec version format want to merge bit more explicit tests as way of wrapping my head around how supposed to send data to the json input json objects space separated or one object per socket connection or what >>>missing_cla
new filter plugin edn hi have implemented new filter to parse edn values based on the json filter plugin filter grok type jetty match message timestamp iso8601 loglevel log level greedydata edn msg add tag jetty grokked edn source edn msg target edn key >>>missing_cla new-plugin
init scripts do not have home set if you start logstash from the init scripts then the home variable is not defined this results in the following messages in the logs no sincedb dir or home environment variable set don know where to keep track of the files watching either set home or sincedb dir in your environment or set sincedb path in in your logstash config for the file input with path full output this results in confusing out of the box experience for new users especially because many of the examples in the documentation refer to home the init script should export the home variable >>>bug
typo on logstash in few files>>>reviewing
ability to capture high resolution timestamp data in date filter this will allow the user to set retain hires to true for iso8601 timestamps and capture the micro and nano second timestamp resolution into new fields joda will still truncate the timestamp at milli as usual but now users can sort on the secondary field or use the original hires timestamp for their purposes looking for feedback on whether regex capture is decent strategy variable field names etc >>>discuss
codecs should return anything inputs should be able to handle any input from codecs as discussed in irc this change makes it so that codecs can return any type of object hash array string logstash event whatever they choose inputs or in future filters are then tasks with converting that object into the kind they need all inputs which use codecs currently expect to work with logstash event objects so the `eventify` method takes what codecs have output and returns the standard event object with timestamp >>>discuss enhancement
single thread the tcp input server should address https logstash jira com browse logstash 922 we ran into that issue on our systems where we had multiple thousands of tcp connections in time wait state indicating that our client process had sent its data and closed its end of the connection and logstash thread to match the root problem was that our output was sluggish and the queue was filling up but logstash wasn applying back pressure well since the tcp input was accepting new connections as fast as it could fork threads we were extending the sizedqueue into the kernel run queue up to the process thread limit by way of blocked threads after applying this patch we saw only hundreds of outstanding connections tcp implementations offer relatively poor control over the sizing of the connect queue from the application level but only single tcp thread that was blocked on the sizedqueue in other words this change allows us to implement back pressure more effectively catching connection failures in the client and retrying with back off by refusing connections earlier when we got backed up and without killing the logstash process or overloading the scheduler >>>enhancement reviewing
add gelf codec this is basically just copy and paste from the gelf output plugin while the output plugin always uses udp through gelf rb this codec can be used to queue messages for graylog2 with the rabbitmq output plugin >>>new-plugin
support folder other than inbox this small patch add folder parameter that defaults to inbox to the imap input>>>enhancement
added new output zulip ve added new output to zulip com it similar service to hipchat in fact based the code off the hipchat output as well as the pagerduty output >>>missing_cla new-plugin
added snmptrap v2c output added working implementation of snmp v2c trap >>>new-plugin
add encode decode filters this is first stab at allowing arbitrary codecs to be applied to individual message fields it has the potential long term to encapsulate behaviour provided by things like the json filter and promotes the migration of many data formats into codecs it also allows for things like utilizing the oldlogstashjson codec on particular event field >>>new-plugin
allowed duplicate array append on def hash merge in util rb fix for logstash 1568 since this modifies existing code please test for side effects test suite seems ok used this in production also >>>bug
added codec for output to log io http logio org cla signed 11 22 2013 github username vmadman thanks >>>new-plugin
add refiltering option for created events currently in logstash an event created by filter split is not processed second time by the filters this pr adds refilter option which will reinsert new events into the chain for further processing tags and conditionals in the configuration can be used to ensure that the filter is only applied to the created events refilter is available to all filters though it only makes sense for filters which yield events back to the pipeline note that this pr includes the split changes from pr https github com logstash logstash pull 787 example filter configuration in this example my log data is presented in one large json array under message records which must be split to be handled correctly on the second pass which only filters the created events the date filter is used to correct the timestamp filter if splitted in tags json source message split field records reuse element false refilter true add tag splitted if splitted in tags date add tag dated match eventtime iso8601 >>>bug
add rackspace cloud files input the rackspace cloud files provides the ability to pull container access logs and cdn access logs from cloud files container >>>new-plugin
support almost iso8601 patterns in date filter iso8601 config use an array for date filter internal field parsers instead of single value under the iso8601 format use first the joda iso parser accepting only then add another parser for almost iso formats accepting space feel free to add other patterns that you also consider iso8601 valid see no evil fix logstash 180 and logstash 1582>>>bug
add wildcard globbing functionality to convert function signed off by robert navarro >>>enhancement reviewing
