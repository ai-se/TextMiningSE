reorganize build files as mentioned in 6354 the cythonize py file is really script and thus should probably not be in the sklearn directory it would benefit from directory of its own propose that we rename the directory continuous integration to build tools maybe rename the various sh files in there to prepend the names with ci as in ci push doc sh and move the cythonize py file in there what do people think >>>build_/_ci
genericunivariateselect has silly defaults it uses ``percentile`` but gives the param as ``1e 5`` not sure it is worth the deprecation cycle though >>>need_contributor
selectpercentile checks for percentile and percentile 100 it looks like selectpercentile disallows the boundaries in `` check params`` but then treats them differently that seems odd either one of the cases must not be covered or something odd is happening >>>easy need_contributor
indexerror invalid slice in test non meta estimators called with genericunivariateselect when running the tests with python against numpy and scipy dev from http travis dev wheels scipy org >>>bug moderate need_contributor
overflowerror value too large to convert to int in sgdregressor when running the tests with python against numpy and scipy dev from http travis dev wheels scipy org similar error happens with passiveaggressiveregressor >>>bug moderate need_contributor
mrg fix test label binarizer on windows fix 6280 looks like fill is not very friendly with unicode numpy scalar on windows this pattern was used here https github com scikit learn scikit learn blob 74475bc929960d98939a12fc2fb68c0e006895be sklearn preprocessing label py l614 >>>needs_review
add numpy dev wheel to travis build matrix >>>build_/_ci
stacking add ensemble selection from libraries of models the following paper by rich caruana http www niculescu mizil org papers shotgun icml04 revised rev2 pdf presents an simple greedy algorithm to stack models it is reported by many people to be an excellent strategy in data competitions we should implement it the paper has only 333 citations which is on the low side for our criteria but hear lot of good on it >>>new_feature
mrg fix nrt signature expects the init to not be defined method py2 fixes 6304 the nrt makes sure there are no errors raised at repr do we need more exhaustive test which will also check the contents or is it too much to have just added it anyway cc kingjr amueller agramfort mechcoder >>>needs_review
mrg fix joblib error in latentdirichletallocation 6258 the joblib error in 6258 is caused by `parallel` parameter not passed to step` when we evaluate perplexity this pr fixed it and set `evaluate every 1` in `test lda multi jobs` test to make sure it works >>>needs_review
add timeseriescv and homogeneoustimeseriescv get this asked about once day so think we should just add it many people work with time series and adding cross validation for them would be really easy the standard strategy is described for example here http stats stackexchange com questions 14099 using fold cross validation for time series model selection there are basically two cases homogeneous time series one sample every seconds days or heterogeneous time series where each sample has time stamp for the homogeneous case we can just put the first ``n samples folds`` in the first fold etc so it very simple variation of kfold for heterogeneous case we need to get ``labels`` array and split accordingly if we cast that to integers people could actually provide pandas time series and they would be handled correctly they will be converted to nanoseconds remember arguing against this addition but changed my mind >>>need_contributor new_feature
lda doesn produce probabilities not sure if this is bug or documentation issue but `latentdirichletallocation` doesn produce normalized probabilities from `transform` and doesn explain how to get these either >>>bug
example document clustering py has broken it seems that `examples text document clustering py` has broken since `silhouette score` don accept sparse matrix following is the error messages traceback most recent call last file examples text document clustering py line 202 in metrics silhouette score km labels sample size 1000 file users yenchen desktop python scikit learn sklearn metrics cluster unsupervised py line 84 in silhouette score labels check labels file users yenchen desktop python scikit learn sklearn utils validation py line 516 in check ensure min features warn on dtype estimator file users yenchen desktop python scikit learn sklearn utils validation py line 375 in check array force all finite file users yenchen desktop python scikit learn sklearn utils validation py line 242 in ensure sparse format raise typeerror sparse matrix was passed but dense typeerror sparse matrix was passed but dense data is required use toarray to convert to dense numpy array >>>bug
added boruta and mutual information based feature selection modules dear fs module maintainers have implemented the boruta algorithm https m2 icm edu pl boruta with sklearn like interface here my original repo https github com danielhomola boruta py and here blog post wrote about this fs method http danielhomola com 2015 05 08 borutapy an all relevant feature selection method also implemented famous mutual information based fs methods jmi mrmr plus the pretty recent jmim and wrapped them up in single module with parallelized execution here my repo https github com danielhomola mifs and here blog post wrote about this method http danielhomola com 2016 01 31 mifs parallelized mutual information based feature selection module wrote docstrings and examples at the end of docstings also ran autopep8 on these files but could you help me with unit testing bit what is expected from feature selectors in terms of unittesing should simulate some data run these fs methods and assert that the discovered features are the same as in previous run also should write test for every single internal function as well best wishes dan >>>new_feature
partial dependence plot example not rendering on website see here http scikit learn org dev auto examples ensemble plot partial dependence html example ensemble plot partial dependence py >>>documentation easy need_contributor
mrg adding python tkinter compatibility to svm gui py example 	modified examples applications svm gui py for some reason the tkinter package is not compatible with python 	try import tkinter as tk works with python 	except importerror import tkinter as tk works with python added in an additional import statement to add compatibility>>>needs_review
mrg doc add doc in dictvectorizer when categorical features are numeric values fixes 4413 ve added paragraph to clarify the use of dictvectorizer when user categorical features are represented as numeric values solve issue 4413 please review amueller jnothman >>>needs_review
test label binarizer failure under windows this failure is revealed by enabling missing tests in 6274 occurs under python either 32 bit or 64 bit >>>bug need_contributor
test pls test scale and stability failure under windows this is bug revealed by enabling some missing tests as part of 6274 it occurs under windows with python 64 bit and numpy with mkl https ci appveyor com project sklearn ci scikit learn build 5133 >>>bug need_contributor
some test directories are not included in installation in ``sklearn setup py`` there are several ``tests`` modules that are not included in the subpackage list for the configuration ``neighbors tests`` ``metrics tests`` etc this means that running ``nosetests sklearn`` outside the source directory will not run these tests is there reason for this >>>build_/_ci
mrg bug fix pickling of distancemetric instances fixes 6269 this fixes an issue when pickling unpickling distancemetric objects and by extension nearest neighbors methods that use them >>>bug
mrg fix performance issue in graph connected component this is reworked version of the fix in 5713 with new test >>>bug
mrg updated examples and tests that use scipy lena this is followup on 5920 squashed all the commits into one and removed the annoying merged commit in the middle to cleanup the history and make it easier to cherry pick this fix to 17 later fixed dtype related error in the denoising example with recent numpy have not fixed the circle ci configuration yet working on it next >>>blocker needs_review
inconsistent attribute naming cv mse path and mse path in lassolarscv and lassocv respectively there is inconsistent attribute names in cross validation lasso models `cv mse path in `lassolarscv` code https github com scikit learn scikit learn blob c957249 sklearn linear model least angle py l1127 `mse path in `lassocv` code https github com scikit learn scikit learn blob c957249 sklearn linear model coordinate descent py l1151 as seen already in this tutorial http scikit learn org stable auto examples linear model plot lasso model selection html unification suggested>>>easy
mrg classification report format supports long string labels here an improvement to the `sklearn metrics classification report` output when `y true` and `y pred` args contain long string labels assumption no `target names` arg is provided long in this case meaning having length greater than the default row title string currently avg total which appears in the last row of the report demo before format enhancement after format enhancement classification test cases >>>needs_review
labelencoder transform should raise helpful error for arrays from sklearn preprocessing import labelencoder le labelencoder le fit apple orange in old versions of numpy le transform apple contains new labels str diff in new versions of numpy le transform apple the fix should be as simple as calling `column or 1d` as the start of transform>>>bug easy
documentation for parameter children in hierarchical py is inconsistent in `hierarchical py` documentation of parameter `children` in function hc cut` is different from itself in other functions in function hc cut` in other functions if this need to be modified may send pr cc mechcoder gaelvaroquaux ogrisel amueller>>>documentation
pr tags used in sklearn was thinking of adding small section in the documentation telling what each tag eg mrg enh etc stands for and when it used somewhere over here http scikit learn org dev developers contributing html contributing code might help beginners in scikit learn and even in other organisations for that matter >>>documentation
no online for doc kernelridge jmetzen not sure whether this is intended in the online doc sklearn linear model ridge html sklearn linear model ridge stable and dev `kernelridge` is mentioned but there no link corresponding to the page >>>documentation easy
mrg much faster prediction with isotonic regression this change add an optional parameter to isotonicregression fit fast predict setting this to true speeds up prediction by orders of magnitude on my tests doesn have meaningful effect on training time and has no effect at all on the values that are predicted unless user cares about storing the fitted values of the training data it an unqualified improvement however in order to avoid breaking legacy code that depends values like self and self left the default value of fast predict to false in other words no speedup this is my first contribution to sklearn so please let me know if need anything else to get this merged into master sample output from the examples fast isotonic py script also in this pull request is below training sample size 100000 prediction sample size 100000 training the old model took 03661 seconds training the new model took 03391 seconds predicting with the old model took 60884 seconds predicting with the new model took 00439 seconds maximum absolute difference between new and old predictions 000000>>>needs_review
inconsistent tsne results seem to be getting inconsistent unexpected results when using sne compared to other implementations ve uploaded and documented reproducible example together with some observations which may help someone to arrive to the root cause as stuck https github com jjvalletta sneissue tree master thanks in advance for anyone looking into this cheers jj>>>bug
partial fit should raise an error when `y` in each batch contains labels not present in `classes first rng randn ovr onevsrestclassifier sgdclassifier ovr partial fit first ovr partial fit first this is the problem with the base estimator as well sgd sgdclassifier sgd partial fit first sgd partial fit first >>>bug
labelbinarizer returns dense output when input has only single label even when sparse output is set to true lb labelbinarizer sparse output true lb fit transform array >>>bug
add raises section across our codebase having clearly defined `raises` section like we have here http scikit learn org stable modules generated sklearn ensemble gradientboostingclassifier html sklearn ensemble gradientboostingclassifier predict proba across all the functions and classes would be super awesome feel but this might add quite lot of lines to our codebase and it is an extra burden to maintain if approved by our devs feel this could make nice project for some student to take up pre gsoc if approved to be tagged large scale and documentation cc mechcoder gaelvaroquaux ogrisel amueller jnothman >>>documentation large_scale
implement different cut criteria for agglomerative clustering we currently have clusters as criterion and single way to cut the tree not sure what our strategy is called scipy implements many more strategies in particular distance http docs scipy org doc scipy 14 reference generated scipy cluster hierarchy fcluster html scipy cluster hierarchy fcluster gaelvaroquaux do we have the inconsistent in this nomenclature >>>enhancement
fetch 20newsgroups remove argument python 11 on python 11 the remove argument of the fetch 20newsgroups method doesn work here an example you can change 10 with another index the problem appear again although the removal of headers footers and quotes is set this is the output problem doesn appear in python 1>>>bug
bug in ledoitwolf shrinkage the estimate of the shrinkage in the ledoit is pretty broken import numpy as np from sklearn import covariance np random seed 42 signals np random random size 75 print covariance ledoit wolf signals this outputs array 08626827 08626827 08626827 08626827 in other words the estimator has deduced that their should be shrinkage of it taking something proportional to the identity that shrinkage is given by in lemma of well conditioned estimator for large dimensional covariance matrices olivier ledoit and michael wolf where is the canonical matrix inner product is the identity and the data scatter matrix as can be seen from this equation is possible only if the scatter matrix is hence this result is false not that believed it at all know where the bug is splits just need to find robust test so that these things don happen again this is quite bad we have had broken ledoit wolf for few releases ledoit wolf is the most useful covariance estimator >>>bug
clustering documentation input space note outdated the note at the beginning of the clustering docs talks about input in data space or similarity space currently all algorithms assume to be the data possibly by choosing some measure of similarity also birch and dbscan are not mentioned in the note http scikit learn org dev modules clustering html clustering>>>bug documentation
unexpected dbscan result guess hitting some boundary case but bit confused by this 894 1168 the second cluster has only one sample but ``min samples 5`` doesn that mean that the cluster should have at least samples ping larsmans jnothman >>>documentation
silhouette score error message this doesn give helpful error message indexerror index is out of bounds for axis with size the error is that ``silhouette score`` takes the data as an input not true labeling it gives these warnings so in 19 it will raise an error because the first input is 1d like to have better error for 18 though >>>easy
make weighted percentile more robust as reported by maniteja123 true weights weighted percentile true weights 50 do we want to do some sort of linear interpolation as described in this method https en wikipedia org wiki percentile the weighted percentile method>>>enhancement
sgd classification unnecessarily slow multiclass prediction using sgd on sparse data is unnecessarily slow it seems to be copying large arrays on every call to `predict` `predict proba` etc which kills its performance think the main culprit is `safe sparse dot` which uses scipy csr dense routine because `b` is transposed and scipy multiplication invokes `b ravel this is very slow copies `clf coef internally keeping `clf coef t` as contiguous array here https github com scikit learn scikit learn blob master sklearn linear model base py l252 improved the prediction performance of sgd classifier 7300x for us 1s vs 137s per call the exact speedup numbers will vary depending on `coef size the number of sgd classes and features this could be raised as an issue in scipy as well see no good reason for such inefficiency that `ravel is just too generous but since the fix seems trivial maybe it worth addressing on sklearn side as well this is using scipy 16 and sklearn 17 >>>bug need_contributor
check array in polynomialfeatures incompatible with sympy it would be really nice to be able to use `sympy` with `preprocessing polynomialfeatures` but can because this line https github com scikit learn scikit learn blob master sklearn preprocessing data py l1189 calls `check array with the default `dtype numeric it would be great if could pass in kwarg `dtype` to `polynomialfeatures` so that it wouldn fail when using symbolic variables instead of floats >>>easy need_contributor
stratifiedkfold does not raise error when number of samples for all the classes is less than folds we should raise an error instead of warning as pointed out by mechcoder here https github com scikit learn scikit learn pull 5703 discussion r49243981 python for tr te in stratifiedkfold folds split print tr te python to be tagged easy need contributor cc mechcoder amueller jnothman>>>easy
supporting dropout for neural networks had recently come across this paper that emphasises the use of dropout to prevent overfitting and provides way of approximately combining exponentially many different neural network architectures efficiently it would be really great to add this dropout feature to current implementation of mlps in scikit learn https www cs toronto edu hinton absps jmlrdropout pdf would be really glad to take up this if you guys consider it worthwhile thanks >>>new_feature
birch fails with cfsubcluster object has no attribute centroid this issue occurs to me during an evaluation with growing feature set sizes in under second after the call to fit predict on the birch instance strangely it works for smaller sets of features and does not run out of memory for my evaluation employ 183719 datasets and construct feature sets of growing size it works with features but returns this error with 12 use the version here is the full stack trace sadly not able to reproduce this with an minimal example >>>bug
sklearn datasets make classification should have targets parameter `make regression` has `n targets` parameter it might be useful to have that in `make classification` as well>>>easy
mrg fix faq link at the bottom of main page on scikit learn org the faq link at the bottom see snapshot below links to http scikit learn org stable faq instead of http scikit learn org stable faq html scikit learn faq https cloud githubusercontent com assets 1680079 12288808 bdb62304 b9d7 11e5 9d03 704f5c7cc569 png >>>needs_review
mrg doc fix redundant doc for regression addresses 6149 >>>needs_review
mrg rewording algorithm requirement in faq fixes 5986 old pr at 5996>>>needs_review
mrg maint refactor and speed up silhoutte score samples refactor of `metrics silhouette score` able to get at least times speedup in most cases samples 10000 labels in this branch 13 4s in master 23 2s samples 10000 labels in this branch 14 4s in master 23 9s samples 1000 labels in this branch 115ms in master 287ms samples 1000 labels in this branch 110ms in master 249ms samples 100 labels in this branch 87ms in master 13ms samples 100 labels in this branch 54ms in master 84ms also fixed bug related to non encoded labels >>>needs_review
step in documentation of regression seems to be redundant the regressor of interest and the data are orthogonalized wrt constant regressors the cross correlation between data and regressors is computed the cross correlation by definition involves orthogonalizing wrt constant regressor mean mean std std which think makes the first step redundant >>>documentation easy
jobs in gridsearchcv issue hi first thanks for your awesome work have an issue with gridsearchcv and jobs for extratreesclassifier model `platform platform linux 13 74 generic x86 64 with debian jessie sid `cpu count ram 32 gb never exceeds go during exec python 11 anaconda 64 bit `sklearn version 17 `numpy version 10 `scipy version 16 `pandas version 17 `joblib version code ko sub process traceback if set my jobs model to and jobs gridsearchcv to it ok try different setup but if gridsearchcv jobs it fails would like to optimize my cpu and think jobs on gridsearchcv it better than jobs on your model maybe someone has feedback possible relation with 6023 >>>bug
better example for different agglomerative clustering methods maybe it me but feel the current example we have comparing agglomerative clustering algorithms doesn provide great intuition not super familiar with them so maybe it just my lack of understanding we currently have this http scikit learn org dev auto examples cluster plot digits linkage html example cluster plot digits linkage py that currently outputs pictures and timings the timings are the same for the three methods average complete ward guess you see that the average linkage has these two singletons and complete has one relatively small cluster maybe it would be nice to visualize the distribution of cluster sizes for each and show that ward creates more equally sized clusters maybe it would also be nice to compute ari or similar supervised clustering measure if there is an obvious clustering solution where the clusters have very different sizes how do the results of ward and the others differ what is happening on the cluster comparison plot in the top row why doesn ward get the circles right ping gaelvaroquaux agramfort >>>documentation enhancement
mrg added sample weight parameter to ransac fit resolved issue 6113 and 5871 for estimators that used sample weight parameter in the fit method it was requested that similar should be applied to ransacregressor this has been intergrated >>>needs_review
document multilabel support for all splitters in model selection module the current documentation states that `y` in `split` methods for all splitters is of samples but all splitters except `stratifiedkfold` will support multilabel `y` samples labels by default this should be documented >>>documentation easy
data target and pairs in fetch lfw pairs should mention that the shape depends on subset >>>documentation easy
spectralbiclustering fit doesn return self need to check for coclustering too >>>easy
eigenface example is confusing there is an example comparing decomposition methods on the olivetti faces http scikit learn org dev auto examples decomposition plot faces decomposition html it prints something like the top is wrong for everything but pca sparse pca and fa think it not the top nmf components they are not ordered and if you gave it more components they would look very differently same for dictionary learning or means we could fix the print message but maybe it would be better to use more components for the different methods even if we are not showing them not sure if that would blow up the runtime though >>>documentation
nmf has no inverse transform this strikes me as odd you can just multiply by to get the inverse transform right >>>easy enhancement
shape of target in fetch lfw pairs docs is wrong should be 2200>>>documentation easy
fix docstring signature mismatch in cython code similar to 2062 but for cython code am not sure how easy it is to find those >>>documentation easy need_contributor
mrg remove useless normalization fixes 6075>>>needs_review
bug for some scorer some scorers the ones derived from the confusion matrix `recall macro` `precision macro` etc are defined with `functools partial` partial functions have no name which creates problems from sklearn metrics scorer import get scorer recall macro get scorer recall macro recall macro traceback most recent call last file line in file usr lib python2 dist packages sklearn metrics scorer py line 49 in repr self score func name attributeerror functools partial object has no attribute name the name attribute can be set after creating the partial function if correct the most correct option would be to use the name of the original function `metric name >>>bug easy need_contributor
fix cluster centers after fit in kmeans and mbkmeans need not be ordered in the same way after printing out `k means cluster centers` and `mbk means cluster centers` get in mbk means cluster centers out array 95903103 00100039 00953167 96610056 13870981 10478529 in means cluster centers out array 07262225 00554224 07510478 06937206 96786467 0173955 which means that this https github com scikit learn scikit learn blob master examples cluster plot mini batch kmeans py l107 line will not work the way it is supposed to get this kmeans after https cloud githubusercontent com assets 1867024 11916630 47145f3c a6ad 11e5 84d0 329c0d7c2a0f png as compared to this in master kmeans before https cloud githubusercontent com assets 1867024 11916638 6fdeec0c a6ad 11e5 8b6d a47da072a01a png >>>needs_review
mrg fix fetch california housing fix 5953 used http www dcc fc up pt ltorgo regression cal housing tgz still has an old cal housing pkz before lib stat cmu edu got broken in scikit learn data so double checked that the content of the pickles were matching exactly here are the plots from examples ensemble plot partial dependence py figure https cloud githubusercontent com assets 1680079 11844040 edd15922 a40c 11e5 8c72 b819e7689c53 png figure https cloud githubusercontent com assets 1680079 11844049 f519ccaa a40c 11e5 8ca1 b26ff607df87 png they match the ones from the stable doc http scikit learn org stable auto examples ensemble plot partial dependence html http scikit learn org stable images plot partial dependence 001 png http scikit learn org stable images plot partial dependence 002 png >>>needs_review
mrg fix in plot out of core classification py just added conditions to check which one to use from `color cycle` or `prop cycle` depending on matplotlib version fix for 6016 >>>needs_review
mrg ensuring consistent transforms for kernelpca previously the following script created an assertionerror that because `kernelpca fit x` has reference to the original `x` for `transform` made one line change to make sure this was not the case as far as know think mblondel did not intend for the following above to raise an error pr includes small change to the source to ensure that copy to the fit data is kept regression test same script as above >>>needs_review
mrg default attribute info for kernelpca added some default attribute information to the kernelpca also added very minimal changes to the rest of the docstring >>>needs_review
make sphinx build without warnings let circle io error on warnings we should fix the remaining sphinx warnings here https circleci com gh scikit learn scikit learn 1629 and then make circle io error if there are any warnings grep ing for ``warnings`` guess this way we immediately see if someone broke anything in the docs >>>build_/_ci documentation
plot out of core classification py uses deprecated color cycle>>>easy need_contributor
mrg cosmit use consts instead of numerical values for better readability glouppe agramfort feel free to ignore really minor pr>>>needs_review
mrg add version added for multinomial sag forgot to add `version added` in the docstring in 5251 here is the fix >>>needs_review
file header in affinity propagation slightly outdated see https github com scikit learn scikit learn blob master sklearn cluster affinity propagation py l1>>>documentation easy need_contributor
problems with data scaling in sklearn cross decomposition plsregression am trying to fit some spectral data using pls and am having difficulties with the module essentially when use the default value of `scale false` get prediction but all my predictions are scaled and just cannot figure out how to convert back to my original data space the same is true for the example code as you see the scaled prediction is just off assumed that should be able to revert back to the unscaled data using `pls scaled mean and `pls scaled std but that doesn seem to work for me any suggestions would be highly appreciated for those with more visual bend figure https cloud githubusercontent com assets 13950307 11730049 a1fcfa66 9f60 11e5 960f 90fa260eef6a png >>>bug
doc issues in logisticregression the solver parameter doesn document it default in the docstring as far as can see >>>documentation easy
logisticregression with l1 just realized we haven implemented logreg with l1 apart from sgdclassifier are people just not using this if we do implement it it seems we would need an auto solver guess to pick the solver that supports the combination >>>new_feature
release broke dev doc updates the dev documentation has not been updated since the release guess the circle ci that does the upload doesn do reset to origin master before trying to commit new version >>>build_/_ci documentation
regression in silhouette score apparently introduced last minute regression here https github com scikit learn scikit learn commit f0f174b74fd9684748e7c425b74909272e6ab22d commitcomment 14775170 not sure if that deserves backport bugfix release >>>bug
reorganizing algorithm requirements in faq think my snappy formulation of the faq makes is unhelpful maybe the can add new algorithm and can add this old algorithm section should be summarized into what are the inclusion criteria for algorithms see http scikit learn org dev faq html can add this new algorithm that or someone else just published wdyt >>>documentation easy
mrg fix memory leak in barnes hut sne that seems to fix 5916 for me vighneshbirodkar still seems to have problems here is test program you can run it with `valgrind leak check full track origins yes python test tsne py logfile` and search for barnes in the logfile >>>needs_review
mrg fix kernel pca docstring to reflect how remove zero eig defaults to false>>>needs_review
odd docstring for countvectorizer analyzer it says if callable is passed it is used to extract the sequence of features out of the raw unprocessed input only applies if analyzer word think the last part should be deleted >>>documentation easy need_contributor
mrg doc clarifies that sparse matrices are scipy currently the language states that the mlp operates on numpy sparse matrices while the rest of scikit learn documentation uses different language clearly stating that they use scipy sparse matrices was rather confused when went to add this into my standard list of algorithms to test given that my library works only with scipy sparse matrices was quite happy to find that this does indeed work with scipy sparse matrices copied the language directly from another algorithm so it should be highly consistent thanks for the awesome new mlp this is much more user friendly when user is already working with scikit learn than trying to integrate third party option >>>needs_review
valueerror assignment destination is read only when paralleling with jobs when run `sparsecoder` with jobs there is chance to raise exception `valueerror assignment destination is read only` the code is shown as follow the bigger `data dims` is the higher chance get when `data dims` is small lower than 2000 verified everything works fine once `data dims` is bigger than 2000 there is chance to get the exception when `data dims` is bigger than 5000 it is 100 raised my version infor os os 10 11 python python 10 anaconda numpy 10 sklearn 17 the full error information is shown as follow >>>bug
mrg improve mlp docs fixes 5583 add images linking to mlp examples fix and complete the list of all the relevant examples add warning about mlp implementation here not being applicable to deep architectures or convnets or any serious neural nets point user to appropriate resources >>>needs_review
doc make pipeline doesn say it lower cases the class name in the docs the docstring should be bit more explicit about how ``make pipeline`` works >>>documentation easy need_contributor
mrg lda explained variance ratio can be found using svd solver previously the only way to get the `explained variance ratio from linear discriminant analysis was through using the `eigen` solver option small modification to the source lets you also find the `explained variance ratio from the svd solver overall this is just an incremental change to the source code pr includes changed source code to extract `explained variance ratio from the svd solver change to docstring for lda test case>>>needs_review
mrg enh allow float32 to pass through with copy this is the easy path to fixing this was bit surprised to see the float64 default and the copies elsewhere in the sparse functions are there rules for consistency as to float32 vs float64 in the cython code >>>needs_review
mrg enh minor add quantile low high parameters to robust scaler>>>needs_review
mrg fix for coveralls not sending coverage report coveralls needs to be run from git checkout so keeping git when copying folder in continuous integration install sh talked with arthurmensch and he said that excluding git from the copy was just to save bit of time 10s for reference the error from coveralls from this travis log https travis ci org scikit learn scikit learn jobs 93359303 l2977 >>>needs_review
mrg keyword arguments in functiontransformer this pr enhances the functiontransformer class to store optional keyword arguments for the embedded function the motivation is to reduce the need for lambda functions in many simple cases which should make code more readable and allow objects to be serialized for example rather than doing one can do in the latter case the `f2` object can be serialized and its parameters are available for inspection >>>needs_review
mrg maint deprecate wisely sorry for the sloppy work last time this deprecation method is more elegant gaelvaroquaux amueller>>>needs_review
original traceback in setup py should be displayed in get numpy status and get scipy status the original traceback when the import of numpy or scipy fails should be displayed to be able to debug issues like 5904 >>>enhancement
mrg issue tf idf computation fixes 4391 >>>needs_review
mrg enh add svdd to svm module hi noticed there was an interest to support vector data description algorithm so want to finish pr started by sklef which already contained working version rebased did some cleanups and extended documentation very interested in your reviews >>>needs_review
mrg add convergence warning in labelpropagation otherwise it remains unclear whether the convergence was reached or whether the algorithm ran out of iterations currently all the test cases trigger this warning that is what triggered the investigation which led to 5774 >>>needs_review
mrg read web pages as utf by default use with blocks to open files on windows the default encoding for `open filename is cp1252 calling `open filename read on utf encoded file the wikipedia pages being fetched fails with an error when it encounters multi byte unicode code points this was blocker bug also wrapped the file ops in with blocks as is the preferred style these days >>>needs_review
tfidfvectorizer doesn document vocabulary attribute>>>documentation easy need_contributor
mrg maint deprecated spectralembedding renamed to laplacianeigenmap fixes 5875 https github com scikit learn scikit learn issues 5875 >>>needs_review
latentdirichletallocation doesn explain parameters in user guide the lda user guide doesn explain any of the parameters and only uses the greek letter notation not the actual parameter names http scikit learn org dev modules decomposition html latent dirichlet allocation lda>>>documentation easy need_contributor
lda doesn have link to user guide http scikit learn org dev modules generated sklearn decomposition latentdirichletallocation html sklearn decomposition latentdirichletallocation the lda docstring doesn have link back to the user guide on lda >>>documentation easy need_contributor
confusing samples features variables in example this example defines ``n features`` and ``n samples`` in the beginning but doesn use them as far as can see http scikit learn org dev auto examples applications topics extraction with nmf lda html example applications topics extraction with nmf lda py>>>documentation easy
website link to lda broken in example in the topic model example the lda class should link to the api docs but it doesn http scikit learn org dev auto examples applications topics extraction with nmf lda html example applications topics extraction with nmf lda py not sure what the problem is >>>documentation
rename spectral embedding to laplacian eigenmaps from what understand from this http sas uwaterloo ca aghodsib courses f06stat890 readings smdr ssl05 pdf and this https lvdmaaten github io publications papers tr dimensionality reduction review 2009 pdf paper on dimensionality reduction spectral embeddings refer to any technique that conducts an eigendecomposition of an affinity matrix not just laplacian eigenmaps those papers and numerous other explicitly state the algorithms spectral embedding includes for spectral embedding algorithms such as metric multidimensional scaling mds cox cox 1994 spectral clustering see weiss 1999 for review laplacian eigenmaps lle and isomap http www mitpressjournals org doi pdfplus 10 1162 0899766041732396 in fact the sklearn documentation was the only source could find that refers to laplacian eigenmaps and spectral embedding synonymously if am correct propose renaming spectral embedding to laplacian eigenmaps or at the very least correct the misleading documentation that says spectral embedding also known as laplacian eigenmaps spectral methods are able to reveal low dimensional structure in high dimensional data from the top or bottom eigenvectors of specially constructed matrices http sas uwaterloo ca aghodsib courses f06stat890 readings smdr ssl05 pdf >>>documentation
mrg parallel nearestneighbors execution in isomap patches issue 5867 >>>needs_review
logisticregressioncv fails when labels are strings while logisticregression can handle string labels logisticregressioncv fails when labels are strings with `valueerror could not convert string to float` guess the problem comes from calling `y test check array test dtype np float64 ensure 2d false within function log reg scoring path in file logistic py>>>easy enhancement
mrg fix for missing classes found in fixes 4327 fixes 4327>>>needs_review
mrg fixes issue 5482 disambiguation of parameter analyzer docs have been updated with which steps are actually skipped when providing callable as analyzer for countvectorizer additionally previous docstring wrongly indicated that this behavior only applies if analyzer word >>>needs_review
mrg insert versionadded versionchanged directives in docstrings for 18 issue 5505 versionadded versionchanged directives for new stuff in 18 it was not clear to me if should also add these at the file module level for new files did >>>needs_review
mrg compare add changes to whats new for https github com scikit learn scikit learn issues 5842 collaborated with pavlop >>>needs_review
robust pca think it would be great to add robust pca the original algorithm is here http statweb stanford edu candes papers robustpca pdf there is an implementation here https github com dfm pcp by dfm this paper using trimmed grassmann average promises better performance http files is tue mpg de black papers rga2014 pdf glennq implemented it here https github com glennq tga it is bit unclear to me at the moment what the benefits of the two approaches are and how they compare for example for outlier detection also think netflix uses an improved version of the candes algorithm for which didn find reference yet need to ping the netflix people >>>new_feature
mrg fixed issue 5830 capitalization in advanced installation documentation documentation around advanced installation had lost capitalization issue 5830 fixed capitalization and ensured other changes were kept in newer version >>>needs_review
mrg fix for uneven grids in partial dependence plots example fixes 5846 sorry 5810 the problem was not in the code base but the shape of `z` the output of the example won change but user can change the `grid resolution` param such that it exceeds the number of unique values and then the shapes become invalid >>>needs_review
mrg add contingency matrix documentation and example fix https github com scikit learn scikit learn issues 4805>>>needs_review
image links to examples not created as part of latex build the same links are created as part of an html build sample of errors thrown believe that this is related to this bug in sphinx https github com sphinx doc sphinx issues 372 originally posted here https github com scikit learn scikit learn issues 5729 >>>bug build_/_ci documentation
check if all changes in master are actually in whatsnew someone should check whether all changes that happened since the 17 branch split from master are actually present in the whatsnew rst file see also 5640>>>documentation easy
mrg fix issue 4964 model evaluation docs fix 4964 which was also addressing 4804 brier score loss documentation added >>>needs_review
mrg minor edits to multiclass documentation minor changes to become familiar with the process>>>needs_review
mrg added warm start flag to example issue 5581 docs example missing warm start flag>>>needs_review
add contributors to whatsnew for 17 and 16 using git shortlog we should add all contributors to the whatsnew though without commit count and ordered alphabetically you can get the names using something like ``git log git shortlog n``>>>documentation easy
meta estimators for multi output learning think it would be useful to have meta estimators for turning classifier or regressor into multi output classifier or regressor it recurrent pattern and find myself reimplementing it every once in while this is of course useful for estimators that don have native multi output support but even for those that have like rf find that estimating model independently for each output sometimes works better class names `multioutputclassifier` and `multioutputregressor` >>>easy new_feature
mrg doc reworded cv documentation fixes https github com scikit learn scikit learn issues 5822 amueller >>>needs_review
add the diffusion map dimensionality reduction technique the diffusion map is dimensionality reduction technique that uses transitional probability as its distance measure it is noise resistant and non linear moreover the algorithm itself is fast and scalable ve used it with 50k samples wrote quick implementation here https gist github com rohanp 2b950640c94c8e293c40 it has been of interest in numerous scientific fields diffusion maps http www sciencedirect com science article pii s1063520306000546 1119 citations geometric diffusions as tool for harmonic analysis and structure definition of data diffusion maps http www pnas org content 102 21 7426 short 672 citations functional diffusion map noninvasive mri biomarker for early stratification of clinical brain tumor response http www pnas org content 102 15 5524 short 491 citations diffusion maps and coarse graining unified framework for dimensionality reduction graph partitioning and data set parameterization http ieeexplore ieee org xpls abs all jsp arnumber 1661543 450 citations furthermore google scholar search for diffusion map dimensionality reduction yields more results than isomap locally linear embedding or hessian eigenmapping if fix up my implementation would you all be interested in having this in sklearn >>>new_feature
gradientboostingclassifier 40 50 slower in 17 vs 16 ve run several tests with 17 and found that gradientboostingclassifier takes 40 50 longer to run 50k 61 dataset 16 min 17 11 min 11 min 200k 61 dataset 16 43 min 17 62 min tried adding feature scaling but that doesn help tried disabling presort but it runs slower good sign at least another strange part is that my accuracy improved slightly with gradient boosting in 17 could just be randomness and small sample but thought should note it just in case on the 200k test got 67 66 in 16 and 67 75 in 17 on the 50k tests got 66 08 in 16 and 66 17 and 66 34 in 17 the latter surprises me ve seen variation due to randomness but usually under 05 not 17 also tested randomforestclassifier but found that it was slightly faster in 17 ve prepared fork of my repo https github com ktrnka league match predictor if you like to take look there dropbox link to the data in the readme the main experimental script is src exploration train test and gradient boosting is in the function gradient boosting exp great apologies if you have to read my code ve been working on this solo for while if you want code explanations let me know running on mid 2014 macbook pro 6ghz i5 8gb ram integrated graphics>>>bug
unify errors for class dataset if train classifier on dataset with train for each get different exceptions for different classifiers for example adaboost raises zerodivisionerror randomforest does not raise an exception svc raises valueerror be better if the error would be the same so they don have to be caught separately if one is trying different classifiers for given task alternatively the classifier functions predict predict proba decision function could become degenerate to constant function if it consistent with theory >>>easy need_contributor
mrg raise notfittederror in votingclassifier raise `notfittederror` if `predict` `predict proba or `transform` is called on the unfitted `vottingclassifier` object >>>needs_review
randomizedlasso doesn accept sparse matrix the documentation or randomized lasso states that fit function accepts sparse matrices but it doesnt file usr local lib python2 dist packages sklearn linear model randomized l1 py line 100 in fit estimator func params self make estimator and params file usr local lib python2 dist packages sklearn linear model randomized l1 py line 337 in make estimator and params model fit file usr local lib python2 dist packages sklearn linear model least angle py line 1403 in fit check numeric true file usr local lib python2 dist packages sklearn utils validation py line 510 in check ensure min features warn on dtype estimator file usr local lib python2 dist packages sklearn utils validation py line 371 in check array force all finite file usr local lib python2 dist packages sklearn utils validation py line 238 in ensure sparse format raise typeerror sparse matrix was passed but dense typeerror sparse matrix was passed but dense data is required use toarray to convert to dense numpy array >>>documentation easy
expose base estimator interface in isolation forest as followup of 5678 it is clear that it is very important to have fine control over the tree structure of the base estimators in the forest for now the only way to tune this is through `max samples` which both acts on the effective number of training samples and on the `max depth` value of the trees believe we should decouple this and make it possible to adjust `max samples` without necessarily changing the tree structure and vice versa practically this simply means adding `max depth` and other tree hyper parameters to the interface of the `isolationforest` and plug default auto values wherever it is fit >>>enhancement
check classification targets should print out type not for wrong type from sklearn utils multiclass import check classification targets np array check classification targets valueerror unknown label type array >>>easy need_contributor
random state impossible to set for the entire run for testing replicability it is often important to have the entire execution controlled by seed for the pseudo random number generator in pure python it can be done with `random seed in numpy with `numpy random seed it seems that sklearn requires this to be done in every place separately it rather troublesome and especially so since it not immediately obvious where it needed for example `dummyclassifier` needs one but `bernoullinb` doesn thought it would worth implementing something like `np random seed functionality which seeds the entire execution of sklearn for all its functions and classes >>>documentation easy need_contributor
mrg fix inspect getargspec deprecationwarning in cross validation repr >>>needs_review
mrg improve benchmark on nmf previous benchmark used simulated data did not use the new coordinate descent solver 4852 and found the plot very uninformative scikit learn non negative matrix factorizationbenchmark results https cloud githubusercontent com assets 11065596 11060014 b3e180f6 879d 11e5 944e bfebc103d4b0 png scikit learn non negative matrix factorizationbenchmark results2 https cloud githubusercontent com assets 11065596 11060013 b3df64ce 879d 11e5 8dc4 40af574d676b png this new benchmark tests nmf on two datasets 20 newsgroup dataset sparse shape 11314 39116 olivetti faces dataset dense shape 400 4096 it uses three different solvers projected gradient deprecated coordinate descent multiplicative update 5295 not merged and three different initialization schemes random nndsvd nndsvdar the total running time is about minutes for 20 newsgroups dataset and minute for olivetti faces dataset on the plots each point corresponds to one more iteration figure https cloud githubusercontent com assets 11065596 11059895 de69c334 879c 11e5 97c7 25fea07acd3a png figure https cloud githubusercontent com assets 11065596 11059894 de6765bc 879c 11e5 8d77 972e4bf783e6 png >>>needs_review
discretizer `binarizer` transforms continuous values to two states or it would be nice to generalize this to an arbitrary number of states this preprocessor would produce scipy sparse matrix of shape samples features using the one of encoding the thresholds could be chosen uniformly between the min and max of each feature or using the quantiles for example using uniformly chosen thresholds if min max and feature value between and 33 would be encoded as value between 33 and 66 as and value between 66 and as my usecase is that this encoding might be more meaningful than continuous values when using `polynomialfeatures` possibly related to 1062 >>>new_feature
mrg fix import of reload for python forward port of da4f480a6adf5fed30a42500fe0e5a21c404ac2a to fix the python3 build fixes 5738 >>>needs_review
formatting issues in cross validation docs the warning after lolo has some formatting issues http scikit learn org dev modules cross validation html leave one label out lolo>>>documentation easy
functiontransformer docstring is missing link to user guide>>>documentation easy
mrg fixed isolationforest max features predict fails input validation issue 5732 >>>needs_review
add more documentation to pca teaching class where students are learning about pca so pointed them to scikit learn implementation of pca however reading the docstring realized that some information was missing are the components in `pca components sorted by eiganvalues how do you obtain the eiganvalues corresponding to each of the components it turns out that this so post answered my questions but it might be helpful to mention these answers in the docstring >>>documentation easy need_contributor
link to pdf broken the pdf is moved to scikit learn docs pdf not user guide pdf >>>documentation easy
remove replace usage of scipy misc lena in the upcoming 17 release of scipy the lena image has been removed https github com scipy scipy pull 5162 in scikit learn several examples and tests https github com scikit learn scikit learn search python lena rely on the lena image these should be updated to maintain compatibility with scipy >>>documentation easy need_contributor
python3 compatibility there is still bug in 5429 there should be an ``else`` before the import >>>bug
use detected os to give installation instructions see example https circle artifacts com gh nilearn nilearn 287 artifacts home ubuntu nilearn doc build html introduction html installation and discussion here https github com scikit learn scikit learn pull 5257 issuecomment 154098632>>>documentation moderate need_contributor
introduce solver auto for logisticregression logistic regression has many different possible solvers choosing the best is difficult and requires expert knowledge think that it would be useful to introduce solver auto that tries to make good guess on the best approach it would have to be tuned using heaving benchmarks on many different problems good place to start is using the script bench rcv1 logreg convergence py in benchmarks and applying it to variety of problems would people agree with such an idea >>>enhancement moderate new_feature
roc auc score does not handle nans infs well normally when given scores which are the same roc auc score will return but in the case of all nan inf it seems to return the auc for the labels if ranked in the order given 	in roc auc score np inf np inf np inf np inf 	c winpython 64bit python amd64 lib site packages numpy lib function base py 1114 runtimewarning invalid value encountered in subtract return slice1 slice2 	out 	in roc auc score np nan np nan np nan np nan 	out 	in 10 roc auc score np inf np inf np inf np inf 	out 10 	in 11 roc auc score np nan np nan np nan np nan 	out 11 	in 12 roc auc score 	out 12 >>>bug
isolationforest max features predict fails input validation when subsampling features `isolationforest` fails the input validation when calling `predict gives the following in `predict` one of the individual fitted estimators is used for input validation `self estimators validate predict check input true but it is passed the full `x` which has all the features after looking into it bit `bagging py` sub samples the features itself where as `forest py` delegates it to the underlying `decisiontree` >>>bug
mrg simplifiy example fix for https github com scikit learn scikit learn issues 5720>>>needs_review
unusable target reference when doing pdf doc build when building the pdf documentation make latexpdf there are many unusable target reference warnings think they are all dead links at least some of them seem to be it would be great to check fix them all >>>documentation easy
use of deprecated ax set color cycle deprecated in matplotlib examples linear model plot lasso coordinate descent path py ax set color cycle examples linear model plot lasso coordinate descent path py ax set color cycle examples linear model plot lasso coordinate descent path py ax set color cycle examples linear model plot ridge path py ax set color cycle >>>documentation easy
string to array comparison in randomizedlasso here https github com scikit learn scikit learn blob master sklearn linear model randomized l1 py l333 this popped up in the examples but not in the tests as far as can tell which probably means it is not covered in the tests ping agramfort >>>bug easy
applications plot stock market py segfault with openblas and jobs not sure if should delay the release for this but this example is broken ``quotes historical yahoo`` was moved to ``quotes historical yahoo ochl`` or ``quotes historical yahoo ohlc`` don know which is the right one but they both give me segfaults that could just be my broken setup though can anyone with new matplotlib try >>>documentation need_contributor new_feature
cosine similarity is not linked from the docs in the list of pairwise metrics http scikit learn org stable modules classes html module sklearn metrics pairwise `cosine similarity` is not listed also in the metrics module http scikit learn org stable modules metrics html there is no link to the documentation page the documentation page itself http scikit learn org stable modules generated sklearn metrics pairwise cosine similarity html seems to be non existing >>>documentation easy
mrg don use deprecated 1d or deprecated matplotlib stuff in examples>>>blocker needs_review
examples applications plot prediction latency py reimplements train test split in the ``generate dataset`` there is lot of lines that could be killed by using train test split and ``standardscaler`` >>>documentation easy
mrg mlp bug fixes and removing `decision function` amueller fix the wrong way of using random state and mistakenly modifying parameter `loss` some minor fixes and more tests also included remove decision function to make the design particularly with forward pass` cleaner btw have already implemented dropout for mlp in my fork going to make pull request for that once this one is merged >>>needs_review
deprecation warnings in examples in 17 many but hard to find >>>blocker
metrics log loss checking for isinstance np ndarray metrics log loss currently checks if pred isinstance of np ndarray with an error message saying it should be an array of floats this prevents using pandas series inputs perhaps this should be changed to check for dtype instead >>>need_contributor
mrg test runtime down to 30 min on an old laptop see 5639 runtime comparison is on laptop configured with tests run in master in >>>needs_review
mrg add missing whatsnew entries for 17 this adds some whatsnew entries for 17 went through the diff of 17 with 16 added entries on all things that were previously deprecated and now removed as felt that might be helpful >>>blocker
mrg issue 5702 added warning tests for test roc curve method author forgot to add assertion for couple of cases which raised warnings included assert warns with expected warning value and it fixed the issue 5702 >>>needs_review
mrg reduce warnings in the model selection tests fix 5669 stack reversed and use it for the multi output case and set random state to sag solver is used that should make the sag solver converge without any warnings for the `test cross val predict input types` use the iris dataset to prevent non convergence this won slow down the tests by any significant amount use atleast samples per class when using `cross val which uses fold cv amueller >>>needs_review
mrg fix 5663 string comparison on arrays in new gaussian process this pr fixes the issue described in described in issue 5663 >>>needs_review
mrg fix mlp batch size test warning for default value initializing batch size to auto and setting it to samples value for the default case >>>needs_review
mrg split data using safe split in permutaion test scorer to fix error when using pandas dataframe series related to issue 5696 >>>needs_review
mrg doc some fixes to the doc build minor fixes for sphinx more to come tomorrow maybe>>>blocker
gaussian process docs are missing reference the gaussian process narrative repeatedly references rw2006 but never defines it >>>documentation easy
mrg skip 32 bit tests that fail skip doctests on 32bit fixes 5534 5177 for some definition of fixes ping ogrisel gaelvaroquaux the goal is that make will run without error so that people will report actual errors it would be good to remove the ``skip if 32bit`` as much as possible but maybe that is for after the release >>>blocker
mrg fix sparse row scaling in robust scaler fixes 5502 >>>blocker
floating point indexing in minibatchdictionarylearning running the common tests on minibatchdictionarylearning or using ``check estimator`` yields >>>easy need_contributor
aim to raise warnings as errors in test suite going through the fun of seeing all the deprecated usages of numpy in master and 17 think it would be nice to let nose break on warnings don think there should be any warnings when running the tests and that would put the effort much more on the contributors instead of the maintainers >>>build_/_ci
mrg don use floats to index numpy arrays>>>blocker
boolean mask misshape in gaussiannb warning in test sklearn tests test naive bayes test gnb under numpy 10 looks suspicious >>>easy
mrg onehotencoder warn fix fixes 5671 `nosetests sv sklearn preprocessing tests test data py test one hot encoder sparse` now passes without warning locally on py2 10 with numpy 10 enc onehotencoder values trans enc fit transform too large enc transform too large used to give home trev virtualenvs ve lib python2 site packages sklearn preprocessing data py 1819 visibledeprecationwarning boolean index did not match indexed array along dimension dimension is but corresponding boolean dimension is during transform mask valueerror unknown categorical feature present during transform now valueerror unknown categorical feature present during transform and enc onehotencoder values trans enc fit transform too large enc transform too large used to give home trev virtualenvs ve lib python2 site packages sklearn preprocessing data py 1819 visibledeprecationwarning boolean index did not match indexed array along dimension dimension is but corresponding boolean dimension is during transform mask indexerror index is out of bounds for axis with size now valueerror unknown categorical feature present during transform >>>blocker
in api docs neural network module only links to unsupervised not supervised docs needs to be fixed in classes rst>>>documentation easy
mrg fix port lda covariance fix to decomposition module this should fix the first part of 5679 >>>blocker
lda bugfix 5092 lost in refactoring noticed that 5092 did not make it into the refactored code in `discriminant analysis py` line 58 >>>bug
linear models crash on non integer values for this crashes while it properly works for estimators outside of `sklearn linear model` >>>bug easy need_contributor
mrg make clear that gmm is clustering algorithm see 5674 >>>needs_review
mrg fix we shouldn warn the user if the solver is auto>>>blocker
onehotencoder uses misshapen boolean mask there are some concerning warnings about shape mismatch of ``x mask `` in the preprocessing tests of ``onehotencoder`` ping vighneshbirodkar if you have any time otherwise ll investigate tomorrow >>>blocker bug
mlp batch size warning the mlp tests raise many warnings in particular they warn because the default batch size is larger than some datasets suggest setting the default batch size to auto which is ``min whateveritisnow shape `` raising warning about our default value makes no sense to me >>>easy
mrg don compare things that can be arrays to strings fixes the remainder of 5413 this will break on future numpy >>>blocker
gaussian process uses string comparison on arrays the new gp raises lot of futurewarning elementwise comparison failed in the tests this should be avoided by checking if the parameter is string as done here https github com scikit learn scikit learn pull 5413 files diff a84a355d447d21d71c4f82afbeba65edr647>>>easy
neural network tests print the tests for the mlpclassifier print stuff it is good to test the verbosity but the output should be caught similarly to here https github com scikit learn scikit learn blob master sklearn cluster tests test means py l305>>>easy
mrg tst make tsne tests 32bit save fixes some of 5534 >>>blocker
sklearn tree tests test tree test huge allocations sometimes hangs on 32 bit needed to be killed in one of two runs on this 32bit vagrant box http files vagrantup com precise32 box>>>blocker bug build_/_ci
mrg train test split conserves type doc continuation of 5476 checked the rendering like to merge and backport this to 17 soon >>>blocker documentation
rfe doc should mention that the estimator can also have feature importances attribute right now it is mentioned that recursivefeatureelimination works only when the estimator has `coef attribute however that is not the case >>>documentation easy
mrg fix estimators to work if sample weight parameter is pandas series type>>>needs_review
add example using nested cross validation to track the issue even though rvraghav93 said he ll work on it nested cross validation was possible before but not when providing custom cv object and either stratification or the number of samples not being divisible by the number of folds maybe stratifiedshufflesplit would be good example >>>documentation easy
add mlp to whatsnew as jnothman points out in 5587 the mlp is not in whatsnew maybe we overlooked more we should add the mlp under new features and check >>>documentation easy
tests run much slower after sprint according to ogrisel needs investigation >>>easy
appveyor failure on 17 branch on python only here is failure we currently have on the 17 branch https ci appveyor com project ogrisel scikit learn build job 5x1jj8tdg7w30ay2 this test seems to be old don understand what has changed beween 17b1 where it worked and the current branch that could trigger this issue >>>blocker bug build_/_ci
test failure in test logistic regression class weights undex os with accelerate under os 10 11 can make them pass by changing the decimals precision to will open pr >>>bug
joblib new forkserver default mode fails on interactively defined callables reported initially in joblib joblib 263 the long term fix is to use dill in joblib to be able to pickle functions by value instead of by reference with `recurse true` think we should revert to the default fork server mode for now we need to release with that stopgap and re sync into scikit learn and backport to 17 before the release >>>blocker bug
link to user guide broken in ransac http scikit learn org dev modules generated sklearn linear model ransacregressor html sklearn linear model ransacregressor should link to http scikit learn org dev modules linear model html ransac random sample consensus>>>documentation easy need_contributor
randomized svd flip sign according to and not when transpose true from the randomized svd doc looking at svd flip the sign flip is done by column so that the maximum of the column is ensured to be positive based decision is true by default here is an example that shows that it is not the case when transpose true guess in this case the svd flip is according to and not output >>>bug easy
using pandas series for ``sample weights`` leads to an error python from sklearn linear model import ridgecv temp1 pd dataframe np random rand 781 21 temp2 pd series temp1 sum weights pd series np random rand 781 result ridgecv normalize true fit temp1 temp2 sample weight weights python exception traceback most recent call last in weights pd series np random rand 781 result ridgecv normalize true fit temp1 temp2 sample weight weights users jakevdp anaconda envs python3 lib python3 site packages sklearn linear model ridge py in fit self sample weight 868 gcv mode self gcv mode 869 store cv values self store cv values 870 estimator fit sample weight sample weight 871 self alpha estimator alpha 872 if self store cv values users jakevdp anaconda envs python3 lib python3 site packages sklearn linear model ridge py in fit self sample weight 793 else alpha 794 if error 795 out errors weighted alpha qt 796 else 797 out values weighted alpha qt users jakevdp anaconda envs python3 lib python3 site packages sklearn linear model ridge py in errors self alpha qt 685 alpha 686 np dot self diag dot qt 687 diag self decomp diag 688 handle case where is 689 if len shape users jakevdp anaconda envs python3 lib python3 site packages sklearn linear model ridge py in decomp diag self prime 672 def decomp diag self prime 673 compute diagonal of the matrix dot dot diag prime 674 return prime sum axis 675 676 def diag dot self users jakevdp anaconda envs python3 lib python3 site packages pandas core ops py in wrapper left right name na op 618 return left constructor wrap results na op lvalues rvalues 619 index left index name left name 620 dtype dtype 621 return wrapper 622 users jakevdp anaconda envs python3 lib python3 site packages pandas core series py in init self data index dtype name copy fastpath 217 else 218 data sanitize array data index dtype copy 219 raise cast failure true 220 221 data singleblockmanager data index fastpath true users jakevdp anaconda envs python3 lib python3 site packages pandas core series py in sanitize array data index dtype copy raise cast failure 2838 elif subarr ndim 2839 if isinstance data np ndarray 2840 raise exception data must be dimensional 2841 else 2842 subarr asarray tuplesafe data dtype dtype exception data must be dimensional>>>bug need_contributor
collection of test failures on 32bit of 17 b1 git14 g4e6829c all full logs for the rebuilds across debian ubuntus are at http neuro debian net files buildlogs scikit learn 17 b1 git14 g4e6829c but major problem seems to be failures on 32bit >>>bug
app veyor failure on master in test logistic regression sample weights appveyor seems to fail on master ex here https ci appveyor com project sklearn ci scikit learn build 3299 here https ci appveyor com project sklearn ci scikit learn build 3302 or here https ci appveyor com project sklearn ci scikit learn build 3206 with always the same error couldn reproduce the error on the following environment windows 64 bit python 10 32 bit numpy and scipy 15 the regression probably comes from 5274 or 5008 which seems to have avoided appveyor attention during the sprint >>>bug
mrg fix nearestneighbors algorithm auto to work with all supported metrics by default 4931 >>>needs_review
contributing page should mention existence of common tests the existence of `estimators checks py` and common infrastructure for testing estimators in scikit learn should be mentioned in the contributing page imho ogrisel>>>documentation need_contributor
mrg enh support threshold auto in birch use `estimate bandwidth` from meanshift to provide an optional `threshold auto parameter for birch meanwhile it would be good if we are able to set heuristic for `n samples` so that we avoid calculating the nearest neighbors for all samples >>>needs_review
example of nested cross validation we recently merged change to cross validation generators that allows kfold to be performed within the training of an outer kfold operation this should be illustrated with an example be creative >>>documentation easy
mrg add balanced accuracy score in metrics work on this one 3506 adding balanced accuracy score during the sprint it my first contribution there was already prs on that issue but not completed 4300 3929 3511 implement simple version which works only for binary classification case also add test and doc inputs thanks for the feed back>>>needs_review
mlp docs are messing practical intuitions and simple messages there should be one or two images linking to the pictures of the mlp examples http scikit learn org dev auto examples index html neural networks maybe http scikit learn org dev auto examples index html neural networks and or http scikit learn org dev auto examples neural networks plot mnist filters html the topic box in the example page linking to the examples is not complete only one listed and the link is incorrect there needs big warning sign in red using the warning directive that says that this mlp is not appliable for deep architectures or convnets or any serious neural nets and that points to other packages for that related to 5581 >>>documentation easy need_contributor
example using warmstart in mlp doesn actually use warmstart see file home andy checkout scikit learn doc build html stable modules neural networks supervised html more control with warm start>>>documentation easy
mrg fix 5269 overflow error with sklearn datasets load svmlight fix for this issue https github com scikit learn scikit learn issues 5269 svmlight implementation uses long data type to read and store qid so think it makes sense to do same in scikit learn implementation >>>needs_review
mrg circle ci push this allows circleci to push the documentation directly to github io dev if everything goes well no traceback the script in continous integration works on his own from the root of the project you need to have the ssh private key setup to access the github io repository though >>>needs_review
mrg maint reuse unaltered classes functions from model selection also clean up some of the `cross validation` and `grid search` tests note lot more lines can be removed from more redundant tests but feel leaving them as such which will cost extra seconds will ensure that we haven regressed on the old modules to be more clear if we remove redundant test for say `cross val score` and later modify the `model selection` version of the function and test people using the deprecated module will be surprised by that change since we simply import that from `model selection` having the test will make sure that such situation won happen by failing the old tests and forcing us to leave copy of the old implementation at the old module amueller vene jnothman gaelvaroquaux ogrisel reviews >>>needs_review
ridge classifier supports multi label classification but doc and tests are lacking to solve one would need to update the class docstring and add tests to ensure correctness of the implementation >>>documentation easy need_contributor
mrg add how lda lda differs from sckit learn lda closes 5529>>>needs_review
mrg bf not mutating alpha in vbgmm using alpha instead fixes issue 5547>>>needs_review
vbgmm mutates alpha in `` init `` we should probably fix this this means ``set params`` was broken think an easy fix that doesn break backward compatibility would be introduce property `` alpha alpha components`` and then use `` alpha`` instead of ``alpha`` everywhere that would mean behavior stays the same for people not using ``set params`` ``clone`` >>>bug easy
mrg remove complicated equality checks in clone as init shouldn touch anything simplifies the check in ``clone`` that checks if `` init `` and ``get params`` play nicely together previously we could clone objects that copy numpy arrays in `` init `` afterwards we can not doing anything in init is not good idea have an additional check for `` `` because ``pipeline`` is evil working on it note this is fix for 5522 >>>needs_review
find new bar for tonight how about we go at different bar tonight >>>blocker need_contributor
mrg added colorblind compatibility for plot examples in calibration reviewed and edited calibration for colorblind compatibility as discussed in 5435 >>>needs_review
sklearn preprocessing labelencoder transform wrong output python windows metadata version name scikit learn version 16 trying to use labelencoder to label mulltiple classes but when using le transform something often the wrong values are received thouhgt that it maybe has to do with my encoding but you can see it doesnt matter thanks in advance example code python v3 9b73f1c3e601 feb 24 2015 22 44 40 msc 1600 64 bit amd64 on win32 type help copyright credits or license for more information import sys sys stdin encoding utf from sklearn import preprocessing le preprocessing labelencoder list place jobtitle concept organisation person event work le fit list 	labelencoder fit classes 	traceback most recent call last file line in 	nameerror name fit is not defined le classes 	array place jobtitle concept organisation person event work dtype u12 le transform place 	6 import codecs codecs register lambda name codecs lookup utf if name cp65001 else none le transform place 	6 le transform jobtitle 	0 le transform concept 	0 le transform organisation 	3 and using inverser transform on these values will give the wrong categories place becomes work jobtitle concept become place etc >>>bug need_contributor
tests bunch of failures with 17b1 i686 on nix numpy 10 sklearn 17b1 on i686 resulted in bunch of tests failing here the log for the case python was used http hydra nixos org build 26933536 nixlog raw see also 5177 for discussion on how and whether to handle i686 tests >>>blocker
remove the lda reference in related packages now that we have it in scikit learn think that we should remove the pointer to lda in http scikit learn org dev related projects html what do people think >>>documentation easy
mrg ridge coefficients as function of regularisation as in ridge path another perspective 5470 ve added this as separate example >>>needs_review
in imputer transform method check array might be performed twice transform makes calls to `as float array here https github com scikit learn scikit learn blob master sklearn preprocessing imputation py l314 `check array however if `isinstance np matrix or not isinstance np ndarray and not sp issparse `as float array already returns `check array here https github com scikit learn scikit learn blob master sklearn utils validation py l100 >>>easy need_contributor
mrg added partial fit method to onevsrestclassifier from 5179>>>needs_review
mrg version added for all classes in 17 fixes 5504 looks like this versionadded https cloud githubusercontent com assets 11410385 10638349 d6f570f4 780a 11e5 8a3e f309a8cf2053 png any suggestions are welcome to proceed >>>blocker
document when new function class method attribute was introduced for the 18 release sphinx makes it possible to declare when new feature was added using thie `versionadded` directive http sphinx doc org markup para html directive versionadded we should review all the classes functions methods attributes introduced in 17 see the changelog and add versionadded 17` declaration in the docstring for those elements it also good opportunity to add the missing links to the github pr numbers or issue number if no pr when those features where added to the matching entry of `doc whats new rst` similar issue is used to track the work related to the 17 release 5504 >>>documentation easy
document when new function class method attribute was introduced for the 17 release sphinx makes it possible to declare when new feature was added using thie `versionadded` directive http sphinx doc org markup para html directive versionadded we should review all the classes functions methods attributes introduced in 17 see the changelog and add versionadded 17` declaration in the docstring for those elements it also good opportunity to add the missing links to the github pr numbers or issue number if no pr when those features where added to the matching entry of `doc whats new rst` the commits to address this pr should first be merged in master and then ogrisel or amueller will take care of the actual backport to the 17 branch >>>documentation easy
fix formatting on gp examples in documentation some of the plot titles legends seem to overrun the margins of the plots and get cut off see the narrative documentation here http scikit learn org dev modules gaussian process html for start>>>documentation easy need_contributor
robustscaler scaling one row and scaling sparse matrix scaling single row in robustscaler doesn work as expected see 5433 and 5449 ping untom jeffrey04 think also we should raise ``valueerror`` in ``transform`` if ``issparse and self with centering`` >>>bug moderate need_contributor
gp plot doesn render nicely in docs the plot in http scikit learn org dev auto examples gaussian process plot compare gpr krr html doesn look good on the website and is referred to in the user guide the legend is not really readable needs some tweaking with the legend position >>>documentation easy
wip storing the best attributes of non gridsearch cv models continuation of work done by eshillts >>>easy need_contributor
mrg deprecate residual metric and add support for loss in ransac partly fixes https github com scikit learn scikit learn issues 4740 supply arbitrary residual metrics for targets was not possible from sklearn linear model import ransacregressor from sklearn datasets import make regression make regression res met lambda dy dy ransac ransacregressor min samples residual metric res met ransac fit indexerror too many indices for array the workaround was to explicitly define res met as accepting arrays since there is reshape done which is non obvious res met lambda dy np sum dy axis ransac ransacregressor min samples residual metric res met ransac fit >>>needs_review
nan handling of the targets in check should be documented `check y` has an optional `force all finite` parameter that checks for finite values on it seems that input checking for is done anyway np random randn 10 10 np random randn 10 np inf check force all finite false valueerror input contains nan infinity or value too large for dtype float64 this should be either documented or improved >>>documentation easy need_contributor
ovr svc fails with decision function shape ovr this fails in ``predict`` >>>bug need_contributor
document pairwise in the dev docs there is `` pairwise`` attribute that some estimators have to allow cross validation with that is samples samples for example when is precomputed kernel matrix this should be documented somewhere in the dev docs >>>documentation easy
cblas not present but scikit does not add the local copy my installation with pip fails because cblas is not present even though atlas is present and the scipy pip installation worked the error is error command pthread shared build temp linux x86 64 sklearn svm liblinear build temp linux x86 64 sklearn svm src liblinear linear build temp linux x86 64 sklearn svm src liblinear tron usr lib64 atlas lbuild temp linux x86 64 lcblas lm build lib linux x86 64 sklearn svm liblinear cpython 35m x86 64 linux gnu so failed with exit status usr bin ld cannot find lcblas collect2 error ld returned exit status when checking the get info see get info blas opt local workspace master thesis 2015 flickr crawl env lib python3 site packages numpy distutils system info py 635 userwarning specified path is invalid warnings warn specified path is invalid language library dirs usr lib64 atlas define macros have cblas none no atlas info include dirs usr include libraries tatlas which indicates that no atlas info is so scikit learn doesn add its own cblas implementation but have cblas none is indicating that it should changing line 64 in sklearn setup py to fixes the problem have cblas was only added in the latest numpy 10 >>>bug build_/_ci
nan errors in mds test on osx el capitan python am seeing an error when running nosetests on fresh developer build from commit 53bf94cdd686e41195d2ef4d9fbc3c7e83be48c1 my environments are managed with anaconda environment details at the bottom of this message have tried scipy 15 and 16 in python and both presented an error message however the error is not present in python was not able to reproduce the error on different mac with yosemite my machine details are as follows the error the error seems to be related to an interdependency between the ledoitwolf and mds estimators in test common py test non meta estimators when ledoitwolf is removed from the testing list the mds test passes see code below environment versions in that failed the test environment versions in that pass the test >>>bug
plot gp regression was removed but is linked to in the carousel the carousel on the landing page uses the plot gp regression example that was removed of the recent gp deprecation we should replace it maybe by new gp example co2 >>>documentation easy
classifier comparison example plot looks bad the formatting of this plot doesn look good any more http scikit learn org dev auto examples classification plot classifier comparison html probably because some more models got added this example is important because it is on the landing page http scikit learn org dev index html and checking how it renders there would be nice >>>documentation easy need_contributor
countvectorizer with custom analyzer ignores input argument example same for `input file not sure if this should be fixed or just documented don like changing the behavior of the vectorizers yet again >>>bug documentation
estimators should not try to modify and inplace in order to handle readonly memory maps pr 4807 reveals variety of estimators that fails on memory mapped input once we allow check array to process memory map without copying its content in memory estimators failing on read only memory maps the whole pls family factor analysis incremental pca nusvc transformers kernelcenterer maxabsscaler minabsscaler robustscaler standardscaler most of these should be easy to fix mean should be replaced etc >>>bug easy
mrg update cross validation py documentation specified that output types for `train test split` depend on input types >>>blocker
gaussian process examples require too recent version of matplotlib looks like the example are dependent on very recent version of matplotlib and that breaks circleci our new ci infrastructure that is meant for testing the examples https circleci com gh scikit learn scikit learn 51 specifically in plot gpc py there is on line 95 plt colorbar label log marginal likelihood and the version of matplotlib that we have doesn like the label argument to colorbar >>>bug easy
approximate runtimes for sklearn functions this is not an issue with any library but something that cannot find information that could be helpful for new users would be tables listing the approximate runtime of the different machine learning algorithms depending on the size of the input and the other specified parameters sgd logistic regression svm etc thanks >>>documentation easy
coordinate descent should work on float32 data in addition to float64 data for large scale application constraining `elasticnet` input to be `float64` is waste of space as same quality results should be obtainable with `float32` or event `float16` input use of cython in coordinate descent module make the type flexibility bit tricky but should be doable >>>enhancement
mrg convert to boolean arrays for boolean distances ex jaccard cf https github com scikit learn scikit learn issues 4523 issuecomment 149247925 ping amueller jakevdp >>>needs_review
configure the travis cache for miniconda and pip downloads travis ci can declare some folders as cached folders to limit the amount of download we do at each build and hopefully speedup the build and avoid wasting bandwidth on redundant downloads our travis yml` could be refactored to benefit from this for instance by taking inspiration from theano https github com theano theano blob master travis yml l4>>>build_/_ci easy enhancement
logisticregressioncv handles class weights differently these two classifiers are not equivalent indeed the first one computes different `class weights` for every folds whereas the second one uses the same `class weights` for every folds that is why have this line https github com scikit learn scikit learn blob master sklearn tests test common py l116 am working on it>>>bug
mrg max abs scaler row csr fix an attempt to fix 5433>>>bug
doc add example for normalization vs standardization for linear models standardize vs normalize in linear models we need an example as explained here https github com scikit learn scikit learn issues 2601 issuecomment 148071040 one can take inspiration from this gist https gist github com gaelvaroquaux 2465c9f3421a393b785f gaelvaroquaux could you add the relevant labels please >>>documentation easy
add an example showing how to extract prediction paths in forests as discussed in 2937 it would be nice to add an example showing how to extract prediction paths in forests and trees see also 1105 as we have no example showing how to plot decision trees >>>documentation easy
mrg documentation referencing datasets documentation in toc fixes 5432 moved the datasets rst files from sklearn datasets descr to doc datasets and referenced those file in the index rst the involved files were boston house prices rst breast cancer rst diabetes rst digits rst iris rst and linnerud rst each of those files were slightly changed in order to use the same title levels and reference >>>documentation
red green scatter plots colorblindness friendlyness in documentation noticed this while reading the documentation on svms http scikit learn org stable modules svm html but it might also be problem on other pages the plots on that documentation page make heavy use of red and green to separate different types of classes in the scatter plot given that red green is the color combination that is the most common colorblindness consider this very bad choice >>>documentation easy
remove deprecated stuff that will no longer be supported by 18 best way to find deprecated stuff is to do `git grep 18 and see where it says will be removed in 18 or will no longer be supported from 18 or something similar to that and explore the file where that line is found once you have removed the deprecated stuff please commit your work and send pr similar to 5437 with the issue description that it partly fixes 5434 the mrg at the start of the pr indicates that the pr is ready for review or if you are not done working with it fully you could use wip zermelozf 5451 `threshold attribute in the `outlierdetectionmixin` at file `covariance outlier detection py` support for `class weight auto in `utils class weight py` `pooling func` in `transform` of `agglomerationtransform` in file `cluster feature agglomeration py` `random state` parameter in `cluster dbscan py` `n components` in `cluster hierarchical py` `max iterations` in `cluster mean shift py` the `allow lists` `allow nd` and `dtype` options in `train test split` of `cross validation py` remove support for `class weight subsample in `ensemble forest py` `estimator params` in `sklearn feature selection rfe py` `precompute` in `sklearn linear models coordinate descent py` `fixed vocabulary` property in `feature extraction text py` lot more aabadie deprecated code in metrics rvraghav93 5437 5469 5528 helper functions in `multiclass py` remove support for uppercase values for loss in sv test in file `svm tests test svm py` uppercase support in fit liblinear` function in `svm base py` refer 4261 and 4260 also svm classes py l192 remove support for `gamma 0` `svm base py` change the default value of `decision function shape` to ovr `svm base py` `fixed vocabulary removing deprecations fully from metrics left over stuff >>>easy
maxabsscaler is unable to scale row sparse matrix suppose have my collection of data scaled with minmaxscaler then need to transform new sparse matrix with one row sparse vector eg the shape is 58188 however if attempt to transform the row sparse matrix above so can do comparison with the training data get this assertion error the value for scaler scale shape is 58188 the workaround to the problem is to use matrix that has more than row due to this part of the code if am not mistaken am using 17b1 of scikit learn with python on os 10 10 yosemite installed by homebrew >>>bug easy
dataset docs don show up the docs included here 4631 don show up as far as can see it looks like the rst is not in the toc tree >>>documentation easy
std deprecation warnings get bunch of those in master >>>easy
fix skip lda deprecation test on python3 that has no reload >>>blocker
python3 compatibility there seems to be single line in test that is not compatible guess we fix it it seems odd to provide wheels but not to ci though importerror cannot import name reload https travis ci org macpython scikit learn wheels jobs 85779068 >>>blocker build_/_ci
os travis has old gcc this build https travis ci org macpython scikit learn wheels jobs 85779070 uses gcc and the broken `` wunreachable code`` which makes the log so long that travis refuses to build >>>build_/_ci
mrg affinity prop fix commit changes defaults to address issues in 5340 commit issue warning if affinity propagation doesn converge error if fit is called after >>>needs_review
mrg doc update doc readme>>>documentation needs_review
logistic regression with class weight balanced there is some special treatment for ovr and multinomial in logistic regression for class weight `` auto `` but not for `` balanced `` assume that bug >>>bug
pca fit transform changes array order pca fit transform apparently changes order arrays into order arrays import numpy as np from sklearn decomposition import pca np random uniform size 10 10 print flags contiguous pca fit transform print flags contiguous prints `true false` >>>documentation easy
mrg bug reset internal state of scaler before fitting fixes 5408 >>>blocker
use class weight auto and multi class multinomial in logisticregression cause unboundlocalerror in line 637 of logistic py code to reproduce innermost exception >>>blocker bug
mrg elkans means it is just minor modifications to amueller pr 2008 >>>needs_review
cleanup tests we shouldn be comparing strings to arrays this behavior will change in numpy and create giant boolean matrix valueerror because the truth value of boolean array is undefined this change was announced with numpy so we are really behind the curve there is also minor change in here to remove two print statements this started out as cleaning out the tests >>>blocker
odd joblib error in test suite not sure if we talked about that already running the unit tests outputs at some point that seems odd >>>bug
broken example examples svm plot rbf parameters py valueerror traceback most recent call last home le243287 dev scikit learn examples svm plot rbf parameters py in 117 scaler standardscaler 118 scaler fit transform 119 2d scaler fit transform 2d 120 121 home le243287 dev scikit learn sklearn base pyc in fit transform self fit params 453 if is none 454 fit method of arity unsupervised transformation 455 return self fit fit params transform 456 else 457 fit method of arity supervised transformation home le243287 dev scikit learn sklearn preprocessing data pyc in fit self 501 passthrough for ``pipeline`` compatibility 502 503 return self partial fit 504 505 def partial fit self none home le243287 dev scikit learn sklearn preprocessing data pyc in partial fit self 565 self mean self var self samples seen 566 incremental mean and var self mean self var 567 self samples seen 568 569 if self with std home le243287 dev scikit learn sklearn utils extmath pyc in incremental mean and var last mean last variance last sample count 730 updated sample count last sample count new sample count 731 732 updated mean last sum new sum updated sample count 733 734 if last variance is none valueerror operands could not be broadcast together with shapes >>>blocker bug
broken example examples model selection plot roc py valueerror traceback most recent call last home le243287 dev scikit learn examples model selection plot roc py in 100 101 compute macro average roc curve and roc area 102 fpr macro np mean fpr for in range classes axis 103 tpr macro np mean tpr for in range classes axis 104 roc auc macro auc fpr macro tpr macro volatile le243287 miniconda3 envs py27 lib python2 site packages numpy core fromnumeric pyc in mean axis dtype out keepdims 2733 2734 return methods mean axis axis dtype dtype 2735 out out keepdims keepdims 2736 2737 def std axis none dtype none out none ddof keepdims false volatile le243287 miniconda3 envs py27 lib python2 site packages numpy core methods pyc in mean axis dtype out keepdims 64 dtype mu dtype f8 65 66 ret umr sum arr axis dtype out keepdims 67 if isinstance ret mu ndarray 68 ret um true divide valueerror operands could not be broadcast together with shapes 21 35 >>>blocker bug easy
broken example examples manifold plot lle digits py nameerror traceback most recent call last home le243287 dev scikit learn examples manifold plot lle digits py in 112 x2 flat shape 01 make invertible 113 t0 time 114 lda discriminant analysis lineardiscriminantanalysis components fit transform x2 115 plot embedding lda 116 linear discriminant projection of the digits time 2fs nameerror name discriminant analysis is not defined>>>blocker bug
broken example examples ensemble plot random forest embedding py valueerror traceback most recent call last home le243287 dev scikit learn examples ensemble plot random forest embedding py in 45 visualize result using pca 46 pca truncatedsvd components 47 reduced pca fit transform transformed 48 49 learn naive bayes classifier on the transformed data home le243287 dev scikit learn sklearn decomposition truncated svd pyc in fit transform self 165 if features 166 raise valueerror components must be features 167 got features 168 sigma vt randomized svd self components 169 iter self iter valueerror components must be 1>>>blocker bug
broken example examples applications plot tomography l1 reconstruction py only numpy 10 error is `typeerror cannot cast ufunc add output from dtype float64 to dtype int64 with casting rule same kind >>>bug
add multi label classification task add dataset with multi label data refer 5105 preferably the emotions dataset http www eecs qmul ac uk mmv datasets deap >>>easy
mrg update joblib to main change from 0b4 to was to revert our attempt to make python compatible pickles which proved too fragile as far as long term maintenance was concerned this should fix 5241 too should add an entry into whats new rst guess there is no new feature per se since 0b4 >>>blocker
numpy 10 compatibility get lot of errors when just upgraded to numpy 10 using conda mostly they are about casting did do something odd or are we just not numpy 10 compatible >>>blocker bug
wip labelkfold balance folds without sorting this changes labelkfold so that the original or shuffled order of samples is reflected in the folds instead of sorting the labels by frequency balance is achieved just by looking at the smallest fold at each iteration this means shuffling has an effect beyond tie breaking and the order of samples can be used as simple way of achieving stratification closes 5390 see also 5300>>>bug
consistent example showing filtering of outliers by different estimators right now we have two examples which are very simlar http scikit learn org stable auto examples linear model plot ransac html example linear model plot ransac py http scikit learn org stable auto examples linear model plot theilsen html it would be useful to have single consistent example comparing the models in both the examples and also maybe adding the sgd with huber loss >>>easy need_contributor
labelkfold shuffling and preserving original order currently labelkfold sorts samples by weight so as to create balanced folds in terms of size however this is at odds with shuffling moreover the regular `kfold` partitions the samples without changing their order which is useful if the order is meaningful or reflects stratification my suggestion is to make the sorting for balanced fold sizes in `labelkfold` optional so that shuffling or the original order of samples is honored by keeping the labels in the order in which they are first encountered >>>bug
missing documentation for pandas dataframe integration with sklearn cross validation train test split the current documentation 16 does not mention that you can pass in and will get as output pandas data frames to the train test split method this was especially unfortunate given that the change between 15 to 16 resulted in different output when pandas dataframe is used as input 15 returns numpy arrays and 16 returns list of pandas dataframes >>>bug documentation
theil sen regression example doesn show theil sen results http scikit learn org dev auto examples linear model plot theilsen html there is is no green line in the left hand plot probably because it overlaps with the red line maybe it possible to make it visible or at least explain what is happening >>>easy
memory leak in gbm implementation when warm start is set think there is memory leak or other unnecessary data copying going on when warm start is used for gbm here is minimal program which reproduces the issue >>>bug moderate need_contributor
add common tests for sample and feature estimators should either set ``min samples`` and ``min features`` or work testing in ``check fit2d 1feature`` and ``check fit2d 1sample`` for good error message is probably the way to go >>>moderate
gridsearchcv documentation confusing for unsupervised methods there is very nice example of using `gridsearchcv` with an unsupervised method `kerneldensity` here http scikit learn org stable auto examples neighbors plot digits kde sampling html it has this code however the documentation for `gridsearchcv` here http scikit learn org stable modules generated sklearn grid search gridsearchcv html sklearn grid search gridsearchcv suggests that that code shouldn work because it assumes that the underlying method is supervised and in particular is classifier it says things like gridsearchcv implements fit method and predict method like any classifier except that the parameters of the classifier used to predict is optimized by cross validation and scoring string callable or none optional default none string see model evaluation documentation or scorer callable object function with signature scorer estimator bold added in both cases in fact `gridsearchcv` correctly ends up using the `kerneldensity score` method it is just that the documentation is confusing >>>documentation
kernel means several people including nellev seem to be interested in merging my kernel means code in scikit learn https gist github com mblondel 6230787 am open to it if someone wants to work on it this will of course need docs tests and examples note that this implementations requires the kernel matrix to fit in memory but this also the case of kernel pca and kernel ridge in scikit learn >>>new_feature
mrg enh feature selection based on mutual information hi this is my attempt to finish rework 2547 tried to address code style issues and also added algorithms estimating mutual information with continuous variable involved there are places for trivial optimization but for now tried to keep the code as transparent as possible it would be great if some of the core developers can start seriously reviewing with pr >>>needs_review
mrg increase length of array indexing type in arraydataset int 32 bit on all platforms will loop around once the number of elements exceed 31 while ints are used elsewhere for row index this is particularly significant here since this int is used as an index into dense matrix as long as rows cols is greater than 31 this will fail this is probably the root cause of 2393 >>>bug
request more criterion for random forest regression current random forest regressor only support for mse can more criterions such as mean square of percentage error can be support by scikit learn >>>enhancement moderate
ridgecv and ridge produce different results when fitted with sample weight import numpy as np from sklearn linear model import ridgecv ridge from sklearn datasets import load boston from sklearn preprocessing import scale boston scale load boston data target load boston target alphas np linspace 200 weight np logspace len target print ridgecv eigen fit0 ridgecv alphas alphas store cv values true gcv mode eigen fit boston target sample weight weight print alpha fit0 alpha print cv fit0 cv values print coef fit0 coef print ridgecv svd fit1 ridgecv alphas alphas store cv values true gcv mode svd fit boston target sample weight weight print alpha fit1 alpha print cv fit1 cv values print coef fit1 coef print ridge fit2 ridge fit0 alpha fit boston target sample weight weight print coef fit2 coef gives if `sample weight` is `none` all three models give the same coefficients >>>bug
mrg fix precomputation of gram matrix in lars this is fix for the bug reported in 1856 the parameter `precompute` in randomizedlasso lars larslasso larscv larslassocv and larslassoic were not consistent and some values proposed in the docstrings false array could raise errors this pr includes the following steps improve `lars path` to allow `gram true` and `gram false` change the get gram` method to handle `precompute` in the same way in every class add warning when an array is given in `precompute` in larscv and larslassocv update the docstring add some tests `test randomized l1 py` is also updated to be shorter from 582s to 817s `test least angle py` goes from 305s to 465s >>>needs_review
mrg fix fit transform stability issue and scale issue in pls this pr fixes stability issue and sign indeterminacy in pls and cca see bug 2821 three issues were adressed `fit transform` did not work for obvious reason fixed this and change estimator checks so that it do not overlook transformer unable to perform `fit transform` without previous `fit` scipy linalg pinv is based on `lstsq` and is subject to more numerical instability than `scipy linalg pinv2` which quite amusingly is the same as `numpy linalg pinv` and is based on svd decomposition pls is subject to sign indeterminacy like any matrix decomposition method similar to `svd flip` we fix this within pls code the signs of `x loadings `x score `x weights `x rotations can differ columnwise from implementation as there is sign indeterminacy that we seek to raise cf svd with `svd flip` since `test pls` is based on output still need to change it so that it does not fail because of sign differences ping twiecki fenugreek for pls proficient reviews>>>bug
mrg maint center data for linear models fixes 2601 no more to do update the docstring saying that we do normalization to reduce surprise clean and factor `center data` and `sparse center data` into new private function and deprecate them add necessary deprecation update docs review all the todo` and xxx` and not to do see 2601 and discussion below deprecate `normalize` signature and property and introduce `standardize` behaviour introduce the same behaviour for every class calling `center data` internally related tests make sense of this old test https github com scikit learn scikit learn blob master sklearn linear model tests test base py l63 on `sample weights` with unused variables done in https github com scikit learn scikit learn pull 5526 change `center data` behaviour `fit intercept` currently input data is not touched https github com scikit learn scikit learn blob master sklearn linear model base py l119 if we not are fitting the intercept see separate issue 5799 3459513455 d1288a14b9 https cloud githubusercontent com assets 2871319 10516143 1afb092a 7357 11e5 81e9 a2835af3aacf jpeg >>>needs_review
rfe rfecv docstring should say estimator can supply feature importances not just coef >>>documentation easy
lasso fit intercept conversion logic missing python from sklearn import linear model import numpy as np np random seed 42 np random randint size np random randint size works model linear model lasso alpha fit intercept true model fit ou oh model linear model lasso alpha fit intercept false model fit valueerror traceback most recent call last in 12 ou oh 13 model linear model lasso alpha fit intercept false 14 model fit users ch miniconda envs sci34 lib python3 site packages sklearn linear model coordinate descent py in fit self 671 coef init coef max iter self max iter 672 random state self random state 673 selection self selection 674 coef this coef 675 dual gaps this dual gap users ch miniconda envs sci34 lib python3 site packages sklearn linear model coordinate descent py in enet path l1 ratio eps alphas alphas precompute xy copy coef init verbose return iter positive params 430 model cd fast enet coordinate descent 431 coef l1 reg l2 reg max iter tol rng random 432 positive 433 else 434 raise valueerror precompute should be one of true false sklearn linear model cd fast pyx in sklearn linear model cd fast enet coordinate descent sklearn linear model cd fast 2839 valueerror buffer dtype mismatch expected double but got long >>>bug
mrg add fast replacement for np cov this is inspired by some recent prs over at numpy concerning `np cov` performance timings with numpy and atlas np random rand 13000 60 timeit np cov loops best of 82 per loop timeit fast cov loops best of 71 per loop memory use is also halved compared to numpy 10 at least for `n samples` `n features` numpy 11 will have more memory efficient `cov` implementation >>>needs_review
custom warnings filter for deprecations it would be good to have custom ignore deprecation warnings that would accept tag parameter and would ignore the warnings only of certain release this will enable us to quickly filter and modify tests after the release while making sure other warnings are not ignored >>>api
affinitypropagation bug runtimewarning mean of empty slice slight modification of the parameters cluster std in the demo code http scikit learn org stable auto examples cluster plot affinity propagation html labels true make blobs samples 300 centers centers cluster std random state produces blown up result fig below and warning anaconda anaconda3 anaconda lib python3 site packages numpy core methods py 59 runtimewarning mean of empty slice warnings warn mean of empty slice runtimewarning version 16 osx jupyter notebook cluster std looks like magic value cluster std 69 and cluster std 71 produce reasonably looking result orange dots the intended centers added to the plot by me https cloud githubusercontent com assets 13791275 10266366 9ba33bb4 6a2a 11e5 9c86 0d39b95278bb png >>>bug
mrg pairwise distances outputs nan and negative values fixes 4475 the problem is about pairwise distances and not sne refer to the issue for discussion 4495 deals with the same issue but it does not seem active any more tests for problems related with negative values now pass regarding `nan` am going to see if fix on the scipy side is possible until then have written wrappers of the scipy functions changes added breaking tests for `tsne` as from 4475 but covering all distances from `sklearn metrics pairwise pairwise distances` added breaking tests for the same `pairwise distances` implemented robust sklearn version of `correlation` almost the same as `cosine` wrote wrappers for scipy yule dice sokalsneath >>>needs_review
sklearn cluster agglomerativeclustering can we do without completing the matrix userwarning the number of connected components of the connectivity matrix is completing it to avoid stopping the tree early have tried this both on the latest 16 version and on the latest bleeding edge version of sklearn 17 dev0 and this appears to be an issue in both use `sklearn cluster agglomerativeclustering affinity precomputed connectivity cmat linkage complete where cmat is connectivity matrix in which there are disconnected components as indicated by the source code get the error message userwarning the number of connected components of the connectivity matrix is completing it to avoid stopping the tree early however reading the source code see that when completing the connectivity matrix the developers are wondering whether the clustering can take place without completing the matrix xxx can we do without completing the matrix am interested exactly in this development do you think sklearn is planning to fix this and make it possible to do the clustering without completing the matrix think it should not be too hard best zhana>>>bug
fail doctest sklearn neighbors approximate lshforest while buidling the scikit learn encountered following error please have look at it regards cosmos >>>bug easy need_contributor
regression models should raise errors when targets are nan inf>>>easy
mrg optional verbosity for pipeline adds named verbosity argument in pipeline constructor after each step verbose pipelines print to standard output lines like pipeline fit or transform 5298>>>needs_review
types in dataset bunches are inconsistent just saw that iris feature names is list but iris target names is an array that is odd not sure how it is for the other datasets this is pretty minor but some consistency would be nice >>>easy need_contributor
make lars and lassolars parallel on the multiple targets lars and lassolars in least angle py could have the loop on the number of targets made parallel using joblib parallel as everywhere in the codebase >>>easy enhancement
empty `residues in `linearregression` no residues returned in `residues attribute >>>easy need_contributor
mrg check should copy also if copy is set to be true is it acceptable to expect also to be copied when `copy` is set to true this makes sure that is not modified when is centered inplace hit this bug here https github com scikit learn scikit learn pull 5291 files diff 7416ccedd45a5840c67ff7877d24e1cer52 also added test case that fails in master >>>needs_review
verbosity in sparse encode sparse encode and the code that uses it like online dict learning doesn have verbosity argument and doesn report progress >>>easy enhancement
mrg collapsing pca and randomizedpca fixes 5243 and 3930 to do collapse the two classes old tests passing integrate `svd solver arpack benchmark the solvers and establish the best `auto` policy fix docstrings uniform with `incrementalpca` by inheritance from basepca` see 3285 add `flip sign` param true by default we flip by default without introducing param for controlling the behaviour arpack backport updated>>>needs_review
verbose option on pipeline would like to see timing information for individual steps in pipeline perhaps named variable for verbose in the pipeline constructor >>>easy enhancement
mrg add scaling to alpha regularization parameter in nmf separated this modification from 4852 for further discussion about it in nmf scaled here the regularization parameter `alpha` with `n samples` and `n features` indeed without scaling two problems appear the regularization penalizes the sum of coefficients in and if the number of element in and is not the same `n samples features` the constraint is unbalanced one of or goes to zero and the other one which is less penalized increases to compensate the value of alpha that makes the coefficients of and collapse is proportional with `sqrt features samples it makes the scaling of alpha depends on the size of the data test to prove the point tested several sizes for the input `x` and plotted how the coefficients in and collapse with respect to the `alpha` parameter without scaling alpha noregul https cloud githubusercontent com assets 11065596 10025176 31ef9e1a 615b 11e5 86b5 70f42ec45442 png with properly scaling alpha regul https cloud githubusercontent com assets 11065596 10025177 31f14080 615b 11e5 90b3 a26a751ce7a6 png scaling used used `alpha alpha features` and `alpha alpha samples` conclusion the effect of the `alpha` parameter is much more consistent if we scale it as l1 and l2 regularizations in nmf is fresh new 4852 it would not really break any code before 17 at least but do we want to add this is it consistent with other estimators in scikit learn what do you think vene mblondel >>>needs_review
mrg add huber estimator to sklearn linear models add robust regression model that filters outliers based on http statweb stanford edu owen reports hhu pdf add fix for random overflowerrors add documentation to the helper function add extensive testing add narrative docs add example support for sparse data support sample weights>>>needs_review
remove files from the repo we should only generate files for releases and not distribute them with the repo as scipy does it pretty easy to find out whether you are doing an dev build and cythonize or just build the files that are shipped with the release >>>build_/_ci enhancement
mrg implement fabia biclustering algorithm this pr adds the fabia biclustering algorithm to sklearn fabia is general biclustering algorithm based on matrix factorization had discussed this addition with kemal eren who implemented the rest of the biclustering package during the gsoc 2013 way back in 2013 as far as know his mentors iirc gaelvaroquaux welcomed the idea back then ve had the code lying around in 2476 but never got around to polish it until now if there is still interest in the addition here it is notes also have cython version that is 20 200 faster the larger the amount of biclusters to detect the smaller the speedup in realistic settings it will be close to 20 however that implementation is based around the `cython lapack` module that comes with scipy 16 without that it would require pulling large ish amount of lapack into sklearn didn think that was worth it >>>needs_review
deprecationwarning for inspect getargspec in python when running the current master in python os 10 10 receive `deprecationwarning`s every time `inspect getargspec` is used incidentally these warnings cannot be turned off using `warnings simplefilter` or `warnings filterwarnings` >>>easy need_contributor
mrg one hot encoder now errors on any unknown categorical feature see the new test case added which fails on the current master >>>needs_review
overflow error with sklearn datasets load svmlight file scikit learn version 16 os yosemite 10 10 ve created svmlight file with only one line from pandas dataframe when open the file in an editor the result looks like this qid 72048431380967004 1440446648 72048431380967004 236784985 when try to load the file with query id true get an overflow error overflowerror signed integer is greater than maximum if load the file with query id false there appears no error message but the value for the query id is wrong this is the output 1440446648 72048431380967008 236784985 72048431380967004 appears now as 72048431380967008 how do avoid this error the maximum value of np uint64 is 9223372036854775807 so there should be no overflow error have tried to load with np int64 as data type too but the output is the same >>>bug need_contributor
problem in using logisticregressioncv hi guys not sure if anyone has experienced this but logisticregressioncv seems to have some problems when the predictor matrix for training train is sliced from some bigger matrix apologies that might be using some incorrect code markdown below but trying to attach my example code the code uses the digits data from sklearn put three possible ways of getting train and feed it into logisticregressioncv labled as safe dodgy and dodgy in dodgy for example slice train from bigger matrix and then change different part of the bigger matrix that isn part of the sliced result the resultant auc changes from to below suspect this is because some inappropriate use of underlying memory does anyone have any comments thanks lot my example code >>>blocker bug
mrg split installation into simple and advanced part fixes 4742>>>blocker build_/_ci documentation easy
random failure of multiprocessing tests on appveyor here is an example https ci appveyor com project sklearn ci scikit learn build 2089 job d3ftyxakgj8q0vgo it happens both on python and python both with 32 bit and 64 bit but randomly >>>build_/_ci
add scaling to sgdclassifier sgdclassifier only really works well with scaled data think we should add some scaling to it by default >>>enhancement
second call to sgd partial fit fails in multiclass setup with averaging turned on test code this last call fails with exception this happens because est standard intercept is of size one instead of size three as needed by the multiclass setup of the test case have found the issue originates from fit multiclass function in stochastic gradient py line 485 https github com scikit learn scikit learn blob master sklearn linear model stochastic gradient py l485 fixed it by replacing the above code with because self intercept is properly created using the intercept values from the various ova jobs in lines 474 475 also line 486 can be removed changing the code as suggest solves the issue but the role of self standard intercept and its relation with self intercept is not 100 clear to me so would like check from people with more experience on sklearn code before calling it bugfix >>>bug
ridge class weight failure on appveyor https ci appveyor com project sklearn ci scikit learn build 2018 job 8tf9xbl5i9j2dcyp>>>bug
doc further documentation building tweaks this extends 5195 to update documentation on building documentation and to make `optipng` execution more economical from within `doc makefile` >>>documentation
don hard code kernel parameters in nystroem the current nystroem kernel approximation interface is bad as it assumes some default parameters for certain kernels it should get dictionary of kernel args instead think see 5211 this needs deprecation >>>easy enhancement need_contributor
add svc documentation for properties issue https github com scikit learn scikit learn issues 4687 documented `fit status `proba and `probb >>>documentation easy
mrg support arbitrary init estimators for gradient boosting in 2691 it was brought up that passing an estimator as base class to gradient boosting classifiers or regressors would cause it to crash due to various shape issues on the main issue being that it was expected that the predictions of the base estimator should be of shape samples classes for multinomial classification or samples for binary classification and regression this pr solves this issue by handling each case separately if the initialization estimator is one of those already in `gradient boosting py` it uses those predictions as normal however if classifier was passed in it will check to see if it has `predict proba` method and use that if possible collapsing into the log odds if only two classes if the classifier does not have `predict proba` method it will use the `predict` method and hot encode that into matrix if this needs to be collapsed because there are only two classes it adds small epsilon to the matrix before calculating the log odds if regressor is passed in then the predictions are just reshaped to make sense also reordered the code little bit for it to be more organized and added two unit tests to make sure that it works it now works with arbitrary estimators as long as they take sample weights into their fit method and the unit test includes tests on support vector machines and ridge regression initializations ping ogrisel agramfort glouppe pprett >>>needs_review
mrg doc update authors rst to better reflect team this removes couple of names that seem to have been misplaced don know if there are other names added here incorrectly and am not brave enough to suggest so while adding some members of the owners reviewers teams https github com orgs scikit learn teams that were absent from `authors rst` members of that team that are not added by this pr are david warde farley very few contribs limited to datasets shiqiao du relatively few contribs to hmm which is now external perhaps statement the following people have been core contributors to scikit learn development and maintenance is also due now included name order is intended to roughly match chronology which can be estimated with `grep doc whats new rst tail n1` now alphabetical by surname >>>documentation needs_review
rfc tree module improvements am planning on submitting several prs in an attempt to merge 5041 in slowly with the ultimate goal being clean implementation of multithreaded decision tree building so that gradient boosting can be faster with one of the main concepts merged 5203 here is list of separate prs which like to merge in the near future reorganize tree pyx into several files see pr 5230 merged add proxy impurity improvement methods to both gini and entropy see pr 5233 closed reevaluate constant feature caching closed support sparse data for gradient boosting see pr 5252 add caching of computation between different split levels to avoid recomputation ensure feature importance converge in ensemble see pr 5261 add tests to ensure the correctness of impurity values wrt hand computed values on toy data longer range goals which like to work towards but have no clear plan as of right now are the following add an approximate splitter add multithreading support for single decision trees add partial fit method for tree building support categorical variables support missing values at this point it will be clearer to me what specific changes to splitter criteria and treebuilder need to be added to make multithreading possibility glouppe arjoly gaelvaroquaux pprett if you have any comments love to hear them >>>enhancement moderate
mrg fixed doctests on i686 related to 5193 5177 5197 https reviewable io reviews scikit learn scikit learn 5208 >>>documentation
super or no super was trying to figure out whether wanted to use super or not in one of my projects and decided to see how scikit learn does it found the following that is ``super base self init `` is used in 70 places in scikit learn core while ``base init self `` is used in ten cases there seems to be broad disagreement about whether ``super `` is harmful https fuhm net super harmful or well super https rhettinger wordpress com 2011 05 26 super considered super but there is agreement on the fact that whichever pattern you use it should be used consistently throughout individual projects do we have policy on this should the non supers be changed to supers here >>>api
build process should check numpy and scipy meet minimum version requirements while we don allow setuptools to automatically install numpy and scipy and we recently f41f2e47 inserted custom error checking for the case that they are not installed we should also error out of the setup process if the minimum version requirements are not met >>>build_/_ci easy need_contributor
gaussian process based hyper parameter optimizer following discussion on issue 474 https github com scikit learn scikit learn issues 474 this pr aims at implementing gp based hyper parameter optimizer this is based on sklearn gaussian process http scikit learn org stable modules generated sklearn gaussian process gaussianprocess html sklearn gaussian process gaussianprocess and randomized search optimizer http scikit learn org stable modules generated sklearn grid search randomizedsearchcv html implementations given budget number of iterations at each step model through gp sample randomly candidates within the hyper parameter space compute the value of the acquisition function for each candidate thanks to the gp model where the acquisition function could be the expected improvement and the upper confidence bound select the candidate that maximizes the acquistion function as the next point to test current acquisition functions implemented are the expected improvement ei and the upper confidence bound ucb examples are provided in `examples model selection gp search py` results obtained with simple pipeline on the iris dataset http scikit learn org stable auto examples datasets plot iris dataset html comparison random based in green vs gp based in blue the 20 first iterations are random iris results https cloud githubusercontent com assets 7746635 9564205 bdc8193c 4e9e 11e5 9de0 938be3aec166 png >>>moderate new_feature
16 failing doctests on i686 when using scikit learn 16 with numpy on i686 system certain doctests fail they don seem to fail on x86 64 systems though haven tested with master in all cases what missing is the dtype of the array here an example and here the log http hydra nixos org build 25129295 nixlog raw >>>bug
unexpected memoryerror from incrementalpca used with memmap prompted by question asked in stackoverflow chat http chat stackoverflow com transcript message 25344627 25344627 investigated why user would encounter memoryerror when using the following minimal code ut np memmap my array mmap dtype np float16 mode shape 140000 3504 clf incrementalpca copy false train clf fit transform ut found that the memoryerror was called by this call to `check array` https github com scikit learn scikit learn blob master sklearn decomposition incremental pca py l167 check array dtype np float the problem is with adding the `dtype np float` to the call to `check array` this means that the `copy false` default of `check array` is ignored because the `dtype` has changed in that call to `np array and the docs state that change of `dtype` will force copy irrespective of the `copy` argument made simple gist demonstrating the issue here https gist github com rsnape bd1f30db4b789a5f7665 propose that the line above could be changed to check array but am not expert enough in this tool to understand whether that might have negative consequences further along the chain of execution if that is good solution happy to submit pr >>>bug
sklearn datasets dump svmlight file multilabel support documentation currently the class label must be an integer or float lists as used for multilabel classification cause an exception starting with line 289 currently use this workaround if hasattr iter line pattern if query id is not none line pattern qid line pattern if comment write generated by dump svmlight file from scikit learn version write column indices are based zero one one based write writelines line for line in comment splitlines if hasattr iter for in enumerate join map str >>>documentation easy need_contributor
after build and install scikit learn test will fali pre requisitions ubuntu 15 10 python 10 gcc version 20150808 ubuntu 15ubuntu2 reproduce steps git clone latest version of code from github install dependencies build and install the scikit learn from latest code execute test via command nosetests sklearn output result >>>blocker bug
dense svm and zeroed weight for samples of entire class this bug appears in current master and for any dense svm class output here we see that svmlib internally have lost 2nd class at the same time sklean wrapper class keeps all class labels inside that why predict proba returns matrix of shape samples instead of sample what is expected by bagging classifier implementation understand that it insane usage of weights by itself but together with bagging and dataset with many labels bagging randomly zeroes complete classes and this bug shows itself because bagging expects that svm return probability of classes which they hold all classes investigated this little bit and can try to fix this if someone will say that all this usage with bagging makes sense because don really sure about this >>>bug
lda predict proba should use softmax it uses an ovr normalization for multi class for some unknown to me reason see 5134 >>>bug
add don make bunch to faq frequently asked question is how do make bunch the answer is don make bunch they are not part of the scikit learn api they are just way package some numpy arrays you only ever need numpy arrays to put data into scikit learn >>>documentation easy need_contributor
bug in predict proba of multinomialnb when fitted with fit but not when fitted with partial fit hello can provide ipython notebook where test the accuracy calculation via three methods for multinomialnb score method predict method and then computing the mean of predictions being equal to predict proba and the computing of preditcions with argmax and then computing the mean of predictions being equal to all three are equals as expected when fitted the multinomialnb model with partial fit method the seems to be inconsistent when fitted the multinomialnb model with fit method best regards >>>bug
suggestion to have multiclass py allow prediction over one sample only greetings guys came through the contributed implementation to multiclass py in scikit learn just have suggestion for you to consider the case when only one testing sample is passed to decision function decision function for the onevsoneclassifier as for the current implementation an undesirable output comes since samples shape will take number larger than one when is only single list vector with some values may suggest you check the shape of before parsing it in particular way or update the documentation to advise the user on suggested way to get the prediction for one testing sample in sense it is true to say that usually there is testing set of many samples but in specific case of mine it was preferable to predict sample by sample overcome this by using instead of where is testing set of several samples the sklearn version have installed is 16 did not get an error when inputing 1d and what receive back are predictions as many as the length of this 1d list for example from sklearn import datasets from sklearn multiclass import onevsoneclassifier from sklearn svm import linearsvc iris datasets load iris iris data iris target onevsoneclassifier linearsvc random state fit predict out array and by replacing to be which in terms of values are the same onevsoneclassifier linearsvc random state fit predict out array proper output regards othman>>>bug easy need_contributor
logisticregression predict proba is incorrect when multiclass multinomial looking at the code for logisticregression predict proba it seems to assume that multiclass ovr it does sigmoid wtx and then normalizes over the classes think that when multiclass multinomial is used it should use softmax instead >>>bug
cross val predict should work for sparse `y` currently it uses `np concatenate` to merge predictions but predictions could be sparse matrices >>>bug easy need_contributor
link to silhouette score example in user guide at silhouette score>>>documentation easy need_contributor
pca score is log density right the docstring says it log likelihood same for score samples kde correctly says log density xuewei4d gmm also now says log density right >>>documentation easy need_contributor
mrg added predict proba functionality to cross val predict method modified the call signature of cross val predict to accept proba keyword argument and fit and predict to require proba boolean see signatures below when set to true predict proba is called on the estimator and predict when false default value is false to preserve existing functionality cross val predict estimator none cv none jobs proba false verbose fit params none pre dispatch jobs fit and predict estimator train test verbose fit params proba >>>needs_review
wip text vectorizers memory usage hi the other day ve tried to vectorize some big text data and wondered why sklean would use that much memory so looked into it and think ve found some points for testing purposes used the enron data set http www cs cmu edu enron enron data set to reproduce my results without having to modify sklearn you can use this little script https gist github com ephes 90193567b8c0501b13ef enron test script now including the vectorizer from 4968 just unpack the enron dataset and start the script with here little table showing the results countvectorizer and hashingvectorizer are the unmodified vectorizers from sklearn leancountvectorizer and leanhashingvectorizer are the new modified versions aupiffcountvectorizer is the modified version from 4968 inheriting from leancountvectorizer from countvectorizer in parantheses fastaupiffcountvectorizer uses if else instead of get in inner loop and keys and values insted of iteritems an explicit del feature counter after adding new doc vectorizer after 300k after 510k peak time countvectorizer 43 gb 84 gb 14 gb 237 24s leancountvectorizer 08 gb 41 gb 87 gb 268 19s aupiffcountvectorizer 41 gb gb 86 gb gb 287 43s 280 02s fastaupiffcountvectorizer 27 gb 43 gb 69 gb 253 92s hashingvectorizer 46 gb 75 gb 82 gb 243 02s leanhashingvectorizer 28 gb 55 gb 64 gb 232 62s why is the default countvectorizer using gb memory to produce feature matrix which is only 15 gb in size when dumped to disc via joblib maybe it the vocabulary let see well it not the vocabulary it the feature matrix and if using gb is not bad enough either sum duplicates or sp csr matrix are copying some data because saw 25 gb memory usage even with an sys exit at the end of count vocab in the leancountvectorizer iterate chunk wise over the documents create temporary feature matrix for each chunk and append this temporary feature matrix then to the final feature matrix in place so there never this big values array and the data gets also copied but only for the small chunk based feature matrices after count vocab returned the feature matrix the method sort features is called although it modifies the vocabulary in place as stated in the docstring it does not modify the feature matrix in place but makes copy via fancy indexing return map index so changed the sort features method for leancountvectorizer to modify the feature matrix in place this operation is rather slow and the main reason why leancountvectorizer is slower than countvectorizer maybe there better way to swap the columns of the feature matrix and finally the limit features method also makes full copy of the feature matrix via fancy indexing because it high and low arguments are set to numerical values per default so the if high is none and condition is always false in leancountvectorizer this is also changed the leanhashingvectorizer has only the iterate in chunks over documents modification and since the values array would not get as big it uses less memory best regards jochen>>>need_contributor
multicore latentdirichletallocation is dead slow on my box fitting lda to all of 20news with `n jobs 1` or `n jobs 4` is twice as slow as doing it single core see one python process taking up 49 of one core and few more doing next to nothing will investigate further >>>bug
gridsearchcv freezes indefinitely with multithreading enabled jobs ve been intermittently running into this issue in the subject with gridsearchcv over year now across python and two jobs several different mac osx platforms laptops and many different versions of numpy and scikit learn keep them updated pretty well ve tried all of these suggestions and none of them always work https github com scikit learn scikit learn issues 3605 setting multiprocessing start method to forkserver https github com scikit learn scikit learn issues 2889 having issues only when custom scoring functions are passed ve absolutely had this problem where the same gridsearchcv calls with jobs freeze with custom scorer but do just fine without one https github com joblib joblib issues 138 setting environment variables from mkl thread counts have tried this when running numpy sklearn built against mkl from an anaconda distribution scaling inputs and making sure there are no errors with jobs completely sure that the things trying to do on multiple threads run correctly on one thread and in small amount of time it very frustrating problem that always seems to pop back up right when confident it gone and the only workaround that works 100 of the time for me is going to the source for gridsearchcv in whatever sklearn distribution on an manually changing the backend set in the call to paralell to threading instead of multiprocessing haven benchmarked the difference between that hack and setting jobs but would there be any reason to expect any gains with the threading backend over no parallelization at all certainly it wouldn be as good as multiprocessing but at least it more stable btw the most recent versions ve had the same problem on are mac os 10 python continuum analytics inc scikit learn 16 scipy 16 numpy pandas 16 joblib 4>>>bug
latentdirichletallocation number of iterations when amend `examples applications topics extraction with nmf lda py` to print `lda iter after fitting it reports 81 that clearly more than `max iter 5` >>>bug need_contributor
reference for the agglomerative clustering with connectivity constraints sorry if this is not the right place to ask but can`t find contact email for the sklearn team my question is is there paper or scientific source where the agglomerative hierarchical clustering with connectivity constraints is from am currently using that algorithm and would like to cite it properly and also study it in more depth any pointer is appreciated >>>documentation
add classical binary classification task there is not really any real world binary classification dataset in scikit learn find this bit frustrating because it means that every time want to explain auc have to make one of the datasets binary which seems very unnatural does anyone have good idea for binary dataset should we include one from uci know we already have too many loaders but this seems like such basic thing >>>easy need_contributor
bug in cross val score python from sklearn datasets import make regression from sklearn cross validation import cross val score leaveoneout from sklearn linear model import ridge coef make regression random state 42 noise samples 200 coef true cross val score ridge cv leaveoneout len >>>api bug
according to description of epsilon above default value must be 1>>>documentation
oneclasssvm sparse matrix return different result than dense tried to solve this problem http stackoverflow com 31856501 1030820 and seems it bug not sure but maybe somewhere in svm csr train can somebody confirm this >>>bug
as user want function similar cross val predict which instead returns probabilities intro cross val predict is useful because it returns the predicted targets opposed to cross val score and hides the parallelization logic behind simple interface there should be similar function for predicting the probability distribution predict proba over classes discussion would this be welcomed new feature should this feature be flag for cross val predict probability true should cross val predict then return both the classes and probabilities or only probabilities should this feature be its own function cross val predict proba>>>new_feature
fix deprecation warnings in tests there are way too many warnings in the test suite see https travis ci org scikit learn scikit learn jobs 74122431 function decision function is deprecated decision function was removed from regressors datadimensionalitywarning in random projection not sure if the test should just ignore those or we should have different defaults ping ogrisel default multioutput behavior now corresponds to variance weighted value not sure if there is way around these ping arjoly jnothman the decision function shape default value will change from ovo to ovr in 18 this will change the shape of the decision function returned by svc svc has new decision function shape should either be ignored or the shape should be set to ``ovr`` explicitly for now convergencewarning objective did not converge these are in coordinate decent in the linear models not sure when they started showing up maybe agramfort knows >>>easy enhancement need_contributor
mrg edit the docs to clarify inputs for haversine distance metric the haversine distance metric requires units of radians and this simple pr edits the distancemetric documentation to make this more clear cc jakevdp because he wrote it thanks dude >>>documentation easy
setting search parameters on estimators the underscore notation for specifying grid search parameters is unwieldy because adding layer of indirection in the model `pipeline` wrapping an estimator you want to search parameters on means prefixing all corresponding parameters we should be able to specify parameter searches using the estimator instances the interface proposed by amueller at https github com scikit learn scikit learn issues 4949 issuecomment 127289568 and elsewhere suggests syntax like calling `search params` would presumably set an instance attribute on the estimator to record the search information questions of fine semantics that need to be clarified for this approach include does call to `search params` overwrite all previous settings for that estimator does `clone` maintain the prior `search params` should this affect the search space of specialised cv objects `lassocv` questions of functionality include is `randomizedsearchcv` supported by merely making one of the search spaces `scipy stats` rv making some searches `gridsearchcv` incompatible is there any way to support multiple grids as is currently allowed in `gridsearchcv` have proposed an alternative syntax that still avoids problems with underscore notation and does not have the above issues but is less user friendly than the syntax above here parameters are specified as pair of estimator parameter name but they are constructed directly as grid and passed to `gridsearchcv` `randomizedsearchcv`>>>api
polymorphic clone `sklearn base clone` is defined to reconstruct an object of the argument type with its constructor parameters from `get params deep false recursively cloned there are cases where think the one obvious way to provide an api entails allowing polymorphic overriding of clone behaviour in particular my longstanding implementation https github com jnothman scikit learn tree remember of wrappers for memoized and frozen estimators relies on this and would like to have that library of utilities not depend on change to `sklearn base` so we need to patch the latter let me try to explain let say we want way to freeze model that is cloning it should not flush its fit attributes and calling `fit` again should not affect it syntax like the following seems far and away the clearest it should be obvious that the standard definition of `clone` won make this operate very easily we need to keep more than will be returned by `get params` unless `myestimator dict becomes param of the `freeze model` instance which is pretty hacky alternative syntax could be class decoration `freeze model myestimator or mixin `class myfrozenestimator myestimator frozenmodel pass` such that the first call to `fit` then sets frozen model these are not only uglier but encounter the same problems ideally this sort of estimator wrapper should pass through set get params` of the wrapped estimator without adding underscored prefixes not that this is so pertinent for frozen model but for other applications of similar wrappers it should also delegate all attributes to the wrapped estimator without making mess of `freeze model init this is also not possible imo without redefining `clone` so can we agree that it would not be bad thing to allow polymporphism in cloning on name for the polymorphic clone method `clone` or `clone params` or `sklearn clone` >>>api enhancement
docstring for sgdclassifier and sgdregressor are misaligned some docstring for sgdclassifier some docstring for sgdregressor ll post my pull request here soon >>>documentation
bugs in metrics ranking precision recall curve current code for precision recall curve assumes the curve always passes through recall precision however this is not the case for instance pred proba true value metrics precision recall curve true value pred proba will return precision 33333333 recall index https cloud githubusercontent com assets 1704511 9019531 34e97af6 37a2 11e5 88e4 4cb2b703874d png the result not correct and actually in favor of the poor model the model misclassified points with high score will have more area under the curve be careful when using auc based on metrics ranking precision recall curve before the bug is solved>>>bug
add more extensions and related packages to related projects rst think we should extend this http scikit learn org dev related projects html with at least auto sklearn nolearn https github com rasbt mlxtend https github com yandex rep there are bunch more repos with helper functions that think might be useful but don remember them all >>>documentation easy need_contributor
use type of target in all classifiers to reject regression targets think we should use ``type of target`` ``unique labels`` in all classifiers to reject regression targets also adding common test clearly wdyt arjoly jnothman gaelvaroquaux might be interested >>>enhancement moderate
selectkbest default and parameter name the default parameter of features to select in selectkbest is 10 this is not reasonable default maybe it should be 10 or 50 but 10 leads to it crashing when there are less then 10 features and it rarely seems reasonable also the name is ``k`` usually we don like single letter names maybe it should be ``n selected`` don have good idea really >>>enhancement
master fails with scipy 16 see https travis ci org scikit learn scikit learn jobs 72439348 passing with 15 and https travis ci org scikit learn scikit learn jobs 72957365 failing with 16 looking into it but help would be nice >>>bug build_/_ci
documentation of callable kernel in svm bad the callable kernel in the svm needs to work on arrays of shape `` samples features `` this is not clear from the docs and should be made explicit here http scikit learn org dev modules generated sklearn svm svc html sklearn svm svc also the example here uses lowercase letters for the parameters suggesting vectors http scikit learn org dev auto examples svm plot custom kernel html example svm plot custom kernel py same here http scikit learn org dev modules svm html custom kernels the docs do mention matrices but are not explicit about the shapes again think we should use upper case letters for things that are `` samples features `` and mention the shapes explicitly via http stackoverflow com questions 31599624 user defined svm kernel with scikit learn >>>bug documentation easy need_contributor
kernelpca causes future seemingly unrelated matplotlib plot call to fail simple `kernelpca fit transform call when `n components none` causes later matlotlib `plot to fail raising `valueerror cannot convert float nan to integer` the problem disappears when setting `n components` to say `kernelpca kernel rbf am using sklearn 16 and matplotlib as bundled in winpython 64bit 10 >>>bug
mrg deprecate iter in sgdclassifier and implement max iter solve 5022 in sgdclassifier sgdregressor perceptron passiveagressive deprecate `n iter` default is now `none` if not none it warns and sets `max iter iter` and `tol 0` to have exact previous behavior implement `max iter` and `tol` the stopping criterion in `sgd fast plain sgd is identical to the one in sag new solver for ridge and logisticregression add `self iter after the fit for multiclass classifiers we keep the maximum `n iter over all binary ova fits >>>needs_review
baggingclassifier support for sparse matrices problem estimator fit features sample weight curr sample weight throwing error when using coo matrices typeerror coo matrix object has no attribute getitem >>>bug
pipeline inverse transform works oddly for 1d arrays when 1d array is passed to pipeline `inverse transform` method it wraps it in another array before processing it pipeline py line 306 https github com scikit learn scikit learn blob 0650d5502e01e6b4245ce99729fc8e7a71aacff3 sklearn pipeline py l306 this means an inverse transform on pipeline containing just one element can produce different result than an inverse transform on only that element which confused me greatly when replacing an explicit set of transform calls with pipeline the following script shows the problem using trivial transformer when run it it says transform pipelined results do not match am not well versed in numpy sklearn so maybe there is reason for this wrapping but suspect it bug and even if it not think it should be documented more loudly >>>bug easy need_contributor
what is the standard way to check the type of an estimator in sklearn base there are the functions `is classifier estimator `is regressor estimator they both check `getattr estimator estimator type none the attribute estimator type` is defined for classifiermixin regressormixin clustermixin but not for biclustermixin transformermixin another method that is used very often is `issubclass estimator mixin which is possible for all types of estimators what is the preferred way to check the type of an optimizer >>>question
more intuitive scoring argument for loss and error using the grid search meta estimator with the mean square error the mean absolute error the median absolute error or the log loss as scoring parameters leads to the negation of those metrics this is confusing especially for new users suggest that we prefix those strings by neg or negative this would make clear from the start that the score is obtained from the negation of the loss error >>>api
our rand is duplicated and should not be seeded with `our rand r` is fast and simple random generator defined in `sklearn tree tree pyx` problems the functions only return 0s if seeded with we need to audit the use of this function and make sure it is never seeded with the code is duplicated `sklearn linear model cd fast pyx` and will be in 4738 in 4873 and possibly other pr my first attempt to re use only one code by moving the inline function in tree pxd file has failed every tests passed on linux travis but it broke 45 tests on windows appveyor did not figure out why >>>enhancement moderate
random segfault under windows in sklearn decomposition tests test sparse pca test fit transform this problem can be seen from time to time on appveyor builds >>>bug
mrg initialize arpack eigsh `v0 random state rand shape leads to an initial residual vector in arpack which is all positive however this is not the absolute or squared residual but true difference thus it is better to initialize with `randn` to have an equally distributed sign the effect of the previous initialization is that eigsh frequently does not converge to the correct eigenvalues negative eigenvalues for matrix which leads to an incorrect null space >>>bug
mrg fix logistic regression class weights this pr tests that these two classifiers are equivalent edit this pr also tests that these two classifiers are equivalent fix 5450 that is why we can remove this line https github com scikit learn scikit learn blob master sklearn tests test common py l116 also updated some remaining auto deprecated into balanced added the test from 5420 which tests the bug detailed in 5415 changed the variable names to distinguish `y bin` and `y bin`>>>blocker bug
add table dictionary for good parameter values feel we should add good grids to search over for all estimators both in the docs and as dict think good source would be https github com automl auto sklearn and possibly carret >>>documentation
add fixed width binning for discretization notice this project doesn have any binning methods it be helpful to add at least fixed width binning when preprocessing data >>>new_feature
the shape of threshold returned by precision recall curve in the `sklearn metrics precision recall curve` documentation thresholds array shape thresholds len np unique probas pred but as the example below shows scores np array 35 thresholds array 35 the shape of threshold is not `len np unique probas pred >>>bug
mrg bug fix for unnormalized laplacian so far set diag always set the diagonal of the laplacian to this is only valid for the normalized laplacian for the unnormalized laplacian the diagonal should not be changed >>>bug
huber loss regression in linear models just realized we have huber loss for sgd but we don have nice out of the box solver for huber loss is there any reason for that should we add huberregressor or add loss to ridge linearregression >>>new_feature
build docs and run examples with circleci circleci allows much more power and storage space compared to travis we should use it to build docs and run example we just did it in nilearn massive doc downloads and build times https github com nilearn nilearn pull 679>>>build_/_ci new_feature
issue with sparse matrices in minibatchkmeans possible issue with assign rows csr apologize for not debugging this further but do not and cannot have development environment on my machine in trying to figure out this stackoverflow question http stackoverflow com questions 31337217 scikit learn minibatch kmeans sparse vs dense matrix clustering 31456290 31456290 determined that at least on my our platforms assign rows csr is zeroing the output matrix before copying rows it successfully copies the new rows this code replicates the error am on win7 64 anaconda python with sklearn 15 but so far as can tell the subject function has not been modified since then and numpy output >>>bug
metrics mutual info score hangs when given real vectors accidentally passed two real vectors to this function and it ended up completely hanging my mac requiring several hard reboots until discovered the issue version 16 mac os 10 10 should probably validate the inputs to prevent this >>>bug easy need_contributor
mrg metric precision at score this pull request implement precision at score for multilabel classification >>>needs_review
lda qda user guide not that great feel the user guide on lda and qda could use some attention it doesn really explain the transformation how many dims and feel the mathematical description could be more intuitive >>>documentation easy need_contributor
mrg add grouped option to scaler classes as per discussion in issue 4892 add per feature option to the scaler classes when false defaults to the previous behavior of true this modifies behavior such that scaling is based on consideration of the entire data array at once instead of one feature at time also allow axis none in addition to axis or axis in the standalone scaling functions this pr includes tweaks to functions in the sparsefuncs module where it makes axis none behavior easier to code todo add per feature option to robustscaler add axis none option to `preprocessing data scale` add axis none option to `preprocessing data maxabs scale` add axis none option to `preprocessing data robust scale`>>>needs_review
gridsearchcv should accept factory functions for estimators according to the current documentation http scikit learn org stable modules generated sklearn grid search gridsearchcv html `gridsearchcv` accepts object type that implements the fit and predict methods as the `estimator` parameter while fine for most certain use cases are made quite unintuitive by this api for instance consider the `adaboostclassifier` http scikit learn org stable modules generated sklearn ensemble adaboostclassifier html api essentially this classifier just wraps the boosting around whatever classifier is provided by `base estimator` parameter most of the parameter tuning therefore happens in this `base estimator` rather than the booster itself if were to use grid search for parameter tuning would probably do something among the lines of which is already quite ugly and am only tuning the `max depth` parameter imagine if also wanted to tune some other parameter in `decisiontreeclassifier` class one way to fix this is to make `gridsearchcv` accept factory functions for classifiers and not only the classifiers themselves particularly something among the lines could make things bit easier obviously the contract where the objects returned from the factory function contain `fit` and `predict` methods should remain in place not only does this solve this particular problem it would also allow one to test multiple estimators within the same grid search just add parameter to your factory function >>>bug
thresholding in samme proba` in adaboostclassifier in the subject line function log probability is calculated as follows lines 287 88 proba proba 1e log proba np log proba oftentimes one encounters probabilities significantly smaller than 0e that are still nonzero in the current implementation for example the log prob of 0e will actually evaluate higher than log prob of it seems to me that better implementation of this would be floor like function as follows proba proba 1e 9>>>bug easy
oneclasssvm crash using 16 took the example in http scikit learn org stable auto examples svm plot oneclass html and changed np random randn 100 np random randn 100000 this causes process finished with exit code 1073741819 0xc0000005 on the oneclasssvm fit call>>>bug need_contributor
bug in changed parameter values from l2 to squared hinge for linearsvc the loss parameter for linearsvc used to be l1 or l2 this was recently changed to hinge or squared hinge according to the documentation however supplying those as parameters gives very unhelpful error which believe misidentifies the loss parameter as the penalty parameter since not even touching the latter valueerror unsupported set of arguments penalty l1 is only supported when dual false parameters penalty l2 loss squared hinge dual true if instead change back to loss l2 it appears to work just fine believe this recent stackoverflow question concerns the same issue http stackoverflow com questions 29902190 value error happens when using gridsearchcv >>>bug easy need_contributor
mrg added average option to passive aggressive classifier regressor differently from the sgdclassifier and sgdregressor the passiveaggressiveclassifier and passivieaggressiveregressor does not expose the average option of the basesgd class the average option helps smoothing out the impact of rarely observed variables for example when used in combination with the hashingvectorizer on text it helps to compensate for the lack of idf information lowering the impact low idf rare features the following is an example of using averaging both on sgdclassifier and passiveaggressiveclassifier the data is the bo pang movie review dataset https www cs cornell edu people pabo movie review data review polarity tar gz the results show that averaging in basesgd works perfectly for both classifiers to remove noise features averagedemo https cloud githubusercontent com assets 6543521 8570575 8e7df796 2581 11e5 8fa0 61000a12b73f png the following is the code to replicate the experiment that generated the above plot >>>needs_review
mrg fixes 4577 adds interpolation to pr curve fixes 4577 added boolean parameter interpolated to sklearn metrics precision recall curve returns an interpolated de noised precision score if true>>>needs_review
suggestion on nmf initialization of below is something found troublesome but not exactly bug when setting init random nmf draws initial from standard normal distribution and then take absolute values while the default init nndsvd takes values from results of randomized svd with small manipulations the magnitudes of the initial and from the former random are irrespective of the data entry wise but linear to size of of course whereas the latter nndsvd tends to give initial and whose magnitudes are highly dependent on the data since the termination criterion during fitting is set based on the norms of the initial and this often requires the user to supply very different values of tol when using nndsvd and random to initialize my experience was that using the default tol 0001 and init random while fitting row normalized of size 10000x1000 results in immediate termination since the effective tolerance during the update step in fit is too large accordingly suggest the author add normalization step when init random such that the initial and have norms comparable to that of data or similar to what would result from nndsvd >>>bug need_contributor
nmf documentation mistake on init attribute regarding the init parameter in sklearn decomposition nmf class initialization the documentation says method used to initialize the procedure default nndsvdar if components features otherwise random whereas the source code suggests the default is in fact nndsvd when components features >>>documentation easy need_contributor
doc add anisotropic dataset to cluster comparison maybe it is getting too much but think it would be interesting to add non isotropic gaussian example to the cluster comparison something like anisotropic kmeans fail https cloud githubusercontent com assets 449558 8487972 adfd79a0 20dd 11e5 9034 58645ad6e32b png >>>documentation easy
class specified in class weight is missing in classes error hi all ve been using sklearn svm for bit and ve encountered small edge case in the compute class weight function in sklearn utils class weight py the issue occurs at line 60 here some context basically we are affirming that each key class in the class weight dict actually exists in the classes the issue occurs when class in class weight is greater than all the values in the classes array instead of raising the specified value error you simply get an unhelpful indexerror here is the proposed solution thanks for all you do guys this library is huge help to everyone >>>bug easy
onehotencoder should accept string values how hard would it be to hash incoming string values or use the labelencoder internally be willing to contribute some code for this if there are no outstanding design blockers cc jnothman >>>new_feature
random failure on sklearn linear model tests test ridge test class weight vs sample weight under windows the following seems to happen randomly on appveyor at least under 32 bit python >>>bug
add documentation on class weight and sample weight think these should be documented in the quick start guide http scikit learn org dev tutorial basic tutorial html>>>documentation easy
ransac and residual threshold feature request if the residual threshold argument in ransacregressor is set to zero the regression will almost certainly fail however figuring out what is going on based on the error messages is not obvious believe that when residual threshold one of the cross validation classes is empty and things break because think there is no legitimate reason to set residual threshold and to save some future soul the debugging journey just went through it might be helpful to throw an exception or at least clear warning if residual threshold >>>bug easy need_contributor
perf use joblib parallel backend threading for sparse encode when called with algorithm lasso cd since we released the gil in most of the cython coordinate descent solver 3102 we could now sparse encode in parallel efficiently with threads when using that solver making this change in the code of `sparse encode` should be straightforward and the tests should stay the same but accepting pr for that will require running some benchmarks to check that switching to the threading backend improves memory usage reduces scheduling overhead and therefore should slightly improve overall sparse encoding speed note using threading for the lars solver might not be efficiently parallelizable with threads the lars solver is primarily written in python numpy although we should check as numpy releases the gil often >>>enhancement
pickle tfidfvectorizer with given set of features dear all would like to inform scikit learn community about my experience in pickling vectorizer and classifier each time read pickled vectorizer and pickled classifier which are tfidfvectorizer and multinomial naive bayes objects was getting different result for test document after two days of analysis discovered that assigning set object to the vocabulary parameter of the tfidfvectorizer object makes the features to get random order and let the classifier generate random estimations after convert my set of features to list everything become normal you may want to take that into consideration in the documentation or code improvements thanks for the great effort you spend for that great project ali>>>bug easy
mrg cca stability this pull request should address 4888 on windows machine with 64bit python the unit tests for cca would fail because of the presence of nan this issue was traced to the function nipals twoblocks inner loop` conceptually the function takes in data matrix and multivariate response and tries to find lower dimensional representation of both one component at time however if earlier components can reconstruct the data well later components may have their weights shrunk to quantities below machine precision in the case of the unit test the values are 5e 16 which can be represented on ubuntu machines but not windows machines where they would be rounded to practically this caused an issue because on line 47 and 60 of pls py the weights are normalized by dividing by some function of themselves instead of explicitly raising an error numpy would fill in nan in those positions which would cause math issues for the remainder of the function but return successfully it also wouldn be caught in lines 300 302 because the numbers were not small they were nan it isn until line 336 338 where the pseudoinverse is calculated that the array is checked to make sure no nan elements are present and since they exist the error above is raised this pr fixes the issue by adding an epsilon close to machine precision to the weights before they are divided so that there is never divide by zero issue unit tests run successfully on both ubuntu and windows 64bit machines >>>bug
sklearn preprocessing minmaxscaler not preserving symmetry add axis none minmaxscaler does not preserve symmetry scikit learn 15 and scikit learn 16 windows sp 64 bit python 32 bit an affected numpy matrix and the script to reproduce the problem are available at https www dropbox com vkcuq71wa69jrw7 sklearn bug tar dl >>>documentation easy
test failure in sklearn tests test common test transformer iter cloned sklearn v0 17 dev0 built it on windows for 64bit python and ran the nosetests get one error in sklearn tests test common test transformer iter am using numpy v1 and scipy v0 15 running `c anaconda python import nose nose main sklearn tests test common test transformer iter` yields the following logs will begin looking deeper into this issue >>>bug
improve featurehasher compatibility with dictvectorizer `featurehasher` does not currently support string values for its dict input format see 4878 ideally its input format should be compatible with `dictvectorizer` one hot encoding any string valued items >>>easy need_contributor
improve `featurehasher` documentation an example should be added to `featurehasher` docstring there should also be some description of input that specifies dict values must be finite numeric >>>documentation easy
logisticregressioncv best model with l1 penalty and refit true is not sparse when `logisticregressioncv` is run with an l1 penalty and `refit true` the final model does not seem to be doing any variable selection the final coefficients are all non zero models fit separately using `logisticregression` on the same values of in the grid passed to `logisticregressioncv` result in mostly zero coefficients >>>bug
randomforestclassifier changes label values consider the following example the output is whereas expect it to be traced the cause of the error to here https github com scikit learn scikit learn blob 733629d256abaf9a31d6e6305f859768432907ed sklearn ensemble forest py l418 happy to put in pull request but can others please verify they get the same unexpected behaviour first system information `` cpython ipython numpy scipy 14 scikit learn 16 conda compiler gcc apple inc build 5577 system darwin release 13 machine x86 64 processor i386 cpu cores interpreter 64bit>>>bug
mrg misc add alternate compact logo for ads merchandise this is more compact form for the logo that feel is better suited for print mugs signs etc>>>needs_review
add contingency matrix to reference and user guide fix 4805>>>documentation easy
wip sparse pca online in the direction of samples following 4856 implemented dictionary learning algorithm that output dense code and sparse dictionary which corresponds to the description of spca given in it alternated between ridge regression for learning code for batch of samples and projected block coordinate descent on the elastic net ball for each features pixel in faces example we project the `n component` vector that contains all dictionary component value for this feature which explicitly enforce dictionary components to be non overlapping this differ from where projection occurs in the feature space and not the component space for the moment there is no unit tests but output of the method can be seen running `example decomposition lot decomposition faces` as we use large outer loop of `n feature` iterations and an inner loop for elastic net projection wrote cython extension for speed consideration does this method seem to have an interest for the project mairal bach ponce sapiro 2010 online learning for matrix factorization and sparse coding the journal of machine learning research 11 19 60 >>>api
has fit parameter will not work with kwargs bagging and boosting use `sklearn utils validation has fit parameter` to produce clear error when `sample weight is not none` and the base estimator does not support `sample weight` however the method of checking the argspec will not work if `sample weight` is supported as kwargs` in `fit` thus raising an exception when none applies similar concern exists for the proposed alternative to `sample weight` as keyword arg 4696 >>>bug
document and adapt isclose usage `sklearn metrics` introduces `isclose in https github com scikit learn scikit learn blob master sklearn metrics ranking py which can leave the unaware data practitioner with hours of debugging in very unbalanced classification probabilities scores can be very small and yet meaningful this however will cause unexpected missing precision recall points due to `isclose` treating values within 10e as equal suggest to place warning about `isclose` in the documentation and also replace the absolute epsilon by relative closeness comparison in order to avoid the problems with small probabilities in unbalanced classification >>>documentation
sparsepca is online in the direction of features presentlyu sparsepca used `dict learning` or `dict learning online` on `x t` and sets its `components to be the outputted code of these functions which is sparse though it is simple way to reuse code from `dict learning py` it has for drawback that it does not allow the user to learn in the sample direction which prevents the use of `partial fit` and is not adapted in setting where data is streamed solution for this would be to use another formulation for sparse pca found in which enforces an elastic net constraint for and thus implies projecting on the elastic net ball instead of the l2 ball as it is done today efficient projection algorithms exists as described in mairal bach ponce sapiro 2010 online learning for matrix factorization and sparse coding the journal of machine learning research 11 19 60 rodola torsello harada kuniyoshi cremers 2013 december elastic net constraints for shape matching in computer vision iccv 2013 ieee international conference on pp 1169 1176 ieee >>>new_feature
mrg multioutput bagging this pull request brings multi output support 3449 to the bagging meta estimators it different of https github com scikit learn scikit learn issues 3449 since the implementation to make the averaging is shared for single output and multi output data haven implemented multi output decision function as no base estimator currently support this >>>needs_review
ridgeclassifier triggers data copy ridgeclassifier always triggers data copy even when not using sample weights regression introduced in 4838 see https github com scikit learn scikit learn pull 4838 discussion r32090535>>>bug
added error messages in case user provides one dimensional data when trying to learn gmm on one dimensional data both weights and the data can be represented as vectors however this breaks gmm fit and it used to die with cryptic error messages this addition specifically checks for one dimensional input and issues an error message accordingly >>>bug
mrg add knn strategy for imputation trying to solve 2989 imputation strategy is following find all rows with full features as complete set and impute the missing features in row by taking the mean of those features among its nearest neighbors in complete set use scikit learn neighbors nearestneighbors to find neighbors now it can only handle dense matrix based on this paper http web stanford edu hastie papers missing pdf similar package for impute http www bioconductor org packages release bioc manuals impute man impute pdf similar function for matlab knnimpute http www mathworks com help bioinfo ref knnimpute html still working on documentation and examples >>>needs_review
doc code block does not render in python colors in http scikit learn org stable developers index html in deprecation section first code block does not render in python colors >>>documentation easy
rfc api objects for out of core fitting partial fit pipelines gaelvaroquaux and me recently discussed better support for out of core processing this issue is to collect comments and summarize discussions to me the two core issues are representing streamed datasets and out of core pipelines out of core pipelines should not be that hard if we only support stateless transformers this was discussed previously though don remember where it would also be possible with transformers implementing ``partial fit`` by going over the dataset multiple times that is not possible in streaming infinite dataset setting but would work for reading from disk for representing streamed datasets think gaelvaroquaux proposed conductor object that handles the stream and passes it to the estimator another approach he mentioned is creating transformer that reads files form disk that would work if the data is already in batches on disk by transforming file names to samples if we can change the number of samples that might even work with single file it would be cool to read csvs in chunks with pandas not sure we should prototype this in scikit learn but think we should at least discuss it here some libraries that work on similar concepts are rosetta http pythonhosted org rosetta examples fuel https github com mila udem fuel and pescador https github com bmcfee pescador>>>api
implementing stacking and other ensemble techniques don find open issue for this just wondering what the plan to implement them in sklearn is there roadmap some of the techniques are listed in wiki http en wikipedia org wiki ensemble learning>>>new_feature
rfc change default gamma in svc to none think we should change the default gamma in svc to none instead of will be replaced by data dependent default which is features this seems very non idiomatic usually we use ``none`` for this parameter is not provided we can just change the default value and deprecate setting it but doubt that many people will even see the deprecation warning it would mean they explicitly passed the default parameter >>>easy need_contributor
cross validation cross val score type error hi when use cross validation cross val score with parameter jobs 10 came across typeerror below process poolworker traceback most recent call last file usr lib64 python2 multiprocessing process py line 232 in bootstrap self run file usr lib64 python2 multiprocessing process py line 88 in run self target self args self kwargs file usr lib64 python2 multiprocessing pool py line 57 in worker task get file usr lib64 python2 site packages sklearn externals joblib pool py line 363 in get return recv typeerror type partial takes at least one argument process poolworker >>>bug
mrg read only input data in common tests following pr 4775 added checks in estimator checks in order to verify `estimator` behavior on read only mem mapped data few issues there registering clean temp memory with atexit yield failure as it called at the end of every test and delete temp memory whereas the next test has already begun overloaded make blobs into make blobs in order to be able to easily yield read only memmap which is only positive this looks quite messy though cf pr 4775 this does not introduce tests that fails on current master whereas `sklearn linear model cd fast pyx` still raise errors on some use cases this is related to the fact that we cannot make lasso fails using simple read only memmap as input >>>needs_review
polynomialfeatures not documented in the user guide>>>documentation easy need_contributor
contingency matrix missing from references and user guide metrics cluster contingency matrix is public and should therefore be in the references and the user guide or be made private >>>documentation easy
brier loss has no real explanation in the narrative docs it is mentioned in the calibration docs but not in the metrics docs and it is not really explained >>>documentation easy
multitaskelasticnet and multitaskelasticnetcv not mentioned in narrative >>>documentation easy need_contributor
eigenvalue in kernel pca if follow strictly the formulation of kpca as in schoelkopf et al 1999 the eigenvalues of kernel matrix should be scaled by the number of examples first then we can normalize the eigenvectors by sqrt lambda think by this way you get the interpretation and relations to the non linear feature space do you think this is problem >>>question
nearest neighbor query fails on array of dimension examples on scikit learn 16 import numpy as np from sklearn neighbors import nearestneighbors kdtree np array nbrs nearestneighbors neighbors algorithm kd tree fit nbrs kneighbors traceback most recent call last file line in file usr lib python2 site packages sklearn neighbors base py line 327 in kneighbors check array accept sparse csr file usr lib python2 site packages sklearn utils validation py line 350 in check array array ndim valueerror found array with dim expected tree kdtree tree query traceback most recent call last file line in file binary tree pxi line 1287 in sklearn neighbors kd tree binarytree query sklearn neighbors kd tree 10407 file usr lib python2 site packages sklearn utils validation py line 350 in check array array ndim valueerror found array with dim expected docstrings still say array like last dimension same as that of fit data don say that must be 2d with scikit learn 15 the same code works just fine on the other hand don know maybe this is documentation bug at least now this error is consistent and does not depend on algorithm while on 15 algorithm brute failed with less clear message nbrs nearestneighbors neighbors algorithm brute fit nbrs kneighbors traceback most recent call last file line in file usr lib python2 site packages sklearn neighbors base py line 312 in kneighbors squared true file usr lib python2 site packages sklearn metrics pairwise py line 1073 in pairwise distances return func kwds file usr lib python2 site packages sklearn metrics pairwise py line 212 in euclidean distances xx row norms squared true np newaxis file usr lib python2 site packages sklearn utils extmath py line 65 in row norms norms np einsum ij ij valueerror operand has more dimensions than subscripts given in einstein sum but no ellipsis provided to broadcast the extra dimensions >>>bug easy need_contributor
svm can be tricked into running proba it is possible to make `svm svc` run `svm predict probability without having been trained with `probability true` example interestingly the probabilities do seem to correspond to reasonable predictions but every class has fixed set of probability values saw this when writing my own code against libsvm too don know what to make of it probably an upstream bug libsvm provides svm check probability model precisely to catch this case https github com kousu statasvm blob 813b743aaa36d26f38ce53a9ef11a717caf4b4ad src svm l530 it seems you aren https github com scikit learn scikit learn search utf8 e2 9c 93 svm check probability model but you could >>>easy
wip metric learning nca gsoc 2015 project iteration neighborhood component analysis for details refer to my gsoc blog especially post on nca http barmaley exe blogspot ru 2015 05 nca html >>>needs_review
change graph lasso to exploit block diagonal structure took stab at implementing the optimization described here http faculty washington edu dwitten papers jcgs 2011 pdf the block diagonal structure of the graphical lasso solution can be identified by thresholding the sample covariance and the exact solution is found by solving the graphical lasso for each block separately the authors find that there is huge speedup when the solution is very sparse when the solution is mostly dense the results are basically the same or very slightly slower due to the extra thresholding step this modification was made in the `glasso` package some time ago timing results are given in the paper above but also ran test of my implementation with 1000 100 and block diagonal population covariance matrix couple of questions the `glasso` package was changed to only use this algorithm so followed the same convention and did not allow the user to choose whether to perform the block diagonal screening procedure it would be very easy to add this just not sure if there case where it would ever be desired there bug in our connected components function that was fixed while ago in scipy https github com scipy scipy pull 3819 included this in my commit but maybe it should be separate pull request does the overall logic make sense here only added couple of comments but if it not clear what going on then can try to clarify >>>enhancement
mrg fix rfe rfecv estimator tags pretty bad regression from introducing `` estimator tags`` forgot to define them for rfe which made accuracies on iris be using default cross validation ouch >>>bug
dbscan buffer has wrong number of dimensions expected got running this code that produces this error when running with gamma 0001 when gamma is 10 it runs without problem with gamma 10 it only requires about 40gb of ram when gamma is 0001 124gb ram seem insufficient >>>bug
svd and eigen shouldn yield such different results for ridgecv import numpy as np from sklearn linear model import ridgecv from sklearn datasets import load boston from sklearn preprocessing import scale boston scale load boston data target load boston target alphas np linspace 200 fit0 ridgecv alphas alphas store cv values true gcv mode eigen fit boston target fit0 alpha 0816326530612246 fit0 cv values array 37 65055379 38 25669302 38 99731156 39 51049034 39 85507581 fit1 ridgecv alphas alphas store cv values true gcv mode svd fit boston target fit1 alpha fit1 cv values array nan 38 25669302 38 99731156 39 51049034 39 85507581 the problem here appears to be that `gcv mode svd produces `nan` for `alpha 0` the ridge regression docs http scikit learn org stable modules linear model html ridge regression suggests as valid value of alpha of course corresponding to the unregularized regression seems like solution would be either change computation of cv values under svd to produce value warn or change user docs to discourage using alpha under this case >>>bug
dictionary learning is slower with jobs setting jobs in minibatchdictionarylearning and in function dictionary learning online leads to worse performance multi processing is handled in sklearn decompositions function dict learning 249 minimal example https gist github com arthurmensch 091d16c135f4a3ba5580 output jobs output jobs output jobs we can see that transform function of minibatchdictionarylearning relying on sparse encode function benefits from multi processing as expected dictionary learning relies on successive calls of sparse encode function slowness may come from this >>>bug
prediction interval for random forests hi there is there any plan to add prediction interval range prediction to the randomforecastregressor library think that will be super useful and necessary addition thanks chen>>>enhancement moderate
extend stratifiedkfold to float for regression it is important to stratify the samples according to for cross validation in regression models otherwise you might possibly get totally different ranges of in training and validation sets however current `stratifiedkfold` doesn allow float in case may miss something is there any reason why `stratifiedkfold` does not work properly for float >>>new_feature
it is not possible to set the regularization parameter hi was using the locallylinearembbeding implementation from this package and found bug regarding to the regularization parameter basically setting different regularization values leads to the same embedding which is not correct the code below reproduce the issue in the class locallylinearembedding scikit learn scikit learn blob master sklearn manifold locally linear py method fit transform the reg parameter is not set with the value defined in the constructor self reg import sklearn manifold import numpy numpy random rand 10 import sklearn manifold import numpy numpy random rand 10 setting different regularizers reg 1e reg 1e training one manifold lle sklearn manifold locallylinearembedding neighbors components eigen solver dense neighbors algorithm brute reg reg lle fit training another manifold lle sklearn manifold locallylinearembedding neighbors components eigen solver dense neighbors algorithm brute reg reg lle fit print lle embedding lle embedding >>>bug easy
ridgecv ignores sample weights if cv none there is fixme in ridgecv to also slice sample weights currently they are silently ignored if ``cv none`` since then we fixed gridsearchcv so this is really easy change >>>bug easy
nearest neighbor chaining for ward someone just complained to me that we should do neighbor chaining in ward and we are not https en wikipedia org wiki nearest neighbor chain algorithm have not really looked it up and not very familiar with our implementation >>>enhancement
mrg fix jobs slicing bug in dict learning also add input validation to gen even slices fixes 4746 >>>bug
mrg use the new container based travis workers this is an attempt to make it possible for the scikit learn project to use the new container based travis workers those workers run on ec2 and should be provisioned elastically meaning that queue time should be reduced more details here http blog travis ci com 2015 03 31 docker default on the way >>>build_/_ci
dictionary learning is slower and fail with jobs dict learning online fails with jobs bug can be reproduced using denoising examples available in the doc https gist github com arthurmensch d85f9efb3716fe090937 observed images are not correct and dictionary learning take much longer time incriminated code can be located in function sparse encode in sklearn decomposition dict learning line 248 >>>bug
bug with using treeclassifier with oob score and sparse matrices when using the extratreesclassifier and likely other classes that are derived from basetreeclassifier there is problem when using sparsematrices `valueerror should be in csr matrix format got tracked the issue down to the following lines on line 195 of forest py the sparse matrix is changed to csc matrix `x check array dtype dtype accept sparse csc however on line 369 of forest py the following is call is made with `check input false` `p estimator estimator predict proba mask indices check input false this leads to valueerror in predict `valueerror should be in csr matrix format got changing check input to true seems to fix the issue it probably best to also include test case for this problem just made quick pr with only the false true fix >>>bug need_contributor
simplify installation instructions by referring to anaconda our current installation instructions are really complicated and feel they don need to be there are basically two kinds of users they use numpy scipy pandas and want sklearn they are new to the scipy ecosystem to we can just tell ``pip install scikit learn`` while to would suggest to install anaconda the installation page even talks about how to build the windows installer exe that should really be in the dev docs think compiling yourself should be left to expert users and they can look into the dev docs if they really want >>>documentation
ransacregressor residual metric has weird docstring not sure if this is docstring or an api issue the ransac estimator has ``residual metric`` which has the docstring however this is also called for ndim and computes the absolute value there it depends bit on what the intention here is do we want to define the loss function or how multi dimensional behave or both had to work around the current interface in 4739 bit >>>documentation
sphinx breaks api docs something changed in autodoc and many of the sections in the api overview are not populated haven investigated further >>>bug documentation
feature request weighted least squares sklearn currently supports ordinary least squares ols would it be possible to support weighted least squares wls from my perspective this seems like pretty desirable bit of functionality details on the problem can be found on wikipedia here http en wikipedia org wiki least squares weighted least squares thank you bill >>>new_feature
doctests download datasets as mentioned in 4711 the doctests seem to download some datasets as they are not using the fixtures >>>bug need_contributor
heisenfailure in dummy code travis failed on dummy tests https travis ci org scikit learn scikit learn jobs 62616416 saw this only once so far weird maybe arjoly knows >>>bug
no list of multi label algorithms the multi class page lists inherently multi class algorithms but not estimators that support multi label support think currently we have at least trees forests and neighbors based algorithms that support multi label any others http scikit learn org dev modules multiclass html>>>documentation easy need_contributor
mrg website adding backlinks to docstrings we discussed previously that doclinks from the api back to the user guide would be helpful and have heard many people wishing for these don think there is another pr for that though the main questions are manual or automatics just on the website or also in the docstring happy to do this manually if we can agree on how to do it doing it directly in the docstring is substantially easier than using sphinx and or js to insert them into the page later the downside is that the the printed docstring looks bit ugly would argue that people mostly look at the docs on the website and that it isn that bad looking good backlinks4 https cloud githubusercontent com assets 449558 7639350 2e1c8d58 fa49 11e4 8226 2a91ad106bcf png not that bad backlinks1 https cloud githubusercontent com assets 449558 7639306 e0b7da68 fa48 11e4 801d 62a5d2e86686 png backlinks2 https cloud githubusercontent com assets 449558 7639307 e0bada38 fa48 11e4 9655 1eefd6d9e39e png the placement directly after the one line summary is slightly violating pep 0257 https www python org dev peps pep 0257 one line docstrings but makes for nice rendering on the website wdyt >>>documentation
gradientboostingclassifier np nan to num np exp pred indexerror too many indices for array scikit learn 16 or 17dev numpy 80 or scipy 14 and get these iter train loss remaining time traceback most recent call last file media internal4tb steven research lre ivector 2015 utils bugtest py line 16 in clf fit datax datay file usr local lib python2 dist packages sklearn ensemble gradient boosting py line 980 in fit begin at stage monitor file usr local lib python2 dist packages sklearn ensemble gradient boosting py line 1040 in fit stages random state file usr local lib python2 dist packages sklearn ensemble gradient boosting py line 747 in fit stage sample weight sample weight file usr local lib python2 dist packages sklearn ensemble gradient boosting py line 550 in negative gradient return np nan to num np exp pred indexerror too many indices for array similar to 2233 2691 not only the same error for rf and svc >>>bug
error gradient boosting py igbrt typeerror fit takes exactly arguments given class baselearner object def init self est self est est def fit self self est fit def predict self return self est predict proba np newaxis print begin train igbrt careful tuning is required to obtained good results rf base randomforestclassifier estimators 100 jobs verbose base estimator baselearner rf base igbrt gradientboostingclassifier loss deviance estimators 100 init base estimator learning rate 025 subsample max depth min samples leaf verbose igbrt fit train train print end train igbrt error file python27 lib site packages sklearn ensemble gradient boosting py line 960 in fit self init fit sample weight typeerror fit takes exactly arguments given >>>documentation easy
omp travis error new heisenfailure in omp https travis ci org scikit learn scikit learn jobs 62182759 saw it couple of times now haven investigated yet >>>bug
minor cosmetic changes to follow the work of mairal 2009 in the paper from mairal et al referenced in the script the set of possible dictionary vectors is not the ball but the convex set of dictionaries whose norm is inferior or equal to one this is simply implemented in the normalization step in the function updating the script corresponding changes in the documentation >>>enhancement
em algorithm in gmm fails for one dimensional datasets using 16 but fine with 15 fitting one dimensional gaussian distribution using gmm fit produces runtime error using scikit learn version 16 but produces appropriate parameters using 15 short example to demonstrate the problem running this example code with scikit learn 15 produces correct output however exactly the same code using scikit learn 16 gives this traceback ve tried various different values of the init iter and covariance type parameters ve also tried range of different datasets all of these result in this error or similar using 16 but there are no issues at all using 15 the problem seems to be related to the initial parameters used in the expectation maximisation so it possible that this is related to this issue 4429 in case this is useful info was using an anaconda virtual environment with clean install of scikit learn set up as follows for version 16 >>>bug
test 20news fails in master branch work on debian gnu linux wheezy the test `test 20news` fails on my three conda environnements python scipy 15 numpy python scipy 15 numpy python scipy 11 numpy >>>bug
sparse ridge regression with intercept is incorrect ridge regression with `fit intercept true` does not give the same result if is dense or sparse the call to center data` in baseridge fit` should probably be call to `sparse center data` test example returns while with `alpha 0` >>>bug
mrg make cross val predict work on lists also test compatibility with various input types and that they are passed through fixes 4700 >>>bug
mrg randomactivation tasks add doc in code add more weight initialization methods add another example this is meant to be the first stage of the pipeline for the random neural network algorithm it fits on the input data by considering the number of features and then randomly generates an `n features activated` coefficient matrix where `n activated` is the number of the hidden layer features defined by the user the coefficient matrix can be used to transform the input data to different space http homepage tudelft nl a9p19 papers icpr 92 random pdf>>>needs_review
python crashed when computing silhouette score silhouette samples of kmeans on large amounts of data firstly show the code km joblib load filename cluster labels km predict silhouette avg silhouette score cluster labels compute the silhouette scores for each sample sample silhouette values silhouette samples cluster labels km is the model that trained using training data see details km kmeans clusters num init means max iter 300 init verbose false km fit when the amount of less than 30 thousands rows both of silhouette score and silhouette samples are ok and can get expected results but when the amount of more than 100 thousands the program crashed and get segmentation fault core dumped see the detail error information traceback most recent call last file test19 statistic silhouette score py line 87 in out file test19 statistic silhouette score py line 63 in out sample silhouette values silhouette samples cluster labels file home supermicro local lib python2 site packages sklearn metrics cluster unsupervised py line 153 in silhouette samples distances pairwise distances metric metric kwds file home supermicro local lib python2 site packages sklearn metrics pairwise py line 1112 in pairwise distances return parallel pairwise func jobs kwds file home supermicro local lib python2 site packages sklearn metrics pairwise py line 962 in parallel pairwise return func kwds file home supermicro local lib python2 site packages sklearn metrics pairwise py line 207 in euclidean distances distances safe sparse dot dense output true file home supermicro local lib python2 site packages sklearn utils extmath py line 178 in safe sparse dot ret file usr lib python2 dist packages scipy sparse base py line 303 in mul return self mul sparse matrix other file usr lib python2 dist packages scipy sparse compressed py line 528 in mul sparse matrix return self class data indices indptr shape file usr lib python2 dist packages scipy sparse compressed py line 84 in init self check format full check false file usr lib python2 dist packages scipy sparse compressed py line 144 in check format raise valueerror last value of index pointer should be less than valueerror last value of index pointer should be less than the size of index and data arrays error in `python munmap chunk invalid pointer 0x00007f9249d68010 aborted core dumped >>>bug
cross val predict attributeerror with lists when calling the cross val predict with an parameter that is list type an attributeerror is raised on line 1209 this is because it is checking for the shape of the parameter but list does not have the shape attribute the documentation says that this function supports lists so am supposing that it isn intended behavior commenting out that line also makes the rest of the function work perfectly fine also not that the cross val score function that takes the same arguments works fine can provide the dataset used if necessary >>>bug
docstring of sklearn utils random sample without replacement the docstring of `sklearn utils random sample without replacement` currently reads at least the list of methods should be updated but it would also be nice to explain more clearly what the subset of selected integer is not randomized is supposed to mean >>>documentation easy
making dictionary learning closer to the sparsenet algorithm the dictionary learning algorithm was assuming that the norm of the filters was equal to one by using heuristic to control for the norm of the filters we allow for more equilibrated learning the implementation is simplification of the one used in the original paper from olshausen the dictionary learning is tested in http blog invibe net posts 2015 05 05 reproducing olshausens classical sparsenet html and this pr is tested in http blog invibe net posts 2015 05 06 reproducing olshausens classical sparsenet part html >>>needs_review
nested models and friendly errors pretty often see people using nested models wrong http stackoverflow com 16437022 http stackoverflow com 12632992 http stackoverflow com 28178763 ve just thought can we throw more helpful exceptions one way is to catch `valueerror`s inside of grid search methods and rethrow them with message like are you trying to search over parameters of nested model if so please refer to the documentation on original exception or we can define custom getter for `pipeline` `onevsrestclassfier` etc that will throw an exception with that message also right now there no clear paragraph about so to say double underscore notation yes it is mentioned on docs for pipeline featureunion etc but feel like this notation is more than just that double underscore is standard sklearn convention for dealing with nested models and think it should be emphasized so we refer people to that place though don know where to put it >>>documentation easy
gradient of mixture of gaussians gmm and possibly list of modes hi would be nice to have not only the probability associated to certain point in the gmm as returned by `score but also similar function `gradient that returns the gradient is that possible having list of the modes http en wikipedia org wiki mode 28statistics 29 would also be great this article mode finding for mixtures of gaussian distributions http ieeexplore ieee org xpl articledetails jsp reload true tp arnumber 888716 provides some information on both the gradient and the modes >>>new_feature
doc svc fit status using 16 and trying to understand the svc fit status logic when it correctly fitted it is gives >>>documentation easy
revisit dtype numeric introduced ``check array dtype numeric `` to handle ``dtype object`` gracefully in 4057 in 4645 tomdlt added much more fine grained control over dtypes we should revisit if the `` numeric `` ever adds anything or if we want to always be more explicit about whether we want integers or floats >>>api enhancement
mrg fix for lassolarscv on with readonly folds fix 4597>>>bug
mincovdet gives different results compared to matlab libra am comparing scikit mcd to matlab libra https wis kuleuven be stat robust libra revision from 01 08 2007 and getting different results matlab results 9839 1287 1287 9619 python results 6928877 12337967 12337967 92182858 matlab code 53356657 49146826 53464831 77884215 179271 54235304 82244695 1602308 80207316 46638638 98169198 72384052 84574713 15995118 12067491 30272032 63592934 53520174 36629677 66372903 11739395 04946755 79636059 83721967 53642667 13695351 06039201 39190745 68697525 29121661 12986671 64405471 97052261 65406501 2143484 88733004 80609268 40985212 95484672 31931632 33245641 75440015 29094285 09554176 77083199 21533913 37560369 15368846 77095853 36153146 mcd mcdcov mcd cov python code import numpy as np from sklearn covariance import mincovdet np asarray 53356657 49146826 53464831 77884215 179271 54235304 82244695 1602308 80207316 46638638 98169198 72384052 84574713 15995118 12067491 30272032 63592934 53520174 36629677 66372903 11739395 04946755 79636059 83721967 53642667 13695351 06039201 39190745 68697525 29121661 12986671 64405471 97052261 65406501 2143484 88733004 80609268 40985212 95484672 31931632 33245641 75440015 29094285 09554176 77083199 21533913 37560369 15368846 77095853 36153146 mcd mincovdet support fraction 75 fit print mcd covariance >>>bug
function value not needed in newton cg `newton cg` requires the function value to compute the step size line search but not to compute the descent direction on line 105 https github com scikit learn scikit learn blob master sklearn utils optimize py l105 `fval` is computed but never used this means that we could just pass `grad hess` function instead of `func grad hess` the overhead of computing the objective value when we already computed the gradient is not big but this is an opportunity to simplify the interface little >>>enhancement
linearmodelcv objects compute mse for cross validation but score gives r2 related to 1831 and bit to 4667 feel it is odd that the cv objects use different scoring function than the one used for model selection >>>bug
ridgecv should provide best score think the best score should be easily accessible in ``best score `` attribute that should be done for all cv objects imho >>>easy enhancement
ridge regression docs say alpha the ridge regression docs say ``alpha c`` in several places iirc that is not true and it should be ``alpha samples c`` see 759 or save yourself the pain and confirm it yourself can someone confirm >>>bug documentation
invalid or missing encoding declaration for sklearn tree tree pyd is thrown when invalid parameter is specified for gridsearchcv specifying invalid parameter for `gridsearchcv` leads to throwing exception `invalid or missing encoding declaration for anaconda3 lib site packages sklearn tree tree pyd was able to reproduce it using here `none` is not valid for `min samples leaf` as the later requires integer however it would be preferred to indicate that passed parameter is invalid or not supported after replacing `none` by `1` was able to start search am using python anaconda 64 bit default mar 2015 12 06 10 msc 1600 64 bit amd64 on win32 >>>bug
doc add testimonial by infonea>>>documentation
check estimator requires raising notfittederror currently the ``check estimator`` function requires that users raise notfittederror which is only possible if they inherit from use the sklearn error this breaks the paradigm of users not requiring inheritance for compatibility possible solution would be to check for the parent of ``notfittederror`` ``valueerror`` and the message >>>easy
establish global error state like np seterr as discussed in 4497 having global error warning level in sklearn seems like good idea possible things that we want to control deprecations numerical instability convergence shape casts type conversions unused sample props as in 4497 unscaled features in estimators that want scaled features changedbehaviorwarning>>>api enhancement
wip sphinx gallery use this is proposal to incorporate sphinx gallery into scikit learn there are still some issues to work on so for know one works with the github pr of sphinx gallery https github com sphinx gallery sphinx gallery pull 26 as the main development version to work on backreferences the documented api gives at the end of every module small gallery of the examples using that module examples are properly identified but the html output fails recognizing the correct path of the image and the html file in scikit learn gen rst py this paths are hard coded to its website structure sphinxgallery uses configuration dictionary this issue is mostly solved with https github com sphinx gallery sphinx gallery pull 26 the sidebar hide behavior it just messes up with the scikit learn design and it is manually deactivated in the gallery implementation with the promise to fix it later https github com scikit learn scikit learn blob master doc sphinxext gen rst py l494 508 the carousel there is an additional image processing step for some images displayed in the carousel done in gen rst py that sphinx gallery does not perform image naming all images generated by sphinx gallery have sphx glr prefix if images of the gallery are manually called by the documentation this would be broken more stuff not aware of maybe as in nilearn put local copy of sphinx gallery inside scikit learn >>>needs_review
more feature selection metric needed couldn find bns metric when need it to do feature selection will it or any other metrics be supported in the near future >>>new_feature
mrg fix pass percentiles to partial dependence in plotting fixes 4625 ping pprett don know how to unit test for this and not sure it is worth the hassle >>>bug
commont tests check fit returns self should be tested in test non meta estimators >>>easy
rfc use explicit module levels skip lists for estimator checks amueller recently 4550 refactored the `test common` `estimators checks` plumbing to provide single `check estimator` utility method to 3rd party developers who want to automate the compatibility checks of their own estimators with scikit learn standards to be pragmatic some checks have to be skipped for some specific estimators at the moment this is done with the following idiom in the body of the checks them selves instead of hardcoding the list of the names of the estimators to skip in the body of the check functions think it would be cleaner to extract those as module levels constants such as and then in the body of the function furthermore we should probably use the fully qualified names or type objects in the list to make it easier for 3rd party developers to register there in classes in the skip list of specific check without risking class name conflicts with classes from scikit learn wdyt >>>enhancement
svc with kernel poly hangs when using small and large values hello am not sure if it is mathematical or implementation problem but it definitely annoying and user should be at least warned when try this code from sklearn svm import svc clf svc kernel poly degree 99999 99999 clf fit process then takes forever can see that it taking full cpu so guess it does not hang but have never got the result even on pretty good pc `scikit learn 16 and `python 3` what is interesting got results immediately for from sklearn svm import svc clf svc kernel poly degree 9999 9999 clf fit method is hence relatively unstable is this somehow solvable or are there some ways by which can predict if it solvable by poly kernel or not in it working ok and got the results for much larger and much complicated larger dimensions and larger dissimilarities datasets by this code not minimal example just for illustration svmfit svm yy xx kernel polynomial degree type classification thank you>>>easy enhancement
oneclasssvm tests hang on both of my boxes the common tests on the oneclasssvm sometimes run indefinitely have not found any way to reproduce that but it happened couple of times now does anyone else observe this >>>bug build_/_ci
broken example for multilabel classification example with cca the multilabel classification example seems to be broken with cca http scikit learn org 14 auto examples plot multilabel html http scikit learn org stable auto examples plot multilabel html http scikit learn org dev auto examples plot multilabel html >>>bug documentation
valueerror in dbscan inner in case of precomputed metric in case metric is precomputed neighborhoods array can be dimensional array which causes >>>bug
documentation of label binarizer and multi label format from the docs feel it is not entirely clear that using label indicators means doing multi label classification think this should be better documented in the multi class narratives the onevsrestclassifier and the labelbinarizer applying label binarizer to your will result in quite different results which is obvious if you know that this will switch the problem to multi label problem but is somewhat unintuitive for the uninitiated >>>documentation easy need_contributor
svc decision function shape svc has decision function of non standard shape we should fix that by aggregating all the decision values that belong to one class or something similar we could also use the we could also use the somewhat odd formula in the ovo classifier that uses mixture of votes and decision function to make sure it is consistent with ``predict`` we should add parameter controlling whether the decision function is aggregated or raw >>>enhancement moderate
documentation of confusion matrix parameter labels hello confusion matrix docstring doesn explains the use of parameter labels it also available at http scikit learn org stable modules generated sklearn metrics confusion matrix html kind regards>>>documentation
mcd exact fit fixes issue 3367 the following patch fixes issue 3367 to the best of my knowledge however while testing with various exact fit scenarios encountered an issue which believe may be somewhere else in the code the data used to test this is simple plane all with few outliers present the exact fit scenario works and no issues arise however taking the same data as above converting it to the affine subspace spanned by the data which is basically rotation about the principal axes and translation by the mean the data occasionally raises an error where the determinant is larger than that of the previous determinant both datasets can be found at https gist github com thatgeoguy 713bd1355b87ea2d5d07 where `good data txt` is the original data and `bad data txt` is the same data transformed into its affine subspace the final result is still correct in the end despite couple of the trials triggering the above issue and it only happens with the `bad data txt` dataset am unsure what is causing this but it appears to be something different than what caused 3367 >>>bug
calibratedclassifiercv in conjunction with svc and multiclass results in index out of bounds error reported this on stackoverflow http stackoverflow com questions 29873981 error with sklearn calibratedclassifiercv and svm this is not an issue with any other classifiers have used including `randomforestclassifier` and `logisticregression` >>>bug
add verbose to iterative algorithms to print iterations for iterative algorithms expectation maximization algorithm verbose argument should be added to print the current iteration >>>easy enhancement
add shuffle parameter to cross val score and gridsearchcv the underlying cv functions in both `cross val score` and `gridsearchcv` have an option to shuffle inputs but these aren exposed this requires the user to shuffle their examples ahead of time this is somewhat inconsistent with `train test split` that uses `shufflesplit` and for the uninformed user might cause confusion in output results in cases where the underlying inputs have some order like in the wine quality dataset for example would it be possible to expose `shuffle` as parameter in both `cross val score` and `gridsearchcv` and simply pass it through to check cv` and on to `stratifiedkfold` and `kfold` >>>new_feature
plot partial dependence ingores percentiles pd result parallel jobs jobs verbose verbose delayed partial dependence gbrt fxs grid resolution grid resolution for fxs in features shall changed to pd result parallel jobs jobs verbose verbose delayed partial dependence gbrt fxs grid resolution grid resolution percentiles percentiles for fxs in features >>>bug
importerror cannot import name mkdtemp while using cython to compile seq dataset pyx met this error tried to put tempfile py just under the same filefolder but still not work is it because there are some conflicts of redundant name or does anyone know how to solve this problem this is the whole bug message >>>bug
python crashes when calculating large sne python scikit learn 16 macbook pro 16gb ram macos 10 10 when running the following code in an ipython notebook it runs for long time producing no output and then the ipython kernel crashes and has to restart running the same code from the command line produces one line of output sne computing pairwise distances and then it dies the error is pretty much the same as reported in this older issue https github com scikit learn scikit learn issues 3088 ll attach crash log next but think it out of memory because if reduce the rows of to 10000 then it runs to completion without error some suggested improvements estimate the memory required to carry out this operation and warn or error out earlier try to recover from oom errors in libblas more gracefully if possible reduce the memory requirements of sklearn manifold tsne or implement out of core document the memory requirements in sklearn manifold and sklearn decomposition and perhaps warn about potential oom errors and what they ll look like to users you ve already nicely documented the runtime complexities of the algorithms but have not documented their space complexities >>>enhancement
cross validation shufflesplit setting train size without setting test size the sum of train size and test size is not equal to cross validation shufflesplit setting train size without setting test size the sum of train size and test size is not equal to now the sum of them is default value of test size train size when setting test size without setting train size the train size is autocomputed by test size so we hope when setting train size the test size is autocomputed by train size as well not defualt value bug https cloud githubusercontent com assets 2970920 7217998 166c617e e685 11e4 9753 bf820d1313d4 jpg >>>bug
tsne fit transform does not raise an error this issue has been mentioned on stackoverflow http stackoverflow com questions 28054958 this does not produce an error in from sklearn manifold import tsne in tsne random state fit transform out array 76405235e 04 00157208e 05 think it should raise an error or return but this one fails because pca raises an error maybe too late >>>bug
pickle tests have bad coverage the pickle tests in the common tests currently only run on the classifier regressor and transformer classes there should only be single tests that runs via the ``test non meta estimators`` not sure how much that might conflict with 4550 at the moment though that was merged>>>easy enhancement need_contributor
uniform columns return standard deviation of in standardscaler it should be >>>documentation easy
lassolarscv error if jobs python 2194 12277 np random normal np random normal l1 lassolarscv jobs fit print l1 coef lassolarscv jobs fit print coef output 91122441 88051206 multiprocessing pool remotetraceback traceback most recent call last file usr local lib python3 dist packages sklearn externals joblib parallel py line 94 in call return self func args kwargs file usr local lib python3 dist packages sklearn linear model least angle py line 853 in lars path residues train mean valueerror output array is read only during handling of the above exception another exception occurred traceback most recent call last file usr lib python3 multiprocessing pool py line 119 in worker result true func args kwds file usr local lib python3 dist packages sklearn externals joblib parallel py line 104 in call raise transportableexception text type sklearn externals joblib my exceptions transportableexception transportableexception valueerror wed apr 15 14 14 46 2015 pid 4123 python usr bin python3 usr local lib python3 dist packages sklearn linear model least angle py in lars path residues train memmap 00577915 05126903 30304231 35100295 9267396 63928884 train array 3232542 84262663 62905025 62472897 45902494 00504709 test array 31256648 8413869 46347277 21977537 12781956 12695671 test array 91413301e 02 90822410e 01 2352138e 01 06750561e 00 79778359e 01 gram auto copy false method lasso verbose fit intercept true normalize true max iter 500 eps 2204460492503131e 16 848 test test copy 849 test test copy 850 851 if fit intercept 852 mean train mean axis 853 train mean train memmap 00577915 05126903 30304231 35100295 9267396 63928884 mean memmap 01531417 02889734 01592266 00315228 00060194 01170645 854 test mean 855 mean train mean axis 856 train as float array train copy false 857 train mean valueerror output array is read only the above exception was the direct cause of the following exception traceback most recent call last file usr local lib python3 dist packages sklearn externals joblib parallel py line 518 in retrieve self output append job get file usr lib python3 multiprocessing pool py line 599 in get raise self value sklearn externals joblib my exceptions transportableexception transportableexception valueerror wed apr 15 14 14 46 2015 pid 4123 python usr bin python3 usr local lib python3 dist packages sklearn linear model least angle py in lars path residues train memmap 00577915 05126903 30304231 35100295 9267396 63928884 train array 3232542 84262663 62905025 62472897 45902494 00504709 test array 31256648 8413869 46347277 21977537 12781956 12695671 test array 91413301e 02 90822410e 01 2352138e 01 06750561e 00 79778359e 01 gram auto copy false method lasso verbose fit intercept true normalize true max iter 500 eps 2204460492503131e 16 848 test test copy 849 test test copy 850 851 if fit intercept 852 mean train mean axis 853 train mean train memmap 00577915 05126903 30304231 35100295 9267396 63928884 mean memmap 01531417 02889734 01592266 00315228 00060194 01170645 854 test mean 855 mean train mean axis 856 train as float array train copy false 857 train mean valueerror output array is read only during handling of the above exception another exception occurred traceback most recent call last file line in file home donbeo desktop prova py line 31 in lassolarscv jobs fit file usr local lib python3 dist packages sklearn linear model least angle py line 999 in fit for train test in cv file usr local lib python3 dist packages sklearn externals joblib parallel py line 666 in call self retrieve file usr local lib python3 dist packages sklearn externals joblib parallel py line 549 in retrieve raise exception type report sklearn externals joblib my exceptions joblibvalueerror joblibvalueerror multiprocessing exception home donbeo desktop in 10 home donbeo desktop prova py in 26 np random normal 27 28 29 l1 lassolarscv jobs fit 30 print l1 coef 31 lassolarscv jobs fit 32 print coef 33 34 35 usr local lib python3 dist packages sklearn linear model least angle py in fit self lassolarscv copy true cv none eps 22044604 normalize true precompute auto verbose false array 31256648 8413869 46347277 35100295 9267396 63928884 array 01914133 79082241 15777265 62472897 45902494 00504709 994 delayed lars path residues 995 train train test test gram gram copy false 996 method self method verbose max self verbose 997 normalize self normalize fit intercept self fit intercept 998 max iter self max iter eps self eps 999 for train test in cv cv sklearn cross validation kfold 2194 folds shuffle false random state none 1000 all alphas np concatenate list zip cv paths 1001 unique also sorts 1002 all alphas np unique all alphas 1003 take at most max alphas values usr local lib python3 dist packages sklearn externals joblib parallel py in call self parallel jobs iterable 661 if pre dispatch all or jobs 662 the iterable was consumed all at once by the above for loop 663 no need to wait for async callbacks to trigger to 664 consumption 665 self iterating false 666 self retrieve self retrieve 667 make sure that we get last message telling us we are done 668 elapsed time time time self start time 669 self print done 3i out of 3i elapsed finished 670 len self output sub process traceback valueerror wed apr 15 14 14 46 2015 pid 4123 python usr bin python3 usr local lib python3 dist packages sklearn linear model least angle py in lars path residues train memmap 00577915 05126903 30304231 35100295 9267396 63928884 train array 3232542 84262663 62905025 62472897 45902494 00504709 test array 31256648 8413869 46347277 21977537 12781956 12695671 test array 91413301e 02 90822410e 01 2352138e 01 06750561e 00 79778359e 01 gram auto copy false method lasso verbose fit intercept true normalize true max iter 500 eps 2204460492503131e 16 848 test test copy 849 test test copy 850 851 if fit intercept 852 mean train mean axis 853 train mean train memmap 00577915 05126903 30304231 35100295 9267396 63928884 mean memmap 01531417 02889734 01592266 00315228 00060194 01170645 854 test mean 855 mean train mean axis 856 train as float array train copy false 857 train mean valueerror output array is read only >>>bug
valueerror buffer dtype mismatch expected int but got long have training data looking like the following this is the first document this is the second document this is the third document essentially list of string train data like the following 1409108 1501079 1335609 1335703 1342230 1335530 1335602 1342114 1335851 1355623 1342299 1342278 1335804 1342189 1351217 1404708 5101079 1335609 1335703 1342230 1335530 1453602 13422214 1335851 1355623 1345299 1342278 1335804 1342189 1351217 essentially list of list where each list within is list of topic train and train has the same length each string in correpsonds to list of topic in am trying to use the pipeline tfidf tfidfvectorizer clf onevsrestclassifier linearsvc to develop model on the train and train data while the system prompts the above error lb preprocessing multilabelbinarizer indicator lb fit transform train clf pipeline vectorizer countvectorizer tfidf tfidftransformer clf onevsrestclassifier linearsvc clf fit train indicator ve seen similar issues posted here and not sure if this is the version issue but ll post them here anyway scipy intel 13 scikit learn intel 15 scikit learn intel 15 running my program on nyu hpc server mercer so not really sure what the platform version here used to run my program on anaconda locally python with every packages updated to date and they turned out to be completely fine really appreciate your help thanks >>>bug
add example of inductive clustering clusters can be found within training dataset transductive then used to train classifier so as to extend the clustering model to new instances see snippet at https github com scikit learn scikit learn issues 4543 issuecomment 91073246 selwyth is apparently working on this https github com scikit learn scikit learn issues 4543 issuecomment 91185832 >>>documentation easy enhancement
make sure that the output of pca fit transform is contiguous otherwise would rather use because of fortran data for inner product is very slow for example in the kmeans >>>easy enhancement
add icl to mixture gmm suggest adding icl integrated completed likelihood or its approximation icl bic which is an information criteria useful for determining the number of clusters essentially it is icl bic entropy of clustering code to demonstrate probs gmm score samples entropy sum sum prob np log prob for prob in probs icl gmm bic entropy biernacki celeux and govaert assessing mixture model for clustering with the integrated completedlikelihood ieee transactions on pattern analysis and machine intelligence 22 2000 719725 mclachlan and peel finite mixture models john wiley sons inc 2000>>>new_feature
add fit predict to mixture gmm similar to clustering methods we can add fit predict to do fit and predict in single function call>>>easy new_feature
precision recall numbers computed by scikits are not interpolated non standard hi scikit learn seems to implement precision recall curves and average precision values auc under pr curve in non standard way without documenting the discrepancy the standard way of computing precision recall numbers is by interpolating the curve as described here http nlp stanford edu ir book html htmledition evaluation of ranked retrieval results html the motivation is to smooth out the kinks and reduce noise contribution to the score in any practical application if your pr curve ever went up then you would strictly prefer to set your threshold there rather than at the original place achieving both more precision and recall hence people prefer to interpolate the curve which better integrates out the threshold parameter and gives more sensible estimate of the real performance this is also what standard code for pascal voc does and explain this in their writeup http citeseerx ist psu edu viewdoc download doi 10 157 5766 rep rep1 type pdf vl feat also has options for interpolation http www vlfeat org matlab vl pr html and as shown in their code here https github com vlfeat vlfeat blob edc378a722ea0d79e29f4648a54bb62f32b22568 toolbox plotop vl pr the concern is that people using the scikit version will see incorrectly reported lower performance than what they might see reported in other papers >>>bug documentation
audit our usage of `numpy astype` to remove unecessary memory copies the following pattern will always trigger memory copy even when `x` as the right type in recent numpy it possible to avoid this problem with however we need to keep the backward compatibility with numpy that does not provide this option therefore we should indeed use the following search reveals that we might have several places in our code were we do unecessary memory copy it would be great if someone could scan those and contribute one or several pull requests to use as `astype dtype copy false each time we find pattern that could potentially do large unwanted memory copies this issue can be tackled by new contributors to scikit learn slightly related to 4555 >>>easy
pipeline should support fit predict it should be possible to have clusterer as the last step in pipeline which may not have separate `predict` to fit it should be possible to call `fit predict` on `pipeline` so that pipeline can be used in context which clusterer can >>>easy enhancement
build failed error command gcc pthread fno strict aliasing o2 dndebug fwrapv o3 wall wstrict prototypes fpic home shenchong usr lib python2 site packages numpy core include home shenchong usr lib python2 site packages numpy core include home shenchong usr include python2 sklearn utils sparsetools graph tools build temp linux x86 64 sklearn utils sparsetools graph tools >>>bug build_/_ci
mrg emptylabelset when using sklearn datasets svmlight format py to load multi label data sets it is possible that the label set is empty for instance line 10 of http www csie ntu edu tw cjlin libsvmtools datasets multilabel mediamill train exp1 svm bz2 in that case the original code would wrongly try to parse the first feature index feature as the label set list which should be string with comma as delimiters causing parsing exceptions the fix is to detect when parsing the label set string if detected then the label set should be empty and the string containing should belong to features instead the fix also improve earlier code that copies line parts the parsed tokens to features the features to be parsed but almost never uses the latter now all the feature parsing part uses the copied list variable features instead of line parts thanks for reviewing >>>bug
bug in assert raise message if the function passed to ``assert raise message`` raises different kind of error than expected this error is not caught the original error is raised example will raise valueerror that how you get ants when it should raise assertionerror didn raise typeerror on the other hand ``assert raises regex`` behaves correctly so think instead of fixing the bug we should just trash assert raise message and use the standard function instead >>>bug easy
classification report not explicit about averaging classification report computes micro averages https github com scikit learn scikit learn blob master sklearn metrics classification py l1265 however that is not documented and can not be changed wonder whether we should add an average keyword or just document it >>>documentation easy
adding feature importance to pipeline and gridsearchcv today there were two questions on stack overflow where the answer was more or less to add ``feature importance `` to pipeline or gridsearchcv wonder if that would be good idea actually think for gridsearchcv it is not very useful but for pipeline it might be with ``pipeline`` there is an additional complication which is that the number of features that goes in might not correspond to the number of features that the last estimator is trained on not sure how to handle that maybe with ``inverse transform`` that would require adding an ``inverse transform`` to ``onehotencoder`` that might actually be feasible >>>new_feature
scikit learn 16 performance drop in randomforests uploading scikit learn 15 profiling png uploading scikit learn 16 profiling png upgrading scikit learn from 15 to 16 using anaconda3 under ubuntu 14 04 64 bits leads in performance drop on project working on using randomforests `sklearn 15 2` running in 44 17 sec 20 235 sec spent in `sklearn ensemble forest py 477 predict proba `sklearn 16 0` running in 80 27 sec 49 902 sec spent in `sklearn ensemble forest py 477 predict proba both runs used same input data and same sklearn pipeline minmaxscaler copy true feature range randomforestclassifier bootstrap true class weight none criterion gini max depth none max features auto max leaf nodes none min samples leaf min samples split min weight fraction leaf estimators 500 jobs oob score false random state 42 verbose false warm start false please note that specified `n jobs 1` for both runs the times shown above are given by predict loop over all test datas 820 call to pipeline predict proba each using the same randomforest with 500 estimators it seems that the performance drop comes from multiprocessing externals joblib but not sure ve cprofiled the runs but it seems can only attach image files png jpg how can join the binary dumps from cprofile is it relevant for you to investigate thanks >>>bug
preprocessing label docs it seems to me that if using any sklearn estimators people never have to use anything in preprocessing label as it is done under the hood if this is the case think we should mention that in the user guide >>>documentation
add cool example on apply of trees comparing randomtreeembedding randomforestclassifier and gradientboostingclassifier for feature extraction and compare pca vs trained classifier on them the gradientboostingclassifier doesn have apply as it is not necessarily tree based so we could use the tree apply see 4488 >>>documentation easy need_contributor
fix bug the result is wrong when use sklearn metrics log loss with one class when there is only one class such as true np array class1 class1 class1 predict np array log loss true predict the result would be wrong which is not the logloss of predict but the logloss of predict the code in log loss if shape np append axis should be change to if shape np append axis >>>bug
error on lasso on constant input variables if lassolarscv is used on dataset where std then the function returns an error here there is an example http jpst it y0rf>>>bug easy
mrg doc add warning for partial pip upgrades add warnings to the install doc to make it explicit that as of now pip cannot properly upgrade scikit learn if it was installed with `python setup py install` or by `conda` `anaconda` this issue caused problems such as 4472 note future versions of pip will refuse to uninstall and therefore upgrade packages that lacks the missing metadata in particular the list of installed files that is usually stored in the old style `site packages package name version egg info installed files txt` or in the new style `site packages package name version dist info record` >>>documentation
pandas validation failure hi downloaded latest pandas version 16 and found that can longer fit my models tried different classifiers and all of them fails with the same error the same code worked fine in previous version of pandas version 15 and sklearn version 15 was able to fix the problem by changing sklearn utils validation py file line 336 from if hasattr array dtype for reference this is direct url to the failed line https github com scikit learn scikit learn blob master sklearn utils validation py l336 since don know the logic of sklearn in details ll leave it up to developers to investigate and apply proper change but removing array dtype kind check fixed the problem for me thanks valentin >>>bug
something wrong with some of cpython file encodings trying to calll predict proba method over the instance of sgdclassifier with loss type that doesn support it brings up syntaxerror invalid or missing encoding declaration for usr lib python3 site packages sklearn linear model sgd fast cpython 34m so >>>bug build_/_ci
calibratedclassifiercv non deterministic by default and can not be made deterministic by default ``calibratedclassifiercv`` uses ``linearsvc`` as ``base estimator`` ``linearsvc`` is non deterministic which makes testing annoying think the default value is not that important and vote to just fix the random state in the ``linearsvc `` that is constructed >>>bug easy
make sure all cv parameters have good docstrings all ``cv`` should say that the default is stratified for classification and then list of available objects is in the cross validation module currently some say cross validation generator to use if int determines the number of folds in stratifiedkfold if is binary or multiclass and estimator is classifier or the number of folds in kfold otherwise if none it is equivalent to cv find the is binary or multiclass confusing and think it is not actually true so remove that part it easy to find all docstring with ``git grep cv ``>>>documentation easy
mrg fix make rfe feature importance test deterministic fixes issues in 4496 which merged to fast >>>bug
mrg listed valid metrics for neighbors algorithms 4521 >>>needs_review
utils testing if matplotlib wrong the utils testing if matplotlib check is too generic and catches all errors think it should only catch importerrror in particular it caches errors in test partial dependence py that look like actual errors to me >>>bug easy
jaccard distance in trees very different from pairwise distances jaccard distance as observed in 4522 balltree and ``pairwise distances`` have very different results for ``metric jaccard `` >>>bug
wip metrics testing there have recently popped up some issues about support for different metrics see 4520 and 4452 for example am trying to add more tests but am not sure am familiar enough with the metrics neighbors modules jakevdp your help would be much appreciated currently travis fails because the jaccard distances in the trees seem to be very different from the scipy ones think this is because our trees cast everything to bool while scipy uses floats this seems to be pretty big issues as the algorithm that is used might change automatically depending on the dataset >>>bug
list valid metrics for neighbors algorithms see 4520 it would be nice to have listing of the valid metrics for kd tree ball tree brute in the neighbors module possibly by just calling the function in doctest or listing them like done here for evaluation metrics http scikit learn org dev modules model evaluation html common cases predefined values >>>documentation easy
dbscan does not accepts distance seuclidean here is quick example if calculate distance matrix with it the everything is just fine but want to use kd tree or something to speed things up >>>bug
array dimension issue when using sklearn covariance fast mcd lines 362 368 in `sklearn covariance robust covariance py` specify the following the problem with this is that if you pass in 1d array of shape samples you typically want the univariate estimate of the mcd for all those samples hence you actually wanted to pass in an array of shape samples however the code above assumes you really wanted to pass in 1d array of shape features which has the following problems this is backwards to the assumption made by libra http wis kuleuven be stat robust html which contains the reference implementation of fastmcd by van dreissen and rombouts this can be found in the `mcdcov m` file lines 213 215 nobody in their right mind would try to find the covariance amongst features using only single sample half kidding but at the very least the behaviour appears unconventional to me perhaps am missing some justification for this the current behaviour raises an exception stating that the covariance matrix is singular when in reality it is non singular just univariate if you for example pass in matrix object instead of an array with the appropriate dimensions then the function will compute without error because of these reasons going to assume this is bug which appears similar to the bugs found in 4509 and 4466 the fix is simple just change the above lines to the following with this fix finding univariate estimates of the mcd becomes much easier have made the above changes to my fork at https github com thatgeoguy scikit learn and can submit pull request at any time however while running nosetests could not correctly get the tests to complete also could not find any documentation mentioning how to run the tests so `sklearn check build` will run appropriately any advice is appreciated am examining the `mincovdet` `fast mcd` so that can hopefully fix issue 3367 which is currently preventing me from completing project am working on >>>bug easy
rfc deprecate 1d in check array was reshape sensibly reshape in ``check array`` for ndim using reshape not reshape see 4509 4466 edit not sure this is the right idea any more edit on master all transform decision function and predict proba take of shape `` features `` without issue investigating whether brought this upon us with ``check array`` sadness so far naive bayes dictionarylearning gradientboosting sgdclassifier lshforest balltree kdtree rbm and some feature selection worked the other way around assuming shape `` features `` trees forests asserted they don work on 1d only slightly saddens me to remove this test >>>api
gmm with population array shape issue using gmm on singe population list with version 16 get the following error after calling the score sample function the shape of is not compatible with self when digging little bit found that what used to be in the previous versions np asarray if ndim np newaxis if size return np array np empty self components if shape self means shape raise valueerror the shape of is not compatible with self is now check array if ndim np newaxis if size return np array np empty self components if shape self means shape raise valueerror the shape of is not compatible with self this changes everything as when you use it on list np asarray returns 1d array which is then turned to 2d array of shape by the next lines and the array is in the correct format whereas check array turns our list into array which leads to the error am getting this wrong or is this indeed what the problem is and in this case it probably bug in the latest release >>>bug
adding very short section on conventions just saw 1679 again and thought we should add some conventions documentation think adding short paragraph about sklearn rules and expectations to the quick start guide would be nice it should contain unless otherwise specified input will be cast to float64 regression targets will be converted to float64 classification targets can be arbitrary and the same type will be produced again also maybe in the same place say that calling fit will forget any previous models and maybe that parameters can be set using ``estimator parameter stuff`` have no other ideas what should be there >>>documentation easy
fix bug in means pyx when kmeans fit bad case >>>bug
mrg add distance threshold on hierarchical clustering see 3796 it is now possible to define distance threshold that will be used as an early break criterion in hierarchical clustering it is used in both ward tree and linkage tree an error is now raised if cluster and distance threshold are not set or are both set don know yet what should be the behavior if the number of clusters and the distance threshold are set together >>>needs_review
api consistent api for attaching properties to samples this is an issue that am opening for discussion problem sample weights in various estimators group labels for cross validation objects group id in learning to rank are optional information that need to be passed to estimators and the cv framework and that need to kept to the proper shape throughout the data processing pipeline right now the code to deal with this is inhomogeneous in the codebase the apis are not fully consistent ie passing sample weights to objects that do not support them will just crash this discussion attempt to address the problems above and open the door to more flexibility to future evolution core idea we could have an argument that is dataframe like object ie collection dictionary of 1d array like object this argument would be sliced and diced by any code that modifies the number of samples cv objects train test split and passed along the data proposal all objects could take as signature fit sample props none with optional for unsupervised learners sample props name to be debated would be dataframe like object ie either dict of arrays or dataframe it would have few predefined fields such as weight for sample weight group for sample groups used in cross validation it would open the door to attaching domain specific information to samples and thus make scikit learn easier to adapt to specific applications proposal could be optionally dataframe like object which would have as compulsory field target serving the purpose of the current and other fields such as weight group in which case arguments sample weights and alike would disappear into it people at the paris sprint including me seem to lean towards proposal implementation aspects the different validation tools will have to be adapted to accept this type of argument we should not depend on pandas thus we will accept dict of arrays and build helper function to slice them in the sample direction also this helper should probably accept data frame but given that data frames can be indexed like dictionaries this will not be problem finally the cv objects should be adapted to split the corresponding structure probably in follow up to 4294 >>>api enhancement
4475 add safe pairwise distances function dealing with zero varian 4475 add safe pairwise distances function dealing with zero variance samples when using correlation metric the best fix would be to have the metric not returning nan values but as the correlation metric is actually computed by scipy we can modify it directly so when metric correlation we replace rows and cols corresponding to zero variance samples by the maximum distance here >>>bug
wip ridgegcv with sample weights is broken what the title says the way it is right now the sample weights weight the eigenspaces of the gram matrix which doesn seem sensible >>>bug
mrg issue 1453 mds fall back to svd when possible this is follow up on pr 3141 ve fixed most of ogrisel comment >>>needs_review
remove array2d from developer docs array2d is removed from sklearn 16 but still present here l456 https github com scikit learn scikit learn blob master doc developers index rst>>>documentation easy
pipeline named steps not documented ``pipeline named steps`` is not documented and there is no example of using either ``named steps`` or ``steps`` to access any attributes of the estimator that question comes up pretty frequently ``named steps`` is weird as it is initialized in `` init `` and doesn have trailing underscore maybe the real fix is 1769 but for the moment we should just document better think >>>documentation easy
documentation for normalize in ridge regression somewhat unclear for linear models with regularization the input variables should be standardized because the solution is not scale invariant noticed that in the ridge regression source code the input variables are centered by mean subtraction but normalization by std deviation is flag my questions are under what circumstances should normalized be set to true so that both centering and normalizing by std dev are turned on does normalize true affect prediction when predicting from new should be centered and normalized does normalizing have any affect on the range of alpha the regularization parameter it would be nice to be able to restrict alpha to it would be great if the documentation made this clear thanks >>>bug documentation
references are missing in stable version of the doc for instance metrics are listed in the dev version but not in the stable version of the references http scikit learn org stable modules classes html module sklearn metrics cluster http scikit learn org stable modules classes html module sklearn metrics cluster this is weird >>>bug documentation
the diabetes dataset has no documentation on what the actual features and target variables represent ve been searching google for hour and not sure anyone knows what these actual variables represent or where the data came from it hard to use this dataset for any sort of meaningful purpose without knowing this stuff even the sklearn examples don have axis labels for plots or examples with this data http scikit learn org stable auto examples linear model plot ols html example linear model plot ols py likewise no luck directly viewing the source or examining the dataset `bunch` object the only actual tidbit of information found on this data set were on this obscure site http www tp umu se nylen pylect advanced scikit learn index html linear model from regression to sparsity the diabetes dataset consists of 10 physiological variables age sex weight blood pressure measure on 442 patients and an indication of disease progression after one year was hoping someone could shed light on this and if so be happy to submit pull request to improve the documentation >>>documentation easy
tsne with correlation metric valueerror distance matrix must be symmetric from sklearn manifold import tsne import numpy as np np random seed 42 data np random rand 10 data model tsne metric correlation model fit transform data valueerror traceback most recent call last in model tsne metric correlation res model fit transform data ran model fit transform ran data users ch miniconda envs sci34 lib python3 site packages sklearn manifold sne py in fit transform self 522 embedding of the training data in low dimensional space 523 524 self fit 525 return self embedding users ch miniconda envs sci34 lib python3 site packages sklearn manifold sne py in fit self 447 self training data 448 449 joint probabilities distances self perplexity self verbose 450 if self init pca 451 pca randomizedpca components self components users ch miniconda envs sci34 lib python3 site packages sklearn manifold sne py in joint probabilities distances desired perplexity verbose 52 conditional conditional 53 sum np maximum np sum machine epsilon 54 np maximum squareform sum machine epsilon 55 return 56 users ch miniconda envs sci34 lib python3 site packages scipy spatial distance py in squareform force checks 1479 raise valueerror the matrix argument must be square 1480 if checks 1481 is valid dm throw true name 1482 1483 one side of the dimensions is set here users ch miniconda envs sci34 lib python3 site packages scipy spatial distance py in is valid dm tol throw name warning 1562 if name 1563 raise valueerror distance matrix must be 1564 symmetric name 1565 else 1566 raise valueerror distance matrix must be symmetric valueerror distance matrix must be symmetric>>>bug easy
cca userwarning scores are null at iteration each of is 300 dimension array each of is 5000 dimension array am trying to run cca for getting an transform matrix from to but keep getting following warning and an error which think are related usr local lib python2 site packages sklearn cross decomposition pls py 290 userwarning scores are null at iteration warnings warn scores are null at iteration >>>bug
implementation of mdlp for discretization of continuous attributes believe this would be good feature in sklearn preprocessing how do others feel about this >>>new_feature
need test that get params deep false is subset of get params deep true this should be an invariance test for all estimators supporting `get params` it would have prevented the bug in 4461 and 4461 needs to be fixed for this invariance test to pass they can be patched together >>>api easy
docs for linearregressioncv somewhat optimistic they say logisticregressioncv implements logistic regression with builtin cross validation to find out the optimal parameter in general the newton cg and lbfgs solvers are found to be faster due to warm starting looking into the pr think what it should say is are faster for high dimensional dense data not in general >>>documentation easy need_contributor
searching across featureunion transformer weights in gridsearchcv have pipeline set up very similar to the featureunion with heterogeneous data sources example http scikit learn org dev auto examples hetero feature union html but attempting to grid search over the different ways of weighting the transformers in the featureunion however it looks like parameters of featureunion objects aren accessible from within gridsearch this would be useful feature for me and be happy to contribute pr if someone could point me in the right direction >>>bug
isotonic calibration example weird broken on the gaussiannb plot the scores contradict the description http scikit learn org dev auto examples calibration plot calibration curve html isotonic calibration actually make things worse ping agramfort jmetzen have vague memory of this being discussed before but didn find it currently there is clearly conflict of result and description >>>bug
mrg implement haversine metric in pairwise fixes 4453 4452 add haversine distrance for pairwise distances and document it did not find any test for pairwise py so did not add any test cases >>>needs_review
inconsistency in randomized svd regarding transpose auto default option when transpose auto the behavior of randomized svd is the opposite of the docstring and code comments from the doc string from the code am unsure which behavior is actually intended or optimal >>>bug documentation easy
mismatching dimensions in extmath weighted mode apparently this check here https github com scikit learn scikit learn blob master sklearn utils extmath py l397 isn enough when using neighbors radiousneighborsclassifer predict keep getting errors due to the mismatching dimensions in the next line https github com scikit learn scikit learn blob master sklearn utils extmath py l398 valueerror operands could not be broadcast together with shapes 8792 8807 valueerror operands could not be broadcast together with shapes >>>bug
implement haversine metric in pairwise document properly see 4452 the haversine metric is implemented in the neighbors trees but not in pairwise module which results in odd crashes also the neighbors module does not list the haversine metric as one of the available metrics in the docstring >>>easy
dbscan and haversine metric hi am observing somewhat weird behavior when using dbscan and am not sure what going on sometimes when am using dbscan with the haversine distance get the following error delorean affinity argparse basemap distribute joblib matplotlib mock nose numpy pygmaps pymongo pyparsing python dateutil pytz 2014 scikit learn 15 scipy 14 six wsgiref 2>>>bug
fix gbrt min leaf weight fixes https github com scikit learn scikit learn issues 4447 cc arjoly >>>bug
gradient boosting estimator presort best splitter expects min weight leaf but is given min weight fraction leaf bugs is at the initialization of splitter https github com scikit learn scikit learn blob master sklearn ensemble gradient boosting py l1007 note that currently this is working partially because the condition is also verified in the tree growing procedure otherwise said we might accept split that violate the pre pruning condition but won grow further node that violates the condition >>>bug
sgd sample weight broken when shuffle true python make data sgdclassifier shuffle true fit sample weight >>>bug
add mask property to learntselectormixin currently it is hard to find which features are selected by model driven feature selectors it would be easy to refactor `` learntselectormixin`` to have ``mask `` property that stores the boolean mask of the selected features and then use that in ``transform`` possibly related to 4242 >>>easy enhancement
test failing after new install ubuntu 14 04 and scikit learn dev 17 after some issues from prior install which finally removed the folders from dist packages and ran make from the cloned repo get the following which see had been an issue prior but it seems that my python joblib is up to date >>>bug easy
problems in sklearn decomposition pca with components mle option we have found several problems in the implementation of the method to automatically tune the number of components of the pca algorithms the algorithm never tests full rank this is most probably due to the fact that loops using the rank end always at rank ``for in range rank `` if two eigen values are equals there is log issue zeros eigen values are not treated explicitly possible solutions for checking the loops ranges for predetecting small eigen values lower than the numerical noise excluding them from rank scan have no idea for we had the problem here with very small eigen values in numerical noise which were totally identical never managed to create syntetic dataset which reproduce the problem since the even with symetric datasets there is always small difference in the order of numerical precision between theoretically identical eigen values >>>bug
should `train test split` support stratified splits would it be useful to other if `train test split` was able to take stratified sample like so instead of random sample as it currently does >>>new_feature
mrg fix make standardscaler scale more numerically stable this is rebased and fixed version of 3747 will merge if travis is still green >>>bug
when fetching both training and test set of the 20newsgroup dataset when fetching both training and test set of the 20newsgroup dataset the data data data target data filenames should be updated >>>bug
joblib numpy arrays not cleaned up from dev shm ran large gridsearch base don the code here http scikit learn org stable auto examples grid search digits html example grid search digits py and the process locked up killed it and tried to rerun and got this error later figured out it is because dev shm was full of old files from numpy arrays ls lrt dev shm joblib dev shm joblib memmaping pool 64060 189405392 total 13528188 rw general 13852862624 mar 20 09 09 64060 190150864 190138048 pkl 01 npy rw general 152 mar 20 09 09 64060 190150864 190138048 pkl or similar files directories were present obviously its not possible to cleanup when killed the task which was probably stuck because of the lack of space in the first place which should have triggered an exception that when caught would cleanup this space but when try to rerun the script these files should be cleaned up in an intelligent manner instead of also crashing or should at least fail with better message as to which directory is full ionly was able to figure it out form reading this https github com scikit learn scikit learn issues 3313 traceback most recent call last file python linux lib python2 site packages sklearn externals joblib numpy pickle py line 240 in save obj filename self write array obj filename file python linux lib python2 site packages sklearn externals joblib numpy pickle py line 203 in write array self np save filename array file python linux lib python2 site packages numpy lib npyio py line 453 in save format write array fid arr file python2 site packages numpy lib format py line 521 in write array array tofile fp ioerror 1731607818 requested and 502 written >>>bug
mrg fix lda solver lsqr make sure the right error is raised on transform fixes part of 4415 >>>bug
link to functions in dataset docs the dataset userguide aka narrative documentation doesn link to the reference guide api section that needs to be fixed each section should link to the function that actually loads fetches the data >>>documentation easy
deprecate load lfw pairs and load lfw people these two functions are just aliases of ``fetch lwf pairs`` and ``fetch lfw people`` and don add anything and don even have proper docstring ping ogrisel >>>easy
mrg fix larscv and lassolarscv fails for numpy fixes 4399 amueller also should also update `y numeric` for https github com scikit learn scikit learn blob master sklearn kernel ridge py l144 and https github com scikit learn scikit learn blob master sklearn linear model stochastic gradient py l868 both are explicitly regressors there couple others that share `fit` between classifiers and regressors too gbm adaboost bagging with no `y numeric true` on `check y` presumably all of the above get through tests because no call to the offending numpy function though can confirm all tests pass locally on this branch and fails on an up to date master with np installed on python ubuntu 14 04 feelsgood >>>bug
should agglomerativeclustering clusters raise an exception note hit this on 16b1 `n clusters 0` seems like invalid input to me and didn see any particular documentation addressing the expected behavior for this setting however it does run without error and does what you might expect this came up in one of my project unit tests the test would expect an exception here and worked as expected in 15 but fails in 16b1 >>>easy enhancement
memoryerror lw features is too large when using shrinkage lda with lsqr solver test with the latest 17dev follow the example here http scikit learn org dev auto examples classification plot lda html but with different size of training data in my case size of traindata 895x2048 samples dim error lda lda solver lsqr shrinkage auto lda fit traindata trainlabel traindatalda lda transform traindata testdatalda lda transform testdata the following errors are printed file usr local lib python2 dist packages sklearn lda py line 428 in fit self solve lsqr shrinkage self shrinkage file usr local lib python2 dist packages sklearn lda py line 271 in solve lsqr self covariance class cov self priors shrinkage file usr local lib python2 dist packages sklearn lda py line 123 in class cov covs append np atleast 2d cov xg shrinkage file usr local lib python2 dist packages sklearn lda py line 56 in cov sc std ledoit wolf sc std scale back file usr local lib python2 dist packages sklearn covariance shrunk covariance py line 291 in ledoit wolf try increasing block size memoryerror lw features is too large try increasing block size error lda lda solver lsqr lda fit traindata trainlabel traindatalda lda transform traindata testdatalda lda transform testdata file usr local lib python2 dist packages sklearn lda py line 453 in transform check is fitted self xbar scalings all or any any file usr local lib python2 dist packages sklearn utils validation py line 622 in check is fitted raise notfittederror msg name type estimator name sklearn utils validation notfittederror this lda instance is not fitted yet call fit with appropriate arguments before using this method >>>bug
dictvectorizer does not work with categorical columns with int type values accepts pairs where value is of type string does not work in scenarios where value is of type int representing categories such as it isn specified in the documentation that value should be of type string either this should be changed or functionality of dictvectorizer should be modified to accept categorical values of numeric data type >>>documentation easy need_contributor
out of bag probability estimates for random forests this is as much proposal as question does it make sense to use out of bag samples for estimating the distributions in the leaves that should give you better estimate of uncertainty right think there is something like that in and it seems to make sense to me ping arjoly glouppe >>>enhancement
partial dependence plots for random forests does scikit learn have any capacity for partial dependence plots and associated data arrays for random forest analyses can find the plot for gradientboostingregressor here http scikit learn org stable auto examples ensemble plot partial dependence html doing the same for rf outputs >>>enhancement moderate
assertionerror dtype uint8 using the conda distribution of scikit just uninstalled and reinstalled using conda remove scikit conda install scikit to resolve previous test error now my test fails with this message fail sklearn datasets tests test base test load sample image traceback most recent call last file anaconda lib python2 site packages nose case py line 197 in runtest self test self arg file anaconda lib python2 site packages sklearn datasets tests test base py line 136 in test load sample image assert equal china dtype uint8 assertionerror dtype uint8 ran 3342 tests in 96 693s failed skip 20 failures >>>bug
mrg fix ompcv on old scipy versions fixes 4387 we have an if old scipy version ignore error which made this error hard to track down here https github com scikit learn scikit learn blob master sklearn linear model omp py l23 solves 3190 once and for all http imgur com ghcgr jpg >>>bug
test fails in least angle on master just updated my local branch to master and am running into some fails during `make` that have not encountered before ubuntu 14 04 lts 64 bit python numpy scikit learn 17 dev0 scipy 13 error sklearn tests test common test non meta estimators larscv traceback most recent call last file opt anaconda lib python2 site packages nose case py line 197 in runtest self test self arg file bigdrive git scikit learn sklearn utils estimator checks py line 178 in check dtype object estimator fit astype object file bigdrive git scikit learn sklearn linear model least angle py line 999 in fit for train test in cv file bigdrive git scikit learn sklearn externals joblib parallel py line 659 in call self dispatch function args kwargs file bigdrive git scikit learn sklearn externals joblib parallel py line 406 in dispatch job immediateapply func args kwargs file bigdrive git scikit learn sklearn externals joblib parallel py line 140 in init self results func args kwargs file bigdrive git scikit learn sklearn linear model least angle py line 855 in lars path residues mean train mean axis file opt anaconda lib python2 site packages numpy core methods py line 67 in mean ret ret dtype type ret rcount attributeerror int object has no attribute dtype error sklearn tests test common test non meta estimators lassolarscv traceback most recent call last file opt anaconda lib python2 site packages nose case py line 197 in runtest self test self arg file bigdrive git scikit learn sklearn utils estimator checks py line 178 in check dtype object estimator fit astype object file bigdrive git scikit learn sklearn linear model least angle py line 999 in fit for train test in cv file bigdrive git scikit learn sklearn externals joblib parallel py line 659 in call self dispatch function args kwargs file bigdrive git scikit learn sklearn externals joblib parallel py line 406 in dispatch job immediateapply func args kwargs file bigdrive git scikit learn sklearn externals joblib parallel py line 140 in init self results func args kwargs file bigdrive git scikit learn sklearn linear model least angle py line 855 in lars path residues mean train mean axis file opt anaconda lib python2 site packages numpy core methods py line 67 in mean ret ret dtype type ret rcount attributeerror int object has no attribute dtype >>>bug
svc and svr docstring not informative for kernel precomputed the shape of in ``fit`` ``predict`` etc is different when ``kernel precomputed `` that is not documented in the docstring as far as can see for everything except ``fit`` it needs to be `` samples predict samples train `` >>>documentation easy
weighted kde not sure this is the correct place but would very much appreciate the ability to pass weight for each sample in kde density estimation there exits adapted version of scipy stats gaussian kde http stackoverflow com questions 27623919 weighted gaussian kernel density estimation in python >>>enhancement
issue tf idf computation hi have some concerns about what is currently implemented as tf idf in https github com scikit learn scikit learn blob master sklearn feature extraction text py tf idf tf idf my concern is regarding the the comment in the source code says the actual formula used for tf idf is tf idf tf tf idf instead of tf idf the effect of this is that terms with zero idf that occur in all documents of training set will not be entirely ignored this is indeed true the computation is effectively linearly interpolating between tf idf and tf however adding one to idf is not standard practice even after extensive search reading many ir and nlp papers regarding tf idf and consulting ir and nlp researchers have not yet encountered an instance of anyone doing this am therefore concerned that this is the default behavior in sklearn all the more so because there is no mention of this in the documentation had to read the source code to figure it out although there are several standard variants for computing tf and for computing idf these are actually pretty well documented on the wikipedia page they are always combined as tf idf not tf idf granted and taking the standard definition of idf for simplicity you can subsume the into the idf score itself giving idf log log log log in effect this means you re pretending you saw times as many documents as you actually did and none of them contained any terms in the vocabulary this means that all terms frequent and infrequent will be treated as if they occurred in fewer documents than they actually did however this is not equivalent to any of the standard variants of idf since sklearn tf idf is widely used think it should reflect standard behavior definitions in the ir and nlp literature and thus the should be removed to be clear happy for the to be left as an option or even changed to be with speficied by the user thereby allowing the user to linearly interpolate between tf and standard tf idf but think users should be aware that they are doing this rather than doing this and thinking they re using standard tf idf >>>bug
mrg replace assert array equal with assert almost equal to compare arrays of floats fixes 4386>>>bug build_/_ci
test non meta estimators orthogonalmatchingpursuitcv valueerror array must not contain infs or nans on older systems such as debian wheezy seems to puke twice >>>bug
little precision issue with test weights multiplied on 32bit systems seems to happen across the board >>>bug easy
move newton cg test out of optimize sklearn utils optimize py contains test in the end that should go in the test folder and become test not smoketest >>>easy
kernelridge doesn work with sparse matrices the problem is just in the input validation >>>bug easy
speed up rfecv by not running rfe currently rfecv fits the estimator twice for each setting of number of selected features think it could be sped up by factor of two by not running the rfe estimator maybe the inner loop of rfe should be factored out also see https github com scikit learn scikit learn issues 2403 issuecomment 33963597>>>enhancement moderate
mrg fixes 4374 linearsvc intercept scaling breaks 4374>>>bug
randomforestclassifier with class weight subsample exit with access violation when run the randomforestclassifier from the master branch with class weight subsample and jobs parameters sometimes it ends with exit code 1073741819 0xc0000005 if know well it means access violation on windows guess the problem is the parallel build trees function calls the compute sample weight auto indices https github com scikit learn scikit learn blob master sklearn ensemble forest py line number 92 which uses np choose https github com scikit learn scikit learn blob master sklearn utils class weight py l141 line number 141 as know it is not thread safe sorry if report this bug in wrong place >>>bug
linearsvc intercept scaling breaks see so http stackoverflow com questions 28888070 sklearn gridsearchcv valueerror has 21 features per sample expecting 19 28955322 28955322 setting ``intercept scaling 0`` changes the shape of ``coef `` so the estimator can not be used am bit surprised that the ``coef `` is reduced by two features but that seems to be the case one fore each class not sure what is happening in liblinear here guess the easiest would be to raise on our side as the combination with ``fit intercept true`` is nonsensical >>>bug easy
remove mutable default arguments we should remove mutable default arguments as much as sensibly possible you can find some using the landscape io bot https landscape io github scikit learn scikit learn 51 messages error page errors or even better with test now in 4379 the default value should be replace by ``none`` and then replaced by the actual value in ``fit`` this is good fit for gsoc first time contributors >>>easy enhancement
mrg add warning for kfold cv if random state must be changed but shuffle is false trying the pr in another issue >>>needs_review
broken test score objects under windows 00 15 09 00 15 09 fail test that scorers support sample weight or raise sensible errors 00 15 09 00 15 09 traceback most recent call last 00 15 09 file python34 x64 lib site packages nose case py line 198 in runtest 00 15 09 self test self arg 00 15 09 file python34 x64 lib site packages sklearn utils testing py line 300 in wrapper 00 15 09 return fn args kwargs 00 15 09 file python34 x64 lib site packages sklearn metrics tests test score objects py line 343 in test scorer sample weight 00 15 09 format name weighted unweighted 00 15 09 assertionerror 29999999999999999 29999999999999999 scorer recall samples behaves identically when called with sample weights vs 00 15 09 00 15 09 >>>bug build_/_ci
scalable kmeans can see kmeans implementation here but do you have scalable kmeans implementation which is supposed to be better than kmeans >>>enhancement large_scale
dictvectorizer restrict docstring unclear to me the dictvectorizer restrict docsting is unclear and didn understand it when reading it it is missing return statement also the function modifies the estimator in place which is rather rare thing in scikit learn only other example can think of is ``sparsify`` so that should be made more explicit maybe also give an example >>>documentation
documentation error in minmaxscaler the math in https github com scikit learn scikit learn blob 38104ff4e8f1c9c39a6f272eff7818b75a27da46 sklearn preprocessing data py l156 does not render correctly in the documentation unfortunately am not familiar with rst files so leave this open >>>documentation
how to transform categories before treating missing values hi would like to compare missing values techniques for this need to deal with missing values after transform categorical features by transformers any idea how this can be done the current transformers don like missing values causes an error thanks >>>question
mrg add scipy2013 tutorial links to presentations on website >>>documentation
wip setup py fix numpy installation pass build requires if numpy is not found fixes 4164 runs doing `pip install `python setup py build` >>>build_/_ci
simultaneous evaluation of several scorers when building validation and learning curves fitting model several times when building validation or learning curve can be costly while the evaluation of the scorer can be very fast it would be interesting if it would be possible to evaluate list of scorers given to `sklearn learning curve learning curve` `sklearn learning curve validation curve` as the argument `scoring scorer1 scorer2 scorer3 as workaround going to see if my scorer can return float with extra info in the form of extra properties like the extra scorers that want to evaluate in my particular case even going to try including confusion matrixes although quite new at python and don know if such thing is possible easy nevertheless such an approach seems unnecessarily twisted learning curve and validation curves are the two functions that are relevant to me don know whether there are any other methods which may be susceptible of this enhancement would you consider as feasible expanding scoring functionality to accept lists of scorers >>>new_feature
compute class weight class param behaviour not sure if it relevant to the motivation behind the implementation as discussed in 4324 but two class `y` array with two classes present in the `classes` param proceeds with the sum of the weights being equal to the number of classes compute class weight auto iris target 100 array while three class array with only two of the classes present in the `classes` param does something different altogether compute class weight auto iris target 120 array 66666667 66666667 had sidestepped this in `compute sample weight` in 4190 by determining the present classes from `y` itself happy to open pr to remove the param and was going to but while the function is somewhat private it is exposed in `partial fit` in `basesgdclassifier` in order to use auto weights use compute class weight auto classes so does this need deprecation warning some more discussion >>>bug
mrg more minor doc fixes checked the rendering of the calibration part surprised it worked before but it did >>>build_/_ci documentation
possible bug in compute class weight hi think there might be bug in the compute class weight method in https github com scikit learn scikit learn blob master sklearn utils class weight py lines 50 and 51 are as follows recip freq bincount ind weight recip freq le transform classes np mean recip freq for two class problem where there are n0 data points belonging to class and n1 data points belonging to class this is equivalent to saying weight w0 n0 n0 n1 n1 n0 n1 and weight w1 n1 n0 n1 these expressions for w0 and w1 do not correspond with my intuition or with the expressions given in this paper by king and zeng intuitively assuming that am trying to balance my classes using my class weights would expect my class weights w0 and w1 respectively to satisfy w0 n0 w1 n1 n0 n1 and w0 n0 w1 n1 solving for w0 gives n0 n1 n0 while solving for w1 gives n0 n1 n1 this intuition is backed up by king and zeng paper which says on pages 144 145 that if tau is the fraction of ones in the population for balanced population which is what we re assuming here and is the fraction of ones in the sample n1 n0 n1 then w1 tau n1 n0 n1 n0 n1 n1 and similarly w0 n0 n1 n0 is this what you were intending to compute in lines 50 and 51 if so then think there is bug >>>bug
mrg pass include self true to kneighbors graph fixes 4235 >>>bug
sphinx throws errors on classes functions with no examples since 3327 any class function that is not included in any example throws when building the docs think we should just make sure to generate empty rst files as suggested in 3327 >>>build_/_ci documentation
unexpected keyword average in accuracy score in this example jnothman arjoly can you confirm when this was removed deprecated >>>bug
mrg skip ompcv on travis by raising skiptest in set fast parameters fixes 4311 centralizes 3473 skips orthogonalmatchingpursuitcv test in centralized way on travis the advantage of doing this in ``set fast parameters`` instead of in ``all estimators`` is that it will give explicit error messages in all tests that it applies to well arguably an advantage >>>build_/_ci
mrg improve doc and test for radius queries this is follow up on the discussions in 4303 and 4072 to improve the docstrings of the `radius neighbors` method of both exact and approximate neighbors methods >>>documentation
non deterministic omp failures on travis they make me unhappy https travis ci org scikit learn scikit learn builds 52648279>>>bug build_/_ci
svm bounds should change loss name to squared hinge as we deprecated l2 in svm we should also deprecate it here sklearn svm bounds py>>>easy
spectralclustering should be explicit about include self currently it raises deprecation warning because it doesn pass include self to ``kneighbors graph``>>>bug easy
the datastructure returned by lshforest radius neighbors should be consistent with the output of exact methods lshforest has not been released yet we should therefore fix this api consistency bug before the 16 release to avoid introducing backward incompatible fix in the future >>>api bug
mrg isotonic regression duplicate fixes fixes 4184 with tests from 4185 this is stupid pure python version not sure if there is an easy way to vectorize it now implements the secondary method which basically replaces duplicate points with weighted averages this is the only method that makes ``fit transform`` behave identical to ``fit transform `` used naive implementation of ``fit transform `` >>>bug
mrg choose number of clusters this module implements algorithms to find optimal number of clusters stabiliity gap statistic distortion jump silhouette calinsky and harabasz index and elbow methods if metric is needed for example to compute distortion the mean distance of point to its cluster center all distance of scipy spatial distance can be used >>>needs_review
make clear that rbfsampler implements variant of random kitchen sinks the name might not be super telling and we should make it more discoverable>>>documentation easy
infinite loop when running isotonic regression with some zero valued weights extract the following bug from the discussion in https github com scikit learn scikit learn issues 2507 issuecomment 72048443 this bug alone should probably be considered release critical bug for 16 >>>bug
friendly error on kneighbors neighbors using zero neighbors should give sensible error on fit and or predict >>>easy
deprecate estimator params in rfe and rfecv for grid searches they can be set using the `` `` delegation mechanism for construction they can just be passed via the estimator see my bone headedness in 4291 >>>api easy
meta estimators should have uniform parameter delegation behavior to grid search parameters of sub estimators ``pipeline`` and ``featureunion`` currently use `` `` syntax and named sub estimators ``baggingclassifier`` and ``rfe`` however use an ``estimator params`` parameter that makes grid searches relatively awkward suggest we change them to the pipeline behavior by overloading ``get params`` or refactoring get params by defining unified way to declare sub estimators >>>api
document oob estimates of randomforest and bagging in the narrative it is not currently mentioned >>>documentation easy
mrg enh labels parameter in may extend or reduce label set this pr replaces 2610 making the `labels` parameter to `precision recall fscore support` more functional and better documented tested but in accordance with 4192 not deprecating `pos label` but instead being restricted to the `average binary case common use of the micro average is to extend the notion of binary to the case where there is frequent negative class and multiple classes of interest following this pr explicitly listing the labels of interest allows the negative class to be excluded from multiclass problem the same result can be achieved by transforming multiclass problem into multilabel problem excluding one label but in the model evaluation api that would necessitate custom and tricky `scoring` object >>>enhancement
sklearn cluster dbscan allow for nan values for user defined metric import sklearn def user defined metric cluster algorithm sklearn cluster dbscan metric user defined metric cluster algorithm fit matrix >>>enhancement
polynomialfeatures uses more memory than necessary if we have data matrix with shape `` examples original features `` and we wish to perform add polynomial features and have new data matrix of shape `` examples polynomial features `` the ``polynomialfeatures`` class uses ``n examples polynomial features original features`` memory rather than just ``n examples polynomial features`` this comes from https github com scikit learn scikit learn blob master sklearn preprocessing data py l504 which does `` none self powers prod `` `` none self powers `` has shape `` examples polynomial features original features `` haven had time to come up with nice vectorized solution that uses the minimum possible memory but my fix for the moment is in the ``transform`` method of ``polynomialfeatures`` this is very slow due to the loop over all features and not suitable for merging for reference trying to run this code with ``n examples 20`` and ``n features 500`` this will produce about 125000 output features run out of memory with the current implementation when try to handle more than examples at once my implementation does not run out of memory but does take 81s to produce the output because it needs to do 500 hadamard products on matrices of size 20 125000 >>>enhancement
enh oob trace for sklearn ensemble classifiers to the best of my knowledge the tree based ensemble classifiers don maintain record of the oob scores during the training phase correct me if wrong would find this useful feature since it would allow me to easily examine the number of trees estimators at which the oob score stabilises the error rate vs estimators chart http scikit learn org stable auto examples ensemble plot adaboost hastie 10 html http statweb stanford edu jtaylo courses stats202 images ensemble fig 00 png related this feature is activated in the `randomforest` package http cran project org web packages randomforest index html by setting `randomforest do trace true when instantiating the classifier thanks >>>documentation easy
bug in bernoullibn hi found small bug in the update feature log prob method of the bernoullinb class https github com scikit learn scikit learn blob master sklearn naive bayes py line 706 currently reads smoothed cc self class count self alpha classes but should instead read smoothed cc self class count self alpha to see why this is the case check out line in the trainbernoulli method on this page http nlp stanford edu ir book html htmledition the bernoulli model html basically because features take on the value of presence absence the class conditional probability of the presence absence of feature must sum to one over since the numerator is data points in class containing feature alpha for and data points in class not containing feature alpha for the denominator must contain alpha happy to explain more if that would be useful >>>bug
density doesn normalise in vbgmm and dpgmm having trouble using the vbgmm and dpgmm for density estimation as far as understand both should have the same interface as the normal gmm however while the normal gmm produces good fit the vbgmm and dpgmm produce bad fits and non normalised densities this leads me to wonder whether there is something deeper wrong than me incorrectly using the code the problem presents itself both in the density estimation example http scikit learn org stable auto examples mixture plot gmm pdf html by appending the line print np sum np exp this is approximately when using normal gmm but much smaller when using the vb or dp gmm the same behaviour is shown on toy 1d density estimation problem import numpy as np import numpy random as rndn import sklearn mixture as skmix import matplotlib pyplot as plt rnd randn 300 np vstack rnd randn 300 gmm skmix gmm gmm skmix dpgmm gmm fit np linspace 10 10 1000 np exp gmm score plt hist bins 50 normed true plt plot plt show integral np sum print integral is this behaviour just the result of poor fit due to local optimum or something the fact that the predictive densities don normalise lead me to believe it something else asked the same question on stackoverflow http stackoverflow com questions 28575943 mixture model predictive distributions in scikit learn >>>bug
better univariate feature selection docs the selectors should have see also sections to the other selectors and to the scoring functions the narrative should give more details >>>documentation easy
svm decision function consistency several people on so and the mailing list have complained they can reproduce the decision function of the kernel svm and was not able to do so myself either something in the docs or in the math is wrong and afraid messed up some sign at some point see http stackoverflow com questions 28503932 calculating decision function of svm manually>>>bug
broken plot svm scale py example here is the exception found this pbm by building the documentation this might have reveal change that broke backward compatibility need investigation >>>bug easy
roc curve should returns fix size for the same size input input length true score is 9177 output fp tp th size is 5816 but when re sample the data it is 5756 guess due to sampling with replacement creates duplicate data which is about in matlab perfcurve returns fp tp th the same size as the input size or at specified fp tp th values >>>enhancement
ensure that fitting on 1d input data is consistent across estimators as noted by amueller in issue 3440 input validation refactoring fitting on 1d input is currently not consistent across estimators depending on the model the following case can either be treated as is array of 100 samples and feature like `minmaxscaler` does for instance or as sample with 100 features as most models currently do even if almost always counter intuitive to do so most models use `check or `check array and leave the `ensure 2d true` kwarg to its default value the current behavior of `ensure 2d` is to cast 1d array as row vectors sample with len features this was done so for backward compatibility reasons think this behavior is counter intuitive and we should break backward compat for this edge case to always treat 1d arrays as multi sample collections of single features rather than the opposite mark this issue as an api discussion it should be tackled before version >>>api bug
mrg fix broken test under 64 bit python windows this is to fix the following broken tests with 64 bit python under windows >>>build_/_ci
mrg fix empty input data common checks this pr includes 4214 but also additional common tests that currently fail on some estimators that do not have consistent behavior and that probably need to be fixed on case by case basis >>>bug
different results on differen versions of sklearn reinstalled my sklearn to the latest 15 and re ran the same code with the same input on same setting fold splitting random seed using svc but the classification results are quite different like 75 vs 93 previously was using 14 any thoughts on why >>>bug
make spectral embedding deterministic there is possible sign flip in the eigensolver that makes ``spectral embedding`` and therefore ``spectralembedding`` not deterministic think we should fix that using similar method to ``sklearn utils extmath svd flip``>>>easy enhancement
check all usages of kneighbors graph after mechcoder fixed kneighbors graph in 4046 we should check all uses in the code for whether we want ``include self true`` or not came across this in ``spectralembedding`` where the current default makes no sense think you can simply ``git grep`` and should find lot of occurrences if our test output wasn so flooded with warnings we would have probably detected that earlier >>>bug
random state in rbm have not scrutinised this properly but the way random state is used in the `bernoullirbm` looks dubious if `random state` is set with an integer `check random state` will return new random genenator with that state if not mistaken this could lead to state loops when trying to do many iterations of gibbs sampling as the new state has become deterministic function of the old state see line 214 `partial fit` seems to already sets `self random state to circumvent problems with reusing random state line 236 perhaps single random generator could be set in init like so `self random state check random state random state line 214 https github com scikit learn scikit learn blob a3283c6d6bf5e4163c2991ec4c4e25cb08ce6e44 sklearn neural network rbm py l214 line 236 https github com scikit learn scikit learn blob a3283c6d6bf5e4163c2991ec4c4e25cb08ce6e44 sklearn neural network rbm py l236>>>bug
ensure sparse `y` is supported in grid search etc as reported at https github com scikit learn scikit learn issues 1233 issuecomment 73467547 `gridsearchcv` currently breaks if it is fit with sparse `y` at least for some supported `scipy` versions this is due to `len` call when we should probably be using `check consistent length` in any case test is needed since we are meant to be preferring sparse matrices for multilabel data now >>>bug easy
local variable referenced before assignment in lassocv and elasticnetcv per gaelvaroquaux comment https github com scikit learn scikit learn issues 1059 issuecomment 73461028 in 1059 opening new ticket for this if try to use lassocv or elasticnetcv to fit target of uniform values it will fail to properly initialize and this leads to an unassigned variable in the fit method this seems to be happening because it tries to pick the alpha values based on the range of the target vector see this line https github com scikit learn scikit learn blob master sklearn linear model coordinate descent py l100 and that leads to bunch of nans which leads to trouble in this comparison https github com scikit learn scikit learn blob master sklearn linear model coordinate descent py l1095 because nan is not less than inf and so best l1 ratio etc are never assigned one possible fix would be at coordinate descent py l100 https github com scikit learn scikit learn blob master sklearn linear model coordinate descent py l100 changing that so it doesn run into numerical problems code to reproduce this was with version 15 but it doesn look like this has been fixed since then >>>bug
mrg neighbors refactor big refactor of the nearest neighbors space partitioning code currently kd tree and ball tree include textually the source of their base class `binary tree pxi` so that the code in that module gets compiled twice the code in this pr merges the modules and compiles the base class once also removal of workaround for old cython and numpy versions tiny optimizations less python api calling preliminary to optimizing radius neighbor queries as promised in 4157 >>>needs_review
mrg gbm meta ensembles support for class weight refactoring 4114 on top of 4190 and removing the gbm coding style changes from the scope of this pr for ease of review basically adding `class weights` to the remaining ensemble classes as was done in 3961 for forests and trees amueller pprett glouppe you have all at least glanced at 4114 so perhaps you ll have chance to review the new refactored version here >>>needs_review
mrg add validation for non empty input data this follows the discussion in 4206 this makes `check array` and `check y` reject input arrays with less than samples and less than feature for 2d inputs while providing informative error message to the caller fyi also have implemented some common checks based on this pr in edcd0793ec8adad7aef1d2de5bdad1c403ced1c6 but this reveals some missing input validation in several estimators those missing validation checks should better be added once amueller own 4136 is merged in master to avoid conflict resolution pain and redundant work >>>enhancement
heisen test failure in test transformer iter with cca the following was caught by 64 bit windows build with python it very rare so this might not be related to the platform nor the python version >>>bug build_/_ci
rbm partial fit should use batches as pointed out in 4205 by treora rbm partial fit should use batches and then fit can be implemented in terms of ``partial fit`` >>>enhancement
mention how trees forests compute probability estimates namely by using the fraction of samples in the leaves given the mathematical detail elsewhere think we can add this to the narrative and to the ``predict proba`` docstring >>>documentation easy
mrg explicit exception message for strict selectors this is fix for 4059 to raise `valueerror` at transform time with an explicit error message instead of crashing when calling `get support with cryptic error message note that for consistency the behavior of `selectkbest is also impacted by this change >>>bug
interpreting output of pred proba have dataset of 35 samples and 28 classes in `decisiontreeclassifier` `predict proba` returns list of 28 `numpy ndarray` all with size 35 or 35 don understand what are the two values in the `ndarray` shouldn there just be one the probability of that class being predicted in which case the array would just be 28 35 why sometimes there are only 35 values providing some data https www dropbox com n9rv0ughbg6z8nx sampledata pickle dl to replicate my issue >>>bug
kneighbors graph param check ineffective in `sklearn neighbors graph` the check params` function is called by both of the graph methods in the module the idea seems to be to ensure that when the neighbors are precomputed that the parameters passed into say `kneighbors graph` match what was used in the computation of the `balltree` however if the `balltree` itself was from prior fit the check misses that fact demonstration not sure any of this matters since `kneighbors graph` and the things it calls doesn do anything with the name of the metric if the balltree has been precomputed but it certainly the case the check params is not having its intended effect so does this matter should `nearestneighbor fit be modified so that it copies all relevant data over when is precomputed this is bit contrived but ran across it while trying to modify `isomap` to handle non euclidean metrics the issue is that isomap initializes `nearestneighbors` instance with metric equal to minkowski and `p 2` so if you call `fit` with precomputed `nearestneighbors` using different metric then this fact is not transferred to the initialized instance this can all be avoided if the api to isomap was changed but this particular point of check params not always doing an effective check still holds >>>bug
adding unit test to cover ties duplicate values in isotonic regression unit test to highlight regression in issue 4184 >>>bug
isotonicregression results differ between fit transform and fit transform with ties in per conversation in issue 2507 isotonicregression appears to have regressed due to commit a9ea55f this ipython notebook http nbviewer ipython org urls gist githubusercontent com mjbommar 74fcefdcd0f2b1a5f708 raw 4742691db799101091598922cd0808f1eb5f07f2 isotonic test case 20150129 json demonstrates the failure on head tested the following two commits with the notebook d255866 no difference success a9ea55f difference failure in other words think we can blame the switch for ``interp1d`` from linear to slinear first thought is that spline slinear matrix formulation is ill posed for ties whereas the piecewise linear implementation is unaffected small additional note confirmed failure with test case where values are all non zero `` `` instead of `` `` so ``x 0`` isn part of the cause >>>bug
mrg give dpgmm covars property allows for sampling fixes 1637 >>>bug
l1 feature selection docs confusing here http scikit learn org dev modules feature selection html selecting non zero coefficients mentions selecting non zero coefficients via transform in linearsvc logisticregression and lasso lasso doesn have transform the other two use the median coefficient for feature selection not being nonzero >>>documentation
convergence check in `gmm fit` it seems to me that `gmm fit` convergence check could benefit from some kind of normalization with regards to the number of samples in `x` here is the current status yet `abs log likelihood log likelihood strongly depends on the number of samples in `x` both mixtures have reached an identical state however in the current implementation the mixture trained with 50 less samples is twice as likely to be marked as `converged that the other one is this the intended behavior or should we use `curr log likelihood mean in place of `curr log likelihood sum >>>enhancement
mrg better error messages in meanshift slightly more robust to bad binning fixes 2356 see discussion there this will still crash for some variant of the reported example like this but it will tell you that no point was within bandwidth of any seed try different seeding strategy trying to put grid on 200d space is just not good idea >>>bug
mrg fix gamma update in dpgmm fixes 1764 tests don change have no idea how to test for this in the light of 2454 it seems unlikely we can currently test for this in sensible way >>>bug
underscore missing from threshold in outlier detection the ``treshold`` parameter in the covariance module should have trailing underscore as it is estimated during ``fit`` >>>api easy
contamination and threshold should be part of covariance outlierdetectionmixin predict the settings of contamination and threshold are currently possible only at the init of the covariance ellipticenvelope and covariance outlierdetectionmixin https github com scikit learn scikit learn blob master sklearn covariance outlier detection py l37 https github com scikit learn scikit learn blob master sklearn covariance outlier detection py l168 these may be the precomputed defaults however it would be much more useful if the predict method accepted the contamination threshold parameters too these parameters are used only to make the output of the decision function binary turn values above the threshold into and the rest into thanks for improving these >>>enhancement
mahalanobis distance in covariance empiricalcovariance is wrong the mahalanobis distance is correctly defined in https github com scikit learn scikit learn blob master sklearn neighbors dist metrics pyx l623 however the mahalanobis method of covariance empiricalcovariance https github com scikit learn scikit learn blob master sklearn covariance empirical covariance py l258 is wrong for two reasons the current implementation returns the square of the distance the np sqrt function must be applied on the current result in order to get the true distance the docs say the provided observations are assumed to be centered yet the opposite is true since the observations are being centered inside the method and the user should not be centering the observations thanks for fixing these and making the relevant changes to the dependent examples >>>bug
partial fit incremental online learning support for multiclass classifiers the multiclass meta estimators in sklearn multiclass do not currently support `partial fit` but think they could easily where the base estimator does >>>easy enhancement
can setup py install without numpy at minimum this could use better error message is it not possible to have project that depends on sklearn and installs all its dependencies to virtualenv in single pass must do one pass to install numpy and everything else and second pass just to install sklearn >>>build_/_ci
mrg fix issue 4154>>>bug
tsne spits an error when components sorry haven taken time to investigate it in detail import numpy as np from sklearn manifold import tsne np random randn 100 10 tsne components fit transform tsne components fit transform >>>bug
mrg fix agglomerative clustering precomputed distances connectivity matrix linkage tree doesn calculate distances when affinity precomputed and connectivity is not none pr includes fix test case let me know if there anything should change >>>bug
test that sparse matrix with 64bit index are supported or give sensible error message basically adding new common test to the sparse matrix test that checks for the other index type and see what happens >>>api
mrg fdr treshold bug continues 2932 fixes 2771 these are some minor fixes on top of 2932 where bthirion already gave his maybe arjoly wants to have look as he commented there this is good bug fix that think we should include asap fyi tests take 5s >>>bug
problem with sample weight in svc hello following andy advice http sourceforge net scikit learn mailman message 33251002 opening this issue here is the description of the problem trying to use the instance weighting capability of the svc class and encountered some weird behavior when the parameter is chosen very small and the weights are not very large weighted svm yields constant prediction below you ll find piece of code that demonstrates this what it does create dummy dataset for binary classification with training and testing dataset create random weights that are very very very close to one so close that they should not influence what follows run unweighted and weighted svm hereafter svm and wsvm with decreasing values of we expect svm and wsvm to yield exactly the same predictions because the instance weights are ridiculously close to one this is exactly what happens for large to small ish values of but at some point when gets smaller wsvm yields constant predictions either all zeros or all ones while svm still behaves normally sylvain >>>bug
allow for transformers on following up on 3113 and 3112 what about arbitrary transforms to the `y` values those issues dealt primarily with label transforms but would like to use transformers to mean or range center the `y` values as well ideally would have some transform that can be applied to the values before fitting and then applied in the inverse to the predicted `y` values coming out of `predict` ideally this transformer could be added to pipeline currently the signature for `transform` for `standardscaler` https github com scikit learn scikit learn blob a413f875f1a7c9528290e01e1c030c336b9f32e4 sklearn preprocessing data py l338 allows for transforming `y` but as pointed out in the linked issues not all transform methods have signature allowing for `y` to be passed in further even for `standardscaler` there is an inconsistency with the `inverse transform` https github com scikit learn scikit learn blob a413f875f1a7c9528290e01e1c030c336b9f32e4 sklearn preprocessing data py l366 not taking `y` >>>api new_feature
mrg bootstrap with test size fix before ``test size 1`` gave you the whole data so we need to change the order of evaluation fixes 4070>>>bug
random travis failure in statistical inference tutorial on python see for example https travis ci org scikit learn scikit learn jobs 47771718>>>build_/_ci
mrg make baggingclassifier use if delegate has method in decision function>>>bug
mrg more robust input validation more testing test lot more of the estimators for input validation etc enforce that they can accept other dtypes in particular ``float32`` hack for parts of 4134 fixing parts of 4056 fixing 4124 fixing 4133 debatable and 4132 >>>api bug
sklearn naive bayes error in variance line 219 in function update mean variance return total sum total total ssd total should be return total sum total total ssd total as you want the unbiased variance and not the biased version if total variance >>>bug
tsne has no ``fit`` the ``tsne`` class has no ``fit`` method this issue is basically asking whether this is ok thought having ``fit`` was an api requirement other manifold methods store the result of ``fit transform`` in member and simply return ``self`` in ``fit`` >>>api
signature of mds fit the signature of ``mds`` is>>>api
test tree failed after installing the package after installed the package run the file test tree py under the directory scikit learn sklearn tree tests here is the message got traceback most recent call last file test tree py line 39 in from sklearn tree tree import sparse splitters importerror cannot import name sparse splitters have no idea why this happens >>>bug
test disk used fails when filesystem is compressing data while building scikit learn 15 with python have experienced the following test failure looking into the test and at the `disk used function am guessing that the most likely reason for the failure is that the test doesn take into account if the filesystem is compressing the data since am using the zfs filesystem and have enabled compression by default it will cause the on disk size of the file to become smaller than the size of the written data unless the written data was random >>>bug
mrg enh robustscaler this pr adds `robustscaler` and `robust scale` as alternative to `standardscaler` and `scale` they use robust estimates of data center scale median interquartile range which will work better for data with outliers most of this was discussed before in 2514 and even older commits separated this out so it can be merged as is originally wanted to submit this only after 3639 was merged but sending the pr now allows it to be discussed concurrently if either this or 3639 get merged ll of course update the other commit >>>new_feature
sklearn manifold tsne valueerror buffer dtype mismatch expected float but got float thank you so much for adding sklearn manifold tsne very excited that it now part of sklearn however when try using it get the following error message both with 15 and 16 to fix this did which seems to work for me my input is list of vectors get from gensim models word2vec kind regards and thanks for the great library hendrik>>>bug
cross decomposition module needs work recently ve spent some time exploring `cross decomposition` http scikit learn org dev modules classes html module sklearn cross decomposition module haven paid attention to `cca` noticed several problems with it the module needs much better narrative documentation now it not clear what algorithms actually do where they might be useful and how they are different the layout of files and import approach are unusual for sklearn the files are named with trailing underscores all is put into individual files but not in init py` the implementation is rather obscure for short and conventional description of pls refer here http statmaster sdu dk courses st02 module08 index html nipals twoblocks inner loop` in fact computes both weights and scores but only weights are returned and scores are then recomputed parameter `norm weights` crucially determines how the algorithm works along with `deflation mode` and `mode` but does it in tricky way it took me lot of time to understand why implemented here `plsregression` is equivalent to pls algorithm described in most sources parameter `norm weights` set to `false` for `plsregression` in order to make regression coefficient see link above between and equal to it is done purely by convention and to compare with implementations in suppose alternative svd cross product` solver is provided but never used in code only in tests also it can be substitution for nipals twoblocks inner loop` with `norm weights false` there are no required early stop checks when `x` or `y` matrix are deflated to zeros iterations become invalid and assumed properties are no longer held that causes the bug 3932 computed `y rotations is not correct for `plsregression` `y scores np dot yc rotations think there is no way to compute these rotations in this case because `y` is deflated on `x scores` several obvious bugs such as modifying non existing variable etc >>>enhancement
mrg fix boundary handling in radius neighbors issue 4072 fixes 4072 this pr makes the `radius neighbors` for brute force to include points lying on boundary of chosen radius this is the same behavior as the kd tree and ball tree `radius neighbors` >>>bug
mrg adding sample weight support to matthews corrcoef metric partially fixes 3450 based on jatin shah implementation of wcorrcoeff here https github com scikit learn scikit learn issues 3450 issuecomment 51236631 jatinshah have credited you in the what new entry thanks should there be any tests >>>needs_review
mrg gmm tied covariance fixes from 4039 following up on 4039 minor fixes >>>bug
move all data independent fit params to `` init `` thought we already did that but qda still has ``tol`` in fit pretty sure we can list all fit params using small snipplet and then go over them by hand >>>api easy
implement single linkage clustering see here https github com scikit learn scikit learn pull 2199 issuecomment 70141935 it should be added as an additional ``linkage`` option to agglomerative clustering had an implementation here but it rebuilds the tree which is very stupid https github com amueller information theoretic mst blob master heuristics py l10>>>new_feature
nosetest failure assertionerror fail sklearn feature extraction tests test image test connect regions traceback most recent call last file library python site packages nose case py line 197 in runtest self test self arg file library python site packages sklearn feature extraction tests test image py line 63 in test connect regions assert equal ndimage label mask connected components graph assertionerror 777 767 fail sklearn feature extraction tests test image test connect regions with grid traceback most recent call last file library python site packages nose case py line 197 in runtest self test self arg file library python site packages sklearn feature extraction tests test image py line 70 in test connect regions with grid assert equal ndimage label mask connected components graph assertionerror 777 767 ran 3342 tests in 148 698s failed skip 20 failures >>>bug
use slinear interpolation in isotonic see https github com scikit learn scikit learn pull 3995 issuecomment 69966446>>>easy enhancement
make the build in evaluation metrics more visible it is only listed in form of weirdly formatted error message as far as can tell http scikit learn org dev modules model evaluation html common cases predefined values that ensures that it is in sync with the ``scorers`` dict but it is really hard to find feel >>>documentation easy
mrg support sample weight in silhouette score sought `sample weight` in `silhouette score` to account for multiple points that are merged into one when calculating average distances hacking it into the current implementation resulted in very slow solution thus this pr also rewrites the implementation yielding something that bit slower than the solution at master but supports `sample weight` ve also added tests for correctness which haven otherwise found in the code >>>needs_review
importerror home yifengli local lib python2 site packages sklearn metrics pairwise fast so undefined symbol intel fast memcpy when ran the random forests of sklearn got the following error exception memoryerror memoryerror in sklearn tree tree tree resize ignored segmentation fault thus tried to install the latest sklearn from github git clone https github com scikit learn scikit learn git cd scikit learn python setup py build python setup py install user however when run from sklearn ensemble import randomforestclassifier got the following error it maybe complier issue traceback most recent call last file main random forests debug py line 14 in from sklearn ensemble import randomforestclassifier file home yifengli local lib python2 site packages sklearn ensemble init py line in from forest import randomforestclassifier file home yifengli local lib python2 site packages sklearn ensemble forest py line 55 in from feature selection from model import learntselectormixin file home yifengli local lib python2 site packages sklearn feature selection init py line 20 in from rfe import rfe file home yifengli local lib python2 site packages sklearn feature selection rfe py line 16 in from cross validation import check cv as check cv file home yifengli local lib python2 site packages sklearn cross validation py line 31 in from metrics scorer import check scoring file home yifengli local lib python2 site packages sklearn metrics init py line 29 in from import cluster file home yifengli local lib python2 site packages sklearn metrics cluster init py line 19 in from unsupervised import silhouette samples file home yifengli local lib python2 site packages sklearn metrics cluster unsupervised py line 10 in from pairwise import pairwise distances file home yifengli local lib python2 site packages sklearn metrics pairwise py line 25 in from pairwise fast import chi2 kernel fast sparse manhattan importerror home yifengli local lib python2 site packages sklearn metrics pairwise fast so undefined symbol intel fast memcpy >>>bug build_/_ci
sync docstring sphinx processing with the numpydoc project numpy has split off their docstring processing into separate project at https github com numpy numpydoc scikit learn has local copy https github com scikit learn scikit learn tree master doc sphinxext numpy ext which has diverged due to stylistic fixes as well as some new feature or data checking needs our copy should be re synced with the `numpydoc` project such that we benefit from any cleaning there so that our changes contribute back to that project allowing other numpydoc using projects to benefit from our enhancements >>>easy
nearest centroid py is iterating over all labels instead of classes in nearest centroid function fit it is looping over all for cur class in ind center mask ind cur class nk cur class np sum center mask if is sparse center mask np where center mask but think the idea is to compute the centroid for each possible classes and by looping over ind it essentially goes over all thus the complexity becomes where is number of examples and is number of features my understanding is it should be where is number of unique classes thus the code should really be for cur class in self classes center mask ind cur class nk cur class np sum center mask if is sparse center mask np where center mask >>>bug
handling of boundary in radius neighbors inconsistent the handling of boundary case in `neghbors radius neighbors` is not properly documented or tested balltree kdtree appear to include the boundary where the distance between the query and target is equal to the radius the target is not returned but the brute method in nearest neighbors does not `lshforest` includes the boundary due to this logic https github com scikit learn scikit learn blob master sklearn neighbors approximate py l314 this should be consistent tested and better documented >>>bug easy
add example of silhouette plot finding correct clustering parameters may benefit from silhouette plot analysis as used in the tutorial at http au mathworks com help stats means clustering html we can calculate the required scores using `silhouette samples` http scikit learn org dev modules generated sklearn metrics silhouette samples html sklearn metrics silhouette score but do not have an example which shows how to turn this into the plot someone is welcome to tell me this technique is not used useful in practice and has been superseded >>>documentation easy
mrg fix pipelined fitting of clustering algorithms scoring of means in pipelines fixes 4063 also fixes the embarrassing bug where clustering algorithms can be used in pipelines >>>bug
pipeline score broken for unsupervised algorithms the score method for pipeline assigns `y none` and always passes it to the score method of the final estimator but some estimators for instance kmeans take only is there reason to use `y none` instead of args` reproducible by >>>bug
kerneldensity and gmm interfaces are unnecessarily confusing to evaluate the density of ``data`` at ``x`` the current interface is ``density np exp kde score samples data `` see in action here http nbviewer ipython org gist jakevdp 0b3e332015ec2de7b973 this seems really silly and unnecessary for such common operation how would people feel about adding ``density`` method to ``kerneldensity`` and to ``gmm`` to make this easier for users to figure out >>>enhancement
crash in univariate feature selection if no feature is selected univariate feature selection crashes if no feature is selected with an unhelpful message >>>bug
ensure common tests cover everything slightly concerned that currently the common tests don cover as much as like them to cover which results in no sparse data tests for clustering 4052 for example think for clustering regression classification and transformers we are in relatively good shape but there are two cases of odd estimators that we need to watch out for estimators not returned by ``all estimators`` by default estimators not belonging to the four mixin classes for the second these are mostly covariance density preprocessing and density models it would be great if we could figure out good way to test them too or make more tests applicable to all estimators without filtering for the four standard kinds >>>api build_/_ci
gmm bic crashes on dtype object gmm is not happy with ``dtype object`` in some cases not sure if there is an open issue on handling dtype object think we should try to convert to float in ``check array`` if ``dtype object`` does anyone remember where the discussion about this was think 4006 is related we should collect dtype object issues somewhere to reproduce >>>bug
add test for non inheriting estimators as we don want to enforce inheritance from sklearn estimators and even say so in the docs we should actually test for that we currently test only ``gridsearchcv`` here https github com scikit learn scikit learn blob master sklearn tests test grid search py l128 we should also test ``cross val score`` ``pipeline`` ``rfe`` and ``rfecv`` think for ``cross val score`` that is only matter of not making the ``mockestimator`` inherit from ``baseestimator`` think >>>api easy
mrg refactor kneighbors graph and radius neighbors graph et al following the discussion in https github com scikit learn scikit learn pull 4019 this pr allows to be none in `neighbors kneighbors` which skips the first neighbor in both distance and connectivity mode do not do anything special in other cases in knn nearestneighbors neighbors fit in knn kneighbors graph toarray out array in knn kneighbors graph toarray out array in knn kneighbors graph toarray out array in knn kneighbors graph mode distance toarray out array in knn kneighbors graph mode distance toarray out array in knn kneighbors graph mode distance toarray out array also happy 2015 to everyone >>>bug
vectorizing distance calculations in approximate neighbor search for batched queries in exact nearest neighbor search when brute force method is used it simply uses `pairwise distance` with entire batch and the calculation is vectorized always in `kneighbors` and sometimes in `radius neighbors` approximate neighbors with `lshforest` does not have this advantage since for different queries neighbors will be searched from different candidates in the input space therefore even for batched queries distance calculations have to be done in conventional loops this issue affects any lsh based technique not only lsh forest since final distances are calculated only in set of selected candidates for each query this is bottleneck when using lsh techniques because most of the time for queries are spent on distance calculations not candidate selections does anyone have suggestions tackle this problem >>>enhancement
corrected two bugs related to tied covariance type in mixture gmm dded test closes 4036 the first bug was with the gaussian log density calculation for the tied covariance type rather than fix this equation reformatted the covars data structure so that it could be fed into the full covariance type log density calculation it might be tiny bit slower but think it is better to have the least amount of potentially redundant code as this should minimize the potential for such errors the second bug fixed was related to the covar mstep tied function only the first part of the equation should be divided by shape >>>bug
mixture gmm produces different bic scores for tied vs other covariance types for component fits to 1d data for dimensional data fit with one component gmm would expect that the bic scores of the tied and other covariance types diag spherical full should be the same as is the case when the data is run through the package mclust note mclust actually plots bic mclust https cloud githubusercontent com assets 3067471 5583501 faffaf7e 902e 11e4 9ac5 6e944bf2bb7e png however this is not the case as can be seen from the following result generated with sklearn mixture gmm on the same 1d data test2 https cloud githubusercontent com assets 3067471 5583531 61f914ea 902f 11e4 8369 febd2c82e4c7 png note that the deltabic score is just given model bic score minus the best model bic score so for component both the tied and diag point should be on top of one another have verified that the bic difference for the component 1d case is only due to different results with self score results for tied vs diag not due to improper estimate of self parameters note that diag spherical and full all produce the same bic score for the component 1d case it is only tied that differs >>>bug
metrics log loss fails when any classes are missing in true when calling log loss with label array not an indicator matrix for true it uses labelbinarizer to construct the indicator matrix if not all classes in pred are present in true this has the wrong shape and it raises>>>enhancement
mrg cemoody bhtsne barnes hut sne introduction this pr presents the barnes hut implementation of sne sne is used to visualize high dimensional data in low dimensional space that attempts preserve the pairwise high dimensional similarities in low dimensional embedding the barnes hut algorithm which is used by astrophysicists to perform body simulations allows the calculation of the sne embedding in nlogn time instead of this effectively allows us to learn embeddings of data sets with millions of elements instead of tens of thousands example an ipython notebook is available where we ve put together simple install instructions demo of both methods http nbviewer ipython org urls gist githubusercontent com cemoody 01135ef2f26837548360 raw 76ce7f0bac916a516501ead719b513b22430cad0 barnes hut 20t sne 20demo ipynb bhtsne https cloud githubusercontent com assets 3419930 5566392 24d8b7dc 8edb 11e4 9e67 4f319fc6dc59 png performance this compares the timings for the barnes hut approximation against the current method note the log axis timing https cloud githubusercontent com assets 3419930 5566592 9f8ba956 8ee2 11e4 88e9 2504485f06c2 png the following diagram shows the relative speedup between both versions speedup https cloud githubusercontent com assets 3419930 5566360 f4802f94 8ed9 11e4 891c da999a0426e8 png todo create fit transform methods to update using new data add test for transform called before fit add test for skip num points raise error if method barnes hut and using sparse data raise error if method barnes hut and embedding dim transform 64bit input floats to 32bit update the narrative documentation in doc modules manifold rst add toy data to test perplexity fix failing tests expose tree consistency checks as unit tests fix memory leaks segfaults on data larger than 50k elements pep8 the code include usage documentation remove extra imports print statements pdb statements ensure python works ensure output dimensionality works for 2d or 3d am using memviews or returning full arrays appropriately incorporate into sklearn remove gil as much as possible in cython code add answer tests ensure old sne tests works changed perplexity calculation to nearest neighbors changed positive gradient calc to nearest neighbors learn you can read more about the technique in general here http lvdmaaten github io tsne the barnes hut approximation is here http lvdmaaten github io publications papers jmlr 2014 pdf >>>needs_review
error sklearn tests test pipeline test feature union parallel when test the scikit learn installation it occurs the error message like that >>>bug
inconsistency between `mode connectivity` and `mode distance` for kneighbors graph can completely understand why this happens but not sure how to handle this the nearest neighbors for sample when using `mode connectivity` includes the current sample but while using `mode distance` uses `k` neighbors does not take into account the current sample from sklearn neighbors import kneighbors graph kneighbors graph toarray array kneighbors graph mode distance toarray array background using connected components using the distance and connectivity modes give different results >>>bug
qda may meet broken 2d array sklearn version 16 git file usr lib64 python3 site packages sklearn qda py line 148 in decision function return norm2 np sum np log self scalings attributeerror numpy ndarray object has no attribute log qda py 134 self scalings np asarray scalings >>>bug
support sample weight in clusterers currently no clusterers or clustering metrics support weighted dataset although support for dbscan is proposed in 3994 weighting can be compact way of representing repeated samples and may affect cluster means and variance average link between clusters etc ideally birch global clustering stage should be provided weighted dataset and is current use of unweighted representatives may make its parametrisation more brittle this could be subject to an invariance test along the lines of there is also minor question of whether `sample weight` should be universally accepted by `clustermixin` or whether `weightedclustermixin` should be created etc sample weight support for clusterers affinity propagation don know this well enough to know the applicability birch dbscan hierarchical ward link hierarchical complete link as far as can tell hierarchical average link means minibatch means mean shift spectral>>>enhancement moderate
support approximating euclidean manhattan metrics in lshforest only cosine distance is currently supported while most neighbors algorithms assume minkowski distance euclidean this may depend on 3988 or we could replace the current hasher as default it would be really good to have this in the next release so that we can allow this to be the default >>>new_feature
support alternative metrics hashers in lshforest the lshforest implementation in scikit learn currently only supports single hasher `gaussianrandomprojectionhash` and its corresponding metric cosine distance it would be much more useful if it supported minkowski distance incl euclidean and distances facilitated by other hash functions minkowski distance might use the stable distributions technique http www immorlica com pubs pstable pdf propose the following parameters thus the auto hasher for `metric cosine might be `gaussianrandomprojectionhash 32 but user could specify an equivalent based on `sparserandomprojections` for instance the following extensions may be best implemented as separate prs for the moment we should retain the requirement that the hash be represented as 32 bit integer we should also implement the stable distributions hash or better alternative if it exists to support minkowski metrics and make this the default hasher before the next scikit learn release see 3990 very low priority in some cases calculating the exact distance in the original feature space may be waste of time while an approximate metric can be evaluated as the hamming distance between the query and returned hashes assuming all hash functions are independent which they are currently one might thus be able to set `metric approximate and rely on `hasher` to calculate the returned approximate distances this also means fit x` does not need to be stored >>>moderate
remove dimension requirement for gridsearchcv and train test split in version 15 gridsearchcv and train test split require the input arrays have the dimensions samples features neither of this functions need to have dimension requirement >>>bug
multinomialnb produces different predictions for same feature values but different label values the `multinomialmb` class can produce different predictions for the same data depending on the values of the labels assigned to the classes given from sklearn naive bayes import multinomialnb this code int print multinomialnb fit int predict produces the expected output while this code rev print multinomialnb fit rev predict produces >>>bug
regression in linearsvc it looks like there is regression in ``linearsvc`` ran the ``bench mnist py`` script in 3939 and compared it against 3204 where the main difference is that 3939 tracks master the fourier approx svm results are much worse on master and take longer on the old branch get which don get on master >>>bug
`n components` parameter seems unused in agglomerativeclustering et al the components parameter is overwritten by the number of connected components found using `sparsetools connected components` over here https github com scikit learn scikit learn blob master sklearn cluster hierarchical py l62 also the attribute `n component is almost always equal to the parameter `n component` over here unless returned by `scipy cluster hierarchy` https github com scikit learn scikit learn blob master sklearn cluster hierarchical py l248 if it is unused think we should just deprecate it >>>bug
scikit gridsearch and python in general are not freeing memory hi recently asked question on stackoverflow here http stackoverflow com questions 27508844 scikits gridsearch and python in general are not freeing memory about an issue that encountered with scikit learn `gridsearch` and memory utilization basically it allocated more and more memory the longer it runs after the job fails when it reaches the 128 gb on the system am running it on have more details written in the stackoverflow question linked above and also created github repo where put the script and data if you want to reproduce this issue https github com rasbt bugreport tree master scikit learn gridsearch memory>>>bug
accelerated coordinate descent for elastic net this contribution implements the accelerated coordinate descent method for the elastic net based on the paper fercoq richtrik 2013 accelerated parallel and proximal coordinate descent arxiv preprint arxiv 1312 5799 it does not replace the existing coordinate descent code although also propose some marginal improvements >>>needs_review
shuffle once by default in sgdclassifier like to make sgdclassifier and related models shuffle the input data by default that will make the model much more robust and make it work out of the box in many more cases and will incur basically no cost actually it should be enough to shuffle the dataset once in the beginning to get good results so was thinking about adding an option ``shuffle once `` and making this the default questions do you think shuffling by default is good idea do you think adding another option for shuffling only once makes sense if so how should it be implemented think the main downside of shuffling by default is that results are not reproducible by default that is not so nice fixing the default seed would be an option but we don usually do that for the implementation strategy ran some benchmarks here http nbviewer ipython org gist amueller 5bbbe6275ef7f94f87cb the options tried are don shuffle shuffle at each iteration shuffle once in the beginning using data copy and shuffle once in the beginning by using the dataset shuffle function it seems for more iterations doing copy pays off but the difference to shuffling at every iteration is pretty small so not sure that is enough to warrant new parameter >>>enhancement
node values at each level for decision tree using this piece of code below decision tree is generated capture https cloud githubusercontent com assets 3757165 5391580 baf90934 8142 11e4 8361 7b21cef6183a png the node values are `clf tree value` which seems incorrect shouldn the node values be the sum of child nodes something like the documented image http scikit learn org stable modules tree html classification capture http scikit learn org stable images iris svg is there way to extract accurate node values and why is there difference between generated image and the documentation image on the docs for same piece of code `sklearn version 15 >>>enhancement
pipeline doesn work with label encoder ve found that cannot use pipelines if wish to use the label encoder in the following wish to build pipeline that first encodes the label and then constructs one hot encoding from that labelling however the following error is returned it seems that the problem is that the fit method for label encoder only takes argument whereas the pipeline assumes that it will take an and an optional >>>api enhancement
mrg fix problem with non positive definite covariance matrices in gmm due to round off errors the formula used to compute the weighted covariance matrix may lead to matrices with large negative eigenvalues the formula is sum mu mu sum mu mu assuming sum and mu sum the second formula does not guarantee that is positive definite the fix may have as side effect to increase the memory consumption since new array containing the difference mu is created and may take longer to compute >>>bug
mrg refactor of sgd code to use only one call to plain sgd average sgd this code also makes all methods private and extracts the multiprocessing function into helper function also note that this does not change the functionality of the code at all it just makes it more clean and maintainable in my opinion >>>needs_review
mrg don set trailing attrs in init as said over at gh 3627 we need to fix all the init `s that set final underscore attributes some of them set those to none or similar values we should do systematic search of the codebase and introduce smoke test did just that note code uses `getattr self someattr none is none` instead of `hasattr` in an attempt to be backwards compatible with pickled estimators that have these attributes not sure how important that is who would pickle before fit and unpickling is not tested >>>needs_review
isomap has hidden randomness just got this the first time ran `nosetests sklearn manifold tests test isomap py` couldn reproduce it there no `random state` on isomap >>>bug easy
bug in plsregression when one of the columns in is constant in plsregression pls transform on the training data should yield the same scores for as returned by pls scores see example below it does when the matrix is full rank none of the columns are of constant value however when adding constant column to this stops being true which appears to be bug another way to think of this is that adding extraneous dimensions to basically embedding its data in higher dimensional space while retaining its orginal true dimensionality shouldn affect the directions obtained by pls the coefficients in the original dimensions should remain the same this is true in the pls implementation in matlab checked but not in the implementation in scikitlearn thoughts questions am copying an example below so you can reproduce it thanks dominique example >>>bug
fix enh pca and randomizedpca now have inconsistent meanings of `` components `` eickenberg introduced new api meaning of the components attribute to pca https github com scikit learn scikit learn commit 3f6c61fed71563cb91d9291d851af5fa5a662eb4 the randomizedpca code still stores whitened components instead of unit scale components this should be changed right cc agramfort ogrisel >>>api bug
sgdclassifier class weights sample weights easy one first there is an unused `class weight` parameter in the `fit` method signature `class weight` flows in through the constructor https github com scikit learn scikit learn blob master sklearn linear model stochastic gradient py l527 just to prove it from sklearn linear model import sgdclassifier from sklearn datasets import make classification from sklearn utils import compute class weight import numpy as np make classification features weights clusters per class random state 415 baseline clf sgdclassifier clf fit print clf coef 13434174 8734288 12685039 08116123 89369872 with unused fit class weight attribute clf sgdclassifier clf fit class weight auto print clf coef 13434174 8734288 12685039 08116123 89369872 now weighting the samples in different equivalent ways with auto weights clf sgdclassifier class weight auto clf fit print clf coef 10 10838607 29529238 13 14026606 99728163 65887541 weights compute class weight auto clf classes weights dict zip clf classes weights mapper np vectorize lambda weights weights mapper with manual auto weights clf sgdclassifier clf fit sample weight weights print clf coef 10 10838607 29529238 13 14026606 99728163 65887541 with manual auto weights unused fit class weight attribute clf sgdclassifier clf fit sample weight weights class weight auto print clf coef 10 10838607 29529238 13 14026606 99728163 65887541 all fine so far but if you do both `class weight` in the constructor and `sample weights` in the fitting the resulting weights appear to be multiplicative with manual auto weights squared clf sgdclassifier clf fit sample weight weights print clf coef 22495438 14 11510502 58504094 38631993 55338404 with auto weights manual auto weights multiplicative clf sgdclassifier class weight auto clf fit sample weight weights print clf coef 22495438 14 11510502 58504094 38631993 55338404 whether this is desirable or not is one thing but it does not appear to be documented anywhere ie neither `class weight` nor `sample weight` refer to one another in their docstrings feel like perhaps warning or error should be raised or at least mention of the interaction in the docstring >>>bug
improve guide to contributing don think the contributor guide http scikit learn org dev developers index html at present is very easy to read and it should contain bit more on certain matters at the moment it is mostly focused on technical how tos the main additional things to get across are what belongs in scikit learn and what doesn and if something doesn where can it go this may belong on separate page more ways to contribute what makes good code contribution the pull request process this needs to be concise as possible one stop shop for the hundreds of requests to contribute would like to see the guidelines have shape like the following scikit learn scope this may belong in the contributor guide or may belong elsewhere in the documentation new about the project or in the faq in any case it should be referenced from the contributor guide well established algorithms and occasionally recent variants of well established algorithms to be mostly usable out of the box in distinction to pylearn2 et al specifically for ml problems whose targets have minimal structure binary regression multiclass multilabel and multitask problems from more or less flat feature vectors these all involve sometimes spare arrays as input and targets ways to contribute this is already mostly there but needs some reordering it needs to begin with an emphasis on how overtasked the core developer group is and how important it is to help complete existing highlights contributor competence leading way for larger contributions reporting bugs easy issues and how to adopt an issue finding and adopting stagnant pull request pr perhaps look for old wips new features see scope and discussion of contributions below first suggest following mailing list documentation examples testing and improving consistency reviewing an extremely valuable contribution after showing you are familiar with what makes good contribution spreading the word how to contribute the pull request process perhaps adopting an issue wip status mrg status mrg mrg adding to what new refinement and rebasing along the way the ideal code contribution well written clear and reasonably efficient code consistent with the project style tests that ensure it works understandable complete docstrings narrative documentation in the user guide examples that highlight interesting features of the algorithm how to inspect its model and how to interpret its hyperparameters code management git coding guidelines api design documentation guidelines>>>documentation moderate
plsregression uses incorrect naming for model attributes `coefs` should be `coef deprecation with `property` may be necessary>>>easy
improve the pdf rendering of the documentation this is sequel to 3830 those are improvements identified by jnothman to improve the pdf output of running the `make latexpdf` command in the doc folder there is couple of useless blank pages before the first chapter there should be table of contents there seem to be many chapters that should really be sections of other chapters the one on fetching covertype changelong entries what would be thumbnails corresponding to examples on the web site show up as duplicated images in the examples themselves as well as as in the examples associated with each class function in the reference assume within documentation references should be hyperlinked but do not seem to be in cases where ve looked >>>documentation enhancement
invariance testing for partial fit much of the common functionality across estimators is tested within `sklearn tests test common` as far as can tell there are no tests of what `partial fit` should do in general such as returning `self` not sure what else is general to all estimators supporting `partial fit` test should be added >>>easy
landscape io for code quality what do you think of using landscape io to track code quality has anybody already tried it here an example of usage for python project https landscape io github cokelaer pypiview 9>>>build_/_ci
mrg add feature extraction columntransformer fixes 2034 todo docstrings simple example test documentation test feature names also see here http zacstewart com 2014 08 05 pipelines of featureunions of pipelines html for how this would help people >>>needs_review
mrg matern kernel add matern kernel to the kernels in pairwise py the matern kernel https en wikipedia org wiki mat c3 a9rn covariance function and rasmussen and williams 2006 pp84 is generalization of the rbf and the absolute exponential kernel with an additional hyperparemeter nu which allows interpolating between these two rbf nu inf absolute exponential nu in contrast to the rbf kernel it makes less strict assumptions on the smoothness of the function to be learned this is shown in an example for step function for different values of nu figure https cloud githubusercontent com assets 1116263 5189587 64c46cb2 74df 11e4 9b94 684e9751bc78 png todos support for arbitrary values of nu coef0 tests>>>needs_review
dbscan documentation suggestions for parallel processing think it is worth adjusting the dbscan documentation to note that if you ask dbscan to calculate pairwise distances for you then it will do so using only one core if you want to take advantage of multiple cores you should pre calculate distance matrix using `pairwise distances jobs and then run dbscan with your pre calculated distance matrix >>>documentation
fix broken examples reported when building the documentation when building the documentation of the current master we get the following failures >>>bug easy
bug in metrics roc auc score pred 1e 10 sol metrics roc auc score sol pred wrong is correct pred sol metrics roc auc score sol pred correct>>>bug
onevsoneclassifier fit returns error when is list hi all if you pass as list the next error appears typeerror only integer arrays with one element can be converted to an index the error goes away when you pass as numpy array however shouldn this be either taken care of in the code check whether is numpy array or list or display warning just saying thanks >>>bug easy
resampler estimators that change the sample size in fitting some data transformations including over under sampling 1454 outlier removal instance reduction and other forms of dataset compression like that used in birch 3802 entail altering dataset at training time but leaving it unaltered at prediction time in some cases such as outlier removal it makes sense to reapply fitted model to new data while in others model reuse after fitting seems less applicable as noted elsewhere https github com scikit learn scikit learn pull 1454 issuecomment 11313359 transformers that change the number of samples are not currently supported certainly in the context of `pipeline`s where transformation is applied both at `fit` and `predict` time although hack might abuse `fit transform` to make this not so `pipeline`s of `transformer`s also would not cope with changes in the sample size at fit time for supervised problems because `transformer`s do not return modified `y` only `x` to handle this class of problems propose introducing new category of estimator called `resampler` it must define at least `fit resample` method which `pipeline` will call at `fit` time passing the data unchanged at other times for this reason `resampler` cannot also be `transformer` or else we need to define their precedence for many models `fit resample` needs only return `sample weight` for sample compression approaches that in birch this is not sufficient as the representative centroids are modified from the input samples hence think `fit resample` should return altered data directly in the form of dict with keys `x` `y` `sample weight` as required it still might be appropriate for many `resampler`s to only modify `sample weight` if necessary another `resampler` can be chained that realises the weights as replicated or deleted entries in `x` and `y` >>>api new_feature
allow connectivity in structured clustering to be callable scikit learn hierarchical clustering supports only considering the locality of each point as defined by connectivity matrix nearest neighbors graph https github com scikit learn scikit learn blob master examples cluster plot agglomerative clustering py l50 might be good connectivity matrix without other knowledge the current approach of supplying connectivity matrix means that it cannot be used in pipeline that alters the nearest neighbors space and certainly not one that alters the number of samples as in birch global clustering hence it should be possible to supply `connectivity` as callable such that `connectivity returns sparse connectivity matrix alternatively we could allow connectivity to be an integer and `kneighbors graph` can be applied directly >>>easy enhancement
bug cross val score ignores scoring when estimator is gridsearchcv object when call cross val score with gridsearchcv object you can see this as nested cross validation the scoring value is systematically ignored take for example the following code np random randn 100 10 np random randn 10 dot alphas np logspace 10 clf grid search gridsearchcv linear model elasticnet alpha np logspace scores cross validation cross val score clf scoring mean absolute error jobs print scores since the scoring function is mean absolute error the values should be negative however what get is 99999806 99999758 99999911 which corresponds to the scoring function r2 the default this happens because cross validation score is not able to find the predict method in the gridsearchcv object that is the test hasattr clf predict in check scoring fails the interesting thing is that the gridsearchcv object does define predict method in basesearchcv only that as property and thus the hasattr method fails >>>bug
add examples to class docs most of the docs in classes lack examples it would be great to add one or two examples similar to this http scikit learn org stable modules generated sklearn linear model lasso html>>>easy
sklearn tree decisiontreeclassifier documentation of max depth parameter the description of the max depth parameter states that this parameter is ignored if max samples leaf is not none what is max samples leaf should this be min samples leaf >>>bug documentation
fetch 20newsgroups failed http error 500 internal server error when try to follow the tutorial of the text analysis got this error have check the internet can download the gzipped data file manually from http people csail mit edu jrennie 20newsgroups 20news bydate tar gz but it seems when run fetch 20newsgroups always failed at urlopen url >>>bug
apply method for trees think it would be nice to add an ``apply`` method to the tree currently there is one in the randomforest but not in the tree there is one in ``tree tree `` but the tree object is not publicly documented think the idea was that we might want to change the structure of the tree object so we don make it public still we could provide public interface to the lower level functions so that people might find them more easily opinions >>>easy enhancement
fix broken pdf generation for the documentation the documentation for this project looks fantastic new to ml but love to have pdf copy of the docs which can read along with text books on the subject just spend half day trying to do make latexpdf only to find out that pdf functionality hasn worked in over year can you please just provide pdf copy of the manual and save lots of people lots of time and frustration even the sourceforge email lists are full of people asking for the pdf >>>bug moderate
log responsibilities in gmm hello the current implementation of `gmm score samples` https github com scikit learn scikit learn blob master sklearn mixture gmm py l277 computes log responsibilities exponentiates them and then returns only the exponentiated version wonder if there is there reason for that having way to extract log responsibilities might improve the accuracy of more complex models built on top of `gmm` for example `gmmhmm` https github com hmmlearn hmmlearn blob master hmmlearn hmm py l1209 >>>enhancement
loading my own datasets hi all am very new in scikit learn my questions is how to download my own dataset csv file will be highly appreciated any answers thanks martin>>>documentation question
mrg store kl divergence after optimization in sne this pr is based on 3422 from joker0x5f5f and fixes this issue http datascience stackexchange com questions 762 which unfortunately has not been reported here additionally renamed the `error to `kl divergence because error is term that might confuse users maybe cost would be better name and added test that requires the attribute `tsne kl divergence >>>needs_review
hierarchical clustering distance threshold so the output of hierarchichal clustering results can be determined either by number of clusters or by the distance thereshold to cut the tree at that threshold however scikit learn only supports one way class sklearn cluster agglomerativeclustering clusters as suggestion is it possible to add the other option to give distance threshold as input argument and get as many clusters are created in the output so one of this argument should be given either clusters or the threshold not both >>>new_feature
consistency in documentation think common things in documentation should be written in consistent way right now can think of the following points whether to name entities which can be transformed to `ndarray` as `array` or `array like` how to list different input options should curly braces always be used for example array like sparse matrix optional arguments default values some convention should be adopted like kernel string default rbf or kernel string default rbf the word `optional` should be dropped anyway as redundant how to name `x` and `y` arrays in `fit` and `predict` methods the one adopted convention would be helpful how to mention shapes of arrays was told that `x shape samples features was adopted is it true how about arrays samples or samples anyway do you think it is an issue at all maybe core developers could decide and update coding guidelines listed only some points >>>documentation
wip adds support for sample weights in median absolute error adds support for sample weight in median absolute error issue 3450 >>>needs_review
mrg doc fix support python and in gen rst py the encoding if not specified used by `open` in python is platform dependent on my windows machine it is `cp1251` so had troubles building docs with the example gallery because of that some examples contain non ascii characters think setting it explicitly to `utf 8` is good thing >>>bug
ensemble models and maybe others don check for negative sample weight when sample weights are negative the probabilities can come out negative as well >>>bug
possible memory leak for ridge solvers running into some memory issues with the linear model ridge class in short when fitting ridge with the lsqr or sparse cg solver getting large memory increases when doing the fitting in loop in cross validation the peak memory used is roughly linear with the number of repetitions in the loop here quick gist http nbviewer ipython org gist choldgraf 6a7be7866f2a3a3d3f98 to show what talking about >>>bug
mrg fix kneighborsregressor and radiusneighborsregressor returning nan predi `kneighborsregressor` with distance weighting will predict `nan` if the data to predict on happens to match data point from the training set this actually happened to me with some data from kaggle competition for example from sklearn import neighbors import numpy as np np array np array clf neighbors kneighborsregressor neighbors weights distance clf fit print clf predict the output is `nan` this seems like undesirable behavior would have expected `pred` to be `1 0` in addition `radiusneighborsregressor` suffers from this problem note that the infinities are already handled properly by `kneighborsclassifier` and `radiusneighborsclassifiers` for example from sklearn import neighbors import numpy as np np array np array clf neighbors kneighborsclassifier neighbors weights distance clf fit print clf predict this outputs `1` as expected this pull request is my proposed solution note that if there are two points with distance it chooses one of them which is consistent with the warning given in the kneighborsregressor docs http scikit learn org dev modules generated sklearn neighbors kneighborsregressor html this is my first pull request for any project so let me know if doing something wrong >>>bug
fix fixing issue 3550 hard clamping fixing issue 3550 >>>bug
nested parallelism hi wanted to bring up an issue with the parallel execution model of scikit learn that has bitten me numerous times often find myself wishing to run sklearn task that can be parallelized with jobs however may wish to run the task itself in parallel with even more tasks an example of this is running grid search on multiple different training sets at once or with different cv generators or may wish to run validation curves on multiple different parameters at once this isn currently possible because you can kick off joblib parallel inside of subprocess in some cases it makes sense to simply break the tasks out into separate programs however often that breakdown doesn make sense and it would really be best for the code if it could all be part of the same program the workaround have used is to reimplement various parts of the sklearn internals in such way that rather than create all the joblib delayed jobs and execute them with joblib parallel in the same place create the jobs in one place and return them and then collect each task delayed jobs and run them together under one parallel outside then take the results of the completed delayed jobs and send them back into their respective tasks to be aggregated and processed so my question is would there be interest in adding this capability to sklearn think basic pattern of providing an option to either return the completed results or delayed jobs result aggregator function tuple would go long way would be interested in working on the pull request for it if there was interest in such thing thanks dan spitz>>>new_feature
change the format of displayed results in classification report it is not possible to display more digits with classification report the format string is hardcoded https github com scikit learn scikit learn blob 4d9a67f77787ffe9955187865f9b95e19286f069 sklearn metrics metrics py l2062 it would be convenient to make this value to parameter >>>easy enhancement
mrg fix preprocessing scale for arrays with near zero ratio variance max fix 3722 prolongating 3725 >>>bug
initialize the code book for multiclass problem just looked at the implementation of outputcodeclassifier for multiclass problem the process for randomly initializing the code book is bit buggy it should be fine if code size is big but when code size is relatively small for example classes code size the only possible code boos is it is very easy to have same binary code for the two different class here if using randomly initialization think it should be an easy fix but there should be some restriction on the output codebook otherwise it could have many possible choices like to hear some suggestion about what kind of code book would be desirable for example the one restriction can think of is that for each column number of and should not differ more than this makes sense because for the binary problem of each column would be relatively balanced in terms of number of classes in and and it make the codes for classes spread over the code space which makes the method of finding the best classes for output by minimzing euclidean distances more reasonable >>>enhancement
should gradientboostingregressor staged predict really modify the array it yields in place recently made the extremely frustrating discovery that this method yields references to single array which is modified in place as each element is yielded for example returns 2d arrays with all elements fixed along the first axis even if the staged predictions are different understand why mutation may be desirable for performance reasons but from the perspective of someone trying to use staged prediction to understand my model found this very surprising thought there was something wrong with how was using gradient boosting at minimum this should be clearly documented but if for some good reason this behavior cannot be changed my preferred resolution would be to add backwards compatible keyword argument such as `copy false` or `inplace true` so that this unintuitive behavior is clearly called out in the method signature thoughts >>>bug
mrg svd implemented svd algorithm as free function notes questions haven done any optimizations yet but left todo notes in places where it can be done am going to profile the code later and see where if the optimizations are necessary the algorithm currently uses omp as sparse coder and it is possible to make it customizable however this will make the function interface more complicated as different sparse coders have different parameters should do it or should leave it like this there are now no unit tests for the implementation but am bit confused on how to create them for such functions should just check the api and simple functions like worst represented example` >>>needs_review
dbscan clustering of string data so want to use the dbscan clustering algorithm from scikit learn on dataset of string charcaters so used metric levenshtein distance and my data is given in numpy array but why it wants to convert them to float am using the following packages and my data shape and dbscan object is defined as below >>>enhancement
bug cross validating gridsearchcv object while preparing the slides for the defense of my thesis encountered what seems to be quite serious bug in gridsearchcv basically wanted to do model selection inside cross validation loop in order to have an unbiased estimate of the generalization error of my selected model so did something like the first estimate on the first fold is correct the following are obviously wrong they should be positive >>>bug
minor doc improvement for nearest neighbors currently sections and of the docs nearest neighbors kdtree and balltree contains links to the docs to the kdtree and balltree classes respectively but both of these pages are essentially empty except for the comment that they are both aliases for binarytree which is quite confusing as they are afaict different and binarytree isn even documented either >>>documentation
installation for scikit learn 15 failing while installation get the following error during python setup py build error is may know what is the problem and how to sort it out thanks mradul>>>bug build_/_ci
mrg fix nearly zero division fixes 3722 separate reset zero to function from mean and std add replace nearly value function with` isclose nealy zero values also replaced to add floating point error testcase>>>bug
preprocessing scale provides consistent results on arrays with zero variance using python numpy and scikit learn 14 on x64 linux all installed through anaconda and getting very inconsistent results for preprocessing scale function print preprocessing scale np zeros np log 1e print preprocessing scale np zeros np log 1e print preprocessing scale np zeros 22 np log 1e would guess this is not is supposed to be happening quick investigation points to the fact that np std of second and third array is not exactly zero but very close to machine zero sklearn still uses it to divide data it doesn go into the std case in the code note that in the case of the array this can be easily fixed by passing with std false but when that happens for one of the many features in 2d matrix this is not an option >>>bug easy
qda crash due to nans from svd reported on so http stackoverflow com 26107930 166749 can cause `qda` to crash the problems is in the `scalings attribute which can take the form the bug doesn show up every time even when fix the random seed so it probably randomness instability inside `np linalg svd` >>>bug
make latexpdf error when run the command make latexpdf in the terminal of ubuntu 13 10 there are something wrong don know how to deal it please give me some help thx >>>bug documentation
explicit error message in adaboost if sample weight not supported in adaboost if the base estimator doesn support sample weight the error message is not very explicit for beginners in machine learning or people who didn read the documentation we should raise more explicit message like base estimator weak learner doesn support sample weight the following line in bagging py could be refactored into an utility function `has sample weight` https github com scikit learn scikit learn blob master sklearn ensemble bagging py l50>>>easy
ridge solver svd is broken on sparse inputs here is test case that reproduces the problem numpy scipy sklearn current master 556903597a0e64f94830b3f0153531ee7b7adeb3 from scipy import sparse as sp import numpy as np from sklearn linear model import ridge sp csc matrix np random rand 100 10 np random rand 100 est ridge solver svd est fit linalgerror dimensional array given array must be at least two dimensional >>>bug
sample weight for lasso elastic etc am using lasso for time series data and would like to decay old data with weight vector any reason why this is not available for lasso meanwhile if fit lasso with dot sqrt diag weights and dot sqrt diag weights would it mean the same thing thanks >>>enhancement
onevsrestclassifier predict proba method does not return probability values for all the classes sklearn classifier predict proba method does not return the probabilities for all the classes am running python and scikit learn 15 consider the following code now run the following command sequence under python interpreter console ovr classes you get as output array one two dtype u3 next execute ovr predict you get as output array one dtype u3 next execute ovr predict proba you only get as output array clearly the probability value for the class two is missing from the output this causes the problem for downstream code to know which classes are present in the output we typically assume probability values even if some are for all the classes are present what is the way out >>>bug
pca complexity formula in decomposition reference documentation http scikit learn org stable modules decomposition html it is stated that the complexity for the regular pca is which becomes for typical setting where there is more sample than feature considering pca only requires to work on the covariance matrix nfeatures nfeatures which construction cost is isn the squared nmax an error >>>documentation question
balanced shuffle folds hi was wondering whether there was an in built function to make fold cross validation where each class is artificially equalized within the training and optionally the testing set train test know it not optimal to throw some data out and we should favor stratified foldings but some do sometimes want to get chance level at 50 if this feature do not already exist do you think it be better to add it as an option in stratifiedkfold and stratifiedshufflesplit or do you think separate function would be more appropriate thanks >>>new_feature
sklearn utils shuffle can shuffle arrays with ndim sklearn utils shuffle can no longer be used to shuffle arrays with ndim since it more precisely it and resample which it calls provides no way to pass the allow nd flag to check arrays sklearn utils init py 245 >>>bug easy
test transformers numerically unstable tests fail on 64 bit python this bug has been reported in other cases 3255 1826 1838 but reported as limited to 32 bit python see specifically 3255 and justification for closure scientificlinux 64 bit gcc python numpy built against mkl 10 scipy 14 scikit learn 15 >>>bug
website typo for isomap reference hi there is formatting typo in the references section of http scikit learn org stable modules generated sklearn manifold isomap html think the problem is that on line 75 of the isomap implementation https github com scikit learn scikit learn blob 1491c1cd065f2f620ce770b3540697b87fc192ea sklearn manifold isomap py l75 the doc string has multiple lines when the one reference should on one line >>>documentation easy
test libsvm iris fails on windows for instance in this build https ci appveyor com project sklearn ci scikit learn build 151 job xnjw15iyoun3r00w this is strange as this test used to pass on the same platform and the first commit that triggered the failure seems to be unrelated to libsvm https ci appveyor com project sklearn ci scikit learn history https github com scikit learn scikit learn commit d34e928059ca320f50d8c1ff7c372d5bfe514555>>>bug build_/_ci
mrg added metrics support for multiclass multioutput classification fix for 3453 ping arjoly added support for `zero one loss` and `accuracy score` >>>needs_review
svr documentation have classification parameters attributes as far as know svr is regression model nevertheless many parameters are about classification such as probability parameter intercept attribute this is really confusing especially for new user >>>bug documentation
linearregression should have the jobs parameter from fit in the constructor in order to solve this issue one would have to deprecate the paramter from the fit and add it to the constructor >>>api easy enhancement
altering precision recall fscore support docstring if the labels are unsorted and precision recall fscore support is used with multilabel classifications it will raise an exception raises also afaict the labels do not need to be integers >>>bug
isotonicregression is not pickleable import pickle from sklearn import isotonic est isotonic isotonicregression np random rand 100 np random rand 100 est fit pickle dumps est typeerror can pickle instancemethod objects >>>bug
document negation of loss functions used as scoring parameters https github com scikit learn scikit learn blob master doc modules model evaluation rst should specify that loss metrics greater is worse are negated when used via `scoring` in cross validation see for example 3660 >>>documentation easy
efficient grid search for random forests to get the best performance off random forests it is necessary to tune parameters like `max depth` `min samples split` and `min samples leaf` if we wrap rf in gridsearchcv trees are built from scratch every time however for depth first tree induction deeper trees share the same base as shallower trees an idea to speed up grid search is thus to not rebuild trees from scratch every time here an example for `max depth 10 set `max depth 10` build `n estimators` fully developed trees prune trees to have maximum depth of `max depth` create rf for this `max depth` and evaluate it using the current train test split decrease `max depth` and go to step such an algorithm could be wrapped in `randomforestclassifiercv` `randomforestregressorcv` classes >>>enhancement
mle for theta in gaussianprocess unreliable the maximum likelihood extimate for theta sometimes produces results that look very unreasonable even trying to fit very simple smooth curve it fails sometimes for example sin divisor where is in 10000 changing the divisor from 636 06767 to 636 06768 changes the mle for theta from to 632 here is the code to reproduce this import numpy as np import sklearn from sklearn gaussian process import gaussianprocess def compute fit divisor np linspace 10000 11 np sin divisor np atleast 2d gp gaussianprocess theta0 thetal 0001 thetau 1000 gp fit theta gp theta return theta gp reduced likelihood function value print sklearn version sklearn version for in 500 636 636 06767 636 06768 637 1000 theta like compute fit print ttheta likelihood theta like python prob py sklearn version 15 500 	theta 632 455532034 likelihood 636 	theta 632 455532034 likelihood 636 06767 	theta 632 455532034 likelihood 636 06768 	theta 47584723676 likelihood 983409372837 637 	theta 18740741469 likelihood 976101646893 1000 	theta 873105480722 likelihood 0844448086551 >>>bug
failing tests on the armel platform apparently on the armel division by zero is not detected by numpy even within `with np errstate all raise block this makes tests in the sklearn suite fail https buildd debian org status fetch php pkg scikit learn arch armel ver 15 stamp 1410187161>>>bug
error in test sklearn linear model tests test base in 15 have found an error when running the tests of 15 it happens both with python and python the problematic test is in `sklearn linear model tests test base` have the following packages numpy 0rc1 scipy 14 in testing in fedora system so numpy and scipy are both precompiled rpms sklearn compiled from the tarball from pypi nosetests v2 sklearn linear model tests test base usr lib64 python2 site packages scipy sparse linalg isolve lsqr py 435 runtimewarning invalid value encountered in double scalars test2 arnorm anorm rnorm error test that linear regression also works with sparse data traceback most recent call last file usr lib python2 site packages nose case py line 197 in runtest self test self arg file home xxx local lib python2 site packages sklearn linear model tests test base py line 78 in test linear regression sparse ols fit ravel file home xxx local lib python2 site packages sklearn linear model base py line 359 in fit out lsqr file usr lib64 python2 site packages scipy sparse linalg isolve lsqr py line 436 in lsqr test3 acond zerodivisionerror float division by zero ran 10 tests in 052s failed errors >>>bug
orthogonal mp doesn respect return path sklearn linear model omp orthogonal mp doesn propagate the return path flag to orthogonal mp gram when precompute is true https github com scikit learn scikit learn blob master sklearn linear model omp py l364>>>easy
sparse matrix error for adaboot the docs say that sparse matrix can be csc csr coo dok or lil dok and lil are converted to csr for the fit function but it appears that type error is given when lil matrix is passed >>>bug documentation
hashingvectorizer tfidftransformer fails because of stored zero reported on so http stackoverflow com 25650601 166749 crashes with `valueerror` the problem is that the sparse matrix contains stored zero which becomes inf` in the sublinear tf transformation and that causes normalization to fail the position changing seems to have to do with unsorted indices in the matrix >>>bug
unstable test gaussian process py test random starts under 32 bit python on windows fail test that an increasing number of random starts of gp fitting only traceback most recent call last file python27 32 lib site packages nose case py line 197 in runtest self test self arg file python27 32 lib site packages sklearn gaussian process tests test gaussian process py line 166 in test random starts assert true rlf best likelihood assertionerror false is not true >>>build_/_ci
jobs support in gradientboostingclassifier the following loop is embarrassingly parallel https github com scikit learn scikit learn blob master sklearn ensemble gradient boosting py l552 edit ogrisel removed the easy tag and put moderate tag instead based on the discussion below the most beneficial way to add `n jobs` support for gbrt would be deep inside the cython tree code to benefit gb regression and adaboost models as wells instead of just gb classification >>>enhancement moderate
should have explicit error message when estimator fit had not been called calling `predict` `transform` etc on an estimator that first requires `fit` often results in an `attributeerror` `coef attribute not found more appropriate error message and perhaps error class should be raised along the lines of b1119bb https github com jnothman scikit learn compare scikit learn master jnothman unfitted error includes some basic tests for most scikit learn estimators but currently many estimators fail working from that branch and modifying the tests if necessary appropriate exceptions should be raised in the remaining estimators >>>moderate
broken handling of numeric data with dtype object this is clarification of the issues in 3616 in some cases notably where feature `series` are mix of boolean and non boolean pandas will produce numeric data with dtype object the handling of such data is currently untested in scikit learn and results in quirks it should either result in specific error messages or be accepted and handled correctly 3616 raises two issues `linearmodel decision function` and `predict` for regressors will output dtype object for similar input despite the precision of the output being limited by `coef anyway regression metrics may break with cryptic errors given dtype object input>>>moderate
cross val score can handle type float when scoring parameter is given was working with pandas and sklearn modules and tried using the following with feature vec and result vec both being pandas dataframes got the following error after quite few hours of debugging tried to convert the dataframe to ndarray but got the same error and then looked at the type of individual datapoints and compared them to types that are known to function properly turns out that the type of my data was float while the type of data known to function properly was numpy float64 so then changed my command to and that fixed the problem it seems that the cross val score should detect and fix this automatically >>>bug
sklearn utils validation check array check have undocumented parameters>>>documentation easy
onehotencoder dtype being ignored when values auto easiest to explain in code na preprocessing onehotencoder dtype np float16 fit transform np array self assertequal np float16 na astype np float16 dtype self assertequal np float16 na dtype fails na dtype is float32 >>>bug
mrg label encoder unseen labels this is pull request to adopt the work done by mjbommar at 3483 this pr intends to make preprocessing labelencoder more friendly for production pipeline usage by adding new labels constructor argument instead of always raising valueerror for unseen new labels in transform labelencoder may be initialized with new labels as none current behavior raise valueerror to remain default behavior update update classes with new ids for new labels and assign an integer value set newly seen labels to have fixed value corresponding to this integer value add classes parameter to transform function classes parameter during initilization >>>needs_review
scikit learn should not have strong dependency on nose on new virtualenv without nose installed get with scikit learn 15 >>>bug easy
python incompatibility when fetching joblib compressed datasets for instance when running python script that loads the olivetti dataset when it has already been loaded with python in the past this should be fixed upstream in joblib but it good to track the issue here as well for discoverability >>>bug
face recognition example is broken when executed without alteration the example code here http scikit learn org stable auto examples applications face recognition html throws an exception have confirmed that the images downloaded successfully using python sklearn 15 numpy scipy 13 python face recognition py faces recognition example using eigenfaces and svms the dataset used in this example is preprocessed excerpt of the labeled faces in the wild aka lfw http vis www cs umass edu lfw lfw funneled tgz 233mb lfw http vis www cs umass edu lfw expected results for the top most represented people in the dataset precision recall f1 score support gerhard schroeder 91 75 82 28 donald rumsfeld 84 82 83 33 tony blair 65 82 73 34 colin powell 78 88 83 58 george bush 93 86 90 129 avg total 86 84 85 282 2014 08 26 13 30 49 451 loading lfw people faces from home jim scikit learn data lfw home 2014 08 26 13 30 49 454 loading face 00001 01140 traceback most recent call last file eigenface py line 52 in lfw people fetch lfw people min faces per person 70 resize file usr local lib python2 dist packages sklearn datasets lfw py line 277 in fetch lfw people min faces per person min faces per person color color slice slice file usr local lib python2 dist packages sklearn externals joblib memory py line 481 in call return self cached call args kwargs file usr local lib python2 dist packages sklearn externals joblib memory py line 428 in cached call out metadata self call args kwargs file usr local lib python2 dist packages sklearn externals joblib memory py line 673 in call output self func args kwargs file usr local lib python2 dist packages sklearn datasets lfw py line 202 in fetch lfw people faces load imgs file paths slice color resize file usr local lib python2 dist packages sklearn datasets lfw py line 156 in load imgs face np asarray imread file path slice dtype np float32 indexerror arrays can only use single or list of newaxes and single as an index>>>bug easy need_contributor
divide by zero error encountered in log when use lassolarsic with small number of samples get the following warning think the problem is here https github com scikit learn scikit learn blob master sklearn linear model least angle py l1290 perhaps some care should be taken when mean squared error >>>easy
need example of heterogeneous input with featureunion pipeline structure many users have asked about handling heterogeneous input an image with text for which `featureunion` consisting of multiple `pipeline`s each operating over different input field can be exploited users would be assisted by an example of how to do this sort of thing >>>documentation easy
link error on windows when recomiling and linking the code find some error like this os windows7 64bit python 32bit vc 2008 express version >>>build_/_ci
wrong docstring for tree value the documentations says value array of double shape node count outputs contains the constant prediction value of each node but it seems that `value` is 3d array what does the 3rd axis correspond to https github com scikit learn scikit learn blob master sklearn tree tree pyx l2205>>>documentation
featureselector for pipeline new feature hi was wondering if it would be worthwhile to add simple `featureselector` class that can be used in scikit `pipeline` for example if user wants to select particular columns useful for cross validation for example and compare it against feature selection techniques etc clf1 pipeline steps scaler standardscaler reduce dim featureselector cols select feature and classifier gaussiannb clf2 pipeline steps scaler standardscaler reduce dim pca components classifier gaussiannb the code could be as simple as import numpy as np class featureselector object def init self cols self cols cols def transform self none col list for in self cols col list append return np concatenate col list axis def fit self none return self ps how would add label to this issue track read in the scikit doc that labels are recommended >>>new_feature
blocked shufflesplit functionality was wondering if anyone would find use in some kind of blocked shufflesplit functionality in sklearn to my knowledge one is only able to shuffle then split set of indices however there are many times that want contiguous data points to remain close to one another if modeling time series to that extent usually want to do something like shuffling in blocks such that timepoints that are right next to each other don end up in the train and test sets wrote quick and dirty script to do shufflesplit in blocks and wonder if others would find this useful basically imagining two options blockshufflesplit in block 10 block indices none in block this would specify the size of blocks the input indices would then be grouped into blocks of this size then the block labels would be shuffled block indices this would be an array of size that would let the user specify custom set of block indices if ve got 100 length set of indices that contains 10 trials of variable length could give the exact trial indices with this parameter and block shuffling would always keep trials together granted some splitting would still occur wherever the train test split happened if it happened in the middle of block but it still better than just shuffling everything together imagine there be some other challenges as well but wanted to throw this idea out there in case anyone thinks it be useful image https cloud githubusercontent com assets 1839645 3912952 82eb0864 2330 11e4 9c73 b9c786bb3185 png and setting in block to would yield the same as shufflesplit image https cloud githubusercontent com assets 1839645 3912959 975a5b9c 2330 11e4 8dea 2067e2a24a20 png >>>new_feature
support sparse targets as output from make multilabel classification scikit learn has changed from an inefficient list of lists sparse representation for multilabel data to using scipy sparse matrices `sklearn datasets make multilabel classification` currently supports the old format and dense format it should also support the new sparse format >>>easy
not saving indices in ensemble py when constructing the estimators in parallel build estimators` the code save which samples where used `estimators samples append samples however in the case of boostraping when one example may be used more than once that information is not stored since so you cant actually reconstruct the estimator glouppe >>>enhancement
labels don stay clamped in labelpropagation in some cases the labels don stay clamped in labelpropagation for example think the problem occurs in label propagation py https github com scikit learn scikit learn blob master sklearn semi supervised label propagation py at line 235 https github com scikit learn scikit learn blob master sklearn semi supervised label propagation py l235 and line 249 https github com scikit learn scikit learn blob master sklearn semi supervised label propagation py l249 when alpha is equal to static is set to in line 235 https github com scikit learn scikit learn blob master sklearn semi supervised label propagation py l235 and then line 249 https github com scikit learn scikit learn blob master sklearn semi supervised label propagation py l249 doesn change self label distributions whereas it should clamp the values of the labelled data points my understanding from the documentation http scikit learn org stable modules label propagation html is that for labelpropagation it is always supposed to do hard clamping and thus it should be completely independent of alpha not actually sure what the intention was here since the same fit method is used for labelspreading >>>bug
enh add parameter pmax that is present in glmnet glmnet has parameter called `pmax` that limits the non zero coefficients which would help lot in the sparse case with l1 norm was wondering if we needed to add this parameter to elasticnet in sklearn >>>enhancement
orthogonalmatchingpursuitcv errors in test regressors the errors in orthogonalmatchingpursuitcv on travis have returned in test regressors think the new filtering way to do the skip check must be lacking something cc amueller ogrisel >>>bug build_/_ci
parallelise nearest neighbors methods the knn data structures kdtree balltree could perform queries in parallel or at least enable multithreading by releasing the gil within their methods >>>enhancement moderate
bug in sklearn manifold tsne it looks to me there an issue when using some distance different from euclidean in tsne implementation example in fact at lines 438 439 of sklearn manifold sne py function fit read distances pairwise distances metric self metric squared true which means that it always provides squared argument to pairwise distances now not all the distances support this see sklearn metric pairwise py which leads to an error report this as an issue because in sne py from line 338 it says if metric is string it must be one of the options allowed by scipy spatial distance pdist for its metric parameter or metric listed in pairwise pairwise distance functions suggest to substitute line 438 with something like but quite sure it not as simple as that don for example understand why the author wanted squared true cheers>>>bug
problem with setup py on osx hi tried to install scikit learn on osx but got this error >>>bug
mrg enh faster low memory polynomialfeatures this is an alternative to 3512 for fast and low memory `polynomialfeatures` it makes use of the powers matrix sparsity and uses logarithmic space so that sparse matrix multiplication can be used the alternative in 3512 saves time and memory by processing each sample at time in python for loop have marked this wip as in some cases binary valued features float typed output as required for logarithmic calculations isn ideal the docstring tests are failing for this reason testing of return values and their dtypes is needed we might now consider accepting some sparse input but that may be up for debate left for another pr has potential to make messy code >>>enhancement
gbrt failed if fitted twice with warm start true and constant estimators here the script to reproduce would have expected warning or nothing as in the random forest module ping pprett >>>bug
polynomial features memory usage hi guys after having lot of memory issues with polynomialsfeatures modify the transform function in order to significantly decrease the memory consumption in the example file the memory consumption of the old and proposed transform functions are compared the results shown that for the example below the memory consumption decreases from 3455 mib to 374 mib without increasing the execution time did not know how to erase transform old and make the tests at the same time new tests and comparison with 3514 compare the results time and memory of the original 3514 and 3512 method time memory initial 75 3701 55 mib 3514 26 753 88 mib 3512 10 175 12 mib change in 3512 is less but involve using other than that is question of preferring less memory or time >>>enhancement
inconsistent mulit label predict proba the output shape for multi label predict proba is inconsistent the onevsrest classifier produces samples classes like multi class where for example randomforestclassifier produces list of probabilities per label which are each samples or samples not sure how to do deprecation for that but we should do common test for whether classifier supports multi label and what the output shapes are >>>api bug
add balanced accuracy score metrics there have been some discussion about adding balanced accuracy metrics see this article for the definition http en wikipedia org wiki accuracy and precision on the mailing list this is good opportunity for first contribution this implies coding the function checking correctness through tests and highlight your work with documentations in order to be easily used by many balanced accuracy scorer is good idea as bonus it could also support `sample weight` >>>easy new_feature
unstable cca test the following failure was observed under windows 32 bit with numpy scipy 14 and mkl >>>bug build_/_ci
make catch warnings blocks in tests more robust some tests use with `warnings catch warnings` to check that warning is raised without calling `sklearn utils testing clean warning registry first as python can decide to not raise the same warning twice it makes those tests sensitives to test suite ordering and complicated to understand in case of failure we should review all the existing tests to ensure that we call `clean warning registry` explicitly or even use `sklearn utils testing assert warns instead of manual `with` block the list of tests to review can be found with >>>easy
sgdclassifier with class weight auto fails on scikit learn 15 but not 14 see the error and workaround here http stackoverflow com questions 24808821 sgdclassifier with class weight auto fails on scikit learn 15 but not 14>>>bug
mrg make labelencoder more friendly to new labels this is final cleanly rebased version of pr 3243 https github com scikit learn scikit learn pull 3243 incorporating discussions summary this pr intends to make ``preprocessing labelencoder`` more friendly for production pipeline usage by adding ``new labels`` constructor argument instead of always raising ``valueerror`` for unseen new labels in transform ``labelencoder`` may be initialized with new labels as `` raise `` current behavior raise ``valueerror`` to remain default behavior `` update `` update classes with new ids `` `` for new labels and assign an integer value set newly seen labels to have fixed value corresponding to this integer value `` classes `` is not property to support the ``new labels update `` behavior tests and documentation updates included >>>needs_review
generalized additive models gams hello there thanks for making this fantastic library use it every day in my bioinformatics research we re developing toolkit for single cell rna seq analysis http github com yeolab flotilla and want to add all current state of the art analyses unfortunately most of these are in can reimplemement some of them but they rely on certain packages in particular vgam http cran project org web packages vgam index html aka vector generalized linear and additive models ve found few mentions of gams here https github com scikit learn scikit learn wiki list of topics for google summer of code gsoc 2012 subtype of gams multiple additive regression mars discussion https github com scikit learn scikit learn issues 845 mars pull request https github com scikit learn scikit learn pull 2285 has there been any update on creating these libraries >>>new_feature
loss function name consistency in gradient boosting it would be nice if the `loss` option in gradient boosting could be more consistent with the one in sgd rather than deprecating names in gradient boosting suggest adding aliases >>>enhancement
docbuild is broken in fresh repo docbuild is broken in fresh repositories which have not done build before to fix this had to do it should be simple fix but am unsure how where it should go >>>bug documentation
mrg fix np1 some numpy stuff had forgotten to push sorry working while traveling has side effects >>>bug
mrg better randomizedpca sparse deprecation better deprecation warning for the problem reported on 3469 this fix should be backported in the 15 branch for inclusion in 15 >>>bug
randomized pca explained variance ratio sums to greater than one in sklearn 15 as reported here http stackoverflow com questions 24875838 randomized pca explained variance ratio sums to greater than one in sklearn trying to get version info for blas etc as well>>>bug
explanation of nu parameter in one class svm in the latest documentation for outlier detection http scikit learn org stable modules outlier detection html it mentioned an important distinction between novelty detection and outlier detection is that in novelty detection the training data is not polluted by outliers and in outlier detection the training data contains outliers and in the example one class svm is used to demonstrate novelty detection however in one class svm it is still possible to accept outliers in the training data particularly the parameter nu is used to tune upper bound on the fraction of outliers in the training dataset as explained in proposition of the original paper estimating the support of high dimensional distribution by schlkopf et al so think that the distinction between outlier detection and novelty detection is not well illustrated in the current documentation by the use of one class svm and in fact would think that we should not differentiate between the two cases besides the current explanation of nu parameter the nu parameter also known as the margin of the one class svm corresponds to the probability of finding new but regular observation outside the frontier should be re written based on the explanation from the original paper to make things clearer >>>documentation
labelbinarizer regression between 14 and 15 in 14 we have the following behavior in 15 the call to `transform` with unseen labels raises `valueerror` if we to change to new behavior we should at least raise deprecation warning and keep the old behavior by default while implementing the new behavior with flag >>>bug
allow to choose the out of bag scoring metric estimators in the forest module random forest and extra trees and in the bagging module allows to compute the out of bag estimates of the performance of the forest nice things to add would to allow the choice of the scoring function using the scorer interface the `oob score` parameter would be equal would be the string corresponding to the appropriate scorer thus you would have >>>easy enhancement
add multioutput multiclass support to metrics some estimators such as trees support multi output multiclass however there isn any metric yet to assess those tasks here list of metrics that could be easily extended to handle this format accuracy score or subset accuracy and zero one loss or subset zero one loss hamming loss ideally it would be one pull request for point and >>>easy enhancement
add multi label support to the confusion matrix metric currently the `confusion matrix` support binary and multi class classification but not multi label data yet >>>easy enhancement
add multiclass support to hinge loss the hinge loss metrics could be improved by adding support multiclass hinge loss for more information see wikipedia http en wikipedia org wiki hinge loss and the narrative documentation this would require to enhance the current code write tests and modify the documentation accordingly >>>easy enhancement
add sample weight support to more metrics most metrics now supports `sample weights` except for the following one confusion matrix hamming loss hinge loss jaccard similarity score log loss matthews corrcoef score median absolute error note that there is already general test in `sklearn metrics tests test common py` for `sample weight` ideally it would be one pull request per metric to ease review >>>easy enhancement
add multi output support to the bagging module this would nice to add multi output support to bagging as in the `sklearn ensemble forest` module some code could be refactored >>>easy enhancement
few docs take orders of magnitude longer than others various agglomerative clustering on 2d embedding of digits snip ward 96 95s average 96 07s complete 97 23s time elapsed 2e 02 sec>>>documentation easy
input validation refactoring propose to refactor the input validation the current zoo of methods is kinda confusing related to 3142 checks that we want are numpy array vs sparse vs list vs anything indexable sparse matrix type inf nan dtype ndims number of samples is consistent in multiple arrays contiguous ll now check if there is anything else that we currently check and see what functions we have remaining issues possibly remove make float array and 1d or column and also make these options of check array currently ensure2d makes vectors into rows which find pretty counter intuitive this is for backward compatibility 1d input is not currently handled consistently >>>api
failing tests on 32 bit platforms there are failing tests on 32 bit platforms am using this issue as unifying place for all of the related issues as they have been reported since some were originally thought to be platform linear algebra specific there are variable failures in lle kernelpca and cca which are mentioned in 3255 1632 >>>bug
numpy version comparison the new numpy development versions `1 10 dev whatever` are uncovering version comparison bugs so thought check `scikit learn` the comparison in line https github com scikit learn scikit learn blob 15 sklearn externals joblib numpy pickle py l110 looks wrong and maybe there are others >>>bug
splitting the metrics module in sub module currently the metrics py module is becoming huge and contains 2345 lines it becomes difficult to enter in the module to newcomers propose to split `sklearn metrics metrics` in `sklearn metrics classification` which would contains all classification metrics without score involved `sklearn metrics regression` which would contains all regression metrics `sklearn metrics ranking` or `sklearn metrics threshold` which would contains all classification metrics with score involved the `sklearn metrics tests test metrics py` which contains 2710 lines would be split in testing files `sklearn metrics tests test invariance py` with invariance tests and common tests to all metrics `sklearn metrics tests test classification py` `sklearn metrics tests test regression py` `sklearn metrics tests test ranking py` or `sklearn metrics tests test threshold py` what do you think >>>api easy
deprecate multiclass public function in the multiclass module there are functions that duplicate the ovr the ovo and the ecoc meta estimators propose to deprecate those and make them private and later refactor those functions in the meta estimators what do you think >>>api
add quantile dummy regressor strategy it would nice to be able to predict given quantile as baseline there is already private estimator in the gradient boosting module https github com scikit learn scikit learn blob master sklearn ensemble gradient boosting py l53 that computes the quantiles >>>easy enhancement
adding `sample weight`support to `dummyregresor` dummyregressor could easily support `sample weight` the main challenge is to implement weighted quantile median function for reference we already have implementation of weighted median https github com scikit learn scikit learn blob master sklearn ensemble weight boosting py l1037 that is hidden in the weight boosting module this package implements weighted quantile https github com nudomarinero wquantiles blob master weighted py and is mit licensed >>>easy enhancement
warm start in the bagging module it would be nice to have the warm start option as in gradient boosting and soon in the random forest module see also 3364 and 3409 >>>easy enhancement
fix resourcewarning unclosed file when running tests with python running the tests highlights that we do not close file object explicitly in many places of the code in python this raises warnings such as this is probably matter of wrapping the code that manipulates such recently opened file objects in with statement by run the tests with `nosetests sklearn` to find them all >>>easy enhancement
remove deprecation warnings on selectormixin the following test command test triggers it >>>easy
deprecation warning when importing numpy in sklearn utils extmath py 527 when running `examples ensemble plot partial dependence py` >>>easy
random doctest failure in statistical inference tutorial model selection this was triggered on travis by completely unrelated commit it seems that the tutorial gets better than expected result on digits the travis configuration that failed is `distrib conda python version install mkl false numpy version scipy version 11 >>>bug build_/_ci
mrg fix some python3 errors while building the doc some fixes had to make to compile sklearn with latests sphinx and python it still does not fully compile but think this is step forward those are encoding errors that are fixed for both python by using io open instead of open >>>build_/_ci documentation
enh add infomaxica object and function we recently added pure numpy implementation of the ica infomax algorithm to mne python https github com mne tools mne python https github com mne tools mne python blob master mne preprocessing infomax py https github com mne tools mne python blob master mne preprocessing tests test infomax py it should not be too difficult to include it in sklearn since we already have tests that are adapted from the fastica tests if people are interested we could start discussing the api cc gaelvaroquaux ogrisel agramfort >>>new_feature
unstable test common check regressors train for ransacregressor heisen failure under python 32 bit for windows >>>bug
failing test common check classifiers input shapes for ridgeclassifiercv under windows failure seen under windows with python 32 bit numpy scipy 14 with mkl >>>bug
heisen failure in of alphas returned by lars path on windows with 32 bit python there seems to be randomly duplicated alpha from time to time >>>bug
robust covaraince fast mcd does not handle singular covariance matrices when the step of fast mcd encounters covariance matrix with determinant it raises an error according to the paper rousseeuw van driessen 1999 it shouldn be the case technically determinant covariance is the optimal solution singular case requires special treatment section of the paper new here but can contribute to this >>>bug
warm start in random forests it would be nice to have the warm start option as in gradient boosting this will of course require to store the random state >>>moderate new_feature
bug very unhelpful error in hashingvectorizer hashingvectorizer gives pretty foul error message if np nan is passed as part of list or dict or pandas dataframe since this can happen fairly often in pandas would like to clean up the error message somehow and ideally spit back the passed in value which causes the problem the position in the document iterator would be useful information as well so that people can clean up the problem in their data without having to search for it feed values one at time sample traceback is minimal reproducing example >>>easy
sklearn preprocessing data normalize axis appears to be untested this is according to coverage report >>>easy
sphinx documentation should use double backtick for think out of confusion with markdown and other rst constructs some of the sphinx documentation intends like fixed width font but uses only single backtick instead of double ignoring docstrings for the moment we find 280 cases with the following command think all are markup errors but not all have the same resolution >>>documentation easy
making kerneldensity parameter of meanshift it would be really great if one could choose sklearn neighbors kerneldensity object to be used by the sklearn cluster meanshift class for my personal use case need to run meanshift with the haversine distance metric on gaussian kernel what do you think >>>new_feature
support for multilevel models scikit learn is notably lacking support for classification problems where the output data is heirarchical http en wikipedia org wiki multilevel model>>>new_feature
joblib breaks automatic memory mapping with large arrays multiprocessing pool self value out of range for format code this reproduces question from stackoverflow the following code runs fine with smaller test samples like 10 for samples at least for the number below 10 the run breaks with the ensuing output this is reproducible on 64 bit windows server 2012 with python from anaconda and put the pool py from anaconda multiprocessing package and parallel py from scikit learn external package on my dropbox for reference all packages are the highest version numbers compatible with py2k from repo continuum io pkgs free pro win 64 could not use conda to install consistent install base the test script is import numpy as np import sklearn from sklearn linear model import sgdclassifier from sklearn import grid search import multiprocessing as mp def main print started print numpy np version print sklearn sklearn version samples 1000000 features 1000 train np random randn samples features train np random randint size samples print input data size 3fmb train nbytes 1e6 model sgdclassifier penalty elasticnet iter 10 shuffle true param grid alpha 10 np arange l1 ratio 05 15 95 99 gs grid search gridsearchcv model param grid jobs verbose 100 gs fit train train print gs grid scores if name main mp freeze support main this results in the output vendor continuum analytics inc package mkl message trial mode expires in 28 days started numpy sklearn 15 0b1 input data size 8000 000mb fitting folds for each of 48 candidates totalling 144 fits memmaping shape 1000000l 1000l dtype float64 to new file users laszlos appdata local temp joblib memmaping pool 6172 78765976 6172 284752304 75223296 pkl failed to save to npy file traceback most recent call last file anaconda lib site packages sklearn externals joblib numpy pickle py line 240 in save obj filename self write array obj filename file anaconda lib site packages sklearn externals joblib numpy pickle py line 203 in write array self np save filename array file anaconda lib site packages numpy lib npyio py line 453 in save format write array fid arr file anaconda lib site packages numpy lib format py line 406 in write array array tofile fp valueerror 1000000000 requested and 268435456 written memmaping shape 1000000l 1000l dtype float64 to old file users laszlos appdata local temp joblib memmaping pool 6172 78765976 6172 284752304 75223296 pkl vendor continuum analytics inc package mkl message trial mode expires in 28 days vendor continuum analytics inc package mkl message trial mode expires in 28 days vendor continuum analytics inc package mkl message trial mode expires in 28 days vendor continuum analytics inc package mkl message trial mode expires in 28 days vendor continuum analytics inc package mkl message trial mode expires in 28 days vendor continuum analytics inc package mkl message trial mode expires in 28 days vendor continuum analytics inc package mkl message trial mode expires in 28 days vendor continuum analytics inc package mkl message trial mode expires in 28 days traceback most recent call last file laszlo gridsearch largearray py line 33 in main file laszlo gridsearch largearray py line 28 in main gs fit train train file anaconda lib site packages sklearn grid search py line 597 in fit return self fit parametergrid self param grid file anaconda lib site packages sklearn grid search py line 379 in fit for parameters in parameter iterable file anaconda lib site packages sklearn externals joblib parallel py line 651 in call self retrieve file anaconda lib site packages sklearn externals joblib parallel py line 503 in retrieve self output append job get file anaconda lib multiprocessing pool py line 558 in get raise self value struct error integer out of range for format code https www dropbox com 7xhf5qiw6bpudv4 pool py https www dropbox com p0risowfjwd8pwl parallel py http stackoverflow com 24406937 938408 >>>bug
mrg gsoc 2014 standard extreme learning machines finished implementing the standard extreme learning machines elms am getting the following results with 550 hidden neurons against the digits datasets training accuracy using the logistic activation function 999444 training accuracy using the tanh activation function 000000 fortunately this algorithm is much easier to implement and debug than multi layer perceptron will push test file soon ogrisel larsmans>>>needs_review
support for multi class roc auc scores low priority feature request support for multi class roc auc score calculation in `sklearn metrics` using the one against all methodology would be incredibly useful >>>new_feature
extract the nudge dataset function to sklearn feature extraction image the nudge dataset https github com scikit learn scikit learn blob master examples plot rbm logistic classification py l48 function would benefit from being extracted as helper function with an additional parameter to configure the shape it should probably be renamed to `nudge samples 2d` to highlight the fact that it interprets samples as 2d images this function will then be reusable to build examples for instance for the upcoming mlp class on larger versions of the digits without having to download large dataset such as mnist >>>new_feature
mrg fix allow nd for cross val score was working in 14 cc ogrisel would be great to get this in the release breaks cross val in mne python>>>bug
partial auc suggest adding partial auc to the metrics this would compute the area under the curve up to specified fpr in the case of the roc curve this measure is important for comparing classifiers in cases where fpr is much more important than tpr the partial auc should also allow applying the mcclish correction see here http cran project org web packages proc proc pdf>>>new_feature
prediction variance in bagging based regressors it would be nice if we could do same for baggingregressor >>>easy enhancement
kerneldensity docstring had troubles understanding how parameters related to kd tree and ball tree affect densityestimation in my understanding kde uses the average evaluation of kernels centered on every training point so didn quite understand how kd tree and ball tree are useful would understand if it used say the average of the nearest neighbors only the docstring says that we can specify tolerance options `rtol` and `atol` with respect to what stopping criterion are these constants used regarding the breadth first option the docstring says use breadth first approach to the problem didn understand what problem it refers to what is the practical impact of of the tree related parameters do they only affect speed or can they also affect quality of estimation sorry for the naive questions but it would help my understanding if we could add couple of words to clarify the docstring btw thanks jakevdp for this great module >>>documentation
bug in kerneldensity sample kerneldensity sample method returns scalar when the number of samples to generate is samples and features the expected result is an array of shape the bug only affects kernel gaussian here minimal example to reproduce the problem on related note this line https github com scikit learn scikit learn blob master sklearn neighbors kde py l203 seems to be using an undocumented functionality of rng normal the documentation http docs scipy org doc numpy reference generated numpy random normal html numpy random normal says that loc should be scalar but here 2d array is passed what does rng normal do in this case guess it generates each feature independently diagonal covariance matrix but comment would be definitely helpful cc jakevdp >>>bug
many redundant prediction probabilities for test instances with sparse svm im having an issue using the prediction probabilities for sparse svm where many of the predictions come out the same for my test instances these probabilities are produced during cross validation and when plot an roc curve for the folds the results look very strange as there are handful of clustered points on the graph here is my cross validation code based it off of the samples on the scikit website skf stratifiedkfold folds numfolds for train index test index in skf split the training and testing sets train test scaled train index scaled test index train test train index test index train on the subset for this fold print training on fold str fold classifier svm svc val kernel rbf gamma gamma val probability true probas classifier fit train train predict proba test compute roc curve and area the curve fpr tpr thresholds roc curve test probas mean tpr interp mean fpr fpr tpr mean tpr roc auc auc fpr tpr im just trying to figure out if theres something im obviously missing here since used this same training set and svm parameters with libsvm and got much better results when used libsvm and printed out the distances from the hyperplane for the cv test instances and then plotted the roc it came out much more like expected and much better auc since the decision function method is not supported for sparse matrices cannot recreate this functionality in scikit and therefore have to rely on the prediction probabilities there are 20k instances total 10k positive and 10k negative and using fold cross validation in the cross validation results there are several prediction values for which there are 1k 2k samples that all have the same prediction value and there are only 3600 distinct prediction values over all of the folds for cross validation the resulting roc looks like five big stair steps with some little bits of fuzziness around the inner corners have many sparse features so hashing those into index ranges for different types of feature subsets so one feature subset will be in the index range million to million the next will be in the range million to million etc >>>bug
remove hmm from the documentation we have policy of deleting the documentation for deprecated features we should therefore note the doc is preserved in the hmmlearn hmmlearn project itself so nothing is lost >>>documentation
unstable test common test transformers under windows with python 32 bit for some estimators am seeing failing tests with both python and python for windows scipy 14 numpy all 32 bit cca lle and kernelpca seem to be the primary culprits here is sample traceback names of estimators that cause the failure kernelpca locallylinearembedding cca>>>bug
sklearn cross validation cross val score and faulty parallelization ve just been playing with the `cross val score` function and observed the following strange behaviour results as expected in if know allow multiple processes threads the results are all exactly equal leads to rerunning the last script changes the result itself but each iteration still yields always the same result as the first could reproduce the behaviour with sklearn `0 14 1` and `0 15 git` any ideas what might cause this and how to overcome it probably some difficulties with `joblib parallel` and random seeds especially since both the fold cross validation and the randomforestclassifier introduce some measures of randomness best loli>>>bug
documentation of baggingclassifier and baggingregressor don mention sparse input support see the title ping hamsal>>>documentation easy
ambiguity on submatrix values with anaconda python2 copy pasted from nose report >>>bug
enh support unlabeled output in label propagation currently when the label propagation algorithm https github com scikit learn scikit learn blob master sklearn semi supervised label propagation py l244 hits `max iter` it possible for some rows of `self label distributions to be entirely zero this makes sense because labels haven yet propagated to those samples unfortunately during the normalization step this turns those label distributions into nan values which results in the first label being assigned `np argmax nan array 0` this also issues runtimewarning about the divide by zero believe it would be better to give the user an option in this case perhaps to set these labels to to indicate no label similar to the input format set these labels to some user supplied value perhaps defaulting to to preserve behavior currently only the warning gives any indication that some labels may not have propagated fully this is awkward to catch in user code and there no easy way to determine which samples failed to be labeled if this makes sense ll be happy to provide pr implementing the change >>>enhancement
kmeans transform should allow metric optional parameter inspired by this http fastml com the secret of the big guys looking to contribute to scikit is it ok if work on this >>>enhancement
new feature nca would like to contribute by adding an algorithm performing the neighborhood component analysis http www cs toronto edu fritz absps nca pdf basically it trying to learn distance metric by optimizing the leave one out performance on the training data in first time would first only follow the paper and then try to add different solving methods in the parameters tell me if you would be interested if have any recommendations for the architecture or if someone else is already doing this >>>new_feature
transformers need to be explained better in tutorial material there just appeared yet another so question http stackoverflow com questions 23899057 saving and using tfidf vectorizer for future examples about the tf idf transformer and how to use it since this comes up again and again and again think our documentation needs improving currently `tfidftransformer fit transform` has the description learn the representation and return the vectors while `transform` has transform raw text documents to tf idf vectors which is bit better think we need to explain the concept of transformer in the text processing tutorial because ml novices don seem to get it not too surprisingly since most other tools either hide the vectorization from the user or require them to hack it up themselves >>>documentation
build errors with clang had an issue compiling sklearn on my new mac the issue has to do with clang and is documented elsewhere http stackoverflow com questions 22313407 clang error unknown argument mno fused madd python package installation fa the issue is that clang doesn like the shorten 64 to 32 cpp flag the build crashes when trying to compile libsvm in order to compile had to do export archflags wno error unused command line argument hard error in future sudo python setup py install edit it finished building with the previous fix but it crashes when use sklearn in python terminal >>>bug build_/_ci
cross val score parallel hangs with large matrices note opened this in joblib as well because not sure which repo would be better to report this in since this occurs with relatively simple use case in sklearn posting this here in case it more appropriate let me know if you want me to move take one of them down recently my processes have started freezing when run models with large ish data and not sure why unfortunately can follow this back to specific change that might have made basically this works fine while running the following code results in the forked processes hanging what happens is that first number of processes spawn off and they churn away at the data for while this is top after few seconds of running the above code image https cloud githubusercontent com assets 1839645 3073244 38cd08a2 e2e1 11e3 9b40 728a6a7aec22 png however after another 10 seconds or so these processes have finished and another set of processes are created that hang image https cloud githubusercontent com assets 1839645 3073251 5c8cb062 e2e1 11e3 9993 a804e6302a36 png you can see the processes that spawned off and that none of them are chewing up any cpu time it remains in this state indefinitely thought this might be problem with joblib trying to memmap things but both matrices are well over the max nbytes default for parallel at least according to nbytes note that these matrices and ones larger than them have worked totally fine in the past for fitting these kinds of models not really sure what going on using sklearn version 14 joblib version 0a3 though this also breaks on all packages linked against mkl though tried it after removing mkl in anaconda and it still hangs unix machine centos >>>bug
heisen bug with omp cv got heisen travis failure while working on 3173 the entire travis log is at https travis ci org scikit learn scikit learn jobs 25868444 the test doesn seem to be always stable >>>bug build_/_ci
class prior has no effect when using partial fit on multinomialnb tried to use class prior when doing an out of core learning using the partial fit method on multinomialnb classifier but it seems like the prior probabilities are not taken into account at all so checked the code of the basediscretenb and it really seems like the class prior is never taken into account when using the partial fit method is this done intentionally or is it bug if it is not bug can you please document why class prior shouldn and wouldn be taken into account when using partial fit thanks lot >>>bug
doc score of `basesearchcv` used different scorer than defined in `scoring` of `gridsearchcv` not sure if this is intended but was confused that the score function after grid search uses different scorer than the scorer defined in gridsearchcv example expected that grid score would use the mean squared error because this was previously defined in the scoring option it took me some time to find out that the number is actually the r2 score which seems to be the score function of linearregression the documentation of score in basesearchcv says the ``score`` function of the best estimator is used or the ``scoring`` parameter where unavailable maybe the documentation of score in basesearchcv could be adapted to make it clear that the calculated score is not necessarily the same as the one defined in the scoring parameter of gridsearchcv >>>bug
multiclass ovo estimator must implement predict proba in the documentation http scikit learn org stable modules generated sklearn multiclass onevsoneclassifier html the following is stated estimator estimator object an estimator object implementing fit and predict but in fact the estimator must implement predict proba call graph >>>bug
tfidfvectorizer doesn export `idf reported on so http stackoverflow com questions 23792781 tf idf feature weights using sklearn feature extraction text tfidfvectorizer easy fix introduce property that refers to tfifd idf >>>bug easy
bug lassocv and elasticnetcv doesn handle input type in np float32 here script to reproduce it pops from 3173 whenever clean the input type checking the output is should it coerce its input type to np float64 aka double >>>bug
tree can fail if max features is low am trying to fit random forest with random search where the `max features` parameter can go from 01 to if specify `max features` as percentage sklearn sometimes raises the exception valueerror max features must be in features is for the iris dataset with `max features 01` do you consider this as problem or think this is mistake by the user as see it the problem lies here https github com scikit learn scikit learn blob 14 sklearn tree tree py l190 adding max features max max features to the next line and maybe warning solves this here is also minimal example for version 14 think the problem also exists in the master branch import sklearn datasets import sklearn ensemble iris sklearn datasets load iris iris data iris target rf sklearn ensemble randomforestclassifier max features 01 rf fit >>>enhancement
eradicate todense with toarray before pursuing this task wanted to confirm that we never want to touch `` todense `` as we want all operations to use and return ``ndarray`` below are instances of `` todense `` in current head >>>enhancement
allow multiple input feature with same value for gaussian process regression salute currently the gp module does not allow to use multiple input feature with the same value at least from the math point of view there is no need for this restriction though didn go through the whole implementation to see if there is something special about it that would require this restriction tested it on some dummy problem with noisy data with and without multiple equal inputs and it worked fine and not surprisingly even better when using duplicates more data yeay any reasons to keep it >>>enhancement
predict ovo wrongly calculates scores for tie break svc and linearsvc didn check other classifiers decision function in binary classification case returns values lower than when predict returns and when predict returns so this part of code is wrong pred estimators predict score predict binary estimators scores score scores score votes pred votes pred in svm case we should substract score from scores and add to scores >>>bug
ward tree fails when connectivity matrix is too sparse hi when running some simulations found out that if the connectivity matrix is too sparse `ward tree` fails with an indexerror it works fine with different connectivity matrix see this notebook for the simulation code http nbviewer ipython org github mvdoc notebooks blob master ward tree failing ipynb>>>bug
linear model giving attributeerror numpy float64 object has no attribute exp sklearn 14 and it happens only with particular dataset using thus not sure how to provide reproducible data sorry per the stacktrace ve tracked the problem to the lines in linear model base py think that linearclassifiermixin decision function is returning an array of dtype object which makes np exp fail none of the values in the array look to my eye like anything other than floats casting the array explicitly as float as the commented line shows allows predict proba to exponentiate there might be something happening in decision function such it returns non float result but can spot it thanks pb >>>bug
test failure in ompcv there is heisenfailure in omp on travis error sklearn tests test common test regressors int orthogonalmatchingpursuitcv array 44836249 47282444 20608008 27435163 81468082 se here https travis ci org scikit learn scikit learn jobs 24654175>>>build_/_ci
implementing correlation model kernels as seen here http scikit learn org stable modules gaussian process html correlation models the matern kernel is not implemented as marked by `todo` what is the best route for one to take to add this kernel to scikit library so the gp can use it definition of matern kernel http en wikipedia org wiki mat c3 a9rn covariance function perhaps good starting point http gptools readthedocs org en latest modules gptools kernel matern html edit to clarify it is something like to add and wondering the best way to start such that it would be accepted >>>enhancement
missmatch between text and code in the in example of univariate selection the text and python code of the example in univariate feature selection http scikit learn org dev modules feature selection html univariate feature selection doesn agree the code example show how the `variancethreshold` transformer work and not the `selectkbest chi2 >>>documentation easy
winsorization trimming in preprocessing useful preprocessing step especially when doing prototyping is to winsorize trim or clip the data to some hard limit ve searched through the repo and mailing list but don see anything like this currently implemented or proposed be willing to submit patch if there support for this it would provide both standalone method and class that follows the transformer api >>>new_feature
mrg fix handling of multilabel targets in cross val score currently ``stratifiedkfold`` is used as split strategy in ``cross val score`` but it won work correctly if ``y`` is multilabel label indicator matrix or sequence of sequences added couple of lines that check the type of ``y`` and if it multilabel simple ``kfold`` strategy is invoked >>>bug
labels argument of classification report is not useful when is list of strings in scikit learn 14 it was possible to have `y true` and `y pred` lists of strings and pass list of strings as `labels` argument to `classification report` and it worked as expected only labels from this list were included to the report this no longer works in scikit learn master it was never documented that it should work docs say that `labels` is an optional list of label indices to include in the report so according to docs it was undefined what happens if `y` consists of strings and `labels` argument is passed caller doesn have correct indices to pass in this case it seems it is better to either raise an error if `labels` is passed when `y` is not pre transformed by labelencoder or to restore and document 14 behavior what do you think >>>bug
the 13 documentation links points toward 14 doc hi team the 13 doc on the website is in fact the 14 http scikit learn org 13 modules classes html notice the very nice warning on the top left corner indicating this is the documentation for 14 >>>bug documentation
mrg added kernel weighting functions for neighbors classes this patch enables the use of kernel functions for neighbors weighting it adds the following keywords for ``weights`` argument ``tophat`` ``gaussian`` ``epanechnikov`` ``exponential`` ``linear`` ``cosine`` all kernels presented in ``kerneldensity`` class for ``kneighborsclassifier`` and ``kneighborsregressor`` the kernel bandwidth is equal to the distance to the nearest neighbor it depends on query point for ``radiusneighborsclassifier`` and `` radiusneighborsregressor`` the kernel bandwidth is equal to the radius parameter of the classifier it is constant please take look >>>needs_review
deadlock using gridsearchcv with randomforestclassifier gist https gist github com gatapia 11363090 data can be downloaded from http oem picnet com au all data zip rename zip to bz2 basically as long as the grid search takes long enough dead lock will eventually occur during grid search have had as few as 25 out of 32 cpus being used jobs 25 and no memory pressure on those processes sometimes this message is displayed on the console error in usr bin python realloc invalid pointer 0x00007fa3bf253a90 but not always and deadlock can occur without this happening ctrl to prints following thread dump just top printed cv max features 39 min samples split estimators 470 max depth 23 min samples leaf 49 9s cv max features 39 min samples split estimators 475 max depth 23 min samples leaf 49 0s parallel jobs 30 done 105 out of 108 elapsed 7min remaining 3s cv max features 39 min samples split estimators 475 max depth 23 min samples leaf 51 8s cv max features 39 min samples split estimators 470 max depth 23 min samples leaf 55 1s cv max features 39 min samples split estimators 480 max depth 23 min samples leaf 0min cv max features 39 min samples split estimators 480 max depth 23 min samples leaf 51 5s cv max features 39 min samples split estimators 475 max depth 23 min samples leaf 1min cv max features 39 min samples split estimators 480 max depth 23 min samples leaf 53 7s cv max features 39 min samples split estimators 480 max depth 23 min samples leaf 1min cprocess poolworker 18 process poolworker 13 process poolworker 12 process poolworker 10 process poolworker 26 process poolworker 21 process poolworker 16 process poolworker traceback most recent call last traceback most recent call last traceback most recent call last traceback most recent call last traceback most recent call last traceback most recent call last traceback most recent call last process poolworker 33 file usr lib python2 multiprocessing process py line 258 in bootstrap file usr lib python2 multiprocessing process py line 258 in bootstrap file usr lib python2 multiprocessing process py line 258 in bootstrap file usr lib python2 multiprocessing process py line 258 in bootstrap file usr lib python2 multiprocessing process py line 258 in bootstrap file usr lib python2 multiprocessing process py line 258 in bootstrap traceback most recent call last file usr lib python2 multiprocessing process py line 258 in bootstrap file usr lib python2 multiprocessing process py line 258 in bootstrap traceback most recent call last file usr lib python2 multiprocessing process py line 258 in bootstrap process poolworker 29 process poolworker 22 process poolworker 24 ps aux showing no real server activity during deadlock image https cloud githubusercontent com assets 135965 2813976 35f9d63e ce9e 11e3 9d5c 663cf0fc44f4 png >>>bug
labelbinarizer and labelencoder fit and transform signatures not compatible with pipeline get this error when try to use `labelbinarizer` and `labelencoder` in pipeline it seems like this is because the classes `fit` and `transform` signatures https github com scikit learn scikit learn blob master sklearn preprocessing label py l85 are different from most other estimators and only accept single argument think this is pretty easy fix just change the signature to `def self none that be happy to send pull request for but wanted to check if there were any other reasons that the signatures are the way they are that didn think of >>>api
use pyplot for plotting instead of pylab many examples use `import pylab as pl` instead of `import matplotlib pyplot as plt` to find all imports to modify one can do `git grep import pylab as pl >>>documentation easy
mrg feature or bug whitened pca does not inverse transform properly and is even document that way the `pca inverse transform` docstring even explicitly states that the inverse transform after whitening is inexact because the necessary rescaling to fall back into the right space is not done is there specific reason for this one would think that the expected behaviour of an `inverse transform` should be that it maps to the closest possible point in input space given the incurred information loss since with full rank pca one can keep all the information the inverse transform should be the true inverse any opinions on this my main concern for changing this is that this behaviour is documented and thus possibly expected by some users making the `pca` object do true inverse is as easy as adding lines to the `inverse transform` as visible in the diff >>>bug
mrg optional whitespace normalisation for countvectorizer analyzer char currently getting character grams from countvectorizer or variants automatically normalises whitespace and there is not current option to turn it off this pr adds this option pretty basic pr here `normalize whitespace` option to countvectorizer and variants true by default which matches current behaviour when set to false the normalisation that occurred in `countvectorizer char ngrams` no longer happens current todo test case narrative documentation updates if applicable>>>needs_review
cross val score and gridsearchcv should allow for missing values encoded as nans assume you want to evaluate or grid search the parameters of the following pipeline at the moment it is not possible as the `cross val score` and `gridsearchcv` tools call `check arrays` internally which raises an exception if there are `nan` values in the data think we should add `allow nans false` parameter to `check arrays` `cross val score` and `gridsearchcv` to make it possible to the user to disable the check for nans and hence allow our imputing pipeline to work as expected >>>bug easy
minibatchkmeans fails with certain combinations of clusters and feature dimensions in latest master code to reproduce when has dimension 500 200 or 500 250 or with larger as well the batch kmeans fails with an exception like this version info python default mar 17 2014 23 20 09 gcc 20140206 prerelease numpy dev fd0d7d2 scipy 15 dev 2e5b1dd sklearn 15 git 9c51bc954718146cb1108f1d8c0a7483d7d6da8d the same issue also appears with the following version combo stable versions of all but sklearn python default feb 26 2014 12 07 17 gcc 20140206 prerelease numpy scipy 13 sklearn 15 git >>>bug
feature selection doesn feature on home page just noticed that there no mention of straightforward feature selection on the home page which could fit under dimensionality reduction or under preprocessing perhaps it should be mentioned with link to http scikit learn org dev modules feature selection html >>>documentation easy
feature request stability of feature subset selection one possible criterion to judge the outcome of feature subset selection is how much the selection depends on the training set the stability estimator runs the feature selection on different subsamples it then computes the cumulative similarity of the selected feature subsets two possible measures for this similarity are the jaccard similarity or kunchevas index see saeys yvan thomas abeel and yves van de peer robust feature selection using ensemble feature selection techniques machine learning and knowledge discovery in databases springer berlin heidelberg 2008 313 325 kunchevas index kuncheva ludmila stability index for feature selection artificial intelligence and applications 2007 edit sorry but it forgot to set label for this issue apparently cannot relabel this once posted >>>new_feature
normalize only applies if fit intercept true number of linear models have `normalize` option to scale all features to equal variance however this only has any effect if `fit intercept true` this interaction does not appear to be documented so this issue requests that one of the following actions be taken the `fit intercept true` requirement should be noted in the comment for `normalize` or `normalize` should apply when `fit intercept false` assuming the data is already centered>>>api bug documentation
wip do not import the sklearn package from setup py the execution of setup py never imports the sklearn package to avoid cyclid dependencies the sklearn version py file is now generated each time setup py is executed if the version is not release version dev aaaaaaa suffix is appended where aaaaaaa is the first digits of the hexdigest of the last git commit in the local repo find this solution less hackish and more informative than the previous stateful builtins based hack >>>enhancement
zlib error while running test covtype the covertype dataset loader test tries to load previously fetched data compressed with joblib zlib if this is fetched with different major version of python and this runs into the following compatibility issue in the zlib compressed data >>>bug
failing tests under windows am working on fixing the failing tests under windows so as to prepare the 15 release will configure jenkins bot as soon as get them to pass to track progress here is the log of the remaining failures those are mostly minor issues think >>>bug
mrg fix more robust skip of implicit constructor parameter introspection requires introspecting the keyword arguments of the constructor of python classes deriving from baseestimator this can be problematic for classes that do not override the default constructor introspecting the implicit constructor used to raise typeerror but this is no longer the case in python hence with use an explicit check for the implicit constructor prior to using inspection >>>bug
imputation by knn adding new strategy knn in sklearn preprocessing imputer class for imputing the missing values usign knn method >>>new_feature
precision recall curve does not take the pos label into account the method metrics precision recall curve has parameter that can be used to define the label of the positive class this parameter is however never used which result in wrong values of precision and recall the problem can be fixed by changing the line 273 of metrics metrics py from to the documentation of the method should also be changed to include the description of the parameter >>>enhancement
zerodivisionerror float division by zero in scipy sparse linalg isolve lsqr py in recent scipy think after 13 built against the reference lapack implementation not the atlas variant the following test fails this is linear regression ordinary least squares on sparse data using the scipy sparse solver the exact code of the test is the tests pass if is converted to an array and the matrix multiplication replaced by `np dot` as the identity matrix is well conditioned and the beta are non zero the ols solver should be able to recover the exact betas before trying to transform it as scipy only code snippet would like to have the confirmation that this is indeed scipy bug and not bug in our test >>>bug
adaboost samme algorithm uses predict while fitting and predict proba while predicting probas subj this seems to me to be wrong approach moreover this drives to such mistakes adaboostclassifier algorithm samme base estimator svc fit trainx trainy predict proba testx notimplementederror traceback most recent call last in adaboostclassifier algorithm samme base estimator svc fit trainx trainy predict proba testx library python site packages sklearn ensemble weight boosting pyc in predict proba self 716 proba sum estimator predict proba 717 for estimator in zip self estimators 718 self estimator weights 719 720 proba self estimator weights sum library python site packages sklearn ensemble weight boosting pyc in estimator 715 else self algorithm samme 716 proba sum estimator predict proba 717 for estimator in zip self estimators 718 self estimator weights 719 library python site packages sklearn svm base pyc in predict proba self 493 if not self probability 494 raise notimplementederror 495 probability estimates must be enabled to use this method 496 497 if self impl not in svc nu svc notimplementederror probability estimates must be enabled to use this method >>>enhancement question
trees incompatible between 32bit and 64bit version not sure if this known issue but think trees build on 64bit can not be unpickled on 32bit how hard would it be to allow that think the problem is that ``size t`` is different between the two platforms >>>enhancement
update cython code to support 64 bit indexed sparse inputs in scipy master to be released as 14 scipy sparse matrices can now be indexed with 64 bit integers https github com scipy scipy blob master doc release 14 notes rst scipysparse improvements this means that we will probably need to use fused types for `indptr` and `indices` arrays whenever we deal with csc or csr datastructures in our cython code base >>>enhancement
pil import in cluster module just upgraded sklearn on one of my boxes and current master had weird issue related to pil import accessinit hash collision for both and the error is caused by mucked up system but would argue that we should not try to import pil when applying clustering algorithm was trying to import ``kmeans`` think the pil import came via matplotlib but did not find where that got pulled in could reproduce simply by ``import sklearn cluster`` >>>bug
mrg theilsen robust linear regression multiple linear theil sen regression for the scikit learn toolbox the implementation is based on the algorithm from the paper theil sen estimators in multiple linear regression model of xin dang hanxiang peng xueqin wang and heping zhang it is parallelized with the help of joblib on personal note think that the popular theil sen regression would be nice addition to scikit learn am looking forward to your feedback florian>>>enhancement
ward clustering too few clusters bug have raised valueerror when too few clusters are formed in ward clustering >>>bug
bug fix selectfdr thresholding bug 2771 from https github com scikit learn scikit learn issues 2771 we were not correctly scaling the alpha parameter http en wikipedia org wiki false discovery rate benjamini e2 80 93hochberg procedure with the number of features hypothesis thus the alpha parameter was not invariant with respect the number of features the correction is as suggested in the original issue and test has been added that verifies that for various numbers of features an appropriate false discovery rate is generated when using the selector this test passes with the new fdr logic and fails with the old fdr logic >>>bug
imputer test relies on anomalous median behaviour test imputation mean median only zero https github com scikit learn scikit learn blob master sklearn preprocessing tests test imputation py l97 tests for median value imputation over column that contains nan not to be imputed the current system determines non nan result for that median not sure this makes sense but don really know what median means with nan moreover the current implementation is emulating the anomalous output of `numpy ma median` https github com numpy numpy issues 4422 with respect to nans in which results differ from the unmasked equivalent think we can choose to define median as ignoring all nans `nanmedian` but this would be inconsistent with mean return nan for median including nans or leave behaviour undefined for columns containing nan and not test it have cleaner and correct implementation of sparse median for `imputer` waiting to pr but wanted to check what the appropriate resolution is >>>bug
assertionerror arrays are not almost equal during test of fresh install 14 the test suite fails with this errors see below any help will be appreciated >>>bug
joblib gracefully handle keyboardinterrupt it would be nice if could easily abort something like grid search with keyboardinterrupt currently joblib seems to require holding down ctrl until all poolworkers are killed off >>>enhancement
data independent cv iterators in many situations you don have test set so you would like to use cv for both evaluation and hyper parameter tuning therefore you need to do nested cross validation this is very difficult to implement in generic way with our current api because cv iterators are tied to particular data for example when doing `cv kfold samples `cv` will only work with dataset of the specified size ideally we would need something closer to the estimator api use constructor parameters for data independent options folds shuffle random state train test proportion etc and `run` method that takes `y` as argument the reason to take `y` is for stratified schemes this would look something like this >>>api
memory leak in minibatchkmeans on sparse data it seems that we have memory leak when running `minibatchkmeans` on sparse data here is the output >>>bug
narrative doc of the olivetti faces dataset the narrative documentation of the olivetti face dataset http scikit learn org dev datasets index html the olivetti faces dataset has no reference to the corresponding function fetch olivetti faces http scikit learn org dev modules generated sklearn datasets fetch olivetti faces html sklearn datasets fetch olivetti faces >>>documentation easy
inconsistencies for the kernel documentation here some inconsistencies that have encountered when wanted to use kernel the degree in kernelpca svm kernel and svc they don agree with the presence of the parameter degree for the sigmoid kernel parameter of kernelpca http scikit learn org stable modules generated sklearn decomposition kernelpca html sklearn decomposition kernelpca is said to be used for the rbf kernel however in the svm kernel documentation http scikit learn org stable modules svm html svm kernels there isn any mention of the degree parameter in kernelpca http scikit learn org stable modules generated sklearn decomposition kernelpca html sklearn decomposition kernelpca svm kernel http scikit learn org stable modules svm html svm kernels and svc http scikit learn org stable modules generated sklearn svm svc html sklearn svm svc they don agree with the presence of the parameter degree for the sigmoid kernel in the kernel pca narrative doc http scikit learn org stable modules decomposition html principal component analysis pca and in kernelpca http scikit learn org stable modules generated sklearn decomposition kernelpca html sklearn decomposition kernelpca there isn any link to the kernel definition when you browse the narrative doc in pairwise metrics affinities and kernels http scikit learn org stable modules metrics html there is no pointer to the kernel approximation definitions of all kernels and estimators transformers that can use kernels the information about kernels is spread in at least four page it would be nice that pairwise metrics affinities and kernels http scikit learn org stable modules metrics html contains most information with links to the relevant pages and backlink from these page >>>bug documentation easy
example rendering of sklearn datasets fetch mldata the example of sklearn datasets fetch mldata http scikit learn org stable modules generated sklearn datasets fetch mldata html with the leukemia dataset doesn render properly >>>bug documentation easy
incomplete documentation for sklearn datasets fetch olivetti faces documentation issues for `sklearn datasets fetch olivetti faces http scikit learn org dev modules generated sklearn datasets fetch olivetti faces html sklearn datasets fetch olivetti faces the return description field is missing the link http www uk research att com facedatabase html is dead function arguments and parameter description are not in the same order>>>documentation easy
allow imputer to accept strategy some callable it seems like `imputer` can be easily extended to handle arbitrary axis wise strategies at least in the case where the data is dense or sparse with non explicit entries to be imputed the `strategy` parameter could accept function or other callable that reduces given masked array along an axis including scipy stats mstats http docs scipy org doc scipy reference stats mstats html functions more flexibly `strategy` could be callable that either takes 2d array and an `axis` value and returns 1d array or just takes 1d array and returns scalar for example one should be able to use to impute with trimmed mean using absolute bounds nb `tmean` http docs scipy org doc scipy reference generated scipy stats mstats tmean html doesn accept an `axis` argument or for trimmed mean with quantile bounds >>>moderate new_feature
add more useful example to the cluster comparison the clustering comparison at http scikit learn org stable auto examples cluster plot cluster comparison html is somewhat misleading in that the data are totally unlike anything that would be seen in 99 of cases realise that they re toy examples but it would also be good to get something more realistic for comparison here is simple dataset that has one wide gaussian distribution with two smaller gaussian distributions overlapping it to different extents clustering with gaussians https cloud github com assets 167164 2252300 9770a114 9da6 11e3 87b1 d0efbefb0ed8 png this shows the performance of the various models on more realistic data it especially shows that dbscan isn perfect here the dataset the parameters are all arbitrary and the performances for the various algorithms change fair bit given different parameters but since this is just to give rough idea of the relative performances don think that matters that much >>>documentation enhancement
sample weights array can be used with gridsearchcv the internal cross validation isn aware of sample weights so and exception is thrown if sample weights sequence is passed to the grid search because fit grid point does not split the weights into training and test sets >>>api enhancement
sklearn metrics adjusted mutual info score returns negative values the definition of adjusted mutual information says it should be float between and yet when you score random multinomial labels you will often get negative values for example y1 y2 print adjusted mutual info score y1 y2 153845866193>>>documentation easy
gbrt monitor held out set was toying with the new monitor callback and ran into an issue not sure if using it incorrectly or if it bug so have something like the following which results in array decisiontreeregressor compute importances none criterion max depth max features none max leaf nodes none min density none min samples leaf min samples split random state splitter none none none >>>enhancement
time clock vs time time git grep indicates that we are using `time time in few places but in general `time clock is more appropriate for benchmarking http stackoverflow com questions 85451 python time clock vs time time accuracy>>>easy enhancement
onehotencoder should raise valueerror when value values for example the following is broken input and output >>>bug easy
remove polynomial regression example there are two examples for polynomial regression https github com scikit learn scikit learn blob master examples plot polynomial regression py https github com scikit learn scikit learn blob master examples linear model plot polynomial interpolation py one of them should be removed and the docstring should be merged >>>easy
fix adaboost citation adaboost was developed by yoav freund not freud this is at least like this on the website http link springer com chapter 10 1007 540 59119 166>>>documentation easy
odd cca scale true behavior this is probably just result of an misunderstanding of mine but anyway expect that if pass in scaled data setting `scale true` or `scale false` on `cca` should have no effect while that true for the first component it not true for the second component >>>bug
decision tree documentation in the decision tree documentation http scikit learn org stable modules tree html in section there are the following lines this results in an error believe it should be `dot data stringio only >>>documentation easy
add support for svdd one class svm support vector data description svdd could be nice enhancement to oneclasssvm implementation technical implementation is described in this paper http www csie ntu edu tw cjlin papers svdd pdf source code compatible with libsvm is available here http www csie ntu edu tw cjlin libsvmtools libsvm for svdd and finding the smallest sphere containing all data>>>enhancement
overflow in matthews corrcoef on 32 bit numpy example this runs fine on 64 bit unix box but not on 32 bit windows machine due to overflows and afaik getting 64 bit numpy to work on windows is hard next to impossble >>>bug
onehotencoder does not have sparse parameter there is no sparse parameter in onehotencoder but there is one in dictvectorizer which does very similar things >>>easy enhancement
doc more docs needed on model and data persistence it seems the only documentation of model persistence is in the quick start tutorial think it needs to be covered in the user guide mentioning security and forward compatibility caveats pertaining to pickle it might note the benefits of joblib for large models at least over pickle most other ml toolkits particularly command line tools treat persistence as very basic operation of the package this was fixed in 3317 similarly there should be some comment on saving and loading custom data input and output indeed can find direct description of the supported data types users are unlikely to have played with `scipy sparse` before although the `feature extraction` module means they may not need to noting the benefits of joblib without which the user may dump sparse matrix `data` `indices` `indptr` using tofile` and memmapping is worthwhile so may be reference to pandas which could help manipulate datasets before after entering scikit learn and provides import export to variety of formats http pandas pydata org pandas docs dev io html have recently discovered new users who think the way to import export large sparse arrays is `load svmlight format` but then note that the loading saving takes much more time than the processing they re trying to do let give them hand >>>documentation easy
add option to isomap for using precomputed neighborhood graph theoretically there no reason why `isomap` can operate on an abitrary graph but the existing implementation assumes nearest neighbor graph adding an option for using precomputed graph would match the api for `spectralembedding` which can accept precomputed affinity matrix in addition to using standard methods for its construction >>>enhancement
regression memory leak in decision trees here is reproduction script used random tree to make it run much faster but think this impacts all tree implementations used very large output dimension to make the leak more visible here is the output on the current master the output on sklearn 14 >>>bug
numerical stability bug in rbm 14 for python code demonstrating stack trace >>>bug
doc mathematical expressions are not rendering see http scikit learn org dev modules sgd html or http scikit learn org dev modules ensemble html >>>build_/_ci documentation
imputer doesn work in grid search when `gridsearchcv` sees nan it panics this is annoying when the estimator is pipeline that starts with an `imputer` as now the imputer must be trained outside of the grid search giving potentially skewed results >>>bug easy
selectfdr has serious thresholding bug the current code reads like def get support mask self alpha self alpha sv np sort self pvalues threshold sv sv alpha np arange len self pvalues max return self pvalues threshold but this doesn actually control fdr at all the correct implementation should have bf alpha alpha len self pvalues threshold sv sv bf alpha np arange len self pvalues max note the term in the equation at http en wikipedia org wiki false discovery rate benjamini e2 80 93hochberg procedure >>>bug
installing problem hi tried to install scikit in my machine ubuntu 12 04 lts gnu linux 53 generic x86 64 using the command sudo apt get install python sklearn it seemed to be fine but when tried to test it nosetests sklearn exe got the following message can anyone help me with this thanks in advance shing >>>bug
baseestimator get params and clone thread safe are not thread safe the handling of deprecated constructor parameters is leveraging the execution python warnings machinery which is not thread safe and could therefore caused hard to diagnose bugs in there was tentative lock based workaround in 2729 better solution however would avoid executing the warning machinery at all in `get params` by leveraging declarative deprecation introspection possibly using class decorator will try to issue pr for this next week >>>bug
sample weight not tested for random forests would be nice to add tests both for the classifier and regressor variants >>>enhancement
sample weight in ridge with fit intercept true currently there is the following test for `sample weight` in ridge the test calls `ridge regression` directly so it only tests for the `fit intercept false` case ideally would like to add test for checking the correctness of the sample weight support in the `fit intercept true` case as well the following test fails but not sure whether the problem is in the test or in the code in any case think it is important to check for the correctness of the `fit intercept true` case cc agramfort gaelvaroquaux >>>bug
correctness issue in lassolars for unluckily aligned values think ve found correctness bug in sklearn linear model lassolars for me it appears only for systems with some exactly aligned non general position values it can be fixed by jiggling the rhs of the system with small random offsets here is test python code import numpy as np import sklearn linear model as sklm np array np array lars sklm lassolars alpha 001 fit intercept false lars fit nojiggle lars coef jiggle np random rand 00001 lars fit jiggle jiggle lars coef print without jiggle nojiggle residual np dot nojiggle print with jiggle jiggle residual np dot jiggle for me with the current anaconda distribution sklearn version 14 the output is without jiggle 998 498 residual 00000000e 03 49800000e 00 with jiggle 49799528 49799561 residual 00200439 00200472 the jiggled version has the expected result whereas the no jiggle version is wrong >>>bug
failed test after installation assertionerror hi have installed scikit learn 14 and got the following error after running the test failed skip 12 failures fail sklearn feature selection tests test feature select test oneway ints traceback most recent call last file usr local lib python2 dist packages nose py2 egg nose case py line 197 in runtest self test self arg file home ai local lib python2 site packages sklearn feature selection tests test feature select py line 45 in test oneway ints assert array equal fint file usr lib python2 dist packages numpy testing utils py line 707 in assert array equal verbose verbose header arrays are not equal file usr lib python2 dist packages numpy testing utils py line 636 in assert array compare raise assertionerror msg assertionerror arrays are not equal mismatch 80 array 41558442 02061856 12328767 23198317 35865504 71223022 05188981 44208611 array 41558203 02061667 12328766 23198143 35865301 71222866 0518877 44208813 dtype float32 the following are the package details linux platform python numpy scipy scikit 14 nose is there fix for this or can it just be ignored >>>bug
four testing cases failed when was testing using `nose` as follow nosetests exe sklearn got `ran 2966 tests in 122 078s` and `failed skip 16 failures the followings are the four failures all of them are `assertionerror first warning for fit is not a` from `assert warns` function in `sklearn utils tesing py` notice comment to remove when we support numpy 7` before the `assert warns` function as current version of numpy is am wondering if `assert warns` should be removed fail check that oob prediction is good estimation of the generalization traceback most recent call last file opt local library frameworks python framework versions lib python3 site packages nose case py line 198 in runtest self test self arg file opt local library frameworks python framework versions lib python3 site packages sklearn ensemble tests test bagging py line 205 in test oob score classification train file opt local library frameworks python framework versions lib python3 site packages sklearn utils testing py line 121 in assert warns func name warning class assertionerror first warning for fit is not is message deprecationwarning using non integer number instead of an integer will result in an error in the future category deprecationwarning filename opt local library frameworks python framework versions lib python3 site packages sklearn svm base py lineno 233 line none fail sklearn linear model tests test least angle test lasso lars vs lasso cd ill conditioned traceback most recent call last file opt local library frameworks python framework versions lib python3 site packages nose case py line 198 in runtest self test self arg file opt local library frameworks python framework versions lib python3 site packages sklearn linear model tests test least angle py line 326 in test lasso lars vs lasso cd ill conditioned linear model lars path method lasso file opt local library frameworks python framework versions lib python3 site packages sklearn utils testing py line 167 in assert warns message func name warning class assertionerror first warning for lars path is not is message deprecationwarning converting an array with ndim to an index will result in an error in the future category deprecationwarning filename opt local library frameworks python framework versions lib python3 site packages sklearn linear model least angle py lineno 368 line none fail sklearn svm tests test sparse test timeout traceback most recent call last file opt local library frameworks python framework versions lib python3 site packages nose case py line 198 in runtest self test self arg file opt local library frameworks python framework versions lib python3 site packages sklearn svm tests test sparse py line 284 in test timeout assert warns convergencewarning sp fit sp file opt local library frameworks python framework versions lib python3 site packages sklearn utils testing py line 121 in assert warns func name warning class assertionerror first warning for fit is not is message deprecationwarning using non integer number instead of an integer will result in an error in the future category deprecationwarning filename opt local library frameworks python framework versions lib python3 site packages sklearn svm base py lineno 233 line none fail sklearn svm tests test svm test timeout traceback most recent call last file opt local library frameworks python framework versions lib python3 site packages nose case py line 198 in runtest self test self arg file opt local library frameworks python framework versions lib python3 site packages sklearn svm tests test svm py line 657 in test timeout assert warns convergencewarning fit file opt local library frameworks python framework versions lib python3 site packages sklearn utils testing py line 121 in assert warns func name warning class assertionerror first warning for fit is not is message deprecationwarning using non integer number instead of an integer will result in an error in the future category deprecationwarning filename opt local library frameworks python framework versions lib python3 site packages sklearn svm base py lineno 233 line none >>>bug
ward clustering index error for few clusters in digit example hej together just tried to compile the following code and got an error for ward when searched for too few clusters file usr local lib python2 dist packages sklearn cluster hierarchical py line 169 in ward tree inert heappop inertia indexerror index out of range import sklearn datasets sklearn neighbors sklearn cluster sklearn datasets load digits data connectivity sklearn neighbors kneighbors graph neighbors 10 clusters ward sklearn cluster ward clusters clusters connectivity connectivity fit this problem also arises for other examples when reduce clusters can anybody help me please best wedge>>>bug
bug tree allows segfault arbitrary memory access the properties for accessing attributes on `tree` return arrays which don own their data and which are malloced and freed by the tree therefore outputs >>>bug
roc auc score fails if dtype is object to reproduce import numpy as np np random seed 13 classes np array yes no classes np random randint size 10 classes np random randint size 10 from sklearn metrics import roc auc score from sklearn metrics import accuracy score accuracy score 800 roc auc score valueerror data is not binary and pos label is not specified >>>enhancement
non deterministic joblibindexerror in sklearn ensemble tests test forest test parallel train as seen on https travis ci org scikit learn scikit learn builds 16461795 `baseestimator get params` handling of the warnings registry is not thread safe and that breaks the new threading backed parallelization of random forests >>>bug
dummyregressor median and constant strategy the dummy regressor could have keyword `strategy` to select between mean median or constant value in the same spirit as `dummyclassifier` >>>easy enhancement
cca test error in master error check transformer wardagglomeration traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file home andy checkout scikit learn sklearn tests test common py line 233 in check transformer transformer fit file home andy checkout scikit learn sklearn cross decomposition pls py line 333 in fit linalg inv np dot self loadings self weights file home andy local lib python2 site packages scipy 11 py2 linux x86 64 egg scipy linalg basic py line 348 in inv raise linalgerror singular matrix linalgerror singular matrix>>>bug build_/_ci
joblib load model from disk error am building my model and storing it at location using joblib dump model modelstorelocation compress then in separate execution am trying to read the model from the location as show below loading the model stored on disk model joblib load modelstorelocation get the following error the same works with out any problem when its in the same execution build the model write to dsik and read from disk in the same execution what is the fix for this >>>bug
model attributes are not documented in `labelpropagation` `labelspreading` docstrings this documentation is absent despite the attributes being introspected in examples http scikit learn org stable auto examples semi supervised plot label propagation digits active learning html example semi supervised plot label propagation digits active learning py>>>documentation easy
add `best score attribute to all cv models gridsearchcv has `best score attribute that is missing from ridgecv lassocv and other cv based objects ideally these would all have consistent api since they re all performing essentially the same task from given set of parameters search for the optimal one according to the cross validation score other attributes that may be beneficial to add `best estimator this may be useful by returning fit object of the non cv version of the class ridgecv ridge `best params this would be helpful especially for elasticnetcv which has multiple parameters set `alpha and `l1 ratio `grid scores this is mostly available for lassocv but will take more work to make available for ridgecv if no one objects ll start working on this ideas for how to improve or other attributes to add are welcome >>>enhancement
doc special handling of binary classification in `labelbinarizer` and `label binarizer` is undocumented binary input results in column vector shape samples rather than samples classes for multiclass input this needs to be documented >>>documentation easy
copy parameter of imputer seems to not work on sklearn 14 and have the following issue created sklearn preprocessing imputer imputer copy false np random random np nan fit a2 transform because of `copy false` expect `id a2 id the nan in `a` to be cleared however neither occurs >>>bug easy
failed test after installation hello am trying to install scikit on macbook pro lion 10 however the test fails with this message how can fix the issue regards >>>bug
gbt fails with rf init here is tiny script which reproduces the crash it also seems that the init param in gradientboostingclassifier is not really tested pprett glouppe ogrisel>>>bug
feature request additional clustering algorithms birch recommend the following clustering algorithms birch is an clustering algorithm that received the sigmod 10 year test of time award the algorithm minimize run time define clusters without scanning all the data and exploit the non uniformity of data to treat dense areas as one https code google com birch clustering algorithm https en wikipedia org wiki birch 28data clustering 29 think this can be very useful for large datasets input parameters would be the data and radius to indicate how close points are >>>new_feature
add varimax rotation for factor analysis and pca rotation methods such as varimax should be added to pca it helps identify the factors that make up the components and would be useful in analysis of data https en wikipedia org wiki varimax rotation http sites stat psu edu ajw13 stat505 fa06 17 factor 13 factor varimax html>>>new_feature
minibatch means does init initialization runs when given explicit cluster centers even when ``init`` is an array the initialization is carried out ``n init`` times obviously with identical results that is pretty weird >>>bug easy
possibly inefficient sparse matrix creation in featurehasher hi it looks like the way that `csr matrix` objects are created by `featurehasher` can result in outputs that explicitly represent lot of 0s `featurehasher` uses the tuple based initialization for `csr matrix` which will just take 0s and store them rather than trying to filter them out for efficient storage think the simplest way to address this is to call `eliminate zeros on the matrix before returning it however not sure this would be efficient enough for very large datasets it might be better to construct one row at time call `eliminate zeros and then stack them or something like that >>>enhancement
randomizedpca explained variance ratio is false as emphasized by this question on stackoverflow http stackoverflow com questions 20563239 truncatedsvd explained variance 20564849 `randomizedpca explained variance ratio is false as it cannot cheaply estimate the total variance of the input data did notebook to check that this is actually bug http nbviewer ipython org github ogrisel notebooks blob master explained 20variances ipynb think we should plainly remove `explained variance ratio from the `randomizedpca` class and document the removal in `whats new rst` write an example that demonstrates how to compute the explained variance empirically for `pca` `randomizedpca` `truncatedsvd` with plots similar to my notebook add new section to the narrative documentation of the `truncatedsvd` model to explain that and include the plot let me put that as easy fix suitable for first time contributor >>>bug easy
associative learning algorithms noticed that there were no associative learning algorithms such as apiori alogorithm equivalence classification algorithm eclat prefixspan fp growth all of them are used to detect combination of patterns in dataset some of them are kind of difficult to implement would say about 200 lines of code >>>new_feature
out of core pca algorithm the randomizedpca algorithm is great you can perform pca much quicker and on larger data sets that otherwise would either take too long or take up too much ram however the original data set still needs to fit into memory was wondering if there was an out of core algorithm for pca and from googling there seems to be one http arxiv org pdf 1007 5510 pdf it by the same authors as the current randomizedpca algorithm and it would be great to see this implemented as well this seems really useful to me and with this scikit learn can deal with datasets of any size interested to hear your thoughts on this >>>new_feature
twentynewsgroups dataset fetch fail with incomplete download am running python using enthought canopy and am having issues with fetching the twenty news groups dataset it says empty file when try using the code provided in the example on the following page http scikit learn org stable datasets twenty newsgroups html the first two lines of the example don work and it throws the following error basically it readerror because it has empty input from the twentynewsgroups as far as can tell but have no idea how to fix it readerror traceback most recent call last in from sklearn datasets import fetch 20newsgroups newsgroups train fetch 20newsgroups subset train users nikhil library enthought canopy 64bit user lib python2 site packages sklearn datasets twenty newsgroups pyc in fetch 20newsgroups data home subset categories shuffle random state remove download if missing 205 if download if missing 206 cache download 20newsgroups target dir twenty home 207 cache path cache path 208 else 209 raise ioerror 20newsgroups dataset not found users nikhil library enthought canopy 64bit user lib python2 site packages sklearn datasets twenty newsgroups pyc in download 20newsgroups target dir cache path 87 88 logger info decompressing archive path 89 tarfile open archive path gz extractall path target dir 90 os remove archive path 91 applications canopy app appdata canopy 1262 macosx x86 64 canopy app contents lib python2 tarfile pyc in open cls name mode fileobj bufsize kwargs 1676 else 1677 raise compressionerror unknown compression type comptype 1678 return func name filemode fileobj kwargs 1679 1680 elif in mode applications canopy app appdata canopy 1262 macosx x86 64 canopy app contents lib python2 tarfile pyc in gzopen cls name mode fileobj compresslevel kwargs 1725 cls taropen name mode 1726 gzip gzipfile name mode compresslevel fileobj 1727 kwargs 1728 except ioerror 1729 raise readerror not gzip file applications canopy app appdata canopy 1262 macosx x86 64 canopy app contents lib python2 tarfile pyc in taropen cls name mode fileobj kwargs 1703 if len mode or mode not in raw 1704 raise valueerror mode must be or 1705 return cls name mode fileobj kwargs 1706 1707 classmethod applications canopy app appdata canopy 1262 macosx x86 64 canopy app contents lib python2 tarfile pyc in init self name mode fileobj format tarinfo dereference ignore zeros encoding errors pax headers debug errorlevel 1572 if self mode 1573 self firstmember none 1574 self firstmember self next 1575 1576 if self mode applications canopy app appdata canopy 1262 macosx x86 64 canopy app contents lib python2 tarfile pyc in next self 2332 except emptyheadererror 2333 if self offset 2334 raise readerror empty file 2335 except truncatedheadererror 2336 if self offset readerror empty file >>>bug
add additional bandwidth settings to kerneldensity hi the new kerneldensity class is really great there are few things might like to see added in future releases per dimension bandwidth control like to be able to pass in an array of bandwidths and apply different smoothing in each dimension adaptive smoothing like to be able to apply variable smoothing such that the bandwidth is chosen equal to the kth nearest neighbor distance at each sample point does anyone have an idea of how easy possible these features might be to implement had look through the code but don know enough about tree based evaluation to tell if it could support these functions thanks >>>new_feature
remove hmms hmms code needs to be removed after the standard deprecation cycle >>>easy
python bytes object has no attribute encode when trying to execute fetch 20newsgroups subset all while being in python environment get the following error the problem is that the value is bytes and in python bytes can not be encoded they can only be decoded >>>bug easy
leading minor not positive definite seem to get this error at random times while training gaussianhmm is this because of underflow >>>bug
use succinct tries for vocabulary storage hey python dictionary is quite wasteful for string data so `countvectorizer` `tfidfvectorizer` and `dictvectorizer` all could take much less memory with an another data structure for `vocabulary here is quick prototype that persists `vocabulary of `countvectorizer` and `tfidfvectorizer` in marisa trie https code google com marisa trie via python wrapper https github com kmike marisa trie https gist github com kmike 7814472 used this https gist github com kmike 7813450 script to measure memory and speed of `fit` and `dump` and this https gist github com kmike 7815149 script to measure parameters of `load` and `transform` the results are quite cool for 20 newsgroups data fit on training subset transform on test subset memory consumption of different vectorizers after loading is the following `countvectorizer 94mb `countvectorizer ngram range 666mb `marisacountvectorizer 2mb `marisacountvectorizer ngram range 13 3mb so using good succinct trie implementation gives us 50x 80x reduction of memory usage it also makes serializing and deserializing almost instant and such vectorizers don have hashingvectorizer limitations the downside is that `fit` method is 2x 3x slower and requires slightly more memory but think it could be changed to require less memory than countvectorizer fit and `transform` is about 2x slower full output https gist github com kmike 7815156 what do you think about adding something similar to scikit learn >>>new_feature
mrg minibatch reassignment fixes this should address the remaining issues of 2185 including 2611 which only saw after writing this still have to merge 2185 for the tests to pass thought about using sampling from np random instead of coding up new function to do multinomial sampling with replacement which should exist >>>bug
log loss and hinge loss are not tested in the invariance metric system both metrics are not in the thresholded metrics dictionnary in test metrics haven looked in detail but think that some tests are missing for that sort of cases >>>easy
sklearn cluster tests test spectral test spectral lobpcg mode ubuntu 13 10 >>>bug
dead links in documentation from http scikit learn org stable documentation html click on scikit learn 15 development http scikit learn org 15 user guide html and got from http scikit learn org dev documentation html click on scikit learn 14 stable http scikit learn org 14 user guide html and got >>>bug documentation
bug kneighborsclassifier kneighborsregressor kwargs ``kneighborsclassifier`` and ``kneighborsregressor`` and any others handle unspecified `` kwargs`` in their initialization this means they will not work correctly with ``clone `` in cross validation the api needs to be changed so that kwargs are passed explicitly as dictionary the good news is that these keyword arguments are used only for obscure metrics so there is likely very little code out in the wild that uses the current problematic api >>>api bug
add support for ml knn add support for the multi label knn algorithm as described here in this paper http cs nju edu cn zhouzh zhouzh files publication pr07 pdf brief description of the algorithm from the above paper as its name implied ml knn is derived from the popular nearest neighbor knn algorithm firstly for each test instance its nearest neighbors in the training set are identied then according to statistical information gained from the label sets of these neighboring instances the number of neighboring instances belonging to each possible class maximum posteriori map principle is utilized to determine the label set for the test instance supporting sparse matrices should be key requirement lot of multi label tasks are for text categorization and these are usually represented as sparse matrices ml knn is actually already implemented in this library http orange biolab si docs latest reference rst orange multilabel ml knn learner but it would be good to bring it under the scikit learn framework as well >>>enhancement
fixes and tweaks for scikit learn example gallery recently the nilearn website http nilearn github io index html received good update congrats again did redo of the docstring popup display for the examples gallery http nilearn github io auto examples index html which uses no javascript cleaner and more stable than the current example the current implementation of the popup docstrings on the scikit learn examples gallery http scikit learn org dev auto examples index html looks nice enough but takes bit of time to initialise due to waiting for other javascripts and can behave buggily if you swoosh the mouse about fast enough so propose to change the scikit learn examples gallery pop ups to match that of the nilearn site one thing though is that using the exact same implementation as in nilearn means not having the larger thumbnail images appear anymore as ogrisel mentioned else could try adding images to the nilearn gallery version let me know what you think on side note there is some general cleanup of gen rst that ll make pr for anyway can either do that separately or together with the above >>>bug documentation enhancement
unexpected normalization in the sklearn linear models base center data function when normalize true and fit intercept true is provided the standard deviation of is calculated by std np sqrt np sum axis think it should rather read std np sqrt np mean axis or is there any special reason why you sum here intead of taking the mean if you just sum then while is increased in dimension std will grow also to infinity this seems odd to me and quite unexpected >>>bug
cross validation generators broken for semi supervised learning `labelpropagation` encodes unlabeled samples with 1` those samples cannot be used for testing cross validation generators should have an option such that certain label always goes to the training split >>>enhancement
make scorer needs threshold makes wrong assumptions found two issues with `make scorer` `needs threshold` option first it doesn work if the base estimator is regressor using regressor is perfectly valid use case if you want do use regressor but still want to optimize your hyper parameters against auc pointwise ranking with two relevance levels it does work with `ridge` but this is because `decision function` and `predict` are aliases of each others see also the discussion in issue 1404 second thresholdscorer` checks that the number of unique values in `y true` is but this need not be the case for example can use regressor and optimize my hyper parameters against ndcg with more than relevance levels >>>bug
invalid warning in recall score in from sklearn metrics import recall score in recall score users mblondel desktop projects scikit learn sklearn metrics metrics py 1550 undefinedmetricwarning precision and score are ill defined and being set to due to no predicted samples out 0>>>bug
enhancement learning curves hope this is not duplicate issue but it something ve been thinking about for while it would be nice to create utility function to generate learning curves both for hyperparameter value vs score error and for number of training samples vs score error it something do by hand very often think an interface similar to grid search would work well with an interface that looks like this some setup code here the first function we should create arguments have the same meaning as in ``gridsearchcv`` here the second function we should create same argument meanings use this sort of thing all the time both in tutorials and in practice it would be nice to have this functionality available in convenience routine any thoughts on this >>>enhancement moderate
adaboostclassifier requires dense array even when the base learner does not adaboostclassifier does does not directly use the feature values of the input array so it should not need to require the input to be dense this limits its applicability to large scale high dimentional problems>>>enhancement
meta estimator by combining classifiers in scikit learn some homogeneous meta classifiers exist to combine classifiers adaboost bagging by applying differents subdatasets on differents instances of the same classifier what about heterogeneous ones combine differents classifiers on the same data training for my own purpose writing some of these my starting point is the work of kuncheva and kittler ve planned to go further and check other strategies does scikit will be interested by pull request with some of these algorithms the syntax will look like featureunion and will obviously support gridsearchcv and pipeline combined classifiers modelunion svc svc sgd sgdclassifier penalty l2 kuncheva bezdek duin 2001 decision templates for multiple classifier fusion an experimental comparison pattern recognition 34 299 314 kittler hatef duin matas 1998 on combining classifiers pattern analysis and machine intelligence ieee transactions on 20 226 239 >>>new_feature
truncatedsvd by eigh the right singular vectors of `x` can be computed by the eigenvalue decomposition of `np dot so if `n features` is not too large say 1000 this could be an efficient solver for `truncatedsvd` likewise if `n samples features` the left singular vectors could be obtained by the eigenvalue decomposition of`np dot but then we would only be able to implement `fit transform` not `transform` see http en wikipedia org wiki singular value decomposition>>>enhancement
mrg pipeline can now be sliced or indexed this pr offers an alternative to 2561 and 2562 making it easy to apply inverse transforms or transforms over only sub sequence of steps in pipeline thus schwarty is this sufficient for your needs >>>needs_review
adding get estimated method to pipelines the motivation is the same as pr 2561 in nutshell we want to be able to apply the inverse transform steps from pipeline on an estimated parameter from the last step of the same pipeline pr 2561 aims to achieve that goal by applying the inverse transforms from all steps except the last one if it misses an inverse transform method gaelvaroquaux pointed out that it will fail in the cases where the last estimator implements both transform inverse transform methods and predict score methods the alternative could be to implement get estimated method for pipelines that explicitly retrieves given attribute from the pipeline last step and subsequently applies the inverse transforms the code would look like the following note that the final learner may itself be pipeline gridsearchcv metaclassifier or any valid combination in sklearn any comments suggestions >>>api
imputer bug with median and dense input this code returns 100 100 100 100 100 100 100 100 100 100 100 100 so returns 100 with dense median>>>bug
variational lower bound for dpgmm is big positive number running this tutorial http scikit learn org stable auto examples mixture plot gmm html with verbose true for dpgmm outputs large positive numbers for variational lower bound since lower bound is calculated in log scale it shouldn be larger that so it seems like bug >>>bug
port fast better ard regression from mne python https github com mne tools mne python blob master mne inverse sparse gamma map py l17 to replace historical ardregression model this issue is just reminder for me cc mluessi>>>enhancement moderate
test failures on master on my box error check fast dot blas wrapper function traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file home andy checkout scikit learn sklearn utils tests test extmath py line 325 in test fast dot assert true isinstance pop message nonblasdotwarning indexerror pop from empty list fail sklearn tests test common test transformers traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file home andy checkout scikit learn sklearn tests test common py line 251 in test transformers assert true succeeded assertionerror false is not true false is not true self formatmessage false is not true is not true safe repr false raise self failureexception false is not true >>>bug build_/_ci
mrg support for distance matrices in nearestneighbor support for nearestneighbor the unsupervised one to handle being given distance matrix matrix such that is the distance between samples and >>>needs_review
mrg sklearn tree export dict for converting tree objects into jsonable format this is useful for viewing tree objects in terminal and working with tree objects in simpler more pythonic form than working directly with tree tree one example would be writing utility which can use the pythonic tree to tell the user why particular decision was made rather than just generating prediction this is especially useful for decisiontrees which are often enjoyed in this simple form for their very transparency >>>needs_review
multiple hyperparameters for gaussian process hi the gaussian process module recently merged some code that allowed multifeature things that is great step but there is an almost equally important thing and it is having multiple hyperparams all kernels in gps have set of hyperparams theta in scikits it seems like this set is restricted to cardinality of one that is you can only have one hyperparameter note that this is not the same as having an element in theta that is multidimensional currently in the scikits code this is allowed for example in the squared exponential kernel can have exp theta and theta can be vector array whose elements correspond to different dimensions features however cannot have this theta exp theta because in order for this to make sense would need theta to actually be matrix where row corresponds to one hyperparam and the columns on that row are the features then for that second kernel above would have theta matrix that had rows this is what makes sense to me but it does not work sometimes have run into problems with the optimizer because have written bad kernels but know theoretically this is not the case the kernel made up above isn necessarily valid don know the one actually tried was periodic kernel where instead of used sin that works but theoretically you can add any two valid kernels together and get new valid kernel this works too but then stuck without hyperparam for the sin part so if doing this multiple hyperparms thing wrong like to know if this is not actually feature like to make it one and need some advice on how to extend the code for this bit of noob with this code so any help or tips you guys have would be helpful >>>enhancement
14 documentation build error htmlhelp utf py sphinx version python version docutils version 10 release jinja2 version traceback most recent call last file usr lib python2 dist packages sphinx cmdline py line 189 in main app build force all filenames file usr lib python2 dist packages sphinx application py line 209 in build self emit build finished none file usr lib python2 dist packages sphinx application py line 314 in emit results append callback self args file mnt hgfs pythonlib doc scikit learn doc sphinxext gen rst py line 1035 in embed code links line line decode utf file usr lib python2 encodings utf py line 16 in decode return codecs utf decode input errors true unicodedecodeerror utf8 codec can decode byte 0xeb in position 33 invalid continuation byte>>>bug documentation
14 documentation build error message searchindex js sphinx version python version docutils version 10 release jinja2 version traceback most recent call last file usr lib python2 dist packages sphinx cmdline py line 189 in main app build force all filenames file usr lib python2 dist packages sphinx application py line 209 in build self emit build finished none file usr lib python2 dist packages sphinx application py line 314 in emit results append callback self args file mnt hgfs pythonlib doc scikit learn doc sphinxext gen rst py line 980 in embed code links relative true file mnt hgfs pythonlib doc scikit learn doc sphinxext gen rst py line 212 in init sindex get data searchindex url file mnt hgfs pythonlib doc scikit learn doc sphinxext gen rst py line 71 in get data with open url as fid ioerror errno no such file or directory mnt hgfs pythonlib doc scikit learn doc build htmlhelp searchindex js >>>bug documentation
isotonicregression gives nans on normal data have problem with isotonicregression it gives some nans in case of fitting some data with values close to zero but greater than sys float info min pickled some breaking data and uploaded them to sendspace http www sendspace com file 0i18ib and below is the crashing example >>>bug
bug coveralls skips `test common` he `test common` tests apparently fail to introspect the list of estimators in the package discussed in 2495 >>>bug
sgd bug coef layout wrong if partial fit happens after fit sgdclassifier fit calls set coef which transforms the coef array into fortran layout for faster prediction time partial fit does not do this thus slower at prediction partial fit does not transform from fortran to in the first place which leads to an exception if you call partial fit after fit for multi class problem fixes either transform fortran back to at the beginning of partial fit or don assume style arrays in plain sgd but rather memory views >>>bug
add coverage tracking on travis see https github com nipy nipy pull 297 files>>>build_/_ci easy enhancement
gradient boosting with sample weights pprett glouppe any plans to add support for sample weights in gradient boosting like they are already supported in decision trees and in adaboost >>>enhancement
bi coclustering api prevents scalability the biclustering and coclustering estimators promise to store boolean arrays `rows and `columns of size `n clusters samples` and `n clusters features` respectively and convert these to indices only on demand for use with large sparse matrices and large numbers of clusters these should be arrays of indices rather than boolean masks >>>enhancement moderate
labelencoder doesn work correctly for unicode labels in python numpy labelencoder works incorrectly for unicode labels in python numpy this is currently untested to reproduce replace bytestrings with unicode strings here https github com scikit learn scikit learn blob master sklearn preprocessing tests test label py l191 this is the cause of jenkins failure that https github com scikit learn scikit learn pull 2462 triggered >>>bug
bug gmm ``score `` returns an array not value the ``gmm score `` function returns an array rather than single value this is inconsistent with the rest of scikit learn for example both ``sklearn base classifiermixin`` and ``sklearn base regressormixin`` implement ``score `` function which returns single number as do ``kmeans`` ``kerneldensity`` ``pca`` ``gaussianhmm`` and others currently ``gmm score `` returns an array of the individual scores for each sample this should probably be called ``gmm score samples `` and ``gmm score `` should return ``sum gmm score samples `` note that in the last release we renamed ``gmm eval `` to ``gmm score samples `` believe this was mistake the ``score samples`` label has very general meaning it is used within ``kerneldensity`` while the results of ``gmm eval `` return tuple containing the per cluster likelihoods which makes sense only with gmm if this change were made so that ``gmm score `` returned single number then the following recipe would work to optimize gmm model as it does for kde http scikit learn org stable auto examples neighbors plot digits kde sampling html as it is this recipe fails for gmm the result >>>bug
test spectral clustering sparse fail on os 10 got this error on sklearn cluster tests test spectral test spectral clustering sparse any one knows what might be wrong os max os 10 numpy scipy 11 fail sklearn cluster tests test spectral test spectral clustering sparse traceback most recent call last file users chyikwei getglue python webservice virtual lib python2 site packages nose case py line 197 in runtest self test self arg file users chyikwei scikit learn sklearn cluster tests test spectral py line 155 in test spectral clustering sparse assert greater np mean labels 89 assertionerror 59999999999999998 not greater than 89 fail immediately with the given message raise self failureexception 59999999999999998 not greater than 89 >>>bug
mrg generative classification this pr adds simple meta estimator which accepts any generative model normal approximation ``gmm`` ``kerneldensity`` etc and uses it to construct generative bayesian classifier todo code documentation narrative docs testing examples allow class wise cross validation for the density model >>>needs_review
multilabel classification with feature selection runtimewarning and memoryerror am using scikit learn to solving multi label classification problem with large number of labels followed the ideas from larsmans it gives me runtime warning and then eventually memory error clf pipeline chi2 selectkbest chi2 1000 svm linearsvc multiclf onevsrestclassifier clf jobs multiclf fit xtr ytr home rsivapr scikit learn sklearn feature selection univariate selection py 157 runtimewarning invalid value encountered in divide chisq exp home rsivapr scikit learn sklearn feature selection univariate selection py 157 runtimewarning invalid value encountered in divide chisq exp home rsivapr scikit learn sklearn feature selection univariate selection py 157 runtimewarning invalid value encountered in divide chisq exp and then after multiple such warnings it fails the error dump below process poolworker 21 traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror exception in thread thread traceback most recent call last file home rsivapr anaconda lib python2 threading py line 808 in bootstrap inner self run file home rsivapr anaconda lib python2 threading py line 761 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 325 in handle workers pool maintain pool file home rsivapr anaconda lib python2 multiprocessing pool py line 229 in maintain pool self repopulate pool file home rsivapr anaconda lib python2 multiprocessing pool py line 222 in repopulate pool start file home rsivapr anaconda lib python2 multiprocessing process py line 130 in start self popen popen self file home rsivapr anaconda lib python2 multiprocessing forking py line 121 in init self pid os fork oserror errno 12 cannot allocate memory home rsivapr scikit learn sklearn feature selection univariate selection py 157 runtimewarning invalid value encountered in divide chisq exp process poolworker 22 traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror process poolworker 23 process poolworker 30 home rsivapr scikit learn sklearn feature selection univariate selection py 157 runtimewarning invalid value encountered in divide chisq exp process poolworker 31 traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap process poolworker 28 traceback most recent call last traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap process poolworker 32 process poolworker 29 traceback most recent call last traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap process poolworker 27 process poolworker 26 traceback most recent call last process poolworker 25 file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap traceback most recent call last traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self run self run self run self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker self target self args self kwargs self target self args self kwargs self target self args self kwargs self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get task get task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get task get task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv return recv return recv memoryerror memoryerror memoryerror return recv memoryerror return recv return recv memoryerror memoryerror return recv memoryerror return recv memoryerror self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker process poolworker 24 traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv unpicklingerror invalid load key self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror process poolworker traceback most recent call last process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker process poolworker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror return recv memoryerror self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv unpicklingerror unpickling stack underflow process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv unpicklingerror invalid load key process poolworker 10 traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv unpicklingerror invalid load key process poolworker 21 traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror exception in thread thread traceback most recent call last file home rsivapr anaconda lib python2 threading py line 808 in bootstrap inner self run file home rsivapr anaconda lib python2 threading py line 761 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 325 in handle workers pool maintain pool file home rsivapr anaconda lib python2 multiprocessing pool py line 229 in maintain pool self repopulate pool file home rsivapr anaconda lib python2 multiprocessing pool py line 222 in repopulate pool start file home rsivapr anaconda lib python2 multiprocessing process py line 130 in start self popen popen self file home rsivapr anaconda lib python2 multiprocessing forking py line 121 in init self pid os fork oserror errno 12 cannot allocate memory home rsivapr scikit learn sklearn feature selection univariate selection py 157 runtimewarning invalid value encountered in divide chisq exp process poolworker 22 traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror process poolworker 23 process poolworker 30 home rsivapr scikit learn sklearn feature selection univariate selection py 157 runtimewarning invalid value encountered in divide chisq exp process poolworker 31 traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap process poolworker 28 traceback most recent call last traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap process poolworker 32 process poolworker 29 traceback most recent call last traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap process poolworker 27 process poolworker 26 traceback most recent call last process poolworker 25 file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap traceback most recent call last traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self run self run self run self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker self target self args self kwargs self target self args self kwargs self target self args self kwargs self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get task get task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get task get task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv return recv return recv memoryerror memoryerror memoryerror return recv memoryerror return recv return recv memoryerror memoryerror return recv memoryerror return recv memoryerror self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker process poolworker 24 traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv unpicklingerror invalid load key self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror process poolworker traceback most recent call last process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker process poolworker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror return recv memoryerror self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv memoryerror process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv unpicklingerror unpickling stack underflow process poolworker traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv unpicklingerror invalid load key process poolworker 10 traceback most recent call last file home rsivapr anaconda lib python2 multiprocessing process py line 258 in bootstrap self run file home rsivapr anaconda lib python2 multiprocessing process py line 114 in run self target self args self kwargs file home rsivapr anaconda lib python2 multiprocessing pool py line 102 in worker task get file home rsivapr anaconda lib python2 multiprocessing queues py line 376 in get return recv unpicklingerror invalid load key http stackoverflow com questions 16400722 feature selection for multilabel classification scikit learn>>>bug
gradient boosting performance regression our new tree engine release 14 caused performance regression in gbrt for small moderate deep trees and large number of samples 100k the regression is even worse if you use large max features ie the default because the new tree engine is optimized for random split point selection if you care about performance on large sample size and moderately deep trees recommend using release 13 for the time being its supposed to be 5x faster than 14 in this regime apologize for the inconvenience we did test for performance regression in gbrt before switching to the new engine but underestimated the regression for large sample sizes the purpose of this issue is to collect some findings from gbrt users and that they care about typical hyper parameters settings typical samples features regimes >>>enhancement large_scale
wip label power set multilabel classification strategy add one of the simplest and common multi label classification strategy which use multi class classifier as base estimator the core code is functional but there is still things to do add some word about binary relevance in ovr narrative doc write narrative doc about lp add some references add some regression tests making your remark about overfitting bit more explicit maybe >>>needs_review new_feature
mrg multilabel indicator roc auc and average precision the goal of this pr is to add multilabel indicator support with various types of averaging for `roc auc score` and `average precision score` still to do implementation of micro macro weighted and sample `roc auc score` implementation of micro macro weighted and sample `average precision score` add general test for binary metric that are extended through averaging harmonize how global tests are performed for the metrics module write the narrative documentation ensure that the scorer interface work with both possible representations see 2451 pep8 priori won add ranking based `average precision score` don want to add support for the `multilabel sequence` format >>>new_feature
scaling kills dpgmm was mixture dpgmm not fitting to data am trying out the gaussian mixture models in the package tried to model mixture with two components 1000 500 and 2000 600 the following is the code data np random normal 1000 500 1000 data2 np random normal 2000 600 1000 data list data list data2 model mixture dpgmm components 10 alpha 10 iter 10000 model fit data print model means and got the following means of the components 13436485 13199086 11750537 10560644 12162311 00204134 12058521 11997703 11944384 11890694 it seems the model does not fit properly to the data is it bug or have got something wrong in the application of the model thanks fan >>>bug
mrg bicluster metrics improvements and additions to the bicluster metrics module todo refactor hungarian matching code let lave this for later vlad tests full code coverage implement gene match score update documentation to explain new functionality implement size bias correction implement other similarity metrics dice and goodness measure >>>needs_review
multi label and multi output multi class decision functions and predict proba aren consistent the `decision function` and `predict proba` of multi label classifier `onevsrestclassifier` is 2d arrays where each column correspond to label and each row correspond to sample added in 14 the `decision function` and `predict proba` of multi output multi class classifier `randomforestclassifier` is list of length equal to the number of output with multi class decision function or predict proba output 2d array where each row corresponds to the samples and where each columns correspond to class so this means that multi output problem with only binary class output is multi label task but isn consistent with the multi label format this is problematic if you want to code `roc auc score` function to support multi label output >>>api
sklearn metrics consensus score potentially gives wrong results hi `sklearn metrics consensus score gives wrong scores if the two results to be compared contain different numbers of biclusters this is because the function contains as its final line return np trace matrix indices max which uses `np trace` under the assumption that `matrix` the similarity matrix is square and thus contains the most similar items in its diagonal however when `matrix` is non square `n a` in the code this fails have an example dataset that shows such case deposited under https www dropbox com sh plmsqof84xhtxry 7lirdvx0mp just use import sklearn metrics rows np loadtxt home tom rows txt cols np loadtxt home tom cols txt rows np loadtxt home tom rows txt cols np loadtxt home tom cols txt print sklearn metrics consensus score rows cols rows cols this gives consensus score of 328 however the real score should be 529 the bug can be fixed by exchanging the last line of the function to return matrix indices indices sum max can send pull request if necessary however since it just single line fix not sure it worth it >>>bug
incorrect sorting by feature frequency in feature extraction text countvectorizer limit features while generating word cloud using andreas muller word cloud script noticed that when the parameter max features for countvectorizer is not none the topmost common features are not being returned this does not seem to be the correct behavior since if limit to top features only the highest frequency features should remain the same it appears that the problem is in countvectorizer limit features where document frequencies are being used for selecting the top occurring features think feature frequencies should be used instead am able to get the desired behavior with this modification here is the diff >>>bug
mse is negative when returned by cross val score the mean square error returned by sklearn cross validation cross val score is always negative while being designed decision so that the output of this function can be used for maximization given some hyperparameters it extremely confusing when using cross val score directly at least asked myself how the mean of square can possibly be negative and thought that cross val score was not working correctly or did not use the supplied metric only after digging in the sklearn source code realized that the sign was flipped this behavior is mentioned in make scorer in scorer py however it not mentioned in cross val score and think it should be because otherwise it makes people think that cross val score is not working correctly >>>documentation
test never finishes sklearn decomposition tests test sparse pca test fit transform recently installed scikit learn with pip install scikit learn version 14 trying to run the tests with nosetests exe sklearn the above mentioned test never seems to finish excluding the test with test fit transform all other tests seem to pass environment is set up according to http joernhees de blog 2013 06 08 mac os 10 scientific python with homebrew >>>bug build_/_ci
sparse matrix support in pairwise distances argmin min pairwise distances argmin min currently lacks support for sparse matrices >>>easy enhancement
memory error while predicting with kneighborsclassifier following is the piece of code that wrote to get feature selection using rfe and estimator linearsvc and then using the reduced data to fit and predict kneighborclassifier clf linearsvc 10 class weight auto rfe rfe estimator clf features to select 700 step 42 rfe fit trainlabels reduced train data rfe transform print reduced train data shape reduced train data shape reduced test data rfe transform test neigh kneighborsclassifier neighbors weights distance algorithm ball tree print knn initiated neigh fit reduced train data trainlabels print knn fitted test predict neigh predict reduced test data print knn predicted following is the output reduced train data shape 42000 700 knn initiated knn fitted and then see the following error this error does not happen everytime run the code by slightly changing the parameter can some one confirm whether this is bug or something else is going on here initial dimension of train data 42000 784 initial dimension of test data test 28000 784 am using version 14 1>>>bug
outdated documentation in the hmm module hi yesterday was browsing the scikit learn code to acquaint myself with the codebase came across this piece of documentation in the hmm module the mod `sklearn hmm` module implements hidden markov models warning mod `sklearn hmm` is orphaned undocumented and has known numerical stability issues if nobody volunteers to write documentation and make it more stable this module will be removed in version 11 as the current version is 14 guess this comment should either be removed or updated to reflect the current status of the hmm module >>>documentation
rfecv is broken rfecv has some issues ``scores shape `` is chosen as features which is the number of evaluations in the worst case step size if different step size is chosen not all cells are filled cells are initialized with zero for each evaluation the score is added to the cell scores can be either all negative or all positive depending on the scorer finally the max is chosen this is bug in the case of negative scores and step best score is the sum of all cv evaluations not the mean this is confusing because the best score cannot be related to the other cv experiments the number of final features selected is ``k`` which seems to refer to the rfe ranking of features where ties have the same rank imagine ranking where are two blocks of tied features `` `` since ``k`` is at most only two features ``n features to select 1`` could be selected at most maybe not getting the whole picture but it smells fishy ping amueller nicolastr >>>bug
elasticnetcv fails if ndim error somewhere in extension module cd fast so np random rand 100 10 np random rand 100 from sklearn linear model import elasticnet elasticnetcv est elasticnet fit fails valueerror buffer has wrong number of dimensions expected got est elasticnetcv fit >>>bug
add public partial fit to bernoullirbm `bernoullirbm` is an online model but the incremental learning method is hidden in the private fit` api `bernoullirbm` should have public `partial fit` akin to the one in `minibatchkmeans` and `minibatchdictionarylearning` along with tests and maybe an example using the digits dataset and random nudging to generate an infinite stream of samples while monitory the performance accuracy of stacked linear model trained on fix heldout training set and tested on fix validation set >>>easy enhancement
add support for sparse input to the bagging models bagging models as implemented in 2375 currently only support dense array like input we need add support for csr or csc input depending on whether sample bagging without weights and or feature bagging are enabled and the kind of input data representation we get some copy of re samples of the input data are likely to be required by calling `tocsr or `tocsc >>>enhancement moderate
segfault with large dataset segmentation fault occurs with the following snippet along with the core dump output the scikit version that on is scikit learn 14 import numpy as np data np memmap tmp features dat dtype float64 mode shape 40000000 100 target np memmap tmp targets dat dtype uint8 mode shape 40000000 from sklearn linear model import sgdclassifier clf sgdclassifier loss log penalty l2 clf fit data target program terminated with signal 11 segmentation fault 0x00007fa05a21c8aa in pyx 7sklearn 5utils 13weight vector 12weightvector dot pyx self 0x329d350 pyx data ptr 0x7f9c651271a0 pyx ind ptr 0x330f400 pyx xnnz at sklearn utils weight vector 1456 1456 sklearn utils weight vector no such file or directory in sklearn utils weight vector >>>bug large_scale
univariate selection api issues think the univariate selection api is bit unfriendly and doesn follow the project philosophy flat is better than nested my main concern is that we shouldn require the user to import callables such as classif regression and chi2 just using string would do the job as far as can see regression is the only function with an option center it can be made an option of the feature selector find the names classif and regression quite inexpressive are there better alternatives also noticed that there is genericunivariateselect class but it not documented in the user guide >>>api enhancement
fix string continuations across lines without whitespace occasionally am annoyed by output from scikit learn that munges words together due to multi line string continuations in the code that forget to include whitespace here collection of them to fix with review it should be possible to correct them automatically and then adjust for pep8 >>>easy
error in nosetests with numpy scipy 12 env skleanr 14 numpy scipy 12 python get this error after trying nosetest is it critical >>>bug
multiclass and multilabel classifiers should accept arrays with string labels with dtype object as numpy does not have dtype for variable length strings is very common to use `dtype object` for arrays of strings so as to no waste memory the default fixed width string dtype of numpy allocates zero padded memory otherwise however in sklearn 14 the `sklearn multiclass type of target` function explicitly rejects in consequence it possible to have `y cat dog fish but not `y np asarray cat dog fish dtype object anymore it used to work in 13 note that `np array list of string dtype object is necessary idiom instead of just using `list of string` directly to do cross validation or other fancy indexing operations think we should accept `y` to have dtype object if and only if `all isinstance six text type six binary type for in ravel this regression was found in the sklearn pandas project https github com paulgb sklearn pandas issues wdyt arjoly >>>bug
stratifiedkfold should do its best to preserve the dataset dependency structure as highlighted in this notebook http nbviewer ipython org urls raw github com ogrisel notebooks master non 2520iid 2520cross validation ipynb the current implementation of `stratifiedkfold` which is used by default by `cross val score` and `gridsearchcv` for classification problems breaks the dependency structure of the dataset by computing the folds based on the sorted labels instead one should probably do an implementation that performs individual dependency preserving kfold on for each possible label value and aggregate the folds to get the `stratifiedkfold` final folds this might incur refactoring to get rid of the basekfold` base class it might also make it easier to implement `shuffle true` option for `stratifiedkfold` >>>bug moderate
neighbors default algorithm description not acurate think the behavior of the auto parameter changed but the narratives don reflect that >>>documentation
example file missing or renamed in sklearn linear model lasso recovery path documentation at the bottom of this page http scikit learn org dev modules generated sklearn linear model lasso stability path html sklearn linear model lasso stability path it states that see examples linear model plot sparse recovery py for an example it looks like this file no longer exists or has been renamed or combined into another file with no clear rule as to which file that would be >>>bug documentation
onevsoneclassifier scores calculation version 14 in multiclass py function predict ovo estimators classes it has scores score scores score however think it should be scores score scores score think the idea here should be when score the positive class increase its value in scores by score and the negative class decrease its value by score because in case of tie we use argmax scores to determine the class so the scores should represent how certain we are about the class therefore in the original code should represent the positive class while represents the negative class since from pred and score you find out when score is positive it has the label of and otherwise it means is the positive class label and is the negative class label however in fit ovo binary estimator with and being the same as used in predict ovo estimators classes we know that since is the positive class label then represent the positive class for classifier trained between and with is the positive class back to function predict ovo estimators classes we see from line scores score if score we decrease the value corresponding to class which is incorrect hope it is not too verbose >>>bug
feature selection based on score dummy columns found that `feature selection` based on `f classif` test can break if one feature has constant value all zeros the best way to test this is to add column of all zeros to `x` in the example `plot feature selection py` see the column `dummy` below `f classif` already throws warning whenever multiple columns multiple features are duplicates of each other it may be good idea to also warn the user when feature is constant across all instances >>>enhancement
bug in meanshift with small number of samples the code from this so question http stackoverflow com 18157273 166749 reposted below for reference sometimes works and sometimes fails too tired to check if this is really bug but if it isn the error message could be made friendlier >>>bug
changes in ridge py break usage with large sparse matrices following code runs fine on 13 fails with memoryerror on 14 import numpy import scipy sparse 50000 10 scipy sparse rand density 001 numpy random random from sklearn linear model import ridgecv mod ridgecv mod fit >>>bug
doc user guide html has crazy amount of white space due to the toc tree collapsing it leaves the page massive will load fix in few minutes>>>bug documentation
minor website tweaks for 14 release aka urgent add link to the citation page on the front page say next to the donate button make carousel with few more examples on the front page later display some sponsors on the front page clean up the examples page that has lot of embedded css that should be fixed by giving proper css class to elements rst has directive class believe to do that make the blue next previous buttons not sliding and fixed at the bottom of the page>>>documentation
doc fork me on github banner blocks `clear search button` will fix shortly>>>bug documentation easy
fix ml flowchart cut off at bottom without javascript hack after the website facelift the machine learning cheat sheet got cut off at the bottom due to some jquery script interfering its been fixed temporarily for the sake of the online website using quick javascript fix but should ideally be done in css without resorting to script will look into it at later point if nobody else jumps on it>>>documentation
example image on front page should be clickable and point to the example page that less work than carousel so we should do this rather than waiting for the carousel nellev >>>documentation easy enhancement
ward test crashes on windows with python from anaconda and msvc 2008 and 2010 the test at fault is check that we obtain the correct number of clusters with ward clustering need break from this and will not pursue at the moment think it works fine with mingw but binaries can be released this way cc ogrisel >>>bug
setup jenkins job to test the result of an installed sklearn tarball in venv this can be done as in this bash script https gist github com ogrisel 6102848 file test procedure sh and wrapped as new jenkins job we first need to fix 2319 though >>>build_/_ci enhancement
make docstring doctest run with `sklearn test behave as when run with `nosetests sklearn` as evidenced by 2318 the doctest runner of `sklearn test does not include the function that carry the docstring doctest its doctest namespace while it is the case when we run the doctests with `nosetests sklearn` if we can find way to fix that we will be able to setup continuous integration for installed packages to automatically test the packaging of the future releases >>>build_/_ci enhancement
run and fix the tests on the installed version of scikit learn 14a1 tarball see the test procedure and failures here https gist github com ogrisel 6102848>>>bug build_/_ci
website alignment broken when disabling certain scripts use browser plugin that disables most cross site extensions that can track you on the scikit learn website it finds google analytics and google ajax search api believe the latter being disabled causes the header to be less tall than it should be and the body to shift bit tagging this as enhancement because if you install such blockers you basically void your warranty and shouldn expect greatness >>>enhancement
have home point to the stable docs all the time for this the home button should refer to stable index html and the makefile should be changed to build in the build html stable directory we also need to update the readme file in the docs folder so that people don push to stable by mistake >>>documentation easy enhancement
add link to whatsnew on website currently there is no link to the whatsnew on the frontpage or anywhere >>>bug documentation
table of scorers not up to date in `model evaluation rst` the table of scorers still lists things like `mse` that were renamed fix it but gotta run >>>documentation easy
backward compatibility problem with the new scorer api the following test fails right now while it worked fine in 13 def test cross val score score func clf mockclassifier score func1 args score func2 args def score func1 data score func1 args append data return def score func2 test predict score func2 args append test predict return score1 cval cross val score clf score func score func1 assert array equal score1 assert len score func1 args score2 cval cross val score clf score func score func2 assert array equal score2 assert len score func2 args >>>bug
failing hashing test on master have no idea what is going on here didn have that before >>>bug
run old tests under new version we need to run the tests of 13 under 14 rc to ensure backward compatibility before tagging flagged as bug for the redness of it would consider this blocking >>>bug
cca example looks broken the multi label example uses cca and looks broken in dev but good in stable cc nellev >>>bug
buffer dtype mismatch in neighbors under windows in windows 32bit mingw compiler the new neighbors module doesn work and get the following errors file binary tree pxi line 223 in sklearn neighbors kd tree get memview nodedata 1d sklearn neighbors kd tree 3071 valueerror buffer dtype mismatch next field is at offset 12 but 16 expected ping jakevdp ogrisel any clues >>>bug
add topical howtos to documentation add topical howtos to documentation possible topics out of core text processing >>>documentation
website here are list of things we need to change in the website the design is slow to load hence it resizes it automatically after loading the top menu needs to be rewritten completely to avoid alignment problem see ogrisel computer fork me on github not working disable the github fork ribbon on small mobile screens sidebar should collapse automatically on very small screens check that we are using the asynchronous syntax for the google analytics tracker https developers google com analytics devguides collection gajs hl fr>>>documentation
adaboost classifier takes mutable default argument so adaboost gets as default argument ``base estimator decisiontree `` this is bad for two reasons it is ugly it doesn cause any bugs because base estimator is always cloned but we should really avoid mutable defaults it breaks sphinx that means the api doc for adaboost is not generated setting the default argument to ``none`` is not real option as that doesn allow grid searching the parameters of ``base estimator`` with the default value we could in principle set change ``base estimator`` in `` init `` but that would violate our policies and mean that ``none`` is not valid parameter setting for ``base estimator`` in grid searches ping nellev for the sphinx issue >>>bug documentation
running tests should not print anything on stdout stderr or warnings it should be possible to run `nosetests sklearn doc` and not get anything on the output besides the progress dots for instance currently we get those specific warnings were discussed here https github com scikit learn scikit learn pull 1988 issuecomment 21662410 my personal opinion is that all expected warnings should be individually catched and checked in tests with the `with warnings catch warnings record true as idiom all un expected warnings should by fixing the root problem we should never print anything to stdout stderr in the tests >>>build_/_ci
replace lists of labels for multi label by sparse matrices we agreed on the sprint that having lists of lists is too hard from an api standpoint and we should rather use sparse matrices to ease input validation and remove ambiguities we will need to provide some helper functions to create the sparse matrix labels though >>>enhancement
developpement doc should clarify some abreviations in pull request name there is wip mrg and in commit there is enh fix tst doc maint >>>documentation easy
mrg nudge images to enhance small datasets this pr is just to do something that we did in examples plot rbm logistic classification py at https github com vene scikit learn commit f37668f148e4460d3eb6892313845f8975e6c95a less readably but faster maybe it could be even faster if we did not ask for samples but guess this is convenient to have should check arrays for inputs example >>>needs_review
doc upgrade jquery to version 10 as discussed in the website redo pr https github com scikit learn scikit learn pull 2201 jquery has been updated from the ancient it was working on to however moving any more recent than that creates problems with the collapsible table of contents on the userguide page it would be useful if somebody can figure out what problem is being caused by the change in the `toggle function in jquery between version and ll tend to this at later stage if nobody has time >>>documentation enhancement
wip fix naive bayes coefficient stuff this fixes 2237 and 2240 not yet mrg and 14 rc because not sure if there good way to preserve backward compat and some more refactoring needs to be done >>>needs_review
common tests for feature selection maybe using `` learntselectormixin``>>>enhancement
gradient boosting oob test error on 32bit fail check oob improvement on multi class dataset traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file home local lamueller checkout scikit learn sklearn ensemble tests test gradient boosting py line 526 in test oob multilcass iris decimal file usr lib python2 dist packages numpy testing utils py line 800 in assert array almost equal header arrays are not almost equal to decimals decimal file usr lib python2 dist packages numpy testing utils py line 636 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals mismatch 100 array 12 61875849 10 42618873 97227818 18745436 95108778 array 12 68 10 45 18 43 02 raise assertionerror narrays are not almost equal to decimals mismatch 100 array 12 61875849 10 42618873 97227818 18745436 95108778 array 12 68 10 45 18 43 02 >>>bug
cython errors on current master get the following errors when trying ``make cython`` have error messages >>>bug
typo in documentation for 19 sklearn metrics fbeta score beta favors precision should be beta favors recall http scikit learn org stable modules generated sklearn metrics fbeta score html sklearn metrics fbeta score>>>documentation
doc docstring for tree the docstring for the cython `tree` implementation disappeared in 2131 it should be put back if only for maintainability also think description of the shapes of attributes especially `value` should be added >>>documentation easy
remove any astype invocation when copy is not required realized that in many places in the code it was assumed that the astype method copied data only if required which is not the case copy is always made even if the array dtype doesn change this causes useless copies to be made in several places one of them being all metrics functions quick fix is to replace any invocation of astype by asarray another is to use the copy false flag on astype but the latter is only available starting with numpy doing this will reduce memory consumption with little or no effort >>>enhancement
write narrative documentation for out of core learning update the out of core example to plot the behavior of `perceptron` `passiveaggressiveclassifier` and `multinomialnb` on the reuters dataset write narrative documentation to explain the motivation explain the `partial fit` method usage in general and refer to the example in particular and give hints implementation constraints stateless feature extraction knowing all the classes ahead of time for classification models to be linked to in this section for classification perceptron multinomialnb bernoullinb sgdclassifier passiveaggressiveclassifier for regression sgdregressor passiveaggressiveregressor for out of core clustering feature extraction minibatchkmeans for out of core decomposition feature extraction minibatchdictionarylearning>>>documentation
option to return an array in metrics if multi output thanks to the work of arjoly regression metrics now support multiple outputs 2d currently the metrics return scalar it would be nice to have an option to return an array of size outputs >>>easy enhancement
crash in meanshift tests after make cython edited from means the crash some related warnings >>>bug
minibatchkmeans bad center reallocation causes duplicate centers for instance have look at http scikit learn org dev auto examples cluster plot dict face patches html some of the centroids are duplicated presumably because of bug in the bad cluster reallocation heuristic >>>bug moderate
random forest memory efficiency training forest of trees in parallel using joblib will create multiple copies of ``x`` in order to limit the memory consumption we have number of alternatives openmp via cython ``prange`` shared memory support for joblib the issue originated from 1435 >>>large_scale
mrg added code for sklearn preprocessing rankscaler wrote code for doing rank scaling this scaling technique is more robust than standardscaler unit variance zero mean believe that scale is the wrong term for this operation it actually feature normalization this name conflicts with the normalize method though wrote documentation and tests however was unable to get the doc suite or test suite to build for the current sklearn head so couldn double check all my documentation and tests >>>needs_review
broken build under windows gradient boosting bad reloc address 0x0 in section data apparently number of windows users could not build the current master under windows the common error message is the following so it might be something in the gradient boosted cython code that is not supported by mingw under windows on stackoverflow http stackoverflow com questions 17621541 building issue of scikit learn python library in windows http stackoverflow com questions 17598112 issue when building scikit learn in windows on the mailing list http comments gmane org gmane comp python scikit learn 7788>>>bug
twenty newsgroups doc does not match api http scikit learn org dev datasets the 20 newsgroups text dataset includes `from sklearn feature extraction text import vectorizer` which raises `importerror cannot import name vectorizer`>>>bug documentation easy
enh inherit from learntselectormixin` where `feature importances is available presume any estimator that sets `feature importances attrib should be usable as feature selector with `sklearn feature selection from model learntselectormixin` at least `gradientboostingclassifier` does not >>>easy enhancement
missing deprecation release info of warn on equidistant in kneighborsclassifier in `kneighborsclassifier` there is deprecation on the parameter `warn on equidistant however there is no information about the ending of the deprecation >>>documentation easy
confusion error message with check clf target in the metrics module `python import numpy as np from sklearn metrics metrics import check clf targets y1 np array y2 np array 35 45 45 65 35 55 35 check clf targets y1 y2 check clf targets y1 y2 users ajoly git scikit learn sklearn metrics metrics pyc in check clf targets true pred 69 if type true startswith multilabel 70 if not type pred startswith multilabel 71 raise valueerror can handle mix of multilabel and multiclass 72 targets 73 if type true type pred valueerror can handle mix of multilabel and multiclass targets >>>bug easy
hmm uses class labels as array index try to correct class labels produced by an svm classifier class labels are the following exception occurs it turns out that class labels are internally used as array indices that definitely should not be labels are completely arbitrary and have semantically meaning while array indices and how indexing works is part of python syntax this must not be mixed up example from text book classes labels and the function will return always the same values since obs is always list list of that contains an >>>bug
adaboost example plots decision boundary incorrect see http scikit learn org dev auto examples ensemble plot forest iris html right most column the decision boundary does not take the weights into account these should be used instead of ``alpha 1`` reported by ian ozsvald on the sklearn mailing list >>>easy
gradientboostingclassifier with baseestimator gradientboostingclassifier does not work correctly when the basepredictor init is set to something like linear model logisticregression thinks the source of the error is in in basegradientboosting fit where init predictions pred self init predict pred should be initialized by class probabilities and not with the winner class replacing pred self init predict with pred self init predict proba can solve the problem >>>bug
implement ``class weights`` parameter for random forests since they now support ``sample weight`` the implementation is pretty straight forward >>>enhancement
multinomialnb bernoullinb coef inconsistency shape is nfeatures not nfeatures am trying to run your 20newsgroups code on my own data with single class it bugs because in the one class case all classifiers use coeff shape nfeatures except multinomialnb and bernoullinb which have coef shape nfeatures if hasattr clf coef print dimensionality clf coef shape infact naive bayes line 265 xxx the following is stopgap measure we need to set the dimensions of class log prior and feature log prob correctly def get coef self return self feature log prob if len self classes else self feature log prob >>>enhancement
sample weight default bug in ridgeclassifier dense cholesky solver always used ridge py line 80 basically ridgeclassifier creates sampleweight vector of 1s by default and has sw isinstance sample weight np ndarray or sample weight if has sw solver dense cholesky which meands that the normal cholesky solver is always used when you don enter any sample weights >>>bug
decomposition nmf transform isn working properly after running the code here without errors on python on windows http scikit learn org stable auto examples applications topics extraction with nmf html example applications topics extraction with nmf py attempting to transform the input data with the fitted model raises an error nmf transform tfidf traceback most recent call last file line in file python27 lib site packages sklearn decomposition nmf py line 563 in transform nnls self components file python27 lib site packages scipy optimize nnls py line 48 in nnls raise valueerror incompatible dimensions valueerror incompatible dimensions >>>bug
norm inconsistency between rfe and selectfrommodel was learntselectormixin in each rfe iteration the `step` features with the lowest importance are discarded https github com djv scikit learn blob master sklearn feature selection rfe py l158 similar thing happens https github com djv scikit learn blob master sklearn feature selection from model py l100 in `selectfrommodel` but selection is by threshold rather than by number of features there are some inconsistencies the mixin admits https github com djv scikit learn blob master sklearn feature selection from model py l44 either `est coef or `est feature importances as the basis of its calculation rfe only `coef fixed in 4496 the mixin uses `np abs est coef while rfe uses `safe sqr est coef the result is the same for selecting features by quantity as long as `coef is 1d but where 2d the sum is taken over axis and the ordering under l1 and l2 norms may differ should rfe support `feature importances for `coef ndim 2` should `selectfrommodel` use `sqrt sqr coef sum axis glouppe think >>>easy
should charset be changed to encoding just fixed the spelling of charset in parameter name 2106 but wonder if all charset related parameters should be deprecated and renamed to encoding the notion that text encoding represents character set is outdated for example both utf and utf 16 represent the same set of characters which is unicode but they do so with very different encodings changing the parameter name to encoding would better match other python functions most notably the decode and encode methods and would also match the python unicode howto >>>easy
some spelling errors in the documentation in case anyone cares enough to spend moment fixing them >>>documentation easy
fastica issues the methods are poorly documented in particular returned shapes there no efficient fit transform think one just needs to return sources there no inverse transform we could provide one since we provide way to get the mixing matrix anticipating the 14 release the deprecated property can be removed will do that tonight >>>easy enhancement
inconsistency for fitting classifiers with only one class for letting all classifiers trivially ``fit`` on dataset with single class >>>bug
inconsistency between precision recall curve and roc curve the axis and axis for precision recall curve and roc curve are reversed which find confusing bothering for roc curve for precision recall curve not sure if there anything we can do about it without breaking the api >>>enhancement
tst add test for `sample weight` parameter to isotonic regression this parameter is apparently untested >>>easy
pls partial least square algorithms occasionally failing attempting to use the cca class in pls py getting some unhelpful errors the example given in the documentation is from sklearn pls import plscanonical plsregression cca 11 12 cca cca components cca fit this works okay and also works okay with the change cca cca components however if is changed to change in last value then the code gives the error valueerror array must not contain infs or nans apologise if am just misusing the function but this error was coming up for me in less contrived example this is using the current master on github >>>bug
enh allow feature agglomeration with any clustering method the ward clusterer is accompanied by `wardagglomeration` which reduces the feature space by pooling `mean` `max` `pca` the values of those that are close in the sample space the implementation only involves fitting on `x t` rather than `x` and inheriting from `agglomerationtransform` to provide `transform` and `inverse transform` methods though the `pooling func` argument to `transform` should probably be an estimator level property it would seem sensible to provide equivalent agglomeration functionality for other clusterers it could be implemented as meta estimator but scikit learn may want to keep the api simpler >>>easy enhancement
enh use the scoring interface in rfecv `gridsearchcv` and `cross val score` recently adopted support for scoring object instead of `score func` and `loss func` 1381 `sklearn feature selection rfecv` also accepts `loss func` or alternatively uses `estimator score` and should instead support the same interface as `gridsearchcv` >>>easy enhancement
sklearn manifold spectral embedding doesn return spectral embedding from pylab import from scipy sparse import linalg as la from sklearn import manifold as rand 50 50 la eigh which sm spectral embedding drop first false dot should return identity dot should return identity but it does not >>>bug
installing on 64bit windows for python using unofficial installers so took your suggestion and installed numpy scipy matplotlib and then scikit learn in that order all from the same website that you listed http www lfd uci edu gohlke pythonlibs scikit learn which was very helpful btw out of curiosity ran the nose tests and got the output below pretty sure can still use most of the scikit learn functionality but would anyone care to comment on that again my approach was to use only the installers am overlooking anything >>>bug
doc fix discrepancies between docstrings and signatures the parameters listed in class method and function docstrings sometimes are obsolete misspelled or missing from the actual call signature often the docstring parameter should be removed but in other cases like 2060 an argument should be added to the function here are some possible discrepancies including number of false positives false negatives include all cython code produced by this script https github com jnothman scikit learn blob test docstring parameters test docstring parameters py >>>documentation easy
documentation needed for bin seeding in sklearn cluster meanshift bin seeding is not documented in sklearn cluster meanshift assume that the documentation from sklearn cluster mean shift can be used >>>documentation
randomizedpca components is not 50 by default looking at https github com scikit learn scikit learn blob master sklearn decomposition pca py the documentation says maximum number of components to keep default is 50 but the behavior is maximum number of components to keep default is shape when calling fit however if no value is passed components is none def init self components none copy true iterated power whiten false random state none and later the shape of the matrix is used if self components is none components shape have not checked the other pca methods in this file just randomizedpca >>>bug easy
tree pxd is not copied when sklearn is installed on linux the file tree pxd is required for extending the tree class using 3rd party cython am using but that fails if this file is unavailable it should be installed with the other sklearn files my current work around sudo cp home tim dev sklearn sklearn tree tree pxd usr local lib python2 dist packages sklearn tree tim>>>bug easy
gradientboostingclassifier train score bug when increased the estimators to 1000 the train score suddenly jumped to large number as follows built tree 723 of 1000 train score 318154e 01 built tree 724 of 1000 train score 317394e 01 built tree 725 of 1000 train score 317101e 01 built tree 726 of 1000 train score 835322e 12 built tree 727 of 1000 train score 835322e 12 built tree 728 of 1000 train score 835322e 12 built tree 729 of 1000 train score 835322e 12 built tree 730 of 1000 train score 835322e 12 and kept 835322e 12 with no change thanks>>>bug moderate
references to means init missing there are no references to the means paper also the notes in the docstring contain more references comments than the narrative which find strange >>>documentation easy
rename isotonicregression fit weight parameter to sample weight assume this parameter should be `sample weight` not `weight` for consistency with other estimators `weight` will need to be deprecated but available for two versions as usual `isotonicregression` documentation should also be checked it says `y` `weight` should be iterable but they should be array like since `np asarray` doesn work with all iterables >>>easy
add hoverintent effect to the gallery upgrade in 2017 although the gallery in 2017 works well if one for some reason swooshes the mouse pointer about in crazy fashion over the gallery items it can sometimes happen that one or two stay open which goes away once moused over and off again it nothing serious and doesn break or impede the functionality of the gallery however this can be avoided with something like jquery hoverintent http cherne net brian resources jquery hoverintent html not saying that is exactly what will fix it but it more of just reference for what needs to be done in nut shell the thumbnail should only expand due to mouseover when the mouse has stopped on top of it ll look into this bit later if nobody spots and does nice solution in the meanwhile>>>documentation enhancement
image in tutorial misaligned the plot at this http scikit learn org dev tutorial statistical inference supervised learning html nearest neighbor and the curse of dimensionality page in the tutorial is sort of got an ugly layout going needs to be resized moved around wee bit>>>documentation easy
shift around docstrings in certain examples this goes with 2017 any type of `rst` code like for example links or math code must be shifted little further down in the docstring as to keep the first 95 characters as normal text this will allow the docstrings to stay legible as the rst doesn render there it just text when seen in the examples gallery will do this shortly if no newcomer grabs it >>>easy
extend `featureunion` to better handle heterogeneous data `featureunion` currently passes identical data to each constituent transformer often one wants to differentiate between groups of features in how they are transformed while this is possible by making each stacked transformer `pipeline` consisting of pre determined feature selector and another transformer this is cumbersome parameter should be added to specify which features are routed to which constituents this is not necessarily trivial to design particularly because the input `x` to `featureunion transform` need not be conventional 2d feature array it may be list array of dicts texts or other objects >>>moderate new_feature
tst ensure successful `from import for all submodules at present `from sklearn datasets import is failing due to an error in its all see 2032 there should be test to ensure that can be imported from all modules packages >>>easy
bug load 20newsgroups in sklearn datasets all but does not exist should `load 20newsgroups` exist or should it be removed from `sklearn datasets all >>>bug
1979 added hamming loss and jaccard similarity to scorers and make hamming loss default fixed scikit learn scikit learn 1979 hi this is my first contribution to the scikit learn project added the hamming loss to scorers and made it default score for onevsrestclassifier if you have any comments please let me know best andreas >>>enhancement
bug need to ensure classification metrics are sane under non stratified cross validation where dataset is split up and not all evaluated at once some classes may be missing from evaluation metrics implementations get around problems relating to classes appearing not in both the `y true` and `y pred` by considering the union of their labels however this is insufficient if label that existed in the training set for fold is absent from both the predicted and true test targets this is at least problem for the family of metrics with `average macro and `labels` unspecified and it should be documented though user shouldn be using macro if there are infrequent labels haven thought yet about whether it is an issue elsewhere or whether it can be reasonably tested >>>bug
test failure in metrics module on 32bit fail doctest sklearn metrics metrics precision recall fscore support traceback most recent call last file usr lib python2 doctest py line 2201 in runtest raise self failureexception self format failure new getvalue assertionerror failed doctest test for sklearn metrics metrics precision recall fscore support file home local lamueller checkout scikit learn sklearn metrics metrics py line 1468 in precision recall fscore support file home local lamueller checkout scikit learn sklearn metrics metrics py line 1600 in sklearn metrics metrics precision recall fscore support failed example precision recall fscore support true pred average weighted doctest ellipsis expected 499 65 none got 65000000000000002 none raise self failureexception self format failure getvalue fail doctest sklearn metrics metrics precision score traceback most recent call last file usr lib python2 doctest py line 2201 in runtest raise self failureexception self format failure new getvalue assertionerror failed doctest test for sklearn metrics metrics precision score file home local lamueller checkout scikit learn sklearn metrics metrics py line 1777 in precision score file home local lamueller checkout scikit learn sklearn metrics metrics py line 1863 in sklearn metrics metrics precision score failed example precision score true pred average weighted doctest ellipsis expected 49 got raise self failureexception self format failure getvalue >>>bug easy
tst need tests for multilabel format issues in `sklearn tests test multiclass py` we should be testing for identical results given sequence of sequences binarized with neg label binarized with neg label the edge case where all entries have the same number of labels ensure it works with sub samples via `cross val score` writing the tests should be easy making them pass may not be >>>easy
unicodedecodeerror when running `gen rst` on my machine ``gen rst py`` throws unicodedecodeerror when creating the permalink headers the paragraph symbol on the right hand side of the title here is trace exception occurred file home pprett workspace scikit learn doc sphinxext gen rst py line 882 in embed code links line line replace name link unicodedecodeerror ascii codec can decode byte 0xc2 in position 232 ordinal not in range 128 maybe its particular issue of my machine haven fiddled with sitecustomized py though would be great if someone could run ``make clean html`` and check whether it works thanks>>>bug documentation
onevsrestclassifier has predict proba but no decision function don really see reason for that >>>easy enhancement
callable kernel for kernelpca while svc supports custom callable kernels kernelpca does not precomputed kernel is still supported however am not sure about other kernel based methods it would be very useful to be able to provide custom kernel to kernelpca too am more interested in custom distance function but custom kernel will do too the reason want something other than current provided kernels is that know my features can be circularly shifted for fixed but unknown delta therefore want to use circular cross correlation to measure distance appreciate if you let me know if there is better way to do this and if this is worthy effort at all also let me know if should have discussion on mailing list before adding an issue in the future >>>enhancement
constant output dummyclassifier for where the class of interest is in the minority `dummyclassifier` currently offers the most frequent strategy to assign the most frequent label from training to every instance in binary classification task where the most frequent class is negative and hence score is used the most frequent strategy will always yield recall of more useful baseline would always output the positive or given label producing recall of and precision of `n positive samples` and thus f1 67 >>>easy enhancement
predicting probabilities with svc is not reproducible from one run to another sklearn metrics tests test metrics test precision recall curve failed any ideas jnothman >>>bug
enh tst need to test multilabel metric invariance where negative indicator currently it seems the tests for multilabel metrics that are passed label indicator matrices have varying positive indicator but always negative indicator in practice neg is much more likely to vary between and >>>easy enhancement
bug labelbinarizer returns label indicator matrices unchanged `preprocessing labelbinarizer` when passed an indicator matrix returns it unchanged it should return it with correct `pos label` and `neg label` indicator values >>>bug easy
enh un confuse pos label use for label indicator matrices some metrics take `pos label` argument and interpret it as indicating the positive class in label indicator matrix multilabel target representation this meaning should be removed because it is unusual for `pos label` to not be and it can be confused with the positive class label which corresponds to column in label indicator matrix not value should `pos label` also be removed from `labelbinarizer` where it means positive indicator value and fixed to assume `neg label` should not be fixed to as some classifiers work with however perhaps that not desirable flexibility in label indicator matrices don particularly like `pos label` being used there either given that `label` is synonymous with `class` elsewhere perhaps the `labelbinarizer` parameters where not removed should be renamed to `pos indicator` and `neg indicator` this was brought up at 1983 and 1985 accidentally posed it at one when it was meant for the other >>>enhancement
enh should be able to ignore majority class in the multiclass case are famous for handling class imbalance in the binary classification case correct me if wrong arjoly but imbalance against majority negative class should also be handled in the multiclass case in particular while the documentation currently states that micro averaged this is not true of the case where negative class is ignored but it should be possible to ignore negative class for any of the `average` settings indeed think the `pos label` argument is mistake except in that you can more reliably provide default value than for `neg label` it only applies to the binary case and overrides the average setting `neg label` would apply to all multiclass averaging methods it should be easy to implement treat the problem as multilabel and delete the `neg label` column from the label indicator matrix it is the case where each instance is assigned or label the tricky part is the interface should `pos label` be deprecated deprecation makes sense as `pos label` and `neg label` should not be necessary together but if so how do we ensure the binary case works by default >>>enhancement
multi label support of precision recall fscore support the narrative docs claim that ``precision recall fscore support`` and ``classification report`` support multi label input don think that is true trying out list of labels representation and looking at the code also there seem to be no tests for this case cc arjoly >>>bug easy
doc fix references to missing examples in few places in the code examples are referenced that no longer exist these references should be updated or removed >>>documentation easy
add hamming loss to the scorers make it default score implementation for ovr ovo classifiers currently the hamming loss is not in the ``scorers`` dict don see reason why we should leave any scores for the moment that return single value out of the dict so we should probably also add jaccardindex and maybe some others there is also no default implementation of ``score`` for the ``onevsrestclassifier`` and ``onevsallclassifier`` in the multi label case think the main reason was that we didn have the hamming loss or any other multi label loss when these were implemented we should definitely add default implementation and vote for the hamming loss currently grid searching multi label problems is bit inconvenient because of the above two issues >>>easy enhancement
doc explain when to use which metric glouppe wrote https github com scikit learn scikit learn pull 1945 issuecomment 17707603 the model evaluation page http scikit learn org dev modules model evaluation html in the narrative documentation is getting quite big and have the impression that it is becoming copy of the reference documentation it lists bunch of metrics explains what they are but not really what they are for think it would be valuable to add some insights for the users in which cases one should prefer metric over the other arjoly replied yes this is something missing more examples are needed to illustrate the metrics module and others should rewritten to give more insight to our user moreover something similar to the clustering metrics documentation http scikit learn org dev modules clustering html clustering evaluation would be great addition to the documentation >>>documentation
mrg blockwise parallel silhouette computation this pull request introduces blockwise computation of the silhouette using less memory but slightly slower first the vocabulary can be debated have chosen the word global for the original silhouette strategy as the global distance matrix is computed could not come with better word and blockwise for my method the other point is that have implementations of the silhouette the original one blockwise single threaded version blockwise multi threaded version which uses bit more memory than the single threaded version even if jobs have decided to leave the original version untouched as the code is far more readable than mine then have not kept the most efficient blockwise single threaded version because the memory gain is not worth the code complication think it is in fact possible to have one implementation to rule them all this could be done by keeping the same code skeleton and using precomputed distance matrix for the original version but think that the code would become too opaque >>>needs_review
enh move non data transform parameters to the object to be used sensibly in `pipeline` parameter search an estimator `transform` method can have parameters other than the data though it may be possible in the future to support more than one data argument rather it should be possible to set the parameter using the estimator `set params` method as used in parameter search hence additional arguments to `transform` should become object parameters though whether they should be made unavailable as arguments directly to transform is up for debate unfortunately these happen to appear in mixin classes meaning lot of sub classes docstrings need altering examples of additional arguments https github com scikit learn scikit learn blob 71d00d94f48f2131ff7fe661c1069ec234c92305 sklearn cluster feature agglomeration py l22 https github com scikit learn scikit learn blob master sklearn feature selection from model py l20 should have `selection threshold` parameter on object>>>easy enhancement
minmax scaler and typeerrors am trying to use the minmax from sklearn my code is quite simple from sklearn preprocessing import minmaxscaler followers np array df followers count astype float scaled followers scaler fit followers get the following error experimented with multiple numpy arrays same problem typeerror traceback most recent call last in followers np array df followers count astype float print followers scaled followers scaler fit followers home amaatouq anaconda lib python2 site packages sklearn preprocessing pyc in fit self 195 scale np max axis min 196 do not scale constant features 197 scale scale 198 self scale feature range feature range scale 199 self min feature range min scale typeerror numpy float64 object does not support item assignment >>>bug
svm svc documentation wrong about sigmoid and poly kernel parameters svm svc documentation states that the degree parameter is significant for the sigmoid kernel also it says that gamma is coefficient for the polynomial kernel and not the sigmoid kernel however gamma is used as coefficient for the sigmoid kernel and degree is not relevant for this kernel also gamma is not related to the polynomial kernel quick check on the source code in metrics pairwise py confirms kernel params rbf set gamma sigmoid set gamma coef0 polynomial set gamma degree coef0 thanks >>>documentation
lda transform gives wrong dimensions help doc of `lda transform` says however produces while expect it to be as `n components 3` looking at the code of transform `return np dot self coef comp where `self coef is computed as in fit `self coef np dot self means self xbar self scalings which produces 2x1 matrix or whatever the number of means is not sure what the correct thing would be but it seems that `lda coef should have length `n compoments` no >>>bug documentation easy
plot lena segmentation is super slow don remember this example taking so long before anyone know why it may have gotten slower please give it run maybe it just on my box ll look into more soon just thought report it in the meanwhile >>>bug
sgd l2 penalty should be applied before additive update the issue was caught by mblondel in scikit learn we do eta then eta alpha the last step is wrong as this will scale eta instead of so if we want to do proper sgd update we should first do the regularization step then the additive step >>>bug
maint some transform methods accept unused argument `transformer`s generally work with single data argument often `x` and sometimes additional parameters as far as can see whenever `x` and `y` are both arguments to `transform` the `y` goes unused to make the api clearer all such instances of `y` should be removed though perhaps deprecated see http scikit learn org dev developers deprecation to avoid `typeerror`s where users have passed in value for `y` redundantly >>>easy
error while fitting gridsearchcv svm pipeline chi2 selectkbest chi2 svm linearsvc class weight auto vectorizer tfidfvectorizer input filename classifier pipeline vect vectorizer clf onevsrestclassifier svm parameters vect min df vect max df 75 vect ngram range clf estimator chi2 100 1000 all clf estimator svm 10 clf estimator svm fit intercept true false data target hamming loss grid gridsearchcv classifier parameters jobs verbose scoring scorer hamming loss greater is better false grid fit data target traceback most recent call last file main py line 140 in grid fit data target file usr local lib python2 dist packages sklearn grid search py line 687 in fit return self fit parametergrid self param grid params file usr local lib python2 dist packages sklearn grid search py line 456 in fit parameter iterator for train test in cv file usr local lib python2 dist packages sklearn externals joblib parallel py line 516 in call self retrieve file usr local lib python2 dist packages sklearn externals joblib parallel py line 449 in retrieve raise exception type report typeerror function takes exactly arguments given >>>bug
precision recall and roc curve example are suboptimal the precision recall curve http scikit learn org dev auto examples plot precision recall html and roc curve http scikit learn org dev auto examples plot roc html example are suboptimal no explanation about the graph displayed no link with average precision or auc score metrics they could be simplified using the `train test split` function it is good start for new contributor >>>documentation easy
bug onevsrestclassifier doesn play nicely with svc reported at so http stackoverflow com 16402236 166749 classifier onevsrestclassifier svc class weight auto classifier fit x1 y1 y2 classifier predict x2 raises an exception because `svc predict proba` doesn actually work unless `probability true` is passed suggested fix refactor the svm code to introduce new class `plattsvc` that functions like `svc probability true except that it uses probabilities for `predict` and `decision function` also remove `predict proba` from `svc` that would immediately fix the problem that `svc predict proba` is inconsistent with `decision function` and `predict` >>>bug moderate
cross validation documentation error computing cross validated metrics print accuracy 2f 2f scores mean scores std shouldn the above be scores std if the intention is to show the 95 confidence level thanks >>>documentation easy
improve dbscan implementation according to this stackoverflow question http stackoverflow com questions 16381577 scikit learn dbscan memory usage 16385556 noredirect comment23486070 16385556 or implementation is highly suboptimal and should be sped up by using the ball tree >>>enhancement moderate
enh matthews correlation coefficient metric throws needless misleading runtime warning the formula for the matthews correlation coefficient metric involves division in certain cases the denominator of this division can be in this situation one of numpy functions called by metrics matthews corrcoef throws warning runtimewarning invalid value encountered in divide however as wikipedia states on the page for the metric if any of the four sums in the denominator is zero the denominator can be arbitrarily set to one this results in matthews correlation coefficient of zero which can be shown to be the correct limiting value think metrics matthews corrcoef should detect if the denominator will be this is trivial property to check and if so set it to instead of triggering runtime warning and returning the right value anyway >>>easy enhancement
test failure in common tests with kernelpca as larsmans observed kernelpca doesn abide by its ``n components`` parameter he introduced new parameter ``remove zero eig`` in 1758 to control removal of empty components with default ``true`` maybe we should aim at changing the default in the future for more expected results in the meantime ll push quick fix for the common tests to set the parameter there >>>bug easy
fix setup py to resolve numpy requirement as mentioned in ark mailing list report https sourceforge net mailarchive message php msg id 30798802 feel free to discuss it further here >>>bug
ridgecv triggers call to toarray on sparse matrix input and thus causes `memoryerror` on high dimensional data details here http stackoverflow com 16351308 163740>>>bug
fix some pep8 fails from this list of violations https jenkins shiningpanda ci com scikit learn job python numpy scipy 10 violations >>>easy
add scipy lecture notes to tutorials page many people that are new to python but want to use sklearn may find it useful to have simple link to the scipy lecture notes since we ve been considering renaming tutorials to getting started find it may be quite fitting there>>>documentation easy
test linearsvc iris fails recently installed scikit tool and when testing it got error test of the sparse linear svc with iris data set failed with the following assertion error arrays are not almost equal to decimals system description scikit version 13 python os windows 32 bit>>>bug
bug dictvectorizer throws exception for empty unknown feature dict the dictvectorizer throws valueerror when no features in the dict are known instead of returning an empty vector from sklearn feature extraction import dictvectorizer dictvectorizer data fit data dictvectorizer dtype separator sparse true transform with stored elements in compressed sparse row format transform traceback most recent call last file line in file home tobi projectname eggs scikit learn 13 py2 linux i686 egg sklearn feature extraction dict vectorizer py line 218 in transform indices np frombuffer indices dtype np int32 valueerror offset must be non negative and smaller than buffer lenth transform traceback most recent call last file line in file home tobi projectname eggs scikit learn 13 py2 linux i686 egg sklearn feature extraction dict vectorizer py line 218 in transform indices np frombuffer indices dtype np int32 valueerror offset must be non negative and smaller than buffer lenth transform traceback most recent call last file line in file home tobi projectname eggs scikit learn 13 py2 linux i686 egg sklearn feature extraction dict vectorizer py line 218 in transform indices np frombuffer indices dtype np int32 valueerror offset must be non negative and smaller than buffer lenth >>>bug
licences are inconsistent in files the licensing in individual files is bit all over the place currently we have the following each followed by list of the files it occurs in license bsd3 sklearn tree tree py license bsd clause sklearn feature selection univariate selection py sklearn linear model bayes py sklearn cluster feature agglomeration py sklearn decomposition fastica py sklearn externals joblib my exceptions py sklearn externals joblib format stack py sklearn externals joblib parallel py sklearn datasets samples generator py license simple bsd sklearn random projection py license simple bsd sklearn datasets svmlight format py sklearn datasets svmlight format pyx license mit see copying mit file in the milk distribution sklearn tree tree py license bsd style doc build html auto examples covariance plot sparse cov html license clause bsd sklearn feature extraction hashing pyx sklearn feature extraction hashing py sklearn feature extraction hashing sklearn feature extraction hashing sklearn cluster eac py sklearn datasets covtype py license bsd style clauses sklearn externals joblib func inspect py sklearn externals joblib test test memory py sklearn externals joblib test test parallel py sklearn externals joblib test test logger py sklearn externals joblib test test hashing py sklearn externals joblib test test func inspect py sklearn externals joblib test test format stack py sklearn externals joblib test test disk py sklearn externals joblib hashing py sklearn externals joblib disk py sklearn externals joblib memory py sklearn externals joblib numpy pickle py sklearn externals joblib logger py license bsd style examples covariance plot sparse cov py doc auto examples covariance plot sparse cov py sklearn base py sklearn covariance graph lasso py sklearn ensemble weight boosting py license new bsd inria 2010 sklearn svm init py license bsd clause examples feature stacker py doc auto examples feature stacker py license bsd style doc build html auto examples gaussian process plot gp regression html doc build html auto examples gaussian process plot gp probabilistic classification after regression html doc build html auto examples gaussian process gp diabetes dataset html license clause bsd doc build html auto examples hashing vs dict vectorizer html license bsd style doc build html auto examples applications plot species distribution modeling html doc build html auto examples applications svm gui html doc build html auto examples linear model plot lasso model selection html doc build html auto examples linear model plot multi task lasso support html doc build html auto examples linear model plot polynomial interpolation html doc build html auto examples linear model plot lasso lars html doc build html auto examples linear model plot logistic path html doc build html auto examples linear model plot ridge path html doc build html auto examples linear model plot lasso coordinate descent path html doc build html auto examples linear model plot logistic l1 l2 sparsity html doc build html auto examples plot train error vs test error html doc build html auto examples cluster plot feature agglomeration vs univariate selection html doc build html auto examples cluster plot lena ward segmentation html doc build html auto examples mixture plot gmm classifier html doc build html auto examples plot classification probability html license bsd clause doc build html auto examples feature stacker html license bsd doc build html auto examples applications plot outlier detection housing html doc build html auto examples applications plot stock market html doc build html auto examples linear model plot logistic html doc build html auto examples linear model plot ols 3d html doc build html auto examples linear model plot iris logistic html doc build html auto examples linear model plot ols html doc build html auto examples linear model plot sparse recovery html doc build html auto examples linear model plot ols ridge variance html doc build html auto examples manifold plot manifold sphere html doc build html auto examples plot classifier comparison html doc build html auto examples cluster plot digits agglomeration html doc build html auto examples cluster plot cluster iris html doc build html auto examples cluster plot lena compress html doc build html auto examples cluster plot color quantization html doc build html auto examples cluster plot lena segmentation html doc build html auto examples cluster plot segmentation toy html doc build html auto examples cluster plot ward structured vs unstructured html doc build html auto examples svm plot svm kernels html doc build html auto examples svm plot svm scale html doc build html auto examples svm plot svm iris html doc build html auto examples svm plot svm margin html doc build html auto examples plot digits pipe html doc build html auto examples ensemble plot gradient boosting regression html doc build html auto examples ensemble plot adaboost hastie 10 html doc build html auto examples ensemble plot adaboost multiclass html doc build html auto examples ensemble plot gradient boosting regularization html doc build html auto examples plot permutation test for classification html doc build html auto examples decomposition plot ica vs pca html doc build html auto examples decomposition plot pca iris html doc build html auto examples decomposition plot faces decomposition html doc build html auto examples decomposition plot pca 3d html doc build html auto examples decomposition plot kernel pca html doc build html auto examples datasets plot digits last image html doc build html auto examples datasets plot iris dataset html license simplified bsd doc build html auto examples applications plot tomography l1 reconstruction html doc build html auto examples applications topics extraction with nmf html doc build html auto examples applications wikipedia principal eigenvector html doc build html auto examples document classification 20newsgroups html doc build html auto examples grid search text feature extraction html doc build html auto examples linear model plot sgd comparison html doc build html auto examples plot kernel approximation html doc build html auto examples cluster plot kmeans stability low dim dense html doc build html auto examples cluster plot adjusted for chance measures html doc build html auto examples document clustering html doc build html auto examples plot digits classification html doc build html auto examples mlcomp sparse document classification html license bsd inria examples neighbors plot regression py doc auto examples neighbors plot regression py license bsd style examples gaussian process gp diabetes dataset py examples gaussian process plot gp probabilistic classification after regression py examples gaussian process plot gp regression py doc auto examples gaussian process gp diabetes dataset py doc auto examples gaussian process plot gp probabilistic classification after regression py doc auto examples gaussian process plot gp regression py sklearn gaussian process init py sklearn gaussian process gaussian process py sklearn gaussian process correlation models py sklearn gaussian process regression models py sklearn gaussian process tests test gaussian process py sklearn linear model tests test omp py sklearn tests test check build py license clause bsd examples hashing vs dict vectorizer py doc auto examples hashing vs dict vectorizer py license bsd like sklearn cluster tests test hierarchical py license bsd style sklearn feature extraction dict vectorizer py sklearn feature extraction tests test dict vectorizer py license bsd inria 2011 doc build html auto examples manifold plot lle digits html doc build html auto examples manifold plot swissroll html license bsd style sklearn utils arraybuilder sklearn utils arraybuilder pyx license bsd style examples applications plot species distribution modeling py examples applications svm gui py examples linear model plot multi task lasso support py examples linear model plot lasso model selection py examples linear model plot ridge path py examples linear model plot polynomial interpolation py examples linear model plot logistic path py examples linear model plot lasso coordinate descent path py examples linear model plot logistic l1 l2 sparsity py examples linear model plot lasso lars py examples plot train error vs test error py examples cluster plot lena ward segmentation py examples cluster plot feature agglomeration vs univariate selection py examples plot classification probability py examples mixture plot gmm classifier py benchmarks bench sgd regression py benchmarks bench covertype py benchmarks bench plot parallel pairwise py doc auto examples applications plot species distribution modeling py doc auto examples applications svm gui py doc auto examples linear model plot multi task lasso support py doc auto examples linear model plot lasso model selection py doc auto examples linear model plot ridge path py doc auto examples linear model plot polynomial interpolation py doc auto examples linear model plot logistic path py doc auto examples linear model plot lasso coordinate descent path py doc auto examples linear model plot logistic l1 l2 sparsity py doc auto examples linear model plot lasso lars py doc auto examples plot train error vs test error py doc auto examples cluster plot lena ward segmentation py doc auto examples cluster plot feature agglomeration vs univariate selection py doc auto examples plot classification probability py doc auto examples mixture plot gmm classifier py sklearn feature selection rfe py sklearn metrics metrics py sklearn metrics cluster supervised py sklearn metrics cluster unsupervised py sklearn metrics cluster supervised py sklearn metrics cluster expected mutual info fast pyx sklearn metrics pairwise py sklearn pls py sklearn linear model omp py sklearn linear model perceptron py sklearn linear model base py sklearn linear model least angle py sklearn linear model passive aggressive py sklearn linear model cd fast pyx sklearn linear model sgd fast pyx sklearn linear model randomized l1 py sklearn linear model stochastic gradient py sklearn linear model tests test randomized l1 py sklearn linear model tests test bayes py sklearn linear model tests test coordinate descent py sklearn linear model tests test base py sklearn linear model coordinate descent py sklearn check build setup py sklearn manifold spectral embedding py sklearn utils weight vector pyx sklearn utils sparsefuncs pyx sklearn utils murmurhash pyx sklearn utils random pyx sklearn utils multiclass py sklearn utils seq dataset pyx sklearn utils seq dataset sklearn utils weight vector sklearn utils tests test murmurhash py sklearn feature extraction text py sklearn grid search py sklearn isotonic py sklearn cross validation py sklearn naive bayes py sklearn cluster means pyx sklearn cluster setup py sklearn qda py sklearn covariance shrunk covariance py sklearn covariance outlier detection py sklearn covariance robust covariance py sklearn covariance empirical covariance py sklearn covariance tests test covariance py sklearn covariance tests test robust covariance py sklearn ensemble gradient boosting py sklearn ensemble partial dependence py sklearn ensemble gradient boosting pyx sklearn decomposition pca py sklearn decomposition kernel pca py sklearn dummy py sklearn kernel approximation py sklearn neighbors nearest centroid py sklearn multiclass py sklearn tests test common py sklearn tree tree pxd sklearn tree tree pyx license bsd examples applications plot outlier detection housing py examples applications plot stock market py examples linear model plot iris logistic py examples linear model plot ols 3d py examples linear model plot logistic py examples linear model plot ols ridge variance py examples linear model plot ols py examples linear model plot sparse recovery py examples manifold plot manifold sphere py examples plot digits pipe py examples cluster plot segmentation toy py examples cluster plot lena segmentation py examples cluster plot cluster iris py examples cluster plot lena compress py examples cluster plot color quantization py examples cluster plot ward structured vs unstructured py examples cluster plot digits agglomeration py examples plot classifier comparison py examples svm plot svm iris py examples svm plot svm kernels py examples svm plot svm scale py examples svm plot svm margin py examples ensemble plot adaboost multiclass py examples ensemble plot gradient boosting regularization py examples ensemble plot gradient boosting regression py examples ensemble plot adaboost hastie 10 py examples plot multilabel py examples decomposition plot ica vs pca py examples decomposition plot faces decomposition py examples decomposition plot pca 3d py examples decomposition plot kernel pca py examples decomposition plot pca iris py examples datasets plot digits last image py examples datasets plot iris dataset py examples plot permutation test for classification py doc auto examples applications plot outlier detection housing py doc auto examples applications plot stock market py doc auto examples linear model plot iris logistic py doc auto examples linear model plot ols 3d py doc auto examples linear model plot logistic py doc auto examples linear model plot ols ridge variance py doc auto examples linear model plot ols py doc auto examples linear model plot sparse recovery py doc auto examples manifold plot manifold sphere py doc auto examples plot digits pipe py doc auto examples cluster plot segmentation toy py doc auto examples cluster plot lena segmentation py doc auto examples cluster plot cluster iris py doc auto examples cluster plot lena compress py doc auto examples cluster plot color quantization py doc auto examples cluster plot ward structured vs unstructured py doc auto examples cluster plot digits agglomeration py doc auto examples plot classifier comparison py doc auto examples svm plot svm iris py doc auto examples svm plot svm kernels py doc auto examples svm plot svm scale py doc auto examples svm plot svm margin py doc auto examples ensemble plot adaboost multiclass py doc auto examples ensemble plot gradient boosting regularization py doc auto examples ensemble plot gradient boosting regression py doc auto examples ensemble plot adaboost hastie 10 py doc auto examples plot multilabel py doc auto examples decomposition plot ica vs pca py doc auto examples decomposition plot faces decomposition py doc auto examples decomposition plot pca 3d py doc auto examples decomposition plot kernel pca py doc auto examples decomposition plot pca iris py doc auto examples datasets plot digits last image py doc auto examples datasets plot iris dataset py doc auto examples plot permutation test for classification py sklearn feature selection selector mixin py sklearn utils testing py sklearn utils extmath py sklearn utils graph py sklearn utils fixes py sklearn utils fixes py sklearn utils tests test extmath py sklearn utils tests test graph py sklearn utils tests test fixes py sklearn feature extraction image py sklearn feature extraction tests test image py sklearn cluster dbscan py sklearn cluster means py sklearn cluster spectral py sklearn cluster affinity propagation py sklearn decomposition sparse pca py sklearn decomposition nmf py sklearn decomposition dict learning py sklearn decomposition tests test sparse pca py sklearn neighbors ball tree sklearn neighbors ball tree pyx sklearn tests test base py sklearn preprocessing py license bsd sklearn utils validation py sklearn ensemble base py sklearn ensemble forest py sklearn ensemble tests test forest py sklearn ensemble tests test forest py sklearn ensemble tests test base py license bsd inria doc build html auto examples neighbors plot regression html license bsd 2011 sklearn manifold isomap py sklearn utils graph shortest path pyx sklearn utils graph shortest path license bsd inria university of amsterdam sklearn neighbors regression py sklearn neighbors graph py sklearn neighbors base py sklearn neighbors classification py license simplified bsd examples applications plot tomography l1 reconstruction py examples applications wikipedia principal eigenvector py examples applications topics extraction with nmf py examples grid search text feature extraction py examples linear model plot sgd comparison py examples plot digits classification py examples plot kernel approximation py examples document classification 20newsgroups py examples cluster plot adjusted for chance measures py examples cluster plot kmeans stability low dim dense py examples mlcomp sparse document classification py examples document clustering py doc auto examples applications plot tomography l1 reconstruction py doc auto examples applications wikipedia principal eigenvector py doc auto examples applications topics extraction with nmf py doc auto examples grid search text feature extraction py doc auto examples linear model plot sgd comparison py doc auto examples plot digits classification py doc auto examples plot kernel approximation py doc auto examples document classification 20newsgroups py doc auto examples cluster plot adjusted for chance measures py doc auto examples cluster plot kmeans stability low dim dense py doc auto examples mlcomp sparse document classification py doc auto examples document clustering py sklearn metrics pairwise fast sklearn metrics pairwise fast sklearn metrics pairwise fast pyx sklearn linear model ridge py sklearn utils class weight py sklearn datasets olivetti faces py sklearn datasets mlcomp py sklearn datasets california housing py sklearn datasets base py sklearn datasets mldata py sklearn datasets twenty newsgroups py sklearn datasets species distributions py sklearn datasets lfw py license bsd inria 2011 examples manifold plot lle digits py examples manifold plot swissroll py doc auto examples manifold plot lle digits py doc auto examples manifold plot swissroll py sklearn manifold locally linear py what exactly should it be is there risk of it changing in the future in which case we should centralise it and refer to licence file instead >>>easy
libsvm gui error as reported by shishir pandey here https sourceforge net mailarchive message php msg id 30772772 get the following error traceback most recent call last file users xyz ml svm gui py line 30 in from sklearn externals six moves import xrange importerror no module named six moves>>>bug
doc minibatchkmeans doesn re run its algorithm init needs to be documented as stefano lattarini mentioned here http permalink gmane org gmane comp python scikit learn 7090 when the init argument is given expect both of these classes to run the corresponding algorithm lloyd and mini batch means respectively init times on the data to be fitted each time with different initialization and then select the result which gives the smallest inertia however while this expectation is met by the kmeans class it not really met the by the minibatchkmeans class the latter only executes the initialization of centroids init times then selecting the initialization that gives the smallest inertia and running the mini batch means algorithm only once with that initialization the above is intended behavior and needs to be mentioned in the docs as the minibatch is meant to do only few passes on the data for efficiency reasons>>>bug documentation easy
adaboost predict proba doesn do any weighting `adaboostclassifier` current implementation of `predict proba` promises to return the weighted mean predicted class probabilities of the classifiers in the ensemble but it doesn touch its `estimator weights or rather it loops over that attribute values but ignores them ping glouppe >>>bug
svr complains about single class in adaboost tests this one escaping me nosetests sklearn ensemble tests test weight boosting py error test different base estimators traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file scratch apps src scikit learn sklearn ensemble tests test weight boosting py line 213 in test base estimator clf fit file scratch apps src scikit learn sklearn ensemble weight boosting py line 911 in fit return super adaboostregressor self fit sample weight file scratch apps src scikit learn sklearn ensemble weight boosting py line 126 in fit argsorted argsorted file scratch apps src scikit learn sklearn ensemble weight boosting py line 972 in boost estimator fit bootstrap idx bootstrap idx file scratch apps src scikit learn sklearn svm base py line 143 in fit raise valueerror the number of classes has to be greater than valueerror the number of classes has to be greater than one ran 10 tests in 893s failed errors this doesn happen every time though nosetests sklearn ensemble tests test weight boosting py ran 10 tests in 899s ok since the adaboost tests don set `random state` >>>bug
decision function is broken in svc here is gist illustrating the problem https gist github com bwhite 5463217 here are two lines of the output run the script to make 100 of these example true label predictions svm predict svm2 predict svm2 dec intercept manual decision functions svm decision function nan svm2 decision function 305067 manual 472692 example true label predictions svm predict svm2 predict svm2 dec intercept manual decision functions svm decision function nan svm2 decision function 112419 manual 0552063 we expect all prediction and decision function methods to agree but the predictions are all the same expect for the one that derive from svm2 decision function but all decision functions disagree the reason show the prediction derived from svm2 decision function is because it shows that it is almost certainly wrong because it doesn agree with it own prediction function however my own custom predictor and decision function derived from the raw model parameters are all consistent with the true predictions in summary think the following are problematic svm and svm2 disagree at all since there shouldn be difference between computing the gram matrix manually vs letting sklearn do it svm decision function the one where we let sklearn compute the gram matrix is basically infinite so that is really wrong svm2 seems more reasonable but still wrong since using it intercept as threshold disagrees with it own prediction my handmade predictor decision function agree in prediction with svm svm2 but the decision function is way off >>>bug
pip install fails on ubuntu 12 04 trying to install scikits learn on ubuntu 12 04 box the commands from http scikit learn org stable install html but for some reason after following easy install sudo pip install scikit learn get the following error error command usr bin g77 wall wall shared build temp linux x86 64 sklearn cluster means usr lib lbuild temp linux x86 64 lcblas lm lg2c build lib linux x86 64 sklearn cluster means so failed with exit status the error states the following customize gnufcompiler found executable usr bin g77 gnu no fortran 90 compiler found gnu no fortran 90 compiler found customize gnufcompiler gnu no fortran 90 compiler found gnu no fortran 90 compiler found customize gnufcompiler using build ext building sklearn cluster means extension compiling sources compiler gcc pthread fno strict aliasing dndebug fwrapv o2 wall wstrict prototypes fpic compile options dno atlas info isklearn src cblas usr lib python2 dist packages numpy core include usr lib python2 dist packages numpy core include usr include python2 gcc sklearn cluster means usr lib python2 dist packages numpy core include numpy ufunc api 226 warning import umath defined but not used wunused function usr bin g77 wall wall shared build temp linux x86 64 sklearn cluster means usr lib lbuild temp linux x86 64 lcblas lm lg2c build lib linux x86 64 sklearn cluster means so usr bin ld cannot find crti no such file or directory usr bin ld cannot find lgcc collect2 ld returned exit status usr bin ld cannot find crti no such file or directory usr bin ld cannot find lgcc is it due to the fact that ubuntu 12 04 does not have any fortran compiler and installed g77 and setup expects fortran 90 just guessing appreciate any help on this >>>bug
doc numbering on tutorials page is buggy the numbering on the tutorials menu of the docs are kind of screwy as shown below screenshot at 2013 04 19 21 02 33 https cloud github com assets 1378870 403585 13e57102 a924 11e2 93de f3cee7307989 png >>>bug documentation easy
problem downloading faces dataset on dbd3109 python version >>>bug
example gallery sort by line count broken busy working it out disabling it for now so that doc building isn disturbed >>>documentation
sidebar bug when returning to docs homepage due to the sidebar button being hidden on the home page the following bug arises if the sidebar is collapsed elsewhere in the documentation and the user returns to the home page the sidebar stays collapsed and cannot be re expanded as the button is hidden on this page >>>bug documentation easy
remove survey banner again if everyone agrees think we can remove the survey banner again for now ll take care of this unless you guys want it to stay on while longer>>>documentation
divide by zero in nystrm approximation sometimes get what seems to be divide by zero in the nystrm kernel approximation am trying to minimal example to reproduce the problem but so far have not been able to do so expect that some eigenvalues of the kernel matrix are rounded to zero which could be caused by rank deficient kernel matrix this is with sklearn version 13 if that is the case this problem can be fixed by adding tiny ridge to the kernel matrix or by adding tiny value to the eigenvalues ``s`` alternatively one could use only positive eigenvalues in the computation >>>bug
mrg fixed precompute false error in randomizedlasso >>>bug needs_review
precompute false option in randomizedlasso throws exception in lars path noticed this in 12 but it appears to be unchanged in the current code the documentation for randomizedlasso says that precompute can be true false or auto however when tried to explicitly pass false got an exception the reason is because the value for precompute is passed straight into lars path as the value for gram which takes different set of values none auto matrix or shape so there an exception when lars path assumes it has matrix example demonstrating the error not sure what the interaction between randomizedlasso randomized lasso and lars path should be presumably the interface to lars path should not change so the fix should be to pass none instead of false when it gets called >>>bug
cross validation returning multiple scores `scorer` objects currently provide an interface that returns scalar score given an estimator and test data this is necessary for searchcv` to calculate mean score across folds and determine the best score among parameters this is very hampering in terms of the diagnostic information available from cross fold validation or parameter exploration which one can see by comparing to the catalogue of `metrics` that includes precision and recall with score scores for each of multiple classes as well as an aggregate and error distributions pr curve or confusion matrix solomonm 1837 and ml an implementation within 1768 have independently sought precision and recall to be returned from cross validation routines when f1 is used as the cross validation objective eickenberg on https github com scikit learn scikit learn pull 1381 commitcomment 2607318 posed concern regarding array of scores corresponding to multiple targets thought it deserved an issue of its own to solidify the argument and its solution some design options allow multiple scorers to be provided to `cross val score` or searchcv` henceforth `cvevaluator` with one specified as the objective but since the `scorer` generally calls `estimator predict decision function predict proba each scorer would repeat this work separate the objective and non objective metrics as parameters to `cvevaluator` the `scoring` parameter remains as it is and `diagnostics` parameter provides callable with similar same arguments as `scorer` but returning dict this means that the prediction work is repeated but not necessarily as many times as there are metrics this diagnostics callable is more flexible and perhaps could be passed the training data as well as the test data continue to use the `scoring` parameter but allow the `scorer` to return dict with special key for the objective score this would need to be handled by the caller for backwards compatibility no existing scorers would change their behaviour of returning float this ensures no repeated prediction work add an additional method to the `scorer` interface that generates set of named outputs as with `calc names` proposed in 1837 again with special key for the objective score this allows users to continue using `scoring f1 but get back precision and recall for free note that and potentially allow for any set of metrics to be composed into scorer without redundant prediction work and allows composition with highly redundant prediction work comments critiques and suggestions are very welcome >>>api
rename grid search module the `grid search` module now supports list of grids and random sampled parameter space and may in the future support other search algorithms the shared purpose is tuning or exploring hyper parameters under cross validation so perhaps the `grid search` name should be deprecated and replaced with something like `cv search` or `search cv` `hyperparams` `model selection` thanks amueller >>>api enhancement
confusion matrix example suboptimal the confusion matrix example is pretty bad think it doesn give any explanation it doesn even explain which axis is which good start for any new contributor >>>documentation easy
nose test fails tried with both methods have tried both the methods am using ubuntu 12 04 32bit with python numpy scipy first installed using apt get install python sklearn but there were many failures from both the methods then remove python sklearn with apt get remove python sklearn then tried installing it from the source package using `python setup py build` `sudo python setup py install` when tried running the nose test it failed the error is shown below error trace1 opensource nosetests sklearn exe error failure importerror no module named check build contents of home manaswi opensource scikit learn 13 sklearn check build check build pyx init pyc check build init py setup pyc setup py it seems that scikit learn has not been built correctly if you have installed scikit learn from source please do not forget to build the package before using it run `python setup py install` or `make` in the source directory if you have used an installer please check that it is suited for your python version your operating system and your platform traceback most recent call last file usr lib python2 dist packages nose loader py line 390 in loadtestsfromname addr filename addr module file usr lib python2 dist packages nose importer py line 39 in importfrompath return self importfromdir dir path fqname file usr lib python2 dist packages nose importer py line 86 in importfromdir mod load module part fqname fh filename desc file home manaswi opensource scikit learn 13 sklearn init py line 31 in from import check build file home manaswi opensource scikit learn 13 sklearn check build init py line 47 in raise build error file home manaswi opensource scikit learn 13 sklearn check build init py line 42 in raise build error local dir join dir content strip msg importerror no module named check build contents of home manaswi opensource scikit learn 13 sklearn check build check build pyx init pyc check build init py setup pyc setup py it seems that scikit learn has not been built correctly if you have installed scikit learn from source please do not forget to build the package before using it run `python setup py install` or `make` in the source directory if you have used an installer please check that it is suited for your python version your operating system and your platform ran test in 001s failed errors then installed sklearn package again tried the nosetests as well with python import sklearn sklearn test the errors are shown below error trace2 opensource nosetests sklearn exe usr local lib python2 dist packages sklearn manifold spectral embedding py 225 userwarning graph is not fully connected spectral embedding may not works as expected warnings warn graph is not fully connected spectral embedding ss usr local lib python2 dist packages sklearn externals joblib test test func inspect py 122 userwarning cannot inspect object ignore list will not work nose tools assert equal filter args ff sss fail sklearn tests test common test transformers traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file usr local lib python2 dist packages sklearn tests test common py line 230 in test transformers fit transform not correct in trans file usr lib python2 dist packages numpy testing utils py line 800 in assert array almost equal header arrays are not almost equal to decimals decimal file usr lib python2 dist packages numpy testing utils py line 636 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals fit transform not correct in mismatch 50 array 97459066 37275475 97199043 22191067 97199043 22191067 array 74590662e 01 38417465e 16 71990427e 01 91932783e 16 71990427e 01 91932783e 16 ran 1603 tests in 90 243s failed skip 11 failures trying with python import sklearn sklearn test gave me the following error trace3 opensource python import sklearn sklearn test other than the doctest failures get the following error fail sklearn tests test common test transformers traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file usr local lib python2 dist packages sklearn tests test common py line 237 in test transformers fit transform not correct in trans file usr lib python2 dist packages numpy testing utils py line 800 in assert array almost equal header arrays are not almost equal to decimals decimal file usr lib python2 dist packages numpy testing utils py line 600 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals fit transform not correct in shapes 30 20 30 18 mismatch array 87664949e 00 57398986e 02 20312700e 02 63938109e 08 00000000e 00 00000000e 00 00000000e 00 00000000e 00 00000000e 00 array 87664949e 00 57398986e 02 20312700e 02 35096502e 08 65023583e 09 94581104e 09 93372216e 08 76708475e 09 25320650e 08 ran 1737 tests in 270 588s failed skip 11 errors 21 failures 15 how should resolve this >>>bug
use cross validation cross val score with metrics precision recall fscore support like to use cross validation cross val score with metrics precision recall fscore support so that can get all relevant cross validation metrics without having to run my cross validation once for accuracy once for precision once for recall and once for f1 but when try this get valueerror >>>enhancement
metrics confusion matrix bug if you specify the optional labels has an input it has to be int labels np asarray labels dtype np int which doesn make sense the proposed fix it simple we should remove the dtype constraint >>>bug
metrics confusion matrix usability issue usability issue current confusion matrix fct doesn return the the labels if you don specified it which make the matrix kind of useless for analysis my recommendation is that the function should return cm labels >>>enhancement
minmaxscaler doesn convert input to float so it converts mnist to all zeros basically >>>bug
bug in score method in gridsearchcv the call to ``scoring`` is broken also think it is weird that the base estimator ``score`` method is preferred over the ``scorer`` this means that ``best score `` is not something you can get by calling ``score`` >>>bug
mrg evidence accumulation clustering evidence accumulation clustering eac an ensemble based clustering framework fred ana ln and anil jain data clustering using evidence accumulation pattern recognition 2002 proceedings 16th international conference on vol ieee 2002 basic overview of algorithm cluster the data many times using clustering algorithm with randomly within reason selected parameters create co association matrix which records the number of times each pair of instances were clustered together cluster this matrix this seems to work really well like kernel method making the clustering easier that it was for the original dataset the default of the algorithm are setup to follow the defaults used by fred and jain 2002 whereby the clustering in step is means with selected randomly from 10 and 30 the clustering in step is the mst algorithm which have yet to implement will do in this pr after initial feedback think people are happy with the api todo mst algorithm from the paper which was used as the final clusterer completed in pr 1991 there is an improvement to the speed of the algorithm don have the paper on hand that has been published that should be incorporated will be done in later pr examples usage narrative documentation revert test clustering line 508 to only check for spectralclustering use sparse matrix for the co association matrix >>>needs_review
test failure in common tests cca in ``test transformers`` cca ``fit transform`` fails for me on 32bit ubuntu anyone else >>>bug
gridsearchcv fit params does not use the params argument hi believe this is small and easy bug to fix gridsearchcv fit params does not use the params argument so it can be removed from the function also in the example http scikit learn org stable auto examples grid search digits html example grid search digits py the following lines should be updated from to >>>bug
test failed after installation in ubuntu12 installed the package using apt get install python sklearn and then tested it by using nosetests sklearn exe but failed error messages below error sklearn datasets tests test lfw test load fake lfw people traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file usr lib pymodules python2 sklearn datasets tests test lfw py line 120 in test load fake lfw people min faces per person file usr lib pymodules python2 sklearn datasets lfw py line 337 in load lfw people return fetch lfw people download if missing download if missing kwargs file usr lib pymodules python2 sklearn datasets lfw py line 266 in fetch lfw people memory cachedir lfw home compress verbose typeerror init got an unexpected keyword argument compress begin captured logging sklearn datasets lfw info loading lfw people faces from tmp scikit learn lfw test yijxlu lfw home end captured logging error sklearn datasets tests test lfw test load fake lfw people too restrictive traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file usr lib python2 dist packages nose tools py line 80 in newfunc func arg kw file usr lib pymodules python2 sklearn datasets tests test lfw py line 149 in test load fake lfw people too restrictive load lfw people data home scikit learn data min faces per person 100 file usr lib pymodules python2 sklearn datasets lfw py line 337 in load lfw people return fetch lfw people download if missing download if missing kwargs file usr lib pymodules python2 sklearn datasets lfw py line 266 in fetch lfw people memory cachedir lfw home compress verbose typeerror init got an unexpected keyword argument compress begin captured logging sklearn datasets lfw info loading lfw people faces from tmp scikit learn lfw test yijxlu lfw home end captured logging error sklearn datasets tests test lfw test load fake lfw pairs traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file usr lib pymodules python2 sklearn datasets tests test lfw py line 158 in test load fake lfw pairs lfw pairs train load lfw pairs data home scikit learn data file usr lib pymodules python2 sklearn datasets lfw py line 433 in load lfw pairs return fetch lfw pairs download if missing download if missing kwargs file usr lib pymodules python2 sklearn datasets lfw py line 404 in fetch lfw pairs memory cachedir lfw home compress verbose typeerror init got an unexpected keyword argument compress begin captured logging sklearn datasets lfw info loading train lfw pairs from tmp scikit learn lfw test yijxlu lfw home end captured logging ran 613 tests in 64 717s failed skip errors ps my environment lsb release no lsb modules are available distributor id ubuntu description ubuntu 12 04 lts release 12 04 codename precise>>>bug
problem with ridgecv centering the design matrix messes the solution when centering the design matrix cancels one of its singular values when this creates numeric mess in the ridgecv computation an example of the bad behaviour is given in https gist github com bthirion 5233416 still not fully sure about the right solution comments welcome best >>>bug
problem with ducktyping and meta estimators in number of places sklearn controls flow according to the existence of some method on an estimator for example searchcv score` checks for `score` on the estimator `scorer` and `multiclass` functions check for `decision function` and it is used for validation in `adaboostclassifier fit` `multiclass check estimator` and `pipeline` and for testing in `test common` meta estimators such as searchcv` `pipeline` `rfecv` etc should respond to such `hasattr`s in agreement with their underlying estimators or else the `hasattr` approach should be avoided this is possible by implementing such methods with `property` that returns the correct method from the sub estimator or closure around it or raises `attributeerror` if the sub estimator is found lacking see 1801 `hasattr` would then function correctly caveats the code would be less straightforward in some cases `help `pydoc` won show the methods as methods with an argument list etc though the `property` docstring will show >>>api
bug `` pipeline featureunion set params`` may overwrite attributes steps in pipelines are named where name equals that of an existing attribute on `pipeline` `transform` `predict` `steps` calling `set params` and setting that name to some value causes the attribute to be overwritten example consider the following this prints `` `` at and ``dummytransformer random state none strategy stratified `` at mechanism the general mechanism of `baseestimator set params` is to set the attribute corresponding to the parameter name in general this is restricted to small set of possible names usually corresponding to constructor arguments that would not conflict with non parameter attributes though don think there test to assure this where double underscore notation is used to set sub estimators parameters the sub estimator name `est` in `est some param` needs to be returned by the estimator `get params` hence `set params` allows `est` to be set in turn calling `setattr` without regard to existing attributes resolution don allow step names to be used as parameter names in `set params` or allow step names to be used as parameter names in `set params` meaningfully while prohibiting constructor arguments and existing attributes as names or prohibiting constructor arguments as names but special casing the setting of steps so that it doesn involve `setattr` rather the modification of the `steps` attribute which needs to happen somehow anyway this approach is taken by 1769 also test should be added for this case and perhaps more generally for all estimators to ensure `set params` does not overwrite class attributes methods etc >>>api
input validation with shape for randomforestclassifier decisiontreeclassifier others from sklearn ensemble import randomforestclassifier np ones shape np ones shape rfc randomforestclassifier in 36 rfc fit valueerror traceback most recent call last in rfc fit xx yy usr local lib python2 site packages sklearn ensemble forest pyc in fit self sample weight 363 random state randint max int 364 verbose self verbose 365 for in xrange jobs 366 367 reduce usr local lib python2 site packages sklearn externals joblib parallel pyc in call self iterable 512 try 513 for function args kwargs in iterable 514 self dispatch function args kwargs 515 516 self retrieve usr local lib python2 site packages sklearn externals joblib parallel pyc in dispatch self func args kwargs 309 310 if self pool is none 311 job immediateapply func args kwargs 312 index len self jobs 313 if not verbosity filter index self verbose usr local lib python2 site packages sklearn externals joblib parallel pyc in init self func args kwargs 133 don delay the application to avoid keeping the input 134 arguments in memory 135 self results func args kwargs 136 137 def get self usr local lib python2 site packages sklearn ensemble forest pyc in parallel build trees trees forest sample weight sample mask argsorted seed verbose 86 curr sample weight sample weight copy 87 88 indices random state randint samples samples 89 sample counts bincount indices minlength samples 90 usr local lib python2 site packages numpy random mtrand so in mtrand randomstate randint numpy random mtrand mtrand 6443 valueerror low high from sklearn tree import decisiontreeclassifier np ones shape np ones shape dtc decisiontreeclassifier dtc fit valueerror traceback most recent call last in dtc fit usr local lib python2 site packages sklearn tree tree pyc in fit self sample mask argsorted check input sample weight 358 sample weight sample weight 359 sample mask sample mask 360 argsorted argsorted 361 362 if self outputs usr local lib python2 site packages sklearn tree tree so in sklearn tree tree tree build sklearn tree tree 4823 usr local lib python2 site packages sklearn tree tree so in sklearn tree tree tree build sklearn tree tree 4636 usr local lib python2 site packages sklearn tree tree so in sklearn tree tree tree recursive partition sklearn tree tree 5156 valueerror attempting to find split with an empty sample mask >>>bug easy
add custom kernels to spectralclustering `spectralclustering` supports the rbf kernel but it could benefit from the generic kernel support in `sklearn metric pairwise kernels` `kernelpca` and `sklearn kernel approximations nystroem` already do this and provide an example api `kernel params` for callables custom attributes for the built in kernels >>>easy enhancement
gridsearchcv can be pickled which is really unfortunate >>>bug
gridsearchcv doesn set cv scores when the grid contains only one point this corner case is handled specially the easiest fix would probably to handle it in the loop >>>bug
face completion example gives completely wrong results just saw the face completion example http meta stackoverflow com questions 66377 what is the xy problem for the first time and it immediately made me wonder what is the purpose of this example if none of the predicted lower halves is correct it looks very silly >>>documentation
partial least squares fit raises singular matrix error hello pls1 worked fine but when trying to fit rather large matrices pls2 fits sometimes raise linalg error for certain number of components in this case however the fit works for components and works again for 20 traceback most recent call last file line in pls fit file python27 lib site packages sklearn pls py line 322 in fit linalg inv np dot self loadings self weights file python27 lib site packages scipy linalg basic py line 348 in inv raise linalgerror singular matrix linalgerror singular matrix am neither mathematician nor professional programmer so do not really understand what is going on there could upload the pickled arrays if needed shape 529 1486 shape 529 thanks for the great package matthias gerstl>>>bug
rfecv step option broken the scores array is always initialized to np zeros shape but with step less scores are collected the trailing zeros lead to the false number of features being selected >>>bug
mrg enh enable setting pipeline components as parameters until now `get params would return the steps of pipeline by name but setting them would fail silently by setting an unused attribute this changeset also prohibits step names that equal initialisation parameters of the pipeline otherwise `featureunion set params transformer weights foo would be ambiguous it also contributes some refactoring of `pipeline` prediction methods >>>needs_review
explain cross validation as we get more and more newbie users it might be good to have some more basic info in the tutorials examples here http www kaggle com data science london scikit learn forums 3986 welcome 21252 post21252 was question for explanation of cross validation currently the docs only cover how to do cross validation with sklearn not really what cross validation does or didn find it think it would be in the scope of the docs to explain the general approach >>>documentation easy
dpgmm update concentrations fail implementation in method update concentration dpgmm think it should be self gamma self gamma sz instead of self gamma self gamma sz >>>bug
move balance weights to utils personally don agree that `balance weights` should be in `preprocessing` it alters neither `x` nor `y` >>>easy need_contributor
adaboost docs broken the reference documentation for the adaboost estimators is not build sphinx throws lot of errors but have no idea what is appening >>>bug documentation
sparse random projections for randomized pca sparse random projections seem to make more sense for randomized pca since the main point is to deal with large matrices and it is easy to get to the point where the gaussian projection matrix becomes to large for ram it looks like it should be easy to change utils extmath randomized svd to use sparse random projections is there any reason not to do this if do it for my own use should submit it >>>enhancement
error building docs when trying to build the docs ``make html`` get the following error on each example it still runs through though not sure what is happening here >>>bug documentation
nosetests fail singular matrix in cca nosetests sklearn exe usr local lib python2 site packages scikit learn 13 py2 linux x86 64 egg sklearn manifold spectral embedding py 225 userwarning graph is not fully connected spectral embedding may not works as expected warnings warn graph is not fully connected spectral embedding ss usr local lib python2 site packages scikit learn 13 py2 linux x86 64 egg sklearn datasets tests test base py 124 userwarning could not load sample images pil is not available warnings warn could not load sample images pil is not available usr local lib python2 site packages scikit learn 13 py2 linux x86 64 egg sklearn datasets tests test base py 145 userwarning could not load sample images pil is not available warnings warn could not load sample images pil is not available usr local lib python2 site packages scikit learn 13 py2 linux x86 64 egg sklearn datasets tests test base py 161 userwarning could not load sample images pil is not available warnings warn could not load sample images pil is not available ss sss usr local lib python2 site packages scikit learn 13 py2 linux x86 64 egg sklearn externals joblib test test func inspect py 122 userwarning cannot inspect object ignore list will not work nose tools assert equal filter args ff sss fail sklearn tests test common test regressors train traceback most recent call last file usr local lib python2 site packages nose py2 egg nose case py line 197 in runtest self test self arg file usr local lib python2 site packages scikit learn 13 py2 linux x86 64 egg sklearn tests test common py line 655 in test regressors train assert true succeeded assertionerror false is not true begin captured stdout cca copy true max iter 500 components scale true tol 1e 06 singular matrix end captured stdout ran 1598 tests in 81 829s failed skip 15 failures >>>bug
add andy machine learning workflow graph to docs ve been trying to get nice way of getting amueller ml flow http bp blogspot com me24epzpzim uqlwtwurfxi aaaaaaaaanw w3eetiroa80 s1600 drop shadows background png into the documentation outside of how trying to do it also need feedback on where exactly this would go in the docs implementing it is another thing basically want it to not just be static image but an html image map that will link to the docs for example if the user clicks on the sgd regressor box he must be sent to the relevant documentation in the guide ve gotten this right using the vue http vue tufts edu software but it has some limitations below made quick rough version of piece of it it not pretty yet and the colors and general look of it just quickly did so yes it ugly hehe screenshot at 2013 03 08 15 30 43 https cloud github com assets 1378870 236777 1aff1774 87fd 11e2 8c17 7450ce0451e0 png this actual works fine it sends me to sgd regressor when click on it as desired the problem is that vue adds that ugly little html button to node when you add hyperlink to it which seem to be unable to remove so using vue can do what want but unless can remove thos ugly little side `html` thingies it ll be ugly one other option is to have just thumbnail or smaller image of andy plot in the docs then have it link to the full ugly one which will have the links and all vue asside ve been trying to find another piece of software that can do this with but without much success inkscape which is what andy map is made in think is great but doesn allow html map exporting also tried the inkscapemap add on program to convert svg files into html maps but without any success so really could use some clever feedback here unless you guys are fine with the thumbnail idea mentioned earlier really need some way of being able to edit recreate the map add the links to the docs to it and make an html image map thereof lastly it would be best if it was simple way else maintaining this in the long run could become pest looking forward to any feedback>>>documentation enhancement
fix class weight auto in sgdclassifier afaik sgdclassifier calls ``compute class weight`` with the ``y`` it got as input instead it should use the class indices corresponding to ``y`` not sure if larsmans is on it think ``y`` should just be replaced by ``np searchsorted classes `` but to tired to do it right now >>>bug easy
refactor accuracy score think it should be computed in terms of ``zero one loss`` to avoid code duplication >>>easy enhancement
svm light loader docstring out of data the svm light loader docstring http scikit learn sourceforge net dev modules generated sklearn datasets load svmlight file html sklearn datasets load svmlight file says that the function is written in python and doesn scale well it does call cython implmentation though as far as can see is the docstring still appropriate ping larsmans mblondel >>>bug documentation easy
mrg training score in gridsearch this pr adds training scores to the gridsearchcv output as wished for by ogrisel >>>needs_review
possible memory leak lasso lassocv in 13 uses far more memory than in 12 not sure what causing this but after upgrading noticed exploding memory usage several gb in use when tried to run lasso or lassocv on my dataset lasso in particular was big difference the version in 12 would use on the order of 100 mb of memory and finish quickly while doing the same thing in 13 hit gb and had to kill it the story for lassocv was similar but it uses more memory overall gb for 12 maybe gb for 13 presumably the leak is in lasso although not sure why lassocv is using so much more shouldn it use the same amount maybe there is separate leak in lassocv in 12 and in 13 this explodes due to the new lasso leak on my laptop this renders these methods unusable it starts to swap and it way too slow edit am using numpy based on other tickets will upgrade and see if this fixes the problem >>>bug
install problem nosetest failed please help me with my installation followed the guideline to install sklearn and numpy but when ran the nosetest it kept showing the following testing message and finally failed message also cited below nose tools assert equal filter args ff ran 1603 tests in 92 776s failed skip 14 failures because the nosetest log is messy tried to excerpt non repetitive paragraph for your diagnosis very appreciate your kind help microsoft windows 7601 copyright 2009 microsoft corporation all rights reserved windows system32 python import sklearn sklearn test running unit tests and doctests for sklearn numpy version numpy is installed in python27 lib site packages numpy python version default apr 10 2012 23 31 26 msc 1500 32 bit intel nose version seeding rngs with 369887653 converged after 58 iterations python27 lib ite packages sklearn manifold spectral embedding py 225 userwarning graph is ot fully connected spectral embedding may not works as expected warnings warn graph is not fully connected spectral embedding 17927109077 55 4082834902 none fffffffff sss python27 lib site packages sklearn externals joblib test test func inspect py 122 userwarnin cannot inspect object ignore list ill not work nose tools assert equal filter args ff test memory setup test memory teardown memory calling sklearn externals joblib test test hashing klasswithcachedmetho s12069 maps nii gz 33 s12158 maps nii gz 33 s12258 maps nii gz 33 s12277 maps nii gz 33 s12300 maps nii gz 33 s12401 maps nii gz 33 s12430 maps nii gz 33 s13817 maps nii gz 33 s13903 maps nii gz 33 s13916 maps nii gz 33 s13981 maps nii gz 33 s13982 maps nii gz 33 s13983 maps nii gz 33 0s 0min memory calling sklearn externals joblib test test hashing klasswithcachedmetho set s12069 maps nii gz s12158 maps nii gz s12258 maps nii gz s12277 maps nii gz s12300 maps nii gz s12401 maps nii gz s12430 maps nii gz s13817 maps nii gz s13903 maps nii gz s13916 maps nii gz s13981 maps nii gz s13982 maps nii gz s13983 maps nii gz 0s 0min test memory setup memory 0s 0min loading sklearn externals joblib test tes memory alias from users navicat appdata local temp tmpydjb57 joblib sklea rn externals joblib test test memory alias 48c4a83e3726da917be80d0e1edc1be1 alias cache loaded 0s 0min memory 0s 0min loading sklearn externals joblib test test memory alias from users navicat appdata local temp tmpydjb57 joblib sklearn externa ls joblib test test memory alias 48c4a83e3726da917be80d0e1edc1be1 alias cache loaded 0s 0min test memory teardown setup numpy pickle python27 lib site packages sklearn exter nals joblib test test numpy pickle py 197 warning file users navicat appda ta local temp tmpfsyive test pkl96 appears to be zip ignoring mmap mode flag passed numpy pickle load this filename mmap mode teardown numpy pickle python27 lib site packages sklearn feature selection univ ariate selection py 327 userwarning duplicate scores result may depend on fea ture ordering there are probably duplicate features or you used classificatio score for regression task warn duplicate scores result may depend on feature ordering python27 lib site packages numpy lib utils py 139 deprecationwarn ing `cs graph components` is deprecated in the future use csgraph connected components note that this new function has slightly different interface see the docstring for more information warnings warn depdoc deprecationwarning python27 lib site packages numpy lib utils py 139 deprecationwarning `cs gr aph components` is deprecated in the future use csgraph connected components note that this new function has slightly different interface see the docstring for more information warnings warn depdoc deprecationwarning python27 lib site packages numpy lib utils py 139 deprecationwarning `cs raph components` is deprecated in the future use csgraph connected components note that this new function has slightly different interface see the docstring for more information warnings warn depdoc deprecationwarning python27 lib site packages numpy lib utils py 139 deprecationwarning `cs gr aph components` is deprecated in the future use csgraph connected components note that this new function has slightly different interface see the docstring for more information warnings warn depdoc deprecationwarning python27 lib site packages numpy lib utils py 139 deprecationwarning `cs raph components` is deprecated in the future use csgraph connected components note that this new function has slightly different interface see the docstring for more information warnings warn depdoc deprecationwarning python27 lib site packages numpy lib utils py 139 deprecationwarning `cs gr aph components` is deprecated in the future use csgraph connected components note that this new function has slightly different interface see the docstring for more information warnings warn depdoc deprecationwarning pytho n27 lib site packages sklearn feature selection univariate selection py 109 run timewarning invalid value encountered in divide msb msw python27 lib site packages sklearn linear model least angle py 233 userwarning regressors in act ive set degenerate dropping regressor after iterations alpha 870e 02 with an active set of regressors and the smallest cholesky pivot element being 220e 16 iter alpha active diag python27 lib ite packages nose util py 14 deprecationwarning the compiler package is deprec ated and removed in python from compiler consts import co generator python27 lib site packages nose util py 14 deprecationwarning the compiler package is deprecated and removed in python from compiler consts import co generator python27 lib site packages sklearn linear model te sts test sparse coordinate descent py 104 userwarning with alpha this algor ithm does not converge well you are advised to use the linearregression estimat or clf fit python27 lib site packages sklearn linear model coordinate descent py 666 userwarning precompute is ignored for sparse data warnings warn precompute is ignored for sparse data python27 lib site packages sklearn linear model coordinate descent py 288 us erwarning objective did not converge for target you might want to increase he number of iterations to increase the number of iterations python27 lib site packages numpy core methods py 57 run timewarning invalid value encountered in double scalars ret ret float rcount ython27 lib site packages sklearn utils extmath py 244 runtimewarning underflo encountered in exp out np log np sum np exp arr vmax axis python27 lib site packages sklearn mixture dpgmm py 42 runtimewarning under flow encountered in exp np exp out python27 lib site packages sklearn mixture gmm py 307 runtimewarning underflow encountered in exp responsibilities np exp lpr logprob np newaxis python27 lib site ackages sklearn utils init py 71 deprecationwarning class nusvc is depreca ted to be removed in v0 14 use sklearn svm nusvc instead warnings warn msg category deprecationwarning python27 lib site packages sklearn utils init py 71 deprecationwarning class nusvr is deprecated to be removed in v0 14 use sklearn svm nusvr instead warnings warn msg category deprecationwarning python27 lib site packages sklearn utils init py 71 deprecationwarning class svc is deprecated to be removed in v0 14 use sklearn svm svc instead warnings warn msg category deprecationwarning python27 lib site packages sklearn utils init py 71 deprecationwarning class svr is deprecated to be removed in v0 14 use sklearn svm svr instead warnings warn msg category deprecationwarning windows system32 nosetests sklearn exe python27 lib sit packages sklearn manifold spectral embedding py 225 userwarning graph is not fully connected spectral embedding may not works as expected warnings warn graph is not fully connected spectral embedding python27 lib site packages sklearn manifold spectral embedding py 225 userwarning graph is not fully connected spectral embedding may not works as xpected warnings warn graph is not fully connected spectral embedding sss python27 lib site packages sklearn externals joblib test test func inspect py 122 userwa rning cannot inspect object ignore li st will not work nose tools assert equal filter args ff ss python27 lib site packages sklearn externals joblib te st test func inspect py 122 userwarning cannot inspect object functools parti al object at 0x04a099c0 ignore list will not work nose tools assert equal filter args ff ff python27 lib site package sklearn manifold spectral embedding py 225 userwarning graph is not fully co nnected spectral embedding may not works as expected warnings warn graph is not fully connected spectral embedding python27 lib site packages sklearn manifold spectral embeddin py 225 userwarning graph is not fully connected spectral embedding may not works as expected warnings warn graph is not fully connected spectral embedding sss python27 lib site packages sklearn externals joblib test test func inspect py 122 userwarning cannot ins pect object ignore list will not work nose tools assert equal filter args ff sss python27 lib site packages sklearn externals joblib test test func inspe ct py 122 userwarning cannot inspect object functools partial object at 0x04a 099c0 ignore list will not work fail test the sparse linearsvc with the iris dataset traceback most recent call last file python27 lib site packages nose case py line 197 in runtest self test self arg file python27 lib site packages sklearn svm tests test sparse py line 17 in test linearsvc iris clf predict iris data todense sp clf predict iris data file python27 lib site packages numpy testing utils py line 812 in asse rt array almost equal header arrays are not almost equal to decimals decimal file python27 lib site packages numpy testing utils py line 645 in asse rt array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals mismatch 666666666667 array array ran 1603 tests in 92 776s failed skip 14 failures python27 lib site packages sklearn manifold spectral embedding py 225 serwarning graph is not fully connected spectral embedding may not works as ex pected warnings warn graph is not fully connected spectral embedding sss python27 lib site package sklearn externals joblib test test func inspect py 122 userwarning cannot in spect object ignore list will not work >>>bug
standardscaler ignores with std for sparse matrices hi looking at the code for standardscaler fit method in preprocessing py noticed that with std is ignored when sp issparse is true noticed this when trying to make dummy transformation in pipeline where was trying to decide whether to scale feature values or not >>>bug easy
minmaxscaler bug when target is not version 13 first of all the formula in the document is wrong the division in the second line should be multiplication std min axis max axis min axis scaled std max min min more interestingly the script neither follows this formula nor gives the correct result train np array scaler minmaxscaler feature range scaler fit transform train this gives 25 25 66666667 33333333 75 16666667 note the second column has values 5>>>bug
better warning in gridsearchcv in gridsearchcv when loss func or score func is passed the warning should mention that the new parameter is called scoring also it would be nice if the mse scorer could accept mean squared error as name to reflect the underlying function >>>easy enhancement
valueerror buffer dtype mismatch expected double but got long long in scikit learn 13 trying to use the class `sklearn preprocessing standardscaler` to scale my data for being used in an svm classifier of class `sklearn svm linearsvc` the essential parts of my code are the following unfortunately an exception is raised by the line `x train scaled scaler fit transform train this is the relevant part of the stacktrace do have to change the `dtype` myself if so how do do that thank youl>>>bug
nosetests fails repeatedly in python get this eror each time run nosetests using the command nosetests sklearn exe guess the nosetests has to pass before continue using scikit learn clf fit file python33 lib site packages sklearn grid search py line 372 in fit for clf params in grid for train test in cv file python33 lib site packages sklearn externals joblib parallel py line 513 in call for function args kwargs in iterable file python33 lib site packages sklearn grid search py line 372 in for clf params in grid for train test in cv file python33 lib site packages sklearn cross validation py line 284 in iter for in xrange folds nameerror global name xrange is not defined error pass as list in gridsearchcv traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn tests test grid search py line 277 in test as list grid search fit tolist score file python33 lib site packages sklearn grid search py line 372 in fit for clf params in grid for train test in cv file python33 lib site packages sklearn externals joblib parallel py line 513 in call for function args kwargs in iterable file python33 lib site packages sklearn grid search py line 372 in for clf params in grid for train test in cv file python33 lib site packages sklearn cross validation py line 284 in iter for in xrange folds nameerror global name xrange is not defined error sklearn tests test grid search test unsupervised grid search traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn tests test grid search py line 286 in test unsupervised grid search grid search fit file python33 lib site packages sklearn grid search py line 372 in fit for clf params in grid for train test in cv file python33 lib site packages sklearn externals joblib parallel py line 513 in call for function args kwargs in iterable file python33 lib site packages sklearn grid search py line 372 in for clf params in grid for train test in cv file python33 lib site packages sklearn cross validation py line 284 in iter for in xrange folds nameerror global name xrange is not defined error sklearn tests test multiclass test ovr gridsearch traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn tests test multiclass py line 200 in test ovr gridsearch cv fit iris data iris target file python33 lib site packages sklearn grid search py line 372 in fit for clf params in grid for train test in cv file python33 lib site packages sklearn externals joblib parallel py line 513 in call for function args kwargs in iterable file python33 lib site packages sklearn grid search py line 372 in for clf params in grid for train test in cv file python33 lib site packages sklearn cross validation py line 379 in iter for in xrange folds nameerror global name xrange is not defined error sklearn tests test multiclass test ovo gridsearch traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn tests test multiclass py line 258 in test ovo gridsearch cv fit iris data iris target file python33 lib site packages sklearn grid search py line 372 in fit for clf params in grid for train test in cv file python33 lib site packages sklearn externals joblib parallel py line 513 in call for function args kwargs in iterable file python33 lib site packages sklearn grid search py line 372 in for clf params in grid for train test in cv file python33 lib site packages sklearn cross validation py line 379 in iter for in xrange folds nameerror global name xrange is not defined error sklearn tests test multiclass test ecoc gridsearch traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn tests test multiclass py line 286 in test ecoc gridsearch cv fit iris data iris target file python33 lib site packages sklearn grid search py line 372 in fit for clf params in grid for train test in cv file python33 lib site packages sklearn externals joblib parallel py line 513 in call for function args kwargs in iterable file python33 lib site packages sklearn grid search py line 372 in for clf params in grid for train test in cv file python33 lib site packages sklearn cross validation py line 379 in iter for in xrange folds nameerror global name xrange is not defined fail test area under receiver operating characteristic roc curve traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn metrics tests test metrics py line 92 in test roc curve assert array almost equal roc auc 80 decimal file python33 lib site packages numpy testing utils py line 812 in assert array almost equal header arrays are not almost equal to decimals decimal file python33 lib site packages numpy testing utils py line 645 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals mismatch 100 array 8932676518883417 array fail roc curve for confidence scores traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn metrics tests test metrics py line 126 in test roc curve confidence assert array almost equal roc auc 80 decimal file python33 lib site packages numpy testing utils py line 812 in assert array almost equal header arrays are not almost equal to decimals decimal file python33 lib site packages numpy testing utils py line 645 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals mismatch 100 array 8932676518883417 array fail roc curve for hard decisions traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn metrics tests test metrics py line 148 in test roc curve hard assert array almost equal roc auc 74 decimal file python33 lib site packages numpy testing utils py line 812 in assert array almost equal header arrays are not almost equal to decimals decimal file python33 lib site packages numpy testing utils py line 645 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals mismatch 100 array 7627257799671592 array 74 fail test precision recall and f1 score for binary classification task traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn metrics tests test metrics py line 194 in test precision recall f1 score binary assert array almost equal 73 75 file python33 lib site packages numpy testing utils py line 812 in assert array almost equal header arrays are not almost equal to decimals decimal file python33 lib site packages numpy testing utils py line 645 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals mismatch 100 array 63333333 array 73 75 fail test confusion matrix binary classification case traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn metrics tests test metrics py line 257 in test confusion matrix binary assert array equal cm 19 18 file python33 lib site packages numpy testing utils py line 719 in assert array equal verbose verbose header arrays are not equal file python33 lib site packages numpy testing utils py line 645 in assert array compare raise assertionerror msg assertionerror arrays are not equal mismatch 50 array 19 11 18 array 19 18 fail test precision recall and f1 score for multiclass classification task traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn metrics tests test metrics py line 286 in test precision recall f1 score multiclass assert array almost equal 82 55 47 file python33 lib site packages numpy testing utils py line 812 in assert array almost equal header arrays are not almost equal to decimals decimal file python33 lib site packages numpy testing utils py line 645 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals mismatch 100 array 79166667 48148148 625 array 82 55 47 fail test confusion matrix multi class case traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn metrics tests test metrics py line 371 in test confusion matrix multiclass 18 file python33 lib site packages numpy testing utils py line 719 in assert array equal verbose verbose header arrays are not equal file python33 lib site packages numpy testing utils py line 645 in assert array compare raise assertionerror msg assertionerror arrays are not equal mismatch 77 77777777777777 array 19 13 10 15 array 23 20 18 fail test confusion matrix multi class case with subset of labels traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn metrics tests test metrics py line 387 in test confusion matrix multiclass subset labels file python33 lib site packages numpy testing utils py line 719 in assert array equal verbose verbose header arrays are not equal file python33 lib site packages numpy testing utils py line 645 in assert array compare raise assertionerror msg assertionerror arrays are not equal mismatch 75 array 19 13 array 23 fail test performance report traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn metrics tests test metrics py line 414 in test classification report assert equal report expected report assertionerror precision recall f1 score support setosa 79 truncated precision recall f1 score support setosa 82 truncated diff is 701 characters long set self maxdiff to none to see it fail sklearn metrics tests test metrics test precision recall curve traceback most recent call last file python33 lib site packages nose case py line 198 in runtest self test self arg file python33 lib site packages sklearn metrics tests test metrics py line 432 in test precision recall curve test precision recall curve true probas pred file python33 lib site packages sklearn metrics tests test metrics py line 452 in test precision recall curve assert array almost equal precision recall auc 82 file python33 lib site packages numpy testing utils py line 812 in assert array almost equal header arrays are not almost equal to decimals decimal file python33 lib site packages numpy testing utils py line 645 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals mismatch 100 array 9315492337212434 array 82 ran 1328 tests in 258 019s failed skip 15 errors 77 failures 10 >>>bug
developer guidelines on randomness in estimators was looking this up myself but it wasn there when an estimator takes `random state` hyperparameter should it validate this in the constructor or in `fit` >>>documentation easy
sgdclassifier doesn forget previous fit sgdclassifier doesn forget the previous fit the ``classes `` parameter is stored leading to an error if fit repeatedly with different label sets could be as easy as removing ``classes `` in ``fit`` shows the need for test in ``test common`` >>>bug easy
kernelpca doesn abide by its components parameter `kernelpca` may return fewer components than requested because it filters out zero eigenvalues this should be documented and maybe it should be an optional feature >>>bug documentation easy
make sure fit transform does the same as fit transform am not entirely sure that is the case currently to be added to the common tests >>>easy enhancement
make gridsearchcv and cross val score work with multilabel data when 1606 is merged we will have some multi label metrics don think they work with gridsearchcv out of the box we should also consider adding default metric as score function in the multi class module >>>new_feature
links from documentation to github thought it would be very convenient to have link from documentation page to the file on github implementing the class method maybe this could be automated somehow when the docs for the modules are generated >>>documentation
plsregression outputs float64 when fed float32 this might matter for really large datasets as float32 is half the size would expect both float32 to output float32 however not sure what expect for hybrid 32 64 inputs maybe the type of >>>documentation easy
check consistency correctness of 1d input and input for all estimators the handling of 1d input should be consistent in all estimators think currently 1d is assumed to be of shape `` features `` and even that might fail sometimes that needs to be checked and needs to be consistent across all estimators also all estimators that don support nd input not sure any do or should do need to raise an appropriate error >>>easy enhancement
implement elkan accelerated means see the paper http www quretec com vilo edu 2003 04 dm seminar 2003 ii clustering elkan fast kmeans icml 2003 111 pdf it uses the triangle inequality to speed up updates bit trickier to implement than the standard algorithm but don see why we shouldn do it >>>new_feature
warm start aware grid search few estimators like `lasso` support the `warm start` option due to how `gridsearchcv` is designed use of `clone` parallelism with `n jobs` setting the `warm start` option wouldn have any effect it would be nice to create grid search object which can benefit from warm start `n jobs` could still be supported but should be with respect to cross validation folds this would require specifying with respect to what parameters the warm starting must be done `alpha` in the case of lasso >>>new_feature
adaboost is slow with ensemble of trees see 1668 `x argsorted` should also be precomputed in adaboost when the base estimator is an ensemble of decision trees >>>enhancement
add covertype from benchmarks to dataset module we should move the loading of the covertype dataset from the benchmarks to the datasets module find it really hard to work with the benchmark to do gridsearch etc also the dataset is quite interesting to reproduce papers >>>easy new_feature
lassocv does not find best lambda am on scikit learn version 13 git here is the problem the lambda value entered by hand for lasso performs much better than 013 found by lassocv which utilizes crossvalidation used the standard diabetes data https gist github com burakbayramli 4750196 based the code on this page http scipy lectures github com advanced scikit learn index html sparse models thanks >>>bug
nosetest failed fail doctest sklearn datasets mldata fetch mldata traceback most recent call last file usr lib python2 doctest py line 2163 in runtest raise self failureexception self format failure new getvalue assertionerror failed doctest test for sklearn datasets mldata fetch mldata file usr local lib python2 dist packages sklearn datasets mldata py line 28 in fetch mldata file usr local lib python2 dist packages sklearn datasets mldata py line 85 in sklearn datasets mldata fetch mldata failed example iris fetch mldata iris >>>bug
nmf doesn document attributes in particular ``components `` >>>documentation easy
test hangs on ubuntu 12 04 lts nosetests sklearn exe sklearn decomposition tests test pca test infer dim ok sklearn decomposition tests test pca test infer dim by explained variance ok test that probabilistic pca yields reasonable score ok test that probabilistic pca correctly separated different datasets ok the homoscedastic model should work slightly worth ok check that ppca select the right model ok sklearn decomposition tests test sparse pca test correct shapes ok sklearn decomposition tests test sparse pca test fit transform hangs here >>>bug
incorrect auc value if is not included in inputs in 114 auc fpr tpr out 114 79316049999999971 in 115 auc fpr tpr out 115 8437834999999998>>>bug
rename pairwise distance function to all upper case letters in accordance with pep8 >>>easy enhancement
memory scalability issues in univariate feature selection gensim has re implementation of `selectkbest` to fix memory scalability issues someone should review them and it integrate the fix back into the original sklearn codebase https github com piskvorky gensim blob a73c84e21aecd3cc77ba2d752912f73b712bc60a gensim models selectkbest py maybe agramfort you can have look >>>bug
default value of normalize inconsistent in linear models this was pointed out in the survey >>>easy enhancement
univariate variate scaling in lda this bug report concerns the univariate normalization that is done in the scikit learn lda implementation the following shows the source code lines from file usr lib pymodules python2 sklearn lda py of scikit learn version 13 which are relevant for the bug report if understand the code correctly it does the following normalize before svd line 154 perform svd line 156 correct svd results for the previous normalization line 162 the code seems to work when more training samples than features are present when the linear system is overdetermined when the linear system is underdetermined when there are less samples than features the code fails have however not yet been able to find mathematical formulation of the algorithm that shows what is going on in the code and why it is working at all have not yet seen this normalization step in any other lda code matlab classify method does not do this normalization nor have ever heard of this normalization before below is the test case that ran with normalization enabled the original code and with normalization disabled replaced line 150 by std if normalization is disabled everything works fine if normalization is enabled the code works in the overdetermined case more training samples than feature dimensions and it fails in the underdetermined case less training samples than data dimensions >>>bug
countvectorizer and character grams having problems with countvectorizer when processing character digrams text the quick brown fox jumped over the lazy dog vect countvectorizer analyzer char ngram range vect fit transform text valueerror empty vocabulary training set may have contained only stop words or min df resp max df may be too high resp too low what expecting from the code above is frequency count of character digrams eg th he qu ui is this user error or have found bug >>>documentation
building docs without internet throws error the new functionality of having doc links in the examples needs internet if there is no connection it fails ungracefully think we should catch that and just issue warning >>>documentation easy
gridsearchcv documentation sample not working hello am trying to run the working with text example on the tutorial however get an error >>>bug
dpgmm sample not working hi guys trying out dpgmm to see if can get more stable solution things look good so far except for one problem the sample method does not work for dpgmm the primary reason is that sample assumes there is self covars but this does not exist there is secondary problem however tried using get covars to set the covars but these covariances are not correct perhaps because of different convention somehow in the definitions of these covariances best and thanks for the good work on sklearn e>>>bug
failure in nostests sklearn in python2 dist packages sklearn cross validation py line 1349 in train test split when trying to run the nosetests get the following error nosetests sklearn exe usr local lib python2 dist packages sklearn manifold spectral embedding py 225 userwarning graph is not fully connected spectral embedding may not works as expected warnings warn graph is not fully connected spectral embedding ss usr local lib python2 dist packages sklearn externals joblib test test func inspect py 122 userwarning cannot inspect object ignore list will not work nose tools assert equal filter args ff sss error split arrays or matrices into random train and test subsets traceback most recent call last file usr lib python2 dist packages nose case py line 197 in runtest self test self arg file usr lib python2 dist packages nose util py line 622 in newfunc return func arg kw file usr local lib python2 dist packages sklearn cross validation py line 1349 in train test split raise valueerror at least one array required as input valueerror at least one array required as input ran 1338 tests in 240 836s failed skip 10 errors >>>bug
hinge loss should do input validation checking just wasted 1h passing hinge loss true with labels and >>>enhancement
test failure in lle on ubuntu 12 10 so my box in uni got upgraded and now have this test failure scipy 10 32bit >>>bug easy
sgdclassifier dumps core when given csr matrices with lots of features to reproduce get `url classify py` https gist github com 4656581 get `training data` http www sysnet ucsd edu projects url url svmlight tar gz then run the script directly on the tarball the svmlight loader seems to work fine but the `sgdclassifier` dumps core usually right after printing epoch 1` >>>bug
website search is not working very well if at all google doesn seem to index the website very well try random forest or decision tree would have expected the reference pages to be the top results but it actually appears they don even show up in the results this makes it quite useless in my opinion any way to fix this think it we would be best to use sphinx search engine instead wouldn it like for the python numpy scipy etc official documentation >>>documentation
api proposal genearlized cross validation and early stopping this is proposal to to resolve two api issues in sklearn generalized cross validation early stopping why should we care about that with generalized cross validation mean finding the best setting of some parameter without refitting the entire model this is currently implemented for rfe and some linear models via estimatorcv these don work well together with gridsearchcv as might be required in pipeline or when more than one parameter needs to be found also similar functionality would be great for other models like gradientboosting for estimators and all tree based methods for max depth with early stopping mean saving computations when more computation doesn improve the result we don have that yet but it would be great maybe even necessary feature for sgd based methods and bagging methods random forests and extra trees note that early stopping needs the use of validation set to evaluate the model how can we solve that let start with the generalized cross validation we need it to work together with gridsearchcv this will definitely require changes in both gridsearchcv and the estimators my idea give the estimator an iterable of values you want to try ``max depth range 10 `` during ``fit`` the estimator will fit in way that it can produce predictions for all of these values when ``predict`` is called the estimator will return dict with keys the parameter values and values the prediction values for these parameters we could also add new ``predict all`` function but not sure about that gridsearchcv could then simply incooperate these values into the grid search result for that gridsearchcv needs to be able to ask the estimator for which parameters it can do generalized cv and just pass on the list of parameters it got there so now to early stopping the reason want to treat the two problems as one is that early stopping is basically lazy form of generalized cross validation so you would provide the estimator with an iterable ``n iter range 100 10 `` the estimator fits for all these values as implemented as above but for each setting it also evaluates on validation set and if there is only small improvement training will stop would provide the validation set that is used either as parameter to `` init `` or ``fit`` not sure so it would be enough to add two parameters to the estimator ``early stopping tolerance`` and ``early stopping set none`` if it is none no early stopping there are two choices that made here provide separate validation set not generate one from the training set on the fly this is again so that this can be used inside gridsearchcv and doesn really add that much overhead if the user doesn use gridsearchcv why would they do that any way it is also very explicit and gives the user lot of control provide the parameter settings as an iterable not maximum the reason for that is that you probably don want to evaluate the validation set every iteration but maybe every iterations what another parameter feel like an iterable is good way to specify this also it allows for unified interface with the generalized cross validation case restrictions in pipelines this will only work for the last estimator so not sure to do this with rfe for example do we really need this the changes proposed above are quite big in some sense but think the two issues need to be resolved if you have any better idea feel free to explain it >>>api new_feature
possible math error in binomial deviance calculations the calculations of the binomial deviance and its gradient in https github com scikit learn scikit learn blob master sklearn ensemble gradient boosting py are bothering me could be missing something but the deviance is calculated as `log exp pred here https github com scikit learn scikit learn blob master sklearn ensemble gradient boosting py l339 this matches equation 10 18 on 346 of elements of statistical learning http www stat stanford edu tibs elemstatlearn however that derivation assumes that is valued whereas in sklearn is effectively the calculation is insensitive to `pred` whenever `y 0` the fix is to change the return line to `np sum np logaddexp pred shape the calculation of the gradient makes sense to me if the `pred` values map to class probabilities via `p exp pred however the loss function calculation above seems to follow the convention that `p exp pred again see the link above one way to make the two equations consistent with each other is to remove the first in the above equation `np sum np logaddexp pred shape >>>bug
slow unpickling of onevsrest random forests seeing very slow unpickling times for multilabel random forests opening this as an issue re my discussion http stackoverflow com questions 14472574 addressing slow unpickling of scikit learn onevsrest randomforests with ogrisel on stack overflow trainx is my training feature matrix it is sparse matrix with shape 926 1236 validx is the feature matrix want to categorize by coincidence it has the same size as the training matrix is numpy array of python lists since this is multilabel problem each sample has at most labels with most having only one there are 52 unique labels output can include the rest but the bulk of the time is spend on init py 93 randomstat ctor note that this is actually slightly smaller example than the one was talking about on stack overflow for the sake of ease it still illustrates the problem >>>bug
unbound variable alphas in lars path found this one doing ``nosetests`` in loop the error happens in ``sklearn linear model least angle py`` in ``lars path`` ``alphas`` does not get set because ``return path`` is ``false`` so when the warning is triggered it throws an exception to trigger the bug in ``sklearn decomposition tests test dict learning py`` >>>bug
random error in sklearn cluster tests test means test input dtypes test found this error when running tests in loop >>>bug
lars coef broken when fit path true am using lassolars to solve multi dimensional sparse coding problem after upgrading from 12 to 13 have encountered bug where the coef attribute of lassolars is list not numpy array this breaks the decision function method since it takes the transpose of coef export disk0 wb python2 lib python2 site packages sklearn linear model base pyc in decision function self 138 139 safe asarray 140 return safe sparse dot self coef self intercept 141 142 def predict self attributeerror list object has no attribute this seems to be due to this change that made it into the 13 release by gaelvaroquaux https github com scikit learn scikit learn commit e18465da6a4c11f2364b2dcdbd1433a094093dab>>>bug
improvements remove unneeded code from balltree as discussed in 1605 with the equal distance warning removed from the ball tree there is some unnecessary code in the ball tree source it should be removed also now that we can rely on cython 17 we should rework balltree to use typed memoryviews rather than raw pointers it should lead to cleaner implementation with negligible speed penalty ve been starting some work in this direction at https github com jakevdp binarytree>>>enhancement
label cannot be used as outlier label for radiusneighborclassifier the radiusneighborclassifier outlier label parameter is set to none by default the predict method checks if an outlier label is provided using if self outlier label this evaluates to false if the outlier label is set to as far as know is generally used as label so the test should probably check if self outlier is not none cheers bastiaan>>>bug
finish merging the old tutorial into the narrative doc this tutorial http scikit learn github com scikit learn tutorial source repo http github com scikit learn scikit learn tutorial is getting old and not maintained to reflect the latest api most of the first sections have already been reused in the astronomy tutorial not yet merged either only the last section on text data remains as original content hence we should finish the merge of the astronomy tutorial todo find the issue number integrate the last section on machine learning with text data into new stand alone tutorial section of the main scikit learn documentation in the main repo update http scikit learn github com scikit learn tutorial to point to the main documentation>>>documentation
change default of neighbors distance warning find the equal distance warning in the neighbors module bit annoying and think we should change the default value so that no warning is raised as iris has duplicate points the warning will always be raised there for digits think the warning is raised because entries are discrete 16 so same distances are very likely >>>enhancement
add import export features using the pmml format for decision tree based models pmml predictive models markup language is standard interchange format for trained predictive models and more here is list of industry players and open source projects supporting pmml http www dmg org products html in particular bigml http bigml com is supporting export import of pmml for decision tree models and maybe ensemble of tree models too need to check this the discussion in the comments of this thread http www quora com machine learning what are the pros and cons of using pmml as an interchange format for predictive analytics models answer francisco martin note bigml also supports simpler more compact and human readable json version of pmml named json pml as documented on this gist https gist github com 4565563 supporting pmml and or json pml export of scikit learn decision trees would make it possible to use the bigml web user interface to introspect the trees and run them on datasets loaded on the platform or publish them using the bigml features using an external format for the persistence of some scikit learn models maybe not all would also provide partial solution to the issue of persistence loading of models trained using prior class incompatible version of scikit learn pmml export would also make it easier to perform science experiment replication and help with reproduction too if scientist using decision tree models would publish the pmml export of their ensemble of trees as technical annex to paper for instance as already rattle and weka support pmml exports and imports open questions how big in bytes would be pmml export of realistic ensemble of trees model such as the ones used in computer vision the pmml format looks very verbose we could probably devise more compact model export format using msgpack http msgpack org bson http bsonspec org avro http avro apache org docs current protocol buffers https developers google com protocol buffers docs overview or parquet http parquet io as more generic solution for the persistence of scikit learn model that does not rely upon the python class structure >>>new_feature
joblib saved classifier slow prediction as per the discussion in this thread http comments gmane org gmane comp python scikit learn 5716 am filing the issue code to reproduce the same https gist github com 4564287 best regards jaggu>>>bug
renaming of label to classes don like saying this but to me it seems that the parameter ``labels`` of ``confusion matrix`` should be called ``classes`` in general we should do ``git grep labels`` and ``git grep classes`` think we use classes in most places now in particular ``classifier classes `` and we should probably not use the name ``labels`` anywhere update we use ``labels `` in clustering guess that should not be renamed to ``classes `` as that would be very confusing so do we keep ``labels `` there and use ``classes`` everywhere in the supervised setting >>>easy enhancement
sparse recovery example gives 10000 warnings the ``plot sparse recovery py`` example gives off 10000 warnings of the form>>>documentation
fitting additional estimators for ensemble methods would like to propose an additional instance method to the ensemble estimators to fit additional sub estimators kluged up an implementation for gradient boosting that appears to work through my limited testing was thinking the signature would be something like where `self estimators estimators` is updated as so don think fit extend is particularly great name so welcome other suggestions perhaps we would want to hash the features and labels when fit is called so we can check that the same features and labels are provided to this function if people think this would be useful addition would be willing to put together pr it seems like it should be straightforward to implement and add tests docs for >>>new_feature
add different averaging methods to accuracy score currently it does micro averaging averaging over instances see the beautiful new docs http scikit learn sourceforge net dev modules model evaluation html classification metrics we should definitely be able to also average over classes >>>enhancement
remove label from svc in 1571 introduced `` label`` former name ``label `` that is completely redundant the code should be refactored to get rid of it >>>enhancement moderate
common tests check that results on sparse and dense matrices are identical as proposed by zxtx >>>enhancement
check stability of vbgmm and dpgmm both seem very unstable wrt random initialization maybe we should try multiple random inits by default as in means or we could try to do some smarter initilalization maybe >>>enhancement
implement means based support point sampling for nystroem method just apply means to the training set and use the clusters as support points >>>easy enhancement
trouble with parallel gridsearchcv update am not sure what the root is but the following was reported on irc and could reproduce when doing nested cross validation with ``gridsearchcv`` and ``cross val score`` there seem to be some parallelization issues there is random error in ``gridsearchcv`` maybe this is joblib related reproduce using was iris for me get `` parallel pool seems closed`` and ``valueerror generator already executing`` the jobs parameter is higher than the number of cores should that in general be forbidden ping gaelvaroquaux >>>bug large_scale
make the random forests predict method check the shape of the data and raise valueerror with informative error message as reported on this so question http stackoverflow com questions 14207410 trouble understanding output from scikit random forest 14212533 it would be interesting to check whether such improvement fix can be made more general in the scikit code base maybe as new private method in the classifier mixin or as function in the `sklearn utils validation` module >>>bug easy
multiple output support in dummyclassifier not documented the docstrings in dummyclassifier attributes predict proba don document the shapes returned in the multiple output case >>>documentation
minmaxscaler doesn support inverse transform should be easy to implement >>>easy enhancement
1d array support in minmaxscaler minmaxscaler is useful for regression to scale for this reason it would be nice to support 1d arrays in fit and transform >>>easy enhancement
stochastic failures of lobpcg test so when diagnosing some other issues ve found that running make leads to test failures approximately 30 of the time the error is reported below suspect this is due to the default tolerance of np allclose being 1e not sure why the test fail is random because the random state should be fixed my system is intel i7 3770 ubuntu64 12 04 enthought python fail sklearn cluster tests test spectral test spectral lobpcg mode traceback most recent call last file home kyleb opt lib python2 site packages nose case py line 197 in runtest self test self arg file home kyleb src scikit learn sklearn cluster tests test spectral py line 64 in test spectral lobpcg mode random state eigen solver lobpcg file home kyleb src scikit learn sklearn cluster spectral py line 265 in spectral clustering eigen tol eigen tol drop first false file home kyleb src scikit learn sklearn manifold spectral embedding py line 300 in spectral embedding largest false maxiter 2000 file home kyleb opt lib python2 site packages scipy sparse linalg eigen lobpcg lobpcg py line 434 in lobpcg assert np allclose grama grama assertionerror assert allclose matri>>>bug
make grid search over kernel parameters possible the chi2 kernel has gamma parameter over which one needs to grid search for the use in svc currenlty think this is only possible doing something like this unfortunately this doesn pickle because of the lambda function so only ``n jobs 1`` is possible is there way around that don see >>>enhancement
gridsearchcv does not work with mix of floats none for logisticregression when set 01 10 20 30 40 50 100 none or none 01 10 20 30 40 50 100 it complains must be float yet 01 10 20 30 40 50 100 works it does not seem to parse out the none correctly >>>bug documentation
implement faster ardregression following http books nips cc papers files nips20 nips2007 0976 pdf>>>enhancement
consistency in gmm get covars there are some consistency issues in the mixtures module the covariance matrices in vbgmm and dpgmm are called ``precision`` and ``covars`` in gmm for example there is also `` get covars`` function in gmm that actually seems pretty helpful it provides the full covariance matrices independent of the covariance type but find the docstring misleading and it is privat so it is not visible in the online docs and to autocompletion >>>enhancement
add normalize option to zero one loss currently this loss gives the number not fraction of mistakes think it is the only loss score that is not normalize with the number of samples think qe should at least add an option to do that >>>easy enhancement
add decision function to onevsoneclassifier we could easily return the votes here which are not really continuous but definitely rank the classes >>>easy enhancement
chi2 kernel fused types as mblondel pointed out to me one has to be careful when working with fused types not to generate exponentially many instantiations see discussion here https github com scikit learn scikit learn commit 87810a2fd0294ea83bdd4409fe77bea126f20af5 commitcomment 2389977 we should check whether this is the case for the chi2 code and possibly fix it >>>enhancement moderate
test that all metrics work with sparse matrices or at least throw good error >>>easy enhancement
make input validation in pairwise preserve float32 when computing large distance matrices memory can be an issue think it would be good if we could preserve 32bit ness in the pairwise metrics module wrote some custom input validation for chi2 to do that but think it should be easy to do that directly in the check pairwise arrays function >>>enhancement moderate
the return types of fit transform methods in vectorizer classes count tfidf is not consistent the fit transform method of tfidfvectorizer returns csr matrix which supports array indexing while countvectorizer returns coo matrix which doesn always liked the clean and interchangeable nature of sklearn so wondered whether it would break other pieces if we would return csr matrix in countvectorizer as well or is performance concern here countvectorizer fit transform https github com scikit learn scikit learn blob master sklearn feature extraction text py l530 tfidfvectorizer fit transform https github com scikit learn scikit learn blob master sklearn feature extraction text py l942 >>>easy enhancement
sparse recovery lasso elasticnet example this example thttp scikit learn org stable auto examples linear model plot lasso and elasticnet html doesn have docstring lasso seems to work better than elasticnet am not sure what the example is supposed to illustrate btw think it would be nice if there was some example comparing lasso and ard on some sparse data >>>documentation
relevance vector machine rvm rvm is bayesian framework for obtaining sparse solutions to regression and classification tasks it used model of identical form to svm support vector machine it solves the following disadvantages of svm the number of basis function in svm grows linearly with the size of the training set in rvm we start with basis and incrementally update add delete the set of basis function until convergence svm predictions are not probabilistic while rvm are probabilistic it is necessary in svm to estimate the margin trade off parameter which is not the case in rvm svm kernel should be positive definite in rvm we can use any kernel it is already implemented in dlib http dlib net dlib svm rvm abstract html and there is also matlab implementation here http www vectoranomaly com downloads downloads htm these codes should serve as guide think it will be good idea to add it to scikit learn references `tipping and faul 2003 fast marginal likelihood maximisation for sparse bayesian models in bishop and frey eds proceedings of the ninth international workshop on artificial intelligence and statistics key west fl jan `tipping 2001 sparse bayesian learning and the relevance vector machine journal of machine learning research 211244 `>>>new_feature
fix class weight parametrization in naive bayes there are some loose ends after merging 1491 and 1499 in nb the class weights are now lists they should be list and also accept an auto keyword that should be easy enough to do using ``sklearn utils compute class weight`` see 1491 >>>easy enhancement
build failure error expected identifier or before numeric constant building failed on solaris system with the following error sklearn utils src cholesky delete 55 13 error expected identifier or before numeric constant there also same error reported for cygwin http permalink gmane org gmane comp python scikit learn 3353 it turns out in `cholesky delete c` it has variable named l` but the l` is defined somewhere as macro put undef l` fixes the build error but proper fix should be rename the l` to something else >>>bug easy
the threshold parameter of the squaredhinge loss is ignored the cython implementation is hardcoded with although `threshold` is badly documented constructor parameter >>>bug easy
some functions in sklearn metrics aren presented in the user guide apparently there isn any narrative documentations for some non clustering metrics as it was pointed in 1507 >>>documentation easy
improve the explanations of the loss plot in the sgd section we should reuse mix of the answers to http www reddit com machinelearning comments 15to9t loss function figure explanation to better explain the source plot from the doc http scikit learn org dev modules sgd html mathematical formulation>>>documentation easy enhancement
dump svmlight file doesn handle csr adds comments just loaded an svmlight file to investigate 1476 tried to dump slice but that wasn possible without converting the matrices to dense in between noticed two things the features where backwards when trying to dump sparse matrix the entries in the libsvm file started with the highes non zero entry this might be the cause of the problem also ``dump svmlight file`` add comment at the beginning of the file libsvm the de facto standard svm implementation does not recognize these comments and had to remove them by hand to load the file there seems to be no way to disable the comment judging from the docstring >>>enhancement moderate
very vague error without scipy installed not sure if this is properly filed with scikit learn or pip but this is what found assumed that pip would install all necessary dependencies upon running however pip did not install scipy this lead to traceback with very vague error message from the file sklearn init py it seems reasonable that scikit learn would instead alert the user to the fact that there is missing dependency and is not actually installed incorrectly >>>easy enhancement
refactor class weight in ridgeclassifier it should reuse the code in utils that is used in svm and sgd >>>enhancement moderate
undefined reference to sync fetch and add when building with mingw on 64bit pc when building `metrics pairwise fast` and `ensamble gradient boosting` got `undefined reference to sync fetch and add 4` used mingw compiler on 64bit pc windows to resolve this added `extra compile args march i486 to `config add extension` of `ensamble` and `metrics` `setup py` files not sure what are the implications on other machines this stackoverflow answer http stackoverflow com questions 7994614 undefined reference to sync fetch and add helped me >>>bug
dict vectorizer variable referenced before assignment hello here an error ve caught file usr local lib python2 dist packages sklearn feature extraction dict vectorizer py line 123 in fit transform return self transform file usr local lib python2 dist packages sklearn feature extraction dict vectorizer py line 206 in transform shape len vocab unboundlocalerror local variable referenced before assignment ve tried the latest scikit learn versions from pip and ubuntu repo and both have this problem >>>bug
svc and linearsvc have inconsistent decision function shape in the binary case not sure how that got across test common >>>enhancement moderate
unexpected class weight behavior in ridgeclassifier while testing the class weight parameter in several estimators to investigate 1411 noticed that the parameter doesn work as would expect in ridgeclassifier either maybe this is some misunderstanding on my part or some regularization issue but if have noisy labels would have expected to be be able to move the decision boundary this is not the case as illustrated in this notebook http nbviewer ipython org 4369742 any input would be appreciated >>>bug
class prior in naive bayes the ``class prior`` in nb should be an `` init `` parameter not fit parameter imho thought we had moved all parameter that don depend on the number of samples to fit it just came up on the ml also if it is an `` init `` parameter maybe it should be called ``class weight`` depends on whether the meaning and range of values is the same as for the linear algorithms >>>easy enhancement
bug in random projection example python examples plot johnson lindenstrauss bound py traceback most recent call last file examples plot johnson lindenstrauss bound py line 112 in min components johnson lindenstrauss min dim samples range eps eps file users mathieublondel desktop projects scikit learn sklearn random projection py line 118 in johnson lindenstrauss min dim the jl bound is defined for eps in got eps valueerror the jl bound is defined for eps in got array >>>bug
document coef attribute in lda and qda just came up on so someone was looking for ``components `` think ``coef `` is the right name but the attribute needs docstring >>>documentation easy
permutation test score is not tested as far as can tell >>>enhancement
svc kernel linear for dense and sparse matrices differ significantly renamed by amueller compare the performance between svc kernel linear and linearsvc the difference is very large linearsvc is far better than svc kernel linear the code is in https gist github com 4294378 also test with the original libsvm toolkit its performance is close to linearsvc under fold cross validation don think it is expected from user perspective >>>bug
link to astroml in dev docs there is pretty detailed contributor workflow in the astro ml docs http astropy readthedocs org en latest development workflow development workflow html jakevdp and his team did really great work there maybe we should link to it >>>documentation
add linearsvr our copy of liblinear already contains it we just need to expose it on the python side >>>enhancement
about plot classifier comparison py when run python plot classifier comparison py get error probabilities all rows idx weights indexerror arrays used as indices must be of integer or boolean type my python is thanks>>>bug
univariate selection py 92 runtimewarning invalid value encountered in divide msb msw always seem to get the same error when wanting to use univariate selection univariate selection py 92 runtimewarning invalid value encountered in divide msb msw am using python 64 bit version and numpy the train array use has the shape 957l 3317l which means there are currently 3317 features and would like to select the 10 most useful ones using selectpercentile the arrays msb and msw are looking as follows msb ndarray 01144492 00071531 00643777 00643777 00643777 00286123 with dtype float64 msw ndarray 00574713 00143678 00431034 00431034 00431034 00287356 with dtype float64 was first running python in 32 bit modus so figured that would ve been the problem but after removing it and installing the 64 bit version and all 64 bit extention packages am still experiencing the same problem >>>bug
tree pyx use np intp instead of int as pointed out in 1458 the use of `int` for everything related to indexing numpy arrays might not be safe seberg recommends using `np intp t` instead >>>bug
random failure of test classifiers classes for an unknown reason `test classifiers classes` just failed on my machine cannot reproduce the error >>>bug
failing spectral clustering test on osx 10 with numpy built against system blas fail sklearn cluster tests test spectral test spectral clustering traceback most recent call last file usr local lib python2 site packages nose case py line 197 in runtest self test self arg file users ogrisel coding scikit learn sklearn cluster tests test spectral py line 44 in test spectral clustering assert array equal labels file usr local lib python2 site packages numpy testing utils py line 707 in assert array equal verbose verbose header arrays are not equal file usr local lib python2 site packages numpy testing utils py line 636 in assert array compare raise assertionerror msg assertionerror arrays are not equal mismatch 57 1428571429 array dtype int32 array raise assertionerror narrays are not equal mismatch 57 1428571429 array dtype int32 array >>>bug
retrieve the mask in selectormixin as was pointed out by one my students there is currently no way to retrieve the selected features upon `transform` in `selectormixin` users should be given the possibility to access in one way or another the `mask` variable that is computed in `transform` >>>enhancement
kneighbors should test that samples because it doesn and raises weird error deep in scipy when trying to predict >>>easy enhancement
mnist gets loaded in doctests something seemed to have changed in the doctests recently mnist now gets loaded on both of my boxes meaning can not really run tests in the background any more mnist takes lot of ram to load and my box started swapping on my new laptop the test failed because war running something else and it threw memory error >>>documentation enhancement
sklearn tree unit test crash on linux with numpy master just installed `sklearn` 61e2a71400541c8440f65629231cd127b3e3c4e8 with `numpy dev b7b54cd` on 64 bit linux and get this crash trying to run the unit tests program received signal sigfpe arithmetic exception 0x00007fffde4631ef in pyx 7sklearn 4tree tree 4tree recursive partition pyx self 0x3787050 pyx 0x34001a0 pyx argsorted 0x32fe3b0 pyx 0x3204460 pyx sample mask 0x33c2f70 pyx node samples pyx depth pyx parent pyx is left child pyx buffer value 0x35248e0 at sklearn tree tree 4698 at least think the problem is in `sklearn tree` didn look closely the full log is here https gist github com 4245504 >>>bug
mrg add resample to preprocessing there have been several requests lately for class rebalancing using under oversampling this utility function addresses most of the use cases can think of for sampling with replacement from dataset one thing it does not do is to sample without replacement before sampling with replacement because it changes the code substantially and there is no efficient version of ``random sample`` as per https github com scikit learn scikit learn pull 1438 issuecomment 11162893 could add that feature eventually >>>needs_review
mds fall back to svd when the full similarity matrix is known right now the mds uses slow majorization optimization method instead of falling back to the svd when the full matrix is known >>>easy enhancement
document clone as it is useful for users via stackoverflow http stackoverflow com questions 13701603 how to duplicate an estimator in order to use it on multiple data sets>>>documentation
consistency between tree estimators to compute feature importances in `sklearn tree` and `sklearn ensemble forest` feature importances are computed when fit` is called this feature is enabled with the `compute importances` arguments results are stored in `self feature importances conversely in `sklearn ensemble gradient boosting` `feature importances is an object property which computes feature importances on the fly consistency would be nice the discussion is opened this was brought into consideration in 1388 >>>enhancement
implement jobs in multiclass estimators the training of all estimators in the multiclass module is embarrassingly parallel >>>easy enhancement
test failing on partial dependence ve been busy on another branch so not sure when this popped up or if it been mentioned so close this if it has but on my latest build get the following errors error test partial dependence plot function traceback most recent call last file usr local lib python2 dist packages nose case py line 197 in runtest self test self arg file home jaques scikit learn sklearn utils testing py line 193 in run test return func args kwargs file home jaques scikit learn sklearn ensemble tests test partial dependence py line 116 in test plot partial dependence feature names boston feature names file home jaques scikit learn sklearn ensemble partial dependence py line 382 in plot partial dependence fig tight layout attributeerror figure object has no attribute tight layout error test partial dependence plot function on multi class input traceback most recent call last file usr local lib python2 dist packages nose case py line 197 in runtest self test self arg file home jaques scikit learn sklearn utils testing py line 193 in run test return func args kwargs file home jaques scikit learn sklearn ensemble tests test partial dependence py line 183 in test plot partial dependence multiclass grid resolution grid resolution file home jaques scikit learn sklearn ensemble partial dependence py line 382 in plot partial dependence fig tight layout attributeerror figure object has no attribute tight layout ran 1430 tests in 77 272s failed skip 10 errors make test code error thanks>>>bug
random forest performance random forest is popular classification technique recent benchmarks have shown that performance of sklearn randomforestclassifier is inferior to competing software implementations the performance penalty most likely stems from the underlying tree building procedure however changes here require considerable effort these changes include better representations for data set partitions currently we use bit mask some low hanging fruits may be found in the forest module itself sampling replacement requires memory copies and re computation of argsorted this can be mitigated by introducing sample weights see 522 http continuum io blog wiserf use cases and benchmarks http wise io wiserf html>>>enhancement
add pyflakes and pep8 to travis>>>enhancement
parallel svm training from what can tell the svm aren being trained in parallel and therefore no matter how many cores are thrown at it it only uses one can we consider something like http www csie ntu edu tw cjlin libsvm faq html f432 or http jmlr csail mit edu papers volume7 zanni06a zanni06a pdf thanks note please tell me if very wrong in this regard >>>enhancement
sklearn cluster tests test spectral test discretize in fails testing adjusted rand score at random travis ci found this unrelated issue when testing my pull request https travis ci org scikit learn scikit learn builds 3454819 936fail sklearn cluster tests test spectral test discretize 937 938traceback most recent call last 939 file home travis virtualenv python2 with system site packages local lib python2 site packages nose case py line 197 in runtest 940 self test self arg 941 file home travis builds scikit learn scikit learn sklearn cluster tests test spectral py line 170 in test discretize 942 assert greater adjusted rand score true pred 943assertionerror 89082564037817402 not greater than 944 fail immediately with the given message 945 raise self failureexception 89082564037817402 not greater than >>>bug
dig up papers folk knowledge about why leave one out is bad the reason is that the variance of the estimate is high according to gaelvaroquaux the papers are hard to find one more reason to reference them in the docs >>>documentation easy
sklearn metrics precision recall curve occasionally fails the precision recall curve metric output is occasionally meaningless as in the following example output caption http s10 postimage org d8uazvjt5 pr curve 1353936568 png three remarks meaningless outputs occurs as well using 13 or 12 if use the lastest git version the auc function raises an exception while it doesn when using 12 version assertionerror reordering is not turned on and the array is not increasing 24195 24145 24161 the true and probas dumps are available here true http pastebin com lmftfdd4 and there probas http pastebin com qnd9bkj9 starting from the available example covering sklearn metrics precision recall curve ve wrote this piece of code which is responsible for the aforementioned picture def plot pr model test test probas model predict proba test precision recall thresholds precision recall curve test probas pr auc auc precision recall pl clf pl plot precision recall label curve pl grid pl xlabel recall pl ylabel precision pl ylim 05 pl xlim pl title precision recall auc 2f pr auc pl legend loc best pl savefig open pr curve png int time time format png np savetxt precision log precision np savetxt recall log recall np savetxt proba log probas thank you for your help franois kawala >>>bug
broken plots in omp example see http scikit learn org dev auto examples linear model plot omp html>>>bug documentation easy
test errors in master in spectralembedding since the merge have three test errors in master they don look 32bit related to me so kind of surprised that neither travis nor jenkins picked them up error test spectral embedding with amg solver traceback most recent call last file usr local lib python2 dist packages nose case py line 197 in runtest self test self arg file home andy checkout scikit learn sklearn manifold tests test spectral embedding py line 126 in test spectral embedding amg solver embed amg se amg fit transform file home andy checkout scikit learn sklearn manifold spectral embedding py line 481 in fit transform self fit file home andy checkout scikit learn sklearn manifold spectral embedding py line 460 in fit random state self random state file home andy checkout scikit learn sklearn manifold spectral embedding py line 267 in spectral embedding ml smoothed aggregation solver laplacian tocsr attributeerror numpy ndarray object has no attribute tocsr fail test spectral embedding with precomputed kernel traceback most recent call last file usr local lib python2 dist packages nose case py line 197 in runtest self test self arg file home andy checkout scikit learn sklearn manifold tests test spectral embedding py line 87 in test spectral embedding precomputed affinity assert true check with col sign flipping embed precomp embed rbf 01 assertionerror false is not true false is not true self formatmessage false is not true is not true safe repr false raise self failureexception false is not true fail test spectral embedding with callable affinity traceback most recent call last file usr local lib python2 dist packages nose case py line 197 in runtest self test self arg file home andy checkout scikit learn sklearn manifold tests test spectral embedding py line 109 in test spectral embedding callable affinity check with col sign flipping embed rbf embed callable 01 assertionerror false is not true false is not true self formatmessage false is not true is not true safe repr false raise self failureexception false is not true ll investiage now >>>bug
mldata org doesn like travis my travis builds and also one in 1416 by awinterman often fail because mldata org throws 500 internal server error this is somewhat annoying >>>bug
joblib dump memory error memory usage by joblib dump jumps to more than times the size of the object while training the classifier takes about 11g of memory but when dumping the classifier object using joblib dump compress the usage jumps up to 38 4g causing issues with limited ram tried values compress always get memory error if compress is not used for joblib dump the classifier object is about 11g following is the minimalistic script that demonstrates the steps in my classifier script from sklearn feature extraction text import tfidfvectorizer from sklearn externals import joblib from sklearn multiclass import onevsrestclassifier from sklearn linear model import sgdclassifier import time here data is the list of plaintext paragraphs and target array has the category each paragraph belongs to one of the categories def train data target vectorizer tfidfvectorizer stop words english ngram range smooth idf true sublinear tf true max df token pattern ur use idf false vectorize the input data print extracting features from dataset using self vectorizer start time time data vectors vectorizer fit transform data extract features time time start time print feature extraction of training data done in seconds extract features time print number of samples in training data number of features data vectors shape print dump the vectorizer dataset and target array objects for later use this seems to work correctly with any value of compress print dumping vectorizer joblib dump self vectorizer vectorizer joblib compress print done print dumping data vectors joblib dump data vectors datavectors joblib compress print done print dumping target array joblib dump target targetarray joblib compress print done train the classifer with ovr the maximum memory used during training is 11g for dataset of size 655m clf onevsrestclassifier sgdclassifier loss log iter 35 alpha 00001 jobs start time time print training clf clf fit data vectors target print done 3fs start time time dump the classifier for later use joblib dumps the classifier correctly without any compression however the size of the vector dumped is about 10 11g this seems to be too large for our purpose and hence trying to compress the dumped object for compress the memory usage jumps to 38 4g since the available memory is only 32g the process ends up using swap space where the process is stalled for long time and eventually killed print dumping classifier joblib dump clf classifier joblib compress print done >>>bug large_scale
multiclass onevsrestclassifier needs predict proba method currently has `predict` method but no `predict proba` which means it is difficult to coax classification probabilities out of scikit learn for multi label problems >>>easy enhancement
weird behavior in logisticregression on parameter class weight the class weight parameter set different weights for misclassify that class for example in classification problem if we set class weight 95 05 then we can expect the classifier to be more careful when it try to classify data sample to be since misclassify to is heavily penalized but the logisticregression class seems go wrong from sklearn import datasets from sklearn import svm from sklearn import linear model 100 sample half of its label is others are datasets make classification sum 50 balance lr classifier clr0 linear model logisticregression clr0 fit clr0 score 84999999999999998 clr0 predict sum 49 imbalance lr classifier clr1 linear model logisticregression class weight clr1 fit clr1 score 63 clr1 predict sum 85 the imbalance classifier clr1 is supposed to classifier more data to be label but it actually predict far more data to be but when we choose another classfier say svm the behavior seems resonable balance svm classifier clr2 svm svc clr2 fit clr2 score 95999999999999996 clr2 predict sum 46 imbalance svm classifier clr3 svm svc class weight clr3 fit clr3 score 84999999999999998 clr1 predict sum 35 another imbalance svm classifier clr4 svm svc class weight clr4 fit clr4 score clr4 predict sum when the class weight vs class weight is svc predict roughly half of data to be when the class weight vs class weight is svc predict more data to be when the class weight vs class weight is svc predict all the data to be is this bug >>>bug
random malloc error on test means plus plus init jobs test happens on current master 3c46ebaa6e5f7bd504158da4aeb8dddd0b8db705 on macosx 10 64bit happens like 10th of the time modern scikit learn erg master nosetests affinity propagation algorithm ok tests the dbscan algorithm with similarity array ok tests the dbscan algorithm with feature vector array ok tests the dbscan algorithm with callable metric ok sklearn cluster tests test dbscan test pickle ok check that we obtain the correct solution for structured ward tree ok check that we obtain the correct solution for unstructured ward tree ok check that the height of ward tree is sorted ok check that we obtain the correct number of clusters with ward clustering ok check that we obtain the correct solution in simplistic case ok test scikit ward with full connectivity unstructured vs scipy ok check that connectivity in the ward tree is propagated correctly during ok check non regression of bug if non item assignable connectivity is ok sklearn cluster tests test means test square norms ok sklearn cluster tests test means test kmeans dtype ok sklearn cluster tests test means test labels assignement and inertia ok check that dense and sparse minibatch update give the same results ok sklearn cluster tests test means test means plus plus init ok sklearn cluster tests test means test means new centers ok sklearn cluster tests test means test means plus plus init jobs python 33971 malloc error for object 0x10dae4000 pointer being freed already on death row set breakpoint in malloc error break to debug python 33972 malloc error for object 0x10daa3000 pointer being freed already on death row >>>bug
floating point exception in gradientboostingclassifier during nosetests on macosx 10 64bit and others fails every time using current master and either ``nosetests`` or ``make`` git id 3c46ebaa6e5f7bd504158da4aeb8dddd0b8db705 sklearn decomposition tests test sparse pca test initialization ok sklearn decomposition tests test sparse pca test mini batch correct shapes ok sklearn decomposition tests test sparse pca test mini batch fit transform skip doctest sklearn ensemble gradient boosting gradientboostingclassifier floating point exception modern scikit learn erg master >>>bug
linearregression has decision function as mentioned by tjanez in 1393 this doesn make sense we should check if other linear models for regression also have it >>>easy
binarize always converts to csr format sparse case in the sparse case `preprocessing binarize` always converts the input matrix to csr format for coo and csc the data attribute can also be accessed directly so in those cases there no reason to convert to csr csc is especially useful for coordinate descent algorithms >>>easy enhancement
enh one vs one heuristic voting strategy biased hello in the documentation for the one versus one heuristic on multiclass classification it is written at prediction time the class which received the most votes is selected the predict ovo def returns the argmax of the votes matrix my intuition is that in cases of ties the vote will be biased towards the classes from the first binary classifiers because argmax selects automatically the first occurrence in cases of ties wondered if it would be possible to implement classification strategy less biased such as selecting the classifier which has the highest output function as is done by the one vs the rest heuristic if am not mistaken thank you for your help mathieu ruiz>>>bug easy
doc sklearn metrics auc score should mention that using probabilities will give better scores the documentation at http scikit learn org dev modules generated sklearn metrics auc score html sklearn metrics auc score says that `y score` can be either probability estimates of the positive class or binary decisions it should warn the reader that by using binary decisions it is only able to compute auc as if the classifier only returned probabilities and and thus not give the real auc here is an example python from sklearn linear model import logisticregression from sklearn import metrics from sklearn import cross validation from sklearn import datasets data datasets load digits data data data target make the classification problem binary clf logisticregression 001 fold cross validation kfold len 10 indices true shuffle true random state 18 aucs aucs proba for train test in fold clf fit train train aucs append metrics auc score test clf predict test aucs proba append metrics auc score test clf predict proba test print aucs print aucs print aucs with probabilities print aucs proba this is the output python aucs 97222222222222221 97058823529411764 aucs with probabilities 99673202614379086 admit this is not very good example as the difference between `aucs` and `aucs proba` could be lot bigger in practice but wanted to use built in data set note that auc computed from binary decisions is always inferior to the auc computed with probability estimates >>>documentation
mds takes proximity matrix as input it seems that the mds pr was in parallel to my pairwise pr didn realize that mds takes distance matrix as input it is now the only algorithm in sklearn that does that would suggest using some standard distance instead this breaks backward compatibility but really like to have some consistent api there >>>enhancement
fit intercept in ridge sparse case in the sparse case `ridge` silently ignores `fit intercept` currently it equivalent to `fit interept false` using the recently added `add dummy feature` it should now be easy to support `fit intercept true` since it corresponds to penalizing the intercept we need to add `intercept scale` option to the constructor like `linearsvc` `add dummy feature` results in copy of `x` suggests to set `fit intercept auto by default in the dense case auto can correspond to `fit intercept true` and in the sparse case to `fit intercept false` to avoid the memory copy this way the code will be backward compatible too >>>bug
manhattan distances does not work for sparse matrices simple case can be found here when manhattan distances take two sparse matrices as input https gist github com 4117966 the function fails without complaining seems jakevdp https github com jakevdp pydistances has many very efficient routines for computing pairwise distances for sparse matrices any plan for adopting some of them to sklearn >>>enhancement
featureunion doc featureunion is bit awkward in the model selection section would rather create new chapter for pipeline and put it there or put it in the feature extraction chapter also since feature union is for combining feature extractors it should ideally come after feature extraction in the user guide >>>documentation
add test for unsupervised gridsearchcv we now have some examples but no unit tests >>>easy enhancement
document passing list of grids to gridsearch>>>documentation easy
model evaluation classification metric docs there is no user guide on the classification regression metrics >>>documentation
add testimonials to website add new page to the website on who uses sklearn and for what >>>documentation
random test failure in test transformers there is random failure in the common tests will try to have look later >>>bug
move isotonic regression out of linear model ping agramfort >>>enhancement
single sample test time performance test time performance on single samples is important in real world applications currently performance on individual samples is often governed by input validation rather than model evaluation consider the following profile of ``gradientboostingregressor decision function`` trained on boston using 250 trees 645 151 151 53 array2d dtype dtype order 646 49 49 17 score self init decision function 647 78 78 27 predict stages self estimators self learning rate score 648 return score the major reason is that ``sklearn validation array2d`` calls ``scipy sparse issparse`` twice this could be fixed but still the overhead from checking if the array values are finite is considerable we should optimize input validation or provide means to turn it off >>>easy enhancement
cross validation and tools for undersampling and oversampling in learning with unbalanced classes it is often good to stratify the data not as in stratifiedkfold by making the classes the same size either by oversampling or undersampling think it would be good to have both utility function that does that once and cross validation object that does that differently for all folds >>>new_feature
train test split sets test size without considering train size if train size is set without setting test size test size will be set to 25 had set where 200000 and set train size to 60000 test size was set to 50000 thanks really like sklearn >>>easy enhancement
developer docs don mention trailing underscore the dev docs should mention that all attributes that are estimated from the data have trailing underscore also init parameters are always remembered and not documented in the attributes section >>>documentation easy
fastica unit test fails at random fail test the fastica algorithm on very simple data traceback most recent call last file usr lib python2 site packages nose py2 egg nose case py line 197 in runtest self test self arg file home erg python scikit learn sklearn decomposition tests test fastica py line 100 in test fastica assert almost equal np dot s1 s1 samples decimal file usr lib python2 site packages numpy testing utils py line 468 in assert almost equal raise assertionerror msg assertionerror arrays are not almost equal to decimals actual 99476064813705389 desired raise assertionerror narrays are not almost equal to decimals actual 99476064813705389 desired >>>bug
fetch 20newsgroups should say it takes while this script gives an error from sklearn datasets import fetch 20newsgroups data train fetch 20newsgroups subset train shuffle true random state 42 think it does not download the 20news bydate tar gz file if download it manually to the scikit learn data folder it fixes the error >>>easy need_contributor
bug precision recall curve recently updated the implementation of `precision recall curve` in metrics py to make it more efficient now see that the output has changed in some situations for example consider the following code from sklearn metrics import precision recall curve labels predict probas precision recall curve labels predict probas the output here will differ depending on whether you use 12 stable or the latest version of master in the stable branch using the old implementation the output is array 33333333 array array in the dev branch using the new implementation the output is array 33333333 array array the output of the new code is wrong ve already created fix for this ll post the pull request here in minute >>>bug
documentation on optional parameters of decision tree am looking at the code for decision tree and the document does not describe what the arguments for fit function sample mask and argsorted are figured out by reading code what argsorted is but still have hard time understanding sample mask perhaps explanation on these arguments should be included in http scikit learn org stable modules generated sklearn tree decisiontreeregressor html sklearn tree decisiontreeregressor >>>bug documentation
perceptron and passiveaggressiveclassifier should not inherit from predict proba perceptron and passiveaggressiveclassifier should not inherit from predict proba and predict log proba solution create new class basesgdclassifier that does not define predict proba and predict log proba >>>bug easy
model persistence documentation how to save model model persistence used to be sub section of the tutorial and visible directly from the homepage but since now it become sub sub section it not visible anymore since it very common need it would be nice to make it more prominent maybe section of its own >>>documentation easy
attribute of pipeline steps should be steps is this correct or should it be fixed from docstring >>>easy
precompute square norms in passive aggressive `passiveaggressiveclassifier` is currently times slower than `perceptron` on the document classification example this is because the current implementation recomputes the square norm which is needed to compute the step size for each example every time the solution would be to add `void precompute norms squared true and `double get norm int to `sequentialdataset` doing so expect the performance to be inline with `perceptron` cc pprett >>>enhancement moderate
check that all attributes are documented list of all attributes can be found here https gist github com 3973308 by jaquesgrobler can we check automatically whether they are all documented or do we want to check by hand >>>documentation
minmaxscaler does not support sparse input just to remind us that minmaxscaler does currently not support sparse input >>>enhancement
plssvd module does not extract the required component specified by user the plssvd specify number of components to be extracted components using svd which is actually not used in the code at all it simply returns all possible components is this true >>>bug
add blas3 to the sources fabianp could you please give me hand in that >>>enhancement
expectation maximization for supervised naive bayes classifiers know this isn code issue really but hopefully my issue fits here somehow anyway like to know whether there is more or less simple way of adding the expectation maximization algorithm to the supervised naive bayes classifiers `multinomialnb` and `bernoullinb` in `sklearn naive bayes` ve found pull request with an implementation of this in semi supervised approach but it seems that it hasn been merged so far to master but need it for completely supervised setting has anyone done something like that or can anyone tell me how to start implementing em bit lost in where to start thank you >>>new_feature
sklearn svm svc and friends have lots of validation usability issues issue ``y`` float values get truncated it predicts ``3 `` instead of ``3 3`` issue output types are float arrays the output is ``float`` array when it could be typed ``int`` maybe issue targets can be strings >>>enhancement
sklearn metrics confusion matrix fails on string labels the confusion matrix method outputs zero matrix when the labels are string to replicate run print confusion matrix and the output is running the same command with integer labels produces the expected output print confusion matrix update it appears have two version of confusion matrix one from sklearn and one from scikits learn am not sure how the sklearn package appeared on my machine suspect it shipped with my python distribution epd the bug reported above only occurs with the sklearn version if install scikit learn through pip and run from scikits learn metrics import confusion matrix import numpy as np print confusion matrix np array np array get the correct result the call requires me to convert the list explicitly to numpy array otherwise get print confusion matrix typeerror traceback most recent call last in print confusion matrix library frameworks epd64 framework versions lib python2 site packages scikits learn metrics metrics pyc in confusion matrix true pred labels 52 53 if labels is none 54 labels unique labels true pred 55 else 56 labels np asarray labels dtype np int library frameworks epd64 framework versions lib python2 site packages scikits learn metrics metrics pyc in unique labels list of labels 22 23 list of labels np unique labels np isfinite labels ravel 24 for labels in list of labels 25 list of labels np concatenate list of labels 26 return np unique list of labels typeerror only integer arrays with one element can be converted to an index with string lists get print confusion matrix notimplementederror traceback most recent call last in print confusion matrix library frameworks epd64 framework versions lib python2 site packages scikits learn metrics metrics pyc in confusion matrix true pred labels 52 53 if labels is none 54 labels unique labels true pred 55 else 56 labels np asarray labels dtype np int library frameworks epd64 framework versions lib python2 site packages scikits learn metrics metrics pyc in unique labels list of labels 22 23 list of labels np unique labels np isfinite labels ravel 24 for labels in list of labels 25 list of labels np concatenate list of labels 26 return np unique list of labels notimplementederror not implemented for this type >>>bug easy
sklearn tests test multiclass test ovr fit predict unit tests fails at random fail sklearn tests test multiclass test ovr fit predict traceback most recent call last file usr lib python2 site packages nose py2 egg nose case py line 197 in runtest self test self arg file home erg python scikit learn sklearn tests test multiclass py line 67 in test ovr fit predict assert equal np mean iris target pred np mean iris target pred2 assertionerror 96666666666666667 97333333333333338>>>bug
sklearn decomposition nmf projectedgradientnmf unit test fails at random erg ommegang python scikit learn sklearn master nosetests ss home erg python scikit learn sklearn externals joblib test test func inspect py 122 userwarning cannot inspect object ignore list will not work nose tools assert equal filter args ff home erg python scikit learn sklearn externals joblib test test numpy pickle py 182 warning file tmp tmpwzukqv test pkl297 appears to be zip ignoring mmap mode flag passed numpy pickle load this filename mmap mode sss fail sklearn tests test common test transformers traceback most recent call last file usr lib python2 site packages nose py2 egg nose case py line 197 in runtest self test self arg file home erg python scikit learn sklearn tests test common py line 179 in test transformers fit transform not correct in trans file usr lib python2 site packages numpy testing utils py line 812 in assert array almost equal header arrays are not almost equal to decimals decimal file usr lib python2 site packages numpy testing utils py line 645 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals fit transform not correct in mismatch 11111111111 array 85073380e 01 26715545e 01 43223579e 00 13547241e 01 40893053e 02 24521866e 01 00000000e 00 06990298e 01 36199787e 01 array 84490731e 01 27413683e 01 43280990e 00 12595386e 01 49583906e 02 24250396e 01 00000000e 00 06929012e 01 36705190e 01 ran 1223 tests in 130 546s failed skip 11 failures erg ommegang python scikit learn sklearn master nosetests ss home erg python scikit learn sklearn externals joblib test test func inspect py 122 userwarning cannot inspect object ignore list will not work nose tools assert equal filter args ff home erg python scikit learn sklearn externals joblib test test numpy pickle py 182 warning file tmp tmpocsn5u test pkl597 appears to be zip ignoring mmap mode flag passed numpy pickle load this filename mmap mode sss ran 1223 tests in 88 815s ok skip 11 erg ommegang python scikit learn sklearn master >>>bug
segmentation fault in kmeans clustering using the kmeans clustering to cluster csr matrix of 10 000x8 000 or greater dimension has produced segmentation fault in title clustering application am working on we have started using recursive hierarchical clustering to avoid the issue but as this has produced less optimal results it is in our interest to solve the segmentation fault >>>bug
update shogun comparison document shogun has comparison table of several machine learning algorithms unfortunately it is not really up to date wrt sklearn talked to the shogun people and they like us to get an instance of their google spreadsheet and add our new algorithms >>>documentation easy
random test failure in pls got this once on the current master cannot reproduce it even by fixing the `sklearn seed` to the one of the failure `1472386125` but the attribute error should be fixable by manual code inspection >>>bug
manifold example not showing image on dev documentation not seeing the nice manifold image in the docs on the dev site it displays on stable though is this known issue or should look into it dev http scikit learn org dev modules manifold html stable http scikit learn org stable modules manifold html >>>documentation easy
get rid of some properties in hmm have been trying to debug the hmm code today to find the error without stepping through the whole thing in the debugger it was impossible for me to understand what is happening assignments in the `` init `` are actually calling setters not only does that break cloning it also makes the code really hard to read >>>enhancement
missing features in onehotencoder using features where only certain entries are categorical support sparse input support non sparse output>>>enhancement moderate
clean up examples in tutorial the tutorial duplicates many of the examples already present for example now there is color quantization example and grey scale quantization example also there are now three means examples pretty sure we can get rid of some maybe jaquesgrobler can have look >>>documentation easy
missing documentation for minmaxscaler in the narrative documentation of the preprocessing module while there is some reference documentation http scikit learn org dev modules generated sklearn preprocessing minmaxscaler html the narrative documentation is completely lacking any reference to minmaxscaler http scikit learn org dev modules preprocessing html we should add dedicated paragraph similar to the one for `standardscaler` and give pro and cons for those two guys >>>documentation easy
misleading exercise in the cross validation estimators section of the tutorial in the exercise in section on cross validation estimators http scikit learn org dev tutorial statistical inference model selection html cross validated estimators one has to find an optimal regularization parameter alpha for lasso regression think the exercise is misleading to say the least the main issue is that the scores for different `alphas` differ insignificantly yet the plot of the solution http scikit learn org dev downloads plot cv diabetes1 py portrays them as something significant to be more concrete the `scores` are 48803450860197256 48803099969675356 48802573754364903 48801773427191092 48800529096977491 48798554724918719 48795319169977985 48789864301061825 48790979589257422 48810545077662604 48833952711517042 4885892181426163 48879397803865515 48900347108427633 48895024452530594 48886339735804762 48836850577232954 48762167781541343 48712963815557303 48692470890140377 yet the plot is something like this https content wuala com contents tadej janez github attachments plot lasso alphas png dl it hides the scale so that the observer can see just how similar the scores are how encountered the bug was that programmed my own solution to the exercise https content wuala com contents tadej janez github attachments sklearn diabetes py dl the plot this solution generates is this one https content wuala com contents tadej janez github attachments plot lasso alphas2 png dl the other problem with the exercise is the bonus question how much can you trust the selection of alpha the answer given in the solution is which produces 10000000000000001 10000000000000001 10000000000000001 in essence the code outputs the last used `alpha` from the `alphas` list this is obviously not the answer to the question the correct solution would preferably say something like the process used to find the optimal value of parameter `alpha` is prone to over fitting possible way to avoid this problem is to perform nested cross validation select the value of `alpha` using internal cross validation on the current training data and compute the estimator score on separate test data obtained via external cross validation the code to perform this would be this was my first issue with scikit learn since started using it week ago trying to be helpful user and contribute something back so please read my comments in constructive light >>>bug documentation
gmm covars structure changed for spherical cvtype it seems the spherical cvtype is using different representation of the covariances docs still state it to be components if spherical features features if tied components features if diag components features features if full indeed not it seems to be components features if spherical so that spherical is the same as diag with constant diagonal it is pita to change my code with every update of sklearn tbh could you perhaps settle for naming and representation schema >>>bug documentation
speed up factoranalysis using warm starts in svd and maybe randomizsvd >>>enhancement moderate
bug fix segfault at import of the scikit hot fix to solve the segfault on the buildbot in general to use the api of numpy cimport numpy in cython you should always insert np import array after the import if not you can have race conditions during the imports >>>bug
update authors rst it seems bit out of date >>>documentation
create examples tests for custom estimators not inheriting from baseestimator also see 1241 >>>documentation enhancement
bad svm example in tutorial exercise one of the tutorial exercises http scikit learn org dev auto examples exercises plot cv digits html example exercises plot cv digits py does grid search using svc searching only for ``c`` and not for ``gamma`` think this is very bad example never do that probably the best remedy would be to switch to linear classifier or grid search both gamma and but that might take longer and is not easily plotable working on that >>>documentation easy
adaptive learning rate for sgd enhancement considering implementing new adaptive learning rate algorithm proposed here http arxiv org abs 1206 1106 anyone have any feedback about where this should go was thinking it would be added somewhere around https github com scikit learn scikit learn blob master sklearn linear model sgd fast pyx l383 since sgd is also applicable to non linear models neural network models are there any plans to move that outside of linear model >>>new_feature
test failure on feature stacker pipeline fail sklearn tests test pipeline test feature stacker weights traceback most recent call last file usr local lib python2 site packages nose case py line 197 in runtest self test self arg file users ogrisel coding scikit learn sklearn tests test pipeline py line 243 in test feature stacker weights assert array almost equal transformed 10 pca fit transform file usr local lib python2 site packages numpy testing utils py line 800 in assert array almost equal header arrays are not almost equal to decimals decimal file usr local lib python2 site packages numpy testing utils py line 636 in assert array compare raise assertionerror msg assertionerror arrays are not almost equal to decimals mismatch 100 array 26 84207125 26607315 27 15390616 69556848 28 8981954 3734561 array 26 84207125 26607315 27 15390616 69556848 28 8981954 3734561 raise assertionerror narrays are not almost equal to decimals mismatch 100 array 26 84207125 26607315 27 15390616 69556848 28 8981954 3734561 array 26 84207125 26607315 27 15390616 69556848 28 8981954 3734561 >>>bug easy
assert non negative data in chi2 make it bit more explicit in the docstring that chi2 can only be used with non negative data and do an input validation because it seems not entirely obvious to everybody http stackoverflow com questions 12987162 strange chi square result using scikit learn with feature matrix >>>documentation easy enhancement
bug in auc metric when tp 100 as an example this works correctly however if there are no true negatives there is only one class an error is thrown is this the correct behavior >>>bug
custom crossvalidation classes look like number type sometimes someone on irc was trying to write their own cross validation class but when calling ``check cv`` it got replaced with ``stratifiedkfolds`` object the validator in question https gist github com 3919224 the reason for this is that returns ``true`` because ``operator`` is written with the api to make the ``cohortcrossvalidator`` work just extend the ``object`` class however this is apparently something that should have gone away in python and is no longer good idiom not sure what to do here but it confusing and bug imho from ``sklearn cross validation py`` >>>bug
unexpected extratrees behavior in certain situations extratrees behave differently from randomforests when no progress can be made on dataset using single split extratrees don grow at all at least this is my diagnosis at the moment this gist https gist github com 7bb07fe022b61b2cd4b4 illustrates the problem really prefer the extratrees to just pick random split which guess is what the random forests do am not terribly familiar with the tree building code could someone else maybe have look >>>bug
far future get rid of doctest options inline in recent versions of nose the options ``normalize whitespace`` and ``ellipsis`` can be set globally that would be awesome this is only available in nose https github com nose devs nose blob master changelog though as removing the flags inline would break them on older versions not sure we can ever make the switch should we try to monkey patch >>>enhancement
building with python3 doesn make check build so and nosetests fails when compiling with python2 with the line ``python2 setup py build ext i`` we get the file ``sklearn check build check build so`` however ``python3`` doesn make this file when attempting to run nosetests the output is something like >>>bug
deprecated numpy api when compiling scikit with the github version of numpy get warning about deprecated api on every file >>>enhancement
decisiontreeclassifier predict and predict proba can take the wrong shape and nan values import sklearn tree import numpy as np clf sklearn tree decisiontreeclassifier np array 10 np array 1000 2000 clf clf fit x2 np array right shape clf predict x2 clf predict proba x2 x3 np array wrong shape clf predict x3 clf predict proba x3 x4 np array np nan nan inputs clf predict x4 clf predict proba x4 >>>easy enhancement
linking problem with atlas on os see mailing list http sourceforge net mailarchive forum php thread name 507f9b81 3050604 40ais uni bonn de forum name scikit learn general >>>bug
normalize whitespace in doctests globally figure out how to set the normalize whitespace option and get rid of all the inline things >>>easy
meta estimator for semi supervised learning using self taught learning it is possible to turn any estimator into semi supervised one not that hard to do >>>new_feature
meta estimators for bagging and boosting just putting this on the long term wish list >>>new_feature
add how to roll your own estimator to docs how to implement an estimator so that it is compatible with skearn and what that means as this doesn seem to be clear to the core devs see discussion in and around 1210 we should probably write it down >>>documentation
broken svm anova example when running `plot svm anova py` >>>bug easy
label propagation example is broken python examples semi supervised plot label propagation digits active learning py label propagation digits active learning demonstrates an active learning technique to learn handwritten digits using label propagation we start by training label propagation model with only 10 labeled points then we select the top five most uncertain points to label next we train with 15 labeled points original 10 new ones we repeat this process four times to have model trained with 30 labeled examples plot will appear showing the top most uncertain digits for each iteration of training these may or may not contain mistakes but we will train the next model with their true labels traceback most recent call last file examples semi supervised plot label propagation digits active learning py line 57 in labels lp model classes file users oliviergrisel coding scikit learn sklearn metrics metrics py line 69 in confusion matrix true np array label to ind for in true keyerror 0>>>bug easy
mix in gmmhmm not documented also not sure about the name it is the number of components in each mixture model while there are ``n component`` mixture models >>>documentation easy
gridsearchcv fails on some sparse matrices the gridsearchcv class appears to run into trouble with some sparse matrix formats in particular the coo format that comes out of the countvectorizer class it looks like it tries to use integer indexing and that isn supported for all sparse matrix types maybe just csr running into this with sklearn version 12 and scipy version 11 here some code that demonstrates it modified from http scikit learn org 11 downloads document classification 20newsgroups2 py import os import sys from sklearn datasets import fetch 20newsgroups from sklearn feature extraction text import countvectorizer from sklearn svm import linearsvc from sklearn grid search import gridsearchcv categories none data train all fetch 20newsgroups subset train categories categories shuffle true random state 42 all len data train all data categories data train all target names train data train all target print extracting features from the training dataset using sparse vectorizer vectorizer countvectorizer min df 500 max df stop words english dtype float train vectorizer fit transform data train all data svc linearsvc loss l2 penalty l2 dual false tol 1e gridsearch gridsearchcv estimator svc param grid print sys stderr trying with csr gridsearch fit train tocsr train print sys stderr trying with default coo fails here gridsearch fit train train >>>bug
get 100 test coverage recently there was bug in error reporting and found several unreachable code path this makes me think that it would be good to have 100 code coverage in not backported modules think this is not really hard to do would also like to cover all the value errors simply for the reason that this makes it much easier to find not covered places if the coverage utility tells me 98 is covered have to go to the source every time to see if the missing lines are ``if raise valueerror`` or something that really should be tested >>>easy enhancement
failed test multiclass test ovr fit predict random failure or precision issue failed while building for ubuntu 11 04 32bit >>>bug
12 test spectral clustering sparse fails on 64bit it is fun one not sure how numpy maintains original decimal representation so it gets this since all hex views are the same but in any case it seems just to be failing test anyways if they should not be equal >>>bug
installation failed in solaris x86 64bit hi guys tried everything but cannot find any solution please help thanks lot the following is from the compilation compiling sources compiler gcc m64 fno strict aliasing o2 dndebug o2 dhave ncurses fpic compile options dno atlas info isklearn src cblas users home aagns9c3 django projects epd lib python2 site packages numpy core include users home aagns9c3 django projects epd lib python2 site packages numpy core include users home aagns9c3 django projects epd include python2 gcc sklearn utils arrayfuncs in file included from sklearn utils arrayfuncs 241 sklearn utils src cholesky delete in function `float cholesky delete sklearn utils src cholesky delete 55 error syntax error before numeric constant sklearn utils src cholesky delete 58 warning passing arg of `cblas scopy makes pointer from integer without cast sklearn utils src cholesky delete 58 warning passing arg of `cblas scopy makes pointer from integer without cast sklearn utils src cholesky delete 59 error invalid lvalue in assignment sklearn utils src cholesky delete 62 error invalid lvalue in assignment sklearn utils src cholesky delete 65 warning passing arg of `cblas srotg makes pointer from integer without cast sklearn utils src cholesky delete 65 warning passing arg of `cblas srotg makes pointer from integer without cast sklearn utils src cholesky delete 66 error subscripted value is neither array nor pointer sklearn utils src cholesky delete 72 error subscripted value is neither array nor pointer sklearn utils src cholesky delete 73 error invalid lvalue in assignment sklearn utils src cholesky delete 76 warning passing arg of `cblas srot makes pointer from integer without cast sklearn utils src cholesky delete 76 warning passing arg of `cblas srot makes pointer from integer without cast in file included from sklearn utils arrayfuncs 241 sklearn utils src cholesky delete in function `float cholesky delete sklearn utils src cholesky delete 55 error syntax error before numeric constant sklearn utils src cholesky delete 58 warning passing arg of `cblas scopy makes pointer from integer without cast sklearn utils src cholesky delete 58 warning passing arg of `cblas scopy makes pointer from integer without cast sklearn utils src cholesky delete 59 error invalid lvalue in assignment sklearn utils src cholesky delete 62 error invalid lvalue in assignment sklearn utils src cholesky delete 65 warning passing arg of `cblas srotg makes pointer from integer without cast sklearn utils src cholesky delete 65 warning passing arg of `cblas srotg makes pointer from integer without cast sklearn utils src cholesky delete 66 error subscripted value is neither array nor pointer sklearn utils src cholesky delete 72 error subscripted value is neither array nor pointer sklearn utils src cholesky delete 73 error invalid lvalue in assignment sklearn utils src cholesky delete 76 warning passing arg of `cblas srot makes pointer from integer without cast sklearn utils src cholesky delete 76 warning passing arg of `cblas srot makes pointer from integer without cast error command gcc fno strict aliasing o2 dndebug o2 dhave ncurses fpic dno atlas info isklearn src cblas users home aagns9c3 django projects epd lib python2 site packages numpy core include users home aagns9c3 django projects epd lib python2 site packages numpy core include users home aagns9c3 django projects epd include python2 sklearn utils arrayfuncs build temp solaris 11 i86pc sklearn utils arrayfuncs failed with exit status command users home aagns9c3 django projects recco site bin python import setuptools file users home aagns9c3 django projects recco site build scikit learn setup py execfile file install single version externally managed record tmp pip ywjh4h record install record txt install headers users home aagns9c3 django projects recco site include site python2 failed with error code exception information traceback most recent call last file users home aagns9c3 django projects recco site lib python2 site packages pip py2 egg pip basecommand py line 130 in main self run options args file users home aagns9c3 django projects recco site lib python2 site packages pip py2 egg pip commands install py line 228 in run requirement set install install options global options file users home aagns9c3 django projects recco site lib python2 site packages pip py2 egg pip req py line 1043 in install requirement install install options global options file users home aagns9c3 django projects recco site lib python2 site packages pip py2 egg pip req py line 559 in install cwd self source dir filter stdout self filter install show stdout false file users home aagns9c3 django projects recco site lib python2 site packages pip py2 egg pip init py line 249 in call subprocess command desc proc returncode installationerror command users home aagns9c3 django projects recco site bin python import setuptools file users home aagns9c3 django projects recco site build scikit learn setup py execfile file install single version externally managed record tmp pip ywjh4h record install record txt install headers users home aagns9c3 django projects recco site include site python2 failed with error code >>>bug
cross validation does not work with precomputed kernel in svc hello believe cross validation cross val score does not work with clf svm svc kernel precomputed when use them get the error scores cross validation cross val score clf dists lbls cv file usr lib pymodules python2 sklearn cross validation py line 838 in cross val score for train test in cv file usr lib pymodules python2 joblib parallel py line 409 in call self dispatch function args kwargs file usr lib pymodules python2 joblib parallel py line 295 in dispatch job immediateapply func args kwargs file usr lib pymodules python2 joblib parallel py line 101 in init self results func args kwargs file usr lib pymodules python2 sklearn cross validation py line 785 in cross val score estimator fit train train file usr lib pymodules python2 sklearn svm base py line 197 in fit raise valueerror shape should be equal to shape valueerror shape should be equal to shape suspect it is due to the argument of svc which is square similarity matrix for kernel precomputed and rectangular matrix of points coordinates for other kernels sorry don have time to go much deaper hope this helps cheers>>>bug
implement ``is classifier`` using custom ducks see things you didn know about python https speakerdeck com mitsuhiko didntknow around slide 76 we can modifier ``classifiermixin`` such that we can test using ``isinstance`` even if ``gridsearchcv`` doesn inherit from ``classifiermixin`` wdyt >>>enhancement moderate
refactor clone testing in ``clone`` there is lot of testing going on but it seems to me that doesn catch all important cases also these tests are not unit tested do we really want to do these tests at runtime instead of in the unit tests and if so how can we improve them maybe we should look into the dict all parameters that are not init parameters should either be internal starting with `` `` or estimated `` `` maybe so that would be easy to check >>>enhancement
make all estimators skip tests the list of all estimators in ``sklearn utils testing`` currently searches all files we should exclude the test files as they contain lot of dummies >>>enhancement moderate
renaming for consistency the following parameters should be renamed for consistency ``learn rate`` in gradientboosting to ``learning rate`` ``n atoms`` to ``n components`` right everywhere ``max iters`` to ``max iter`` in labelpropagation ``chunk size`` to ``batch size`` renaming means add the new parameter in the same place as the old move the old parameter to the end of the parameter list set the default value of the old parameter to none check if it was set and if so raise deprecation warning find others using this gist https gist github com 3849419 >>>easy enhancement
non deterministic test error in cca my favorite kind >>>bug
find good way to run tests from last release the tests from the last release should work with the current release for backward compatibility agramfort suggested we should actually check that 10 on that if anyone has ideas how to do this easily efficiently that would be great >>>enhancement
investigate adagrad for sgd see here http www eecs berkeley edu pubs techrpts 2010 eecs 2010 24 pdf>>>new_feature
name learning rate related parameters consistently across all estimators this issue came up in 1200 parameters should be named consistently across our estimators in the in ``gradient boosting`` module ``learn rate`` refers to constant learning rate whereas in ``sgdclassifier`` ``learning rate`` refers to the learning rate schedule >>>easy enhancement
please disable embedding google analytics js in sphinx htmlhelp output thank you >>>enhancement
exception when doing from sklearn import linear model in scikit learn 12 on os 10 this problem does not happens with scikit learn 11 the problem happens when calling from cd fast import sparse std in base py which is called from from base import linearregression in linear model init py importerror dlopen opt local library frameworks python framework versions lib python2 site packages sklearn linear model cd fast so symbol not found atl daxpy referenced from opt local library frameworks python framework versions lib python2 site packages sklearn linear model cd fast so expected in flat namespace in opt local library frameworks python framework versions lib python2 site packages sklearn linear model cd fast so file users udi documents myprojects edgar xbrl2scikit py line 33 in from sklearn import linear model file opt local library frameworks python framework versions lib python2 site packages sklearn linear model init py line 12 in from base import linearregression file opt local library frameworks python framework versions lib python2 site packages sklearn linear model base py line 28 in from cd fast import sparse std>>>bug
nose tests fail on ubuntu 12 04 python import sklearn sklearn test running unit tests and doctests for sklearn usr local lib python2 dist packages nose util py 14 deprecationwarning the compiler package is deprecated and removed in python from compiler consts import co generator numpy version numpy is installed in usr lib python2 dist packages numpy python version default aug 2012 05 16 07 gcc nose version seeding rngs with 756615311 17927109077 55 4082834902 none ee ss see usr local lib python2 dist packages sklearn externals joblib test test func inspect py 122 userwarning cannot inspect object ignore list will not work nose tools assert equal filter args ff test memory setup test memory teardown test memory setup test memory teardown setup numpy pickle exception attributeerror attributeerror nonetype object has no attribute tell in ignored exception attributeerror attributeerror nonetype object has no attribute tell in ignored usr local lib python2 dist packages sklearn externals joblib test test numpy pickle py 182 warning file tmp tmpevhba9 test pkl30 appears to be zip ignoring mmap mode flag passed numpy pickle load this filename mmap mode exception attributeerror attributeerror nonetype object has no attribute tell in ignored teardown numpy pickle an unexpected error occurred while tokenizing input the following traceback may be corrupted or invalid the error message is eof in multi line statement 39 ee eee fe sss ee error doctest sklearn datasets base load sample image traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn datasets base load sample images traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn ensemble gradient boosting gradientboostingclassifier traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn ensemble gradient boosting gradientboostingregressor traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn linear model randomized l1 randomizedlasso traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn linear model randomized l1 randomizedlogisticregression traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn tree tree decisiontreeclassifier traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn tree tree decisiontreeregressor traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn tree tree export graphviz traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn utils extmath pinvh traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn nosetester test traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror error doctest sklearn test traceback most recent call last file usr local lib python2 dist packages nose plugins doctests py line 419 in teardown delattr builtin mod self result var attributeerror fail doctest sklearn utils extmath pinvh traceback most recent call last file usr lib python2 doctest py line 2201 in runtest raise self failureexception self format failure new getvalue assertionerror failed doctest test for sklearn utils extmath pinvh file usr local lib python2 dist packages sklearn utils extmath py line 302 in pinvh file usr local lib python2 dist packages sklearn utils extmath py line 336 in sklearn utils extmath pinvh failed example pinvh exception raised traceback most recent call last file usr lib python2 doctest py line 1289 in run compileflags in test globs file line in pinvh nameerror name pinvh is not defined file usr local lib python2 dist packages sklearn utils extmath py line 337 in sklearn utils extmath pinvh failed example allclose dot dot exception raised traceback most recent call last file usr lib python2 doctest py line 1289 in run compileflags in test globs file line in allclose dot dot nameerror name is not defined file usr local lib python2 dist packages sklearn utils extmath py line 339 in sklearn utils extmath pinvh failed example allclose dot dot exception raised traceback most recent call last file usr lib python2 doctest py line 1289 in run compileflags in test globs file line in allclose dot dot nameerror name is not defined ran 1255 tests in 85 175s failed skip 11 errors 12 failures >>>bug
better sample weight support in ridge currently only the `dense cholesky` solver in `ridge` supports `sample weight` to support it consistently in all solvers one can use the following trick extract from my post on the ml we want to minimize sum mu where mu is the sample weight this should be equivalent to sum sqrt mu sqrt mu so we obtain the same result by multiplying each and by sqrt mu in the dense case it is trivial to implement but in the sparse case there bit of work to do as scipy sparse matrices do not support element by element multiplication with vector here the vector size is equal to `n samples` one should add an `inplace csr row scale` utility to `sparsefuncs pyx` the test coverage of `sample weight` needs to be greatly improved too >>>enhancement moderate
add api for user defined distance function in means we had case where we wanted to use levenshtein distance instead of the usual euclidean distances we ended monkey patching the cluster module think it ll be nice to add another parameter to kmeans class which is user defined distance function if it not defined then the code will default to usual euclidean distances >>>new_feature
proposal to decouple classifier output classes from the vector with classes parameter in init from the discussion on the mailing list http sourceforge net mailarchive message php msg id 29883772 think we could have `classes none` constructor parameter in sgdclassifier an possibly many other classifiers when provided we would not use the traditional `self classes np unique idiom already implemented in some classifiers of the project but not all also for raising valueerror exception when `classes none` and if the `y` provided at fit time has some values not in `classes` however we need to check with some benchmarks that this integrity check is not too costly this constructor parameters could be overriden by `fit param` to preserve backward compat especially for classifier models with `partial fit` method the expected behavior for classifier that is passed non none `classes` constructor param would be to never predict class value in case of predict proba method the missing fit time class probabilities should be this protocol including expected exception types and error messages should be formalized as series of common tests in sklearn tests test common py and redundant book keeping code should be factorized in the sklearn base py classifiermixin class imho oliver grisel>>>enhancement
pick style and standardize it across all docs each file seems to have some quirks in its docs we could identify these quirks and fix them as we find them so that the docs are easier to use for instance in ``decisiontreeclassifier`` ``predict proba`` returns type ``p`` but in ``sgdclassfiier`` it returns type ``t`` or there no type listed in clf predict proba type instancemethod string form none min density min samples leaf min samples split random state none file usr lib python2 site packages sklearn tree tree py definition clf predict proba self docstring predict class probabilities of the input samples parameters array like of shape samples features the input samples returns array of shape samples classes or list of outputs such arrays if outputs the class probabilities of the input samples classes are ordered by arithmetical order def predict proba self probability estimates probability estimates are only supported for binary classification parameters array like sparse matrix shape samples features returns array shape samples classes returns the probability of the sample for each class in the model where classes are ordered as they are in self classes references the justification for the formula in the loss modified huber case is in the appendix in http jmlr csail mit edu papers volume2 zhang02c zhang02c pdf def predict log proba self log of probability estimates log probability estimates are only supported for binary classification parameters array like shape samples features returns array like shape samples classes returns the log probability of the sample for each class in the model where classes are ordered as they are in self classes input arrays have two styles for the shape def predict log proba self log of probability estimates log probability estimates are only supported for binary classification parameters array like shape samples features vs in 12 decisiontreeclassifier predict log proba type instancemethod string form file usr lib python2 site packages sklearn tree tree py definition decisiontreeclassifier predict log proba self docstring predict class log probabilities of the input samples parameters array like of shape samples features the input samples the first way ``array like shape`` looks like two return values especially in the case above for ``predict proba`` where there no return identifier listed perhaps we should standardize on ``x array like of shape`` there are little spacing differences here and there like strings ending with space or indenting three spaces instead of four in doc strings as in ``decision function`` and ``predict`` in ``sgdclassifier`` anyway volunteer to clean lot of this up if we figured out the right style >>>documentation
gridsearchcv allow for passing extra vectors to score loss function there are situations when having vectors pred and true is not sufficient to compute the score loss function an easy example would be mean squared absolute error weighted by pre defined column of weights in this case this column vector has to be sliced by the cross validator the same way and are sliced and the sliced vector is to be passed to the score loss function while understand that gridsearchcv can be fairly painlessly modified to account for this say an optional parameter to the score loss func was wondering if anyone else ever faced the same problem >>>enhancement
the manifold isomap docs say that it supports sparse matrices which it doesn the docs for sklearn manifold isomap http scikit learn org stable modules generated sklearn manifold isomap html sklearn manifold isomap fit say that the fit and fit transform methods can take sparse matrices but if you pass sparse matrix ve tried scipy sparse dok matrix and scipy sparse csc matrix it throws typeerror typeerror sparse matrix was passed but dense data is required use todense to convert to dense >>>bug documentation
implement parallelized sgd as in nips 2010 paper see http cs markusweimer com pub 2010 2010 nips pdf this will be trivial to implement efficiently once we have proper support for shared memory both for the coef vector and the data in joblib joblib joblib 44>>>enhancement
add intersection kernel and chi2 kernel to the metrics module one down chi2 one to go >>>moderate new_feature
add github compatible contributing howto see here https github com blog 1184 contributing guidelines should link to the docs and give very brief summary wdyt >>>documentation easy
possible bug in linear model linearregression for certain matrices seem to be getting erroneous results in trying to do least squares the answers at least don match what getting from the pseudo inverse and from numpy lstsq here is an example http nbviewer ipython org 3738197 >>>bug
consistency of cross validation parameter name the consistency brigade just noticed that the number of repetitions folds in ``cross validation`` as the following names stratifiedkfold and kfold ``k`` stratifiedshufflesplit shufflesplit ``n iterations`` bootstrap ``n bootstraps`` think ``n folds`` would be good name not sure if ``fold`` is reserved for kfold and doesn apply to ``shufflesplit`` suggestions wdyt edit we generally moved away from one letter parameters and kmeans has ``n clusters`` parameter not ``k`` >>>easy enhancement
nmf throws valueerror when sparseness parameter is passed in am running scikit from trunk and am synced the following code crasshes for me on python under ubuntu from sklearn import datasets decomposition from sklearn feature extraction import text from sklearn pipeline import pipeline pipe pipeline vect text tfidfvectorizer analyzer word ngram range max features 500 sublinear tf true norm none extract decomposition projectedgradientnmf 10 init nndsvd sparseness data train corpus datasets fetch 20newsgroups subset train train data pipe fit transform train corpus data train corpus target the error is train data pipe fit transform train corpus data train corpus target traceback most recent call last file line in file sklearn pipeline py line 137 in fit transform return self steps fit transform xt fit params file sklearn decomposition nmf py line 475 in fit transform gradw iterw self update tolw file sklearn decomposition nmf py line 398 in update np np zeros samples file usr lib pymodules python2 numpy lib index tricks py line 383 in getitem res nx concatenate tuple objs axis self axis valueerror arrays can be concatenated there is no error if the sparseness parameter to nmf is omitted>>>bug
attributeerror multinomialhmm object has no attribute symbols ve defined different hmms gmm hmm hmm gmmhmm components covariance type diag iter 20000 gaussian hmm hmm gaussianhmm components covariance type diag iter 20000 gaussian multinomial hmm multinomialhmm components but the latter does not have the symbols attribute the exact error is attributeerror traceback most recent call last in 10 for model name model in models items 11 model fit train 12 model scores np array model score train xs for in range train shape 13 library frameworks epd64 framework versions lib python2 site packages scikit learn 12 py2 macosx 10 x86 64 egg sklearn hmm pyc in fit self obs kwargs 434 self algorithm viterbi 435 436 self init obs self init params 437 438 logprob library frameworks epd64 framework versions lib python2 site packages scikit learn 12 py2 macosx 10 x86 64 egg sklearn hmm pyc in init self obs params 980 if in params 981 emissionprob normalize self random state rand self components 982 self symbols 983 self emissionprob emissionprob 984 attributeerror multinomialhmm object has no attribute symbols am running the latest version of sklearn checked out from github 12 thanks vishal>>>bug
means has no fit transform would be easy to implement and save computations >>>easy new_feature
add stemming support to countvectorizer an idea for feature enhancement currently using `sklearn feature extraction text countvectorizer` https github com scikit learn scikit learn blob master sklearn feature extraction text py l86 for one of my projects in my opinion it strongly lacks support for stemming an additional attribute such as `self stemmer` which accepts stemming function as callable would be nice together with reasonable default stemmer for english what about an additional stemmer module however there are already some quite good python stemmers available for example as part of the natural language toolkit longer time ago contributed stemmers for 12 languages which are available in `nltk stem snowball` https github com nltk nltk blob master nltk stem snowball py maybe one could support them as dependency in scikit learn the general interface however is not difficult to implement for example one could do it like this introduce an additional attribute `self stemmer` which is initialized as `none` by default write method `build stemmer` as something like this python snowball stemmers could be used as dependency from nltk stem import snowballstemmer def build stemmer self if self stemmer is not none return self stemmer one could provide an english stemmer as default english stemmer snowballstemmer english return lambda tokens english stemmer stem token for token in tokens incorporate this method call in `countvectorizer build analyzer https github com scikit learn scikit learn blob master sklearn feature extraction text py l358 as something like this python def build analyzer self elif self analyzer word stop words self get stop words add stemmer instance here stem self build stemmer tokenize self build tokenizer include stemmer in the method chain return lambda doc self word ngrams stem tokenize preprocess self decode doc stop words what do you think >>>new_feature
attributeerror in countvectorizer build analyzer in line 381 https github com scikit learn scikit learn blob master sklearn feature extraction text py l381 in `countvectorizer build analyzer you refer to an attribute named `self tokenize` which does not exist according to the if else structure assume the correct attribute here is `self analyzer` right >>>bug easy
countvectorizer should document attributes such as ``vocabulary `` etc also when introduces ``min df`` ve overlooked to rename ``max df stop words `` which now contains the words ignored via ``min df`` and ``max df`` >>>documentation easy enhancement
problem with ellipticenvelope it tells me `` valueerror singular covariance matrix please check that the covariance matrix corresponding to the dataset is full rank `` even though the smallest eigenvalue of the covariance matrix is the largest is 500 haven had time to really investigate any ideas >>>bug
precision recall curve is too slow complexity in the worst case `sklearn metrics precision recall curve` has complexity the current approach iterates over all unique values of predict proba for each of these re computes the precision and recall from scratch this evalution which should run quickly is sometimes taking longer than fitting my models and making predictions instead we can sort the values first iterate over them and keep running calculation of precision and recall along the lines of this implementation https github com rlichtenwalter lpmade blob master metrics pr ve implemented the solution and will add pull request for review in minute >>>enhancement
univariate feature selection example confusing wrong find the univariate feature selection http scikit learn org dev auto examples plot feature selection html example confusing it claims that the svm assigns small weights to the significant features but to me it looks like it assigns very large weights also the axis is not labeled and it is not immediately clear to me what the meaning is maybe because not accustomed to seeing value plots closer examination shows ``scores `` actually stores the scores not the values so the legend is wrong and the text misleading also maybe document ``scores `` and ``p values`` attributes in the univariate feature selectors >>>documentation
scikit learn logo has an the logo on the website says scikit learn think we should change that also maybe give it bit of touch up any one has the svg lying around >>>documentation easy
make sklearn utils validation tools preserve memmap when possible most validation utilities in `sklearn utils validation` will trigger expensive memory copy of data inputs that are `np memmap` because those utilities mostly use `np asarray` instead of `np asanyarray` that preserve subclasses of `np ndarray` as is the case for `np memmap` it seems to be that we used to use `np asanyarray` in the past anybody know why those functions use `asarray` instead also it would be better to have and explicit parameter `order` with values in none to respectively force contiguity fortran contiguity or accept any of those edit the above description is incorrect and the issue should be solved in the joblib pickler instead as `np asarray` does not copy the memory buffer hence is perfectly legit in the validation functions >>>bug large_scale
cannot build docs using docutils tried to build the scikit learn docs for version 12 using python and sphinx on osx 10 with the command `make html noplot` but sphinx fails with the following stacktrace python sphinx version python version docutils version release jinja2 version traceback most recent call last file library frameworks python framework versions lib python2 site packages sphinx cmdline py line 189 in main app build force all filenames file library frameworks python framework versions lib python2 site packages sphinx application py line 204 in build self builder build update file library frameworks python framework versions lib python2 site packages sphinx builders init py line 196 in build update out of date len to build file library frameworks python framework versions lib python2 site packages sphinx builders init py line 252 in build self write docnames list updated docnames method file library frameworks python framework versions lib python2 site packages sphinx builders init py line 292 in write self write doc docname doctree file library frameworks python framework versions lib python2 site packages sphinx builders html py line 419 in write doc self docwriter write doctree destination file library frameworks python framework versions lib python2 site packages docutils writers init py line 77 in write self translate file library frameworks python framework versions lib python2 site packages sphinx writers html py line 38 in translate self document walkabout visitor file library frameworks python framework versions lib python2 site packages docutils nodes py line 173 in walkabout if child walkabout visitor file library frameworks python framework versions lib python2 site packages docutils nodes py line 173 in walkabout if child walkabout visitor file library frameworks python framework versions lib python2 site packages docutils nodes py line 173 in walkabout if child walkabout visitor file library frameworks python framework versions lib python2 site packages docutils nodes py line 173 in walkabout if child walkabout visitor file library frameworks python framework versions lib python2 site packages docutils nodes py line 173 in walkabout if child walkabout visitor file library frameworks python framework versions lib python2 site packages docutils nodes py line 173 in walkabout if child walkabout visitor file library frameworks python framework versions lib python2 site packages docutils nodes py line 165 in walkabout visitor dispatch visit self file library frameworks python framework versions lib python2 site packages docutils nodes py line 1611 in dispatch visit return method node file library frameworks python framework versions lib python2 site packages sphinx writers html py line 377 in visit image basetranslator visit image self node file library frameworks python framework versions lib python2 site packages docutils writers html4css1 init py line 1026 in visit image and self settings file insertion enabled attributeerror values instance has no attribute file insertion enabled ve already posted this to the sphinx issue tracker https bitbucket org birkenfeld sphinx issue 1004 attributeerror values instance has no and also tried possible fix stated in this issue https bitbucket org birkenfeld sphinx issue 883 img scale option is broken for html output but to no avail the following is the whole console output that sphinx gives me lot of image files are not readable why is this the case sh peter make html noplot sphinx build plot gallery false html build doctrees build html making output directory running sphinx v1 loading pickled environment not yet created autosummary generating autosummary for about rst data transforms rst datasets index rst developers debugging rst developers index rst developers performance rst developers utilities rst index rst install rst model selection rst tutorial statistical inference finding help rst tutorial statistical inference index rst tutorial statistical inference model selection rst tutorial statistical inference putting together rst tutorial statistical inference settings rst tutorial statistical inference supervised learning rst tutorial statistical inference unsupervised learning rst unsupervised learning rst user guide rst whats new rst autosummary generating autosummary for users peter downloads scikit learn 12 doc modules generated sklearn cluster affinitypropagation rst users peter downloads scikit learn 12 doc modules generated sklearn cluster dbscan rst users peter downloads scikit learn 12 doc modules generated sklearn cluster kmeans rst users peter downloads scikit learn 12 doc modules generated sklearn cluster meanshift rst users peter downloads scikit learn 12 doc modules generated sklearn cluster minibatchkmeans rst users peter downloads scikit learn 12 doc modules generated sklearn cluster spectralclustering rst users peter downloads scikit learn 12 doc modules generated sklearn cluster ward rst users peter downloads scikit learn 12 doc modules generated sklearn cluster affinity propagation rst users peter downloads scikit learn 12 doc modules generated sklearn cluster estimate bandwidth rst users peter downloads scikit learn 12 doc modules generated sklearn cluster means rst users peter downloads scikit learn 12 doc modules generated sklearn svm libsvm predict rst users peter downloads scikit learn 12 doc modules generated sklearn svm libsvm predict proba rst users peter downloads scikit learn 12 doc modules generated sklearn tree decisiontreeclassifier rst users peter downloads scikit learn 12 doc modules generated sklearn tree decisiontreeregressor rst users peter downloads scikit learn 12 doc modules generated sklearn tree extratreeclassifier rst users peter downloads scikit learn 12 doc modules generated sklearn tree extratreeregressor rst users peter downloads scikit learn 12 doc modules generated sklearn tree export graphviz rst users peter downloads scikit learn 12 doc modules generated sklearn utils check random state rst users peter downloads scikit learn 12 doc modules generated sklearn utils resample rst users peter downloads scikit learn 12 doc modules generated sklearn utils shuffle rst building html targets for 53 source files that are out of date updating environment 458 added changed removed reading sources 100 whats new users peter downloads scikit learn 12 doc datasets index rst none warning image file not readable datasets auto examples cluster images plot color quantization png users peter downloads scikit learn 12 doc datasets index rst none warning image file not readable datasets auto examples datasets images plot random dataset png users peter downloads scikit learn 12 doc index rst 24 warning image file not readable auto examples svm images plot oneclass png users peter downloads scikit learn 12 doc index rst 28 warning image file not readable auto examples cluster images plot ward structured vs unstructured png users peter downloads scikit learn 12 doc index rst 32 warning image file not readable auto examples gaussian process images plot gp regression png users peter downloads scikit learn 12 doc index rst 36 warning image file not readable auto examples cluster images plot lena ward segmentation png users peter downloads scikit learn 12 doc index rst 40 warning image file not readable auto examples svm images plot svm nonlinear png users peter downloads scikit learn 12 doc index rst 44 warning image file not readable auto examples applications images plot species distribution modeling png users peter downloads scikit learn 12 doc index rst 48 warning image file not readable auto examples gaussian process images plot gp probabilistic classification after regression png users peter downloads scikit learn 12 doc index rst 52 warning image file not readable auto examples ensemble images plot forest importances faces png users peter downloads scikit learn 12 doc index rst 56 warning image file not readable auto examples svm images plot weighted samples png users peter downloads scikit learn 12 doc index rst 60 warning image file not readable auto examples linear model images plot sgd weighted samples png users peter downloads scikit learn 12 doc index rst 64 warning image file not readable auto examples cluster images plot kmeans digits png users peter downloads scikit learn 12 doc index rst 68 warning image file not readable auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc index rst 72 warning image file not readable auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc index rst 76 warning image file not readable auto examples images plot lda qda png users peter downloads scikit learn 12 doc index rst 80 warning image file not readable auto examples cluster images plot cluster comparison png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples svm images plot oneclass png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples cluster images plot ward structured vs unstructured png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples gaussian process images plot gp regression png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples cluster images plot lena ward segmentation png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples svm images plot svm nonlinear png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples applications images plot species distribution modeling png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples gaussian process images plot gp probabilistic classification after regression png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples ensemble images plot forest importances faces png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples svm images plot weighted samples png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples linear model images plot sgd weighted samples png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples cluster images plot kmeans digits png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc index rst 113 warning image file not readable auto examples images plot lda qda png users peter downloads scikit learn 12 doc modules classes rst 43 warning toctree references unknown document modules generated sklearn cluster dbscan users peter downloads scikit learn 12 doc modules classes rst 81 warning toctree references unknown document modules generated sklearn covariance oas users peter downloads scikit learn 12 doc modules classes rst 224 warning toctree references unknown document modules generated sklearn decomposition fastica users peter downloads scikit learn 12 doc modules classes rst warning literal block expected none found users peter downloads scikit learn 12 doc modules classes rst warning literal block expected none found users peter downloads scikit learn 12 doc modules classes rst warning literal block expected none found users peter downloads scikit learn 12 doc modules classes rst warning literal block expected none found users peter downloads scikit learn 12 doc modules clustering rst none warning image file not readable modules auto examples cluster images plot cluster comparison png users peter downloads scikit learn 12 doc modules clustering rst none warning image file not readable modules auto examples cluster images plot mini batch kmeans png users peter downloads scikit learn 12 doc modules clustering rst none warning image file not readable modules auto examples cluster images plot affinity propagation png users peter downloads scikit learn 12 doc modules clustering rst none warning image file not readable modules auto examples cluster images plot mean shift png users peter downloads scikit learn 12 doc modules clustering rst 244 warning image file not readable modules auto examples cluster images plot segmentation toy png users peter downloads scikit learn 12 doc modules clustering rst 248 warning image file not readable modules auto examples cluster images plot segmentation toy png users peter downloads scikit learn 12 doc modules clustering rst 253 warning image file not readable modules auto examples cluster images plot segmentation toy png users peter downloads scikit learn 12 doc modules clustering rst 253 warning image file not readable modules auto examples cluster images plot segmentation toy png users peter downloads scikit learn 12 doc modules clustering rst 330 warning image file not readable modules auto examples cluster images plot ward structured vs unstructured png users peter downloads scikit learn 12 doc modules clustering rst 334 warning image file not readable modules auto examples cluster images plot ward structured vs unstructured png users peter downloads scikit learn 12 doc modules clustering rst 340 warning image file not readable modules auto examples cluster images plot ward structured vs unstructured png users peter downloads scikit learn 12 doc modules clustering rst 340 warning image file not readable modules auto examples cluster images plot ward structured vs unstructured png users peter downloads scikit learn 12 doc modules clustering rst 384 warning image file not readable modules auto examples cluster images plot dbscan png users peter downloads scikit learn 12 doc modules clustering rst 389 warning image file not readable modules auto examples cluster images plot dbscan png users peter downloads scikit learn 12 doc modules clustering rst none warning image file not readable modules auto examples cluster images plot adjusted for chance measures png users peter downloads scikit learn 12 doc modules covariance rst none warning image file not readable modules auto examples covariance images plot covariance estimation png users peter downloads scikit learn 12 doc modules covariance rst none warning image file not readable modules auto examples covariance images plot lw vs oas png users peter downloads scikit learn 12 doc modules covariance rst none warning image file not readable modules auto examples covariance images plot sparse cov png users peter downloads scikit learn 12 doc modules covariance rst 302 warning image file not readable modules auto examples covariance images plot robust vs empirical covariance png users peter downloads scikit learn 12 doc modules covariance rst 306 warning image file not readable modules auto examples covariance images plot mahalanobis distances png users peter downloads scikit learn 12 doc modules covariance rst 320 warning image file not readable modules auto examples covariance images plot robust vs empirical covariance png users peter downloads scikit learn 12 doc modules covariance rst 321 warning image file not readable modules auto examples covariance images plot mahalanobis distances png users peter downloads scikit learn 12 doc modules decomposition rst none warning image file not readable modules auto examples decomposition images plot pca vs lda png users peter downloads scikit learn 12 doc modules decomposition rst 81 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 85 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 90 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 90 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst none warning image file not readable modules auto examples decomposition images plot kernel pca png users peter downloads scikit learn 12 doc modules decomposition rst 189 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 194 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 194 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 312 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 316 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 322 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 322 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst none warning image file not readable modules auto examples decomposition images plot image denoising png users peter downloads scikit learn 12 doc modules decomposition rst none warning image file not readable modules auto examples decomposition images plot ica blind source separation png users peter downloads scikit learn 12 doc modules decomposition rst 390 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 394 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 399 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 399 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 427 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 431 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 437 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules decomposition rst 437 warning image file not readable modules auto examples decomposition images plot faces decomposition png users peter downloads scikit learn 12 doc modules ensemble rst none warning image file not readable modules auto examples ensemble images plot forest iris png users peter downloads scikit learn 12 doc modules ensemble rst none warning image file not readable modules auto examples ensemble images plot forest importances faces png users peter downloads scikit learn 12 doc modules ensemble rst none warning image file not readable modules auto examples ensemble images plot gradient boosting regression png users peter downloads scikit learn 12 doc modules ensemble rst none warning image file not readable modules auto examples ensemble images plot gradient boosting regularization png users peter downloads scikit learn 12 doc modules feature extraction rst none warning image file not readable modules auto examples cluster images plot lena ward segmentation png users peter downloads scikit learn 12 doc modules feature selection rst none warning image file not readable modules auto examples linear model images plot sparse recovery png users peter downloads scikit learn 12 doc modules gaussian process rst none warning image file not readable modules auto examples gaussian process images plot gp regression png users peter downloads scikit learn 12 doc modules gaussian process rst none warning image file not readable modules auto examples gaussian process images plot gp regression png users peter downloads scikit learn 12 doc modules hmm rst none warning image file not readable modules auto examples images plot hmm sampling png users peter downloads scikit learn 12 doc modules kernel approximation rst none warning image file not readable modules auto examples images plot kernel approximation png users peter downloads scikit learn 12 doc modules label propagation rst none warning image file not readable modules auto examples semi supervised images plot label propagation structure png users peter downloads scikit learn 12 doc modules lda qda rst 17 warning image file not readable modules auto examples images plot lda qda png users peter downloads scikit learn 12 doc modules lda qda rst 22 warning image file not readable modules auto examples images plot lda qda png users peter downloads scikit learn 12 doc modules linear model rst none warning image file not readable modules auto examples linear model images plot ols png users peter downloads scikit learn 12 doc modules linear model rst none warning image file not readable modules auto examples linear model images plot ridge path png users peter downloads scikit learn 12 doc modules linear model rst 231 warning image file not readable modules auto examples linear model images plot lasso model selection png users peter downloads scikit learn 12 doc modules linear model rst 235 warning image file not readable modules auto examples linear model images plot lasso model selection png users peter downloads scikit learn 12 doc modules linear model rst 241 warning image file not readable modules auto examples linear model images plot lasso model selection png users peter downloads scikit learn 12 doc modules linear model rst 241 warning image file not readable modules auto examples linear model images plot lasso model selection png users peter downloads scikit learn 12 doc modules linear model rst none warning image file not readable modules auto examples linear model images plot lasso model selection png users peter downloads scikit learn 12 doc modules linear model rst none warning image file not readable modules auto examples linear model images plot lasso coordinate descent path png users peter downloads scikit learn 12 doc modules linear model rst 309 warning image file not readable modules auto examples linear model images plot multi task lasso support png users peter downloads scikit learn 12 doc modules linear model rst 313 warning image file not readable modules auto examples linear model images plot multi task lasso support png users peter downloads scikit learn 12 doc modules linear model rst 318 warning image file not readable modules auto examples linear model images plot multi task lasso support png users peter downloads scikit learn 12 doc modules linear model rst 318 warning image file not readable modules auto examples linear model images plot multi task lasso support png users peter downloads scikit learn 12 doc modules linear model rst none warning image file not readable modules auto examples linear model images plot lasso lars png users peter downloads scikit learn 12 doc modules linear model rst none warning image file not readable modules auto examples linear model images plot bayesian ridge png users peter downloads scikit learn 12 doc modules linear model rst none warning image file not readable modules auto examples linear model images plot ard png users peter downloads scikit learn 12 doc modules manifold rst none warning image file not readable modules auto examples manifold images plot compare methods png users peter downloads scikit learn 12 doc modules manifold rst 49 warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst 53 warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst 59 warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst 59 warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst 69 warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst 73 warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst 78 warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst 78 warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst none warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst none warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst none warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst none warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst none warning image file not readable modules auto examples manifold images plot lle digits png users peter downloads scikit learn 12 doc modules manifold rst none warning image file not readable modules auto examples manifold images plot lle digits 10 png users peter downloads scikit learn 12 doc modules manifold rst none warning image file not readable modules auto examples manifold images plot mds png users peter downloads scikit learn 12 doc modules mixture rst warning image file not readable modules auto examples mixture images plot gmm pdf png users peter downloads scikit learn 12 doc modules mixture rst none warning image file not readable modules auto examples mixture images plot gmm classifier png users peter downloads scikit learn 12 doc modules mixture rst none warning image file not readable modules auto examples mixture images plot gmm selection png users peter downloads scikit learn 12 doc modules mixture rst 213 warning image file not readable modules auto examples mixture images plot gmm png users peter downloads scikit learn 12 doc modules mixture rst 217 warning image file not readable modules auto examples mixture images plot gmm sin png users peter downloads scikit learn 12 doc modules mixture rst 223 warning image file not readable modules auto examples mixture images plot gmm png users peter downloads scikit learn 12 doc modules mixture rst 223 warning image file not readable modules auto examples mixture images plot gmm sin png users peter downloads scikit learn 12 doc modules multiclass rst none warning image file not readable modules auto examples images plot multilabel png users peter downloads scikit learn 12 doc modules neighbors rst 99 warning image file not readable modules auto examples neighbors images plot classification png users peter downloads scikit learn 12 doc modules neighbors rst 103 warning image file not readable modules auto examples neighbors images plot classification png users peter downloads scikit learn 12 doc modules neighbors rst 108 warning image file not readable modules auto examples neighbors images plot classification png users peter downloads scikit learn 12 doc modules neighbors rst 108 warning image file not readable modules auto examples neighbors images plot classification png users peter downloads scikit learn 12 doc modules neighbors rst none warning image file not readable modules auto examples neighbors images plot regression png users peter downloads scikit learn 12 doc modules neighbors rst 394 warning image file not readable modules auto examples neighbors images plot nearest centroid png users peter downloads scikit learn 12 doc modules neighbors rst 398 warning image file not readable modules auto examples neighbors images plot nearest centroid png users peter downloads scikit learn 12 doc modules neighbors rst 403 warning image file not readable modules auto examples neighbors images plot nearest centroid png users peter downloads scikit learn 12 doc modules neighbors rst 403 warning image file not readable modules auto examples neighbors images plot nearest centroid png users peter downloads scikit learn 12 doc modules outlier detection rst none warning image file not readable modules auto examples svm images plot oneclass png users peter downloads scikit learn 12 doc modules outlier detection rst none warning image file not readable modules auto examples covariance images plot mahalanobis distances png users peter downloads scikit learn 12 doc modules outlier detection rst 141 warning image file not readable modules auto examples covariance images plot outlier detection png users peter downloads scikit learn 12 doc modules outlier detection rst 145 warning image file not readable modules auto examples covariance images plot outlier detection png users peter downloads scikit learn 12 doc modules outlier detection rst 149 warning image file not readable modules auto examples covariance images plot outlier detection png users peter downloads scikit learn 12 doc modules outlier detection rst 164 warning image file not readable modules auto examples covariance images plot outlier detection png users peter downloads scikit learn 12 doc modules outlier detection rst 173 warning image file not readable modules auto examples covariance images plot outlier detection png users peter downloads scikit learn 12 doc modules outlier detection rst 180 warning image file not readable modules auto examples covariance images plot outlier detection png users peter downloads scikit learn 12 doc modules pls rst none warning image file not readable modules auto examples images plot pls png users peter downloads scikit learn 12 doc modules sgd rst none warning image file not readable modules auto examples linear model images plot sgd separating hyperplane png users peter downloads scikit learn 12 doc modules sgd rst none warning image file not readable modules auto examples linear model images plot sgd iris png users peter downloads scikit learn 12 doc modules sgd rst none warning image file not readable modules auto examples linear model images plot sgd ols png users peter downloads scikit learn 12 doc modules sgd rst none warning image file not readable modules auto examples linear model images plot sgd loss functions png users peter downloads scikit learn 12 doc modules sgd rst none warning image file not readable modules auto examples linear model images plot sgd penalties png users peter downloads scikit learn 12 doc modules svm rst none warning image file not readable modules auto examples svm images plot iris png users peter downloads scikit learn 12 doc modules svm rst none warning image file not readable modules auto examples svm images plot separating hyperplane unbalanced png users peter downloads scikit learn 12 doc modules svm rst none warning image file not readable modules auto examples svm images plot weighted samples png users peter downloads scikit learn 12 doc modules svm rst none warning image file not readable modules auto examples svm images plot oneclass png users peter downloads scikit learn 12 doc modules svm rst none warning image file not readable modules auto examples svm images plot separating hyperplane png users peter downloads scikit learn 12 doc modules tree rst none warning image file not readable modules auto examples tree images plot tree regression png users peter downloads scikit learn 12 doc modules tree rst none warning image file not readable modules auto examples tree images plot iris png users peter downloads scikit learn 12 doc modules tree rst none warning image file not readable modules auto examples tree images plot tree regression png users peter downloads scikit learn 12 doc modules tree rst none warning image file not readable modules auto examples tree images plot tree regression multioutput png users peter downloads scikit learn 12 doc modules tree rst none warning image file not readable modules auto examples ensemble images plot forest multioutput png users peter downloads scikit learn 12 doc tutorial basic tutorial rst none warning image file not readable tutorial basic auto examples datasets images plot digits last image png users peter downloads scikit learn 12 doc tutorial statistical inference model selection rst none warning image file not readable tutorial statistical inference auto examples exercises images plot cv digits png users peter downloads scikit learn 12 doc tutorial statistical inference putting together rst none warning image file not readable tutorial statistical inference auto examples images plot digits pipe png users peter downloads scikit learn 12 doc tutorial statistical inference settings rst none warning image file not readable tutorial statistical inference auto examples datasets images plot digits last image png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst none warning image file not readable tutorial statistical inference auto examples datasets images plot iris dataset png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst none warning image file not readable tutorial statistical inference auto examples neighbors images plot classification png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst none warning image file not readable tutorial statistical inference auto examples linear model images plot ols png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst none warning image file not readable tutorial statistical inference auto examples linear model images plot ols ridge variance png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst none warning image file not readable tutorial statistical inference auto examples linear model images plot ols ridge variance png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 276 warning image file not readable tutorial statistical inference auto examples linear model images plot ols 3d png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 280 warning image file not readable tutorial statistical inference auto examples linear model images plot ols 3d png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 284 warning image file not readable tutorial statistical inference auto examples linear model images plot ols 3d png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 296 warning image file not readable tutorial statistical inference auto examples linear model images plot ols 3d png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 296 warning image file not readable tutorial statistical inference auto examples linear model images plot ols 3d png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 296 warning image file not readable tutorial statistical inference auto examples linear model images plot ols 3d png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst none warning image file not readable tutorial statistical inference auto examples linear model images plot logistic png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst none warning image file not readable tutorial statistical inference auto examples linear model images plot iris logistic png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 426 warning image file not readable tutorial statistical inference auto examples svm images plot svm margin png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 430 warning image file not readable tutorial statistical inference auto examples svm images plot svm margin png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 439 warning image file not readable tutorial statistical inference auto examples svm images plot svm margin png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 439 warning image file not readable tutorial statistical inference auto examples svm images plot svm margin png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst none warning image file not readable tutorial statistical inference auto examples svm images plot svm iris png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 475 warning image file not readable tutorial statistical inference auto examples svm images plot svm kernels png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 479 warning image file not readable tutorial statistical inference auto examples svm images plot svm kernels png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 497 warning image file not readable tutorial statistical inference auto examples svm images plot svm kernels png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 499 warning image file not readable tutorial statistical inference auto examples svm images plot svm kernels png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 517 warning image file not readable tutorial statistical inference auto examples svm images plot svm kernels png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst 532 warning image file not readable tutorial statistical inference auto examples svm images plot svm kernels png users peter downloads scikit learn 12 doc tutorial statistical inference supervised learning rst none warning image file not readable tutorial statistical inference auto examples datasets images plot iris dataset png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst none warning image file not readable tutorial statistical inference auto examples cluster images plot cluster iris png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 48 warning image file not readable tutorial statistical inference auto examples cluster images plot cluster iris png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 52 warning image file not readable tutorial statistical inference auto examples cluster images plot cluster iris png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 56 warning image file not readable tutorial statistical inference auto examples cluster images plot cluster iris png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 73 warning image file not readable tutorial statistical inference auto examples cluster images plot cluster iris png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 75 warning image file not readable tutorial statistical inference auto examples cluster images plot cluster iris png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 77 warning image file not readable tutorial statistical inference auto examples cluster images plot cluster iris png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 89 warning image file not readable tutorial statistical inference auto examples cluster images plot lena compress png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 93 warning image file not readable tutorial statistical inference auto examples cluster images plot lena compress png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 97 warning image file not readable tutorial statistical inference auto examples cluster images plot lena compress png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 101 warning image file not readable tutorial statistical inference auto examples cluster images plot lena compress png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 132 warning image file not readable tutorial statistical inference auto examples cluster images plot lena compress png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 134 warning image file not readable tutorial statistical inference auto examples cluster images plot lena compress png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 136 warning image file not readable tutorial statistical inference auto examples cluster images plot lena compress png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 138 warning image file not readable tutorial statistical inference auto examples cluster images plot lena compress png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst none warning image file not readable tutorial statistical inference auto examples cluster images plot lena ward segmentation png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst none warning image file not readable tutorial statistical inference auto examples cluster images plot digits agglomeration png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 244 warning image file not readable tutorial statistical inference auto examples decomposition images plot pca 3d png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 248 warning image file not readable tutorial statistical inference auto examples decomposition images plot pca 3d png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 254 warning image file not readable tutorial statistical inference auto examples decomposition images plot pca 3d png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst 254 warning image file not readable tutorial statistical inference auto examples decomposition images plot pca 3d png users peter downloads scikit learn 12 doc tutorial statistical inference unsupervised learning rst none warning image file not readable tutorial statistical inference auto examples decomposition images plot ica blind source separation png looking for now outdated files none found pickling environment done checking consistency done preparing documents done writing output 31 datasets index exception occurred file library frameworks python framework versions lib python2 site packages docutils writers html4css1 init py line 1026 in visit image and self settings file insertion enabled attributeerror values instance has no attribute file insertion enabled the full traceback has been saved in var folders 60 j3g5rh0d0371gf2pvpz9kdvh0000gn sphinx err nk9vxr log if you want to report the issue to the developers please also report this if it was user error so that better error message can be provided next time either send bugs to the mailing list at or report them in the tracker at thanks make html noplot error thanks lot >>>bug
elasticnet rho in the docstring of ``elasticnet`` it seems to me the role of ``rho`` in the formular and text are inconsistent in the formular ``rho`` and ``1 rho`` should be exchanged although it is late so better double check >>>bug documentation easy
unboxing of lists of strings to numpy arrays wastes memory when doing grid search on text inputs some pipelinable scikit learn estimators such as the vectorizers accept lists of string as input when passing this kind input datastructure to the `gridsearchcv` object the strings are actually unboxed which can be very wasteful if the longest string of the collection is much larger than the median which is quite common in practice the reason is that check arrays used in gridsearchcv is using `np array list of strings without giving dtype which causes the unboxing of the strings to the maximum size of the collection from sklearn utils import check arrays from pprint import pprint 02d for in range 10 pprint 01 0202 030303 04040404 0505050505 060606060606 07070707070707 0808080808080808 090909090909090909 sum len for in 90 check arrays array 01 0202 030303 04040404 0505050505 060606060606 07070707070707 0808080808080808 090909090909090909 dtype s18 nbytes 180 to avoid this we should probably build arrays for text document of variable length with `np array list of strings dtype np object to avoid the memory wasteful string unboxing instead the `np array list of strings pattern also occurs inside the `countvectorizer` code itself for the list of terms and building the vocabulary here again passing `np array list of strings dtype np object might save memory >>>bug moderate
docstring in randomized l1 the docstring is missing some parameters like ``n resampling`` and ``selection threshold`` which seem important also from the docstring it is not clear to me what the effect of the caching is ping agramfort >>>documentation easy
remaining cleanups in rfecv after 1128 is merged the following easy issues remain in rfecv the scores are stored in dictionary where numpy vector would be more appropriate the scores actually store losses not scores in sklearn speak high scores are good for the second remaining one am not sure how to address think the best thing would be to actually use scores and store scores and add ``score func`` parameter that is an incompatible change though as we keep the same name but change the meaning >>>enhancement
can install on mac macports is version up to date sudo port install py26 scikits learn error port py26 scikits learn not found sudo port install py scikits learn computing dependencies for py scikits learn error dependency py27 scikits learn not found to report bug follow the instructions in the guide http guide macports org project tickets error processing of port py scikits learn failed sudo port install py27 scikits learn error port py27 scikits learn not found frustrating >>>bug
failure in low dimensional case for mincovdet what are the minimum number of samples n0 and features n1 required to use mincovdet to me this method should be feasible for n0 however get an exception for n0 n1 the error does not occur for or for suspect this issue has to do with an array being autocast to lower rank object import numpy as np import sklearn covariance n0 n1 np random normal size n0 n1 model sklearn covariance outlier detection mincovdet model fit yields the following error robust covariance pyc in fast mcd support fraction cov computation method random state 337 halves start np where diff np min diff valueerror zero size array to minimum reduce without identity >>>bug
document callable kernels in svc and related models it seems that arbitrary pairwise function can now be passed to `svc` to compute the kernel function between samples for instance tried in from sklearn metrics pairwise import rbf kernel in from sklearn svm import svc in svc kernel rbf kernel out svc cache size 200 class weight none coef0 degree gamma kernel probability false shrinking true tol 001 verbose false in svm svc kernel rbf kernel in from sklearn datasets import load iris in iris load iris in svm fit iris data iris target out svc cache size 200 class weight none coef0 degree gamma kernel probability false shrinking true tol 001 verbose false in svm score iris data iris target out 98666666666666669 this feature is not documented in the docstring http scikit learn org dev modules generated sklearn svm svc html actually the narrative documentation is already up to date http scikit learn org dev modules svm html using python functions as kernels>>>documentation easy
test affinities runtimeerror factor is exactly singular on older scipy 64bit as reported on the list error sklearn cluster tests test spectral test affinities traceback most recent call last file usr lib pymodules python2 nose case py line 183 in runtest self test self arg file tmp buildd scikit learn 12 debian python sklearn usr lib python2 dist packages sklearn cluster tests test spectral py line 121 in test affinities labels sp fit labels file tmp buildd scikit learn 12 debian python sklearn usr lib python2 dist packages sklearn cluster spectral py line 360 in fit random state self random state init self init file tmp buildd scikit learn 12 debian python sklearn usr lib python2 dist packages sklearn cluster spectral py line 218 in spectral clustering mode mode random state random state file tmp buildd scikit learn 12 debian python sklearn usr lib python2 dist packages sklearn cluster spectral py line 122 in spectral embedding sigma which lm file tmp buildd scikit learn 12 debian python sklearn usr lib python2 dist packages sklearn utils arpack py line 1493 in eigsh symmetric true tol tol file tmp buildd scikit learn 12 debian python sklearn usr lib python2 dist packages sklearn utils arpack py line 1031 in get opinv matvec return spluinv tocsc matvec file tmp buildd scikit learn 12 debian python sklearn usr lib python2 dist packages sklearn utils arpack py line 899 in init self lu splu file usr lib python2 dist packages scipy sparse linalg dsolve linsolve py line 129 in splu diag pivot thresh drop tol relax panel size runtimeerror factor is exactly singular on amd64 ok on 32bit debian squeeze ubuntu 10 04 and 10 10 where scipy are scikit learn 12 nd10 04 amd64 build unpacking python scipy from python scipy 2ubuntu0 amd64 deb scikit learn 12 nd10 10 amd64 build unpacking python scipy from python scipy 2ubuntu1 amd64 deb scikit learn 12 nd60 amd64 build unpacking python scipy from python scipy dfsg1 squeeze1 nd60 amd64 deb >>>bug
add test for inf input to all estimators and add test in the common tests >>>enhancement moderate
mrg sgd clone fix the sgd object initialization does not work properly with ``set params`` and thus ``clone`` this pr moves input argument parsing and creation of helper classes loss function to the ``fit`` actually ``partial fit`` methods this pr addresses 1114 the following issues need to be resolved factory for loss function objects epsilon issue see failing test should we do input argument checks in `` init `` or exclusively in ``fit`` the sgd holds some opportunities for refactoring code duplication etc >>>bug
hand waving practical documentation for lasso and elasticnet regression the current narrative documentation http scikit learn org dev modules linear model html elastic net for lasso and elasticnet regression is very mathematical and does not give practical hints on the usage of those models as remarked by this user on stackoverflow http stackoverflow com questions 12283184 how is elastic net used we should quickly explain why l1 penalty and l1 l2 penalty are interesting in practice rather than just mathematically ideally pros vs cons section comparing lasso elasticnet and reference to randomizedlasso for regression and or feature selection also add links to `sgdregressor` with matching loss and penalties for the low penalized and large `n samples` case >>>documentation easy
enh in nmf only use svd initialization components features since nmf can provide sparse solutions components features is often used the current initialization breaks in this setting think the default values should work robustly therefore the different initialization strategy in this case closes issue 584 >>>enhancement
deprecate fit params in gridsearchcv all fit parameters that are data independent are deprecated therefore there is no need for this ``gridsearch`` function any more except if someone wants to pass instance weights but that would be kinda weird and is not possible at the moment >>>enhancement
rfecv not documented first off didn find any mentioning of rfecv in the userguide update rest of this issue was fixed >>>documentation easy
gridsearchcv and cross validation not consistent when performing cross validation on classifier trained with the best parameters found by gridsearchcv the results differ despite using the same random seed folds and evaluation metric so maybe one of them is not working correctly code to reproduce this issue can be found here https gist github com 3188762 grid search best f1 score 556 best parameters set alpha 0001 loss log penalty l1 seed cross validation best f1 score 521 05 >>>bug
inability to upgrade on os 10 when try to update scikit learn on os 10 receive the following error error setup script exited with error command fno strict aliasing fno common dynamic arch i386 isysroot developer sdks macosx10 sdk dndebug o3 arch i386 isysroot developer sdks macosx10 sdk stdc format macros library frameworks python framework versions lib python2 site packages numpy core include library frameworks python framework versions include python2 private var folders g9 1dsf781n34sdxx74jffctxkc0000gn easy install uzf1b0 scikit learn 12 sklearn utils sparsetools csgraph wrap cxx build temp macosx 10 i386 private var folders g9 1dsf781n34sdxx74jffctxkc0000gn easy install uzf1b0 scikit learn 12 sklearn utils sparsetools csgraph wrap failed with exit status library frameworks python framework versions lib python2 site packages numpy distutils misc util py 252 runtimewarning parent module numpy distutils not found while handling absolute import from numpy distutils import log trying to upgrade using easy install scikit learn have the enthought python distribution installed and scikit learn 11 works fine >>>bug
random states not robust if run test with `` shuffle np arange 10 random state `` will get different result when another test was run before it is more complicated >>>bug
add minmaxscaler to preprocessing add an estimator that scales each feature into given range this is easily done by using the min and max on the training set the estimator must remember the scaling so it can be applied to the test set also rename ``scaler`` to ``unitvariancescaler`` the class ``scaler`` should be deprecated and keep for compatibility >>>easy new_feature
common tests check that random state is not altered not sure this is what we want but think it is ``fit`` should not change the ``random state`` so that fitting twice on the same data set should produce the same result there was comment by ogrisel in 455 along these lines think >>>enhancement
add predictive proba sparse support to documentation used scikit and it bothered me that in documentation wasn written that predictive probabilites are created only in boolean classification problems on some classifiers it also bothered me that it is not specified everywhere if classifier supports sparse input can add this or is someone already working on it >>>documentation
add example showing advanced tree usage visualizing leafs and tests and stuff >>>documentation easy need_contributor
mrg raise valueerror in r2 score when given only single sample closes 1054 >>>bug
fix this fixes issues 746 probabilisticpca minor things fix the issues opened here https github com scikit learn scikit learn issues 746 it uses non stanard dim attribute change every dim to features including in the doc strings the score function has an unnecessary loop use matrix multiplication to calculate the log likelihood no loop any more sign error fixed the test script test probabilistic pca also contains an error similar to this one fixed as well passed `test probabilistic pca amueller>>>enhancement
wip mixins everywhere `pls` was kind of ignored by the common tests because of this wonder whether `gmm` should have `clustermixin` there seem to be couple of random failing general tests with `randomizedlogisticregression` that shouldn have touched and with `pls` in case of bad luck numerically think but could only reproduce them with nosetests on the small file not with `make test` so don have the seeds based on initial work by amueller >>>enhancement
mrg deprecated sparse classes from the svm module refs 1093 those classes are now deprecated >>>enhancement
fix in the makefile we should delete pyc and so only from the source ode and not from everything in the root folder sometimes people put there virtualenv sandbox in there and it deletes all the so from the sandbox hence forcing the developper to reinstall numpy and scipy each time they run ``make`` >>>enhancement
random joblib failure in master in this test fail check that using pre dispatch parallel does indeed dispatch items error produced produced consumed produced produced produced produced consumed >>>bug
countvectorizer can find russian grams here is the code import nltk from sklearn feature extraction text import countvectorizer html urllib2 urlopen http habrahabr ru read data nltk clean html html data re sub data lower countvectorizer min max fit transform data keys for in zip inverse transform print keys in result get few english grams changing encoding didn help update another url you can try is http vesna yandex ru >>>bug
we need way to run examples as tests this is slightly related to 857 as part of the developer workflow we often need to run cd doc make html and scan that horrible horrible output to see if anything fails or prints nasty stuff not even redirecting `stdout` to dev null` helps too much since `stderr` is also polluted by sphinx does anybody know of precedent or if not can we hack together way to run the examples as if they were test suite so we can have an output like maybe we can do this with `nose` itself >>>enhancement
wip count vectorizer cythonized term counting just putting it into cython seems to double the speed of fit transform for countvectorizer on my box can any one confirm >>>new_feature
remove sparse keyword from baselibsvm as it is always set to ``auto`` anyway >>>enhancement moderate
implement cluster stability measure this is probably the only decent unsupervised clustering evaluation see here http arxiv org abs 1007 1075 also this one http www kyb mpg de fileadmin user upload files publications attachments benluxpal06 5b0 5d pdf>>>new_feature
overhaul clustering docs there is to much detail on the evaluation metric and to little on the clustering methods the evaluation metrics formulae and details should go on separate page at least the details also most of the examples look ugly do not appeal to my intuition of the algorithms >>>documentation easy
gbrt api consistency this is cerry pick of 1036 that addresses 1085 and some other api issues of the gbrt module summary better docstrings ``gradientboostingclassifier`` now has ``staged decision function`` ``staged predict proba`` and ``staged predict`` these methods are important for efficient model selection for gbrt models >>>enhancement
mechanism to propagate optional estimator fit arguments when using cv instead of opening feature request for this issue http stackoverflow com questions 12131472 additional fitting parameters for cross validation decided to propose possible solution in nutshell what it allows to do python import numpy as np from sklearn cross validation import cross val score from sklearn naive bayes import multinomialnb samples classes 100 np random randint 10 size samples samples np arange classes clf multinomialnb print cross val score clf cv class prior classes those two params will be sample weight 01 samples propagated to clf fit ll admit that as sklearn newbie may not be aware of all the possible effects this addition might have on other types of estimator only tested it in the context of `multinomialnb` also it quite possible that it could be generalized in better way as similar problems likely show up elsewhere in the codebase nevertheless thought it could be an easy and useful modification >>>enhancement
gradientboostingclassifier doesn work with least squares loss triggered by this so question http stackoverflow com questions 12197841 why scikit gradientboostingclassifier wont let me use least squares regression `gradientboostingclassifier` docstring states that `loss` may be ls in which case least squares regression will be performed but when you only try to do that `valueerror` is raised not sure if the code or the docs should be changed also noticed that huber and quantile loss are not advertised in the regressor docstring >>>bug
mrg sgd fix for shape samples this fixes 604 the pr also includes some cosmit in the sgd module constants input validation >>>enhancement
nearest neighbors interface was just talking to ryan from mlpack he did benchmark of some nearest neighbors implementation when he used sklearn he had hard time figuring out how to use particular method for fitting and just get the nearest neighbors for given set looked at the docs and it is not so obvious to me it seem you have to construct tree and then feed it to ``kneighbors graph`` or use ``nearestneighbors`` and then look at the internal and hence undocumented `` tree`` attribute feel that should be easier to doo >>>easy enhancement
mrg support custom kernels on sparse matrices think mentioned this on the ml we don actually need sparse kernels we just need kernels on sparse data this fixes code that previously did random memory access maybe should put guard up somewhere closes 918 >>>bug
support for sparse matrices in random feature selection ``randomizedlasso`` and ``randomizedlogisticregression`` currently don support sparse matrix input but it should be easy enough to add >>>moderate new_feature
documentation and issues in affinitypropagation there are several issues with ``affinitypropagtion`` first the easy ones ``affinity propagation`` doesn document ``convit`` and ``max iter`` don think ``convit`` does what the ``affinitypropagation`` docstring says it does setting ``max iter`` to 10 in the ``plot cluster comparison py`` example yields label of 2147483648`` for all data points the hard one it is way to slow not sure there is any good way to speed it up >>>documentation easy
vectorize or cythonize expected mutual information there are nested for loops think we should try to see if it is possible to vectorize haven had the formular before me when looked at the code and it wasn so clear maybe go through the formular again and see if vectorization is sensible otherwise we might have to resort to cython >>>easy enhancement
mrg coordinate descent dict learning code improvements contains lassolars multiple targets elasticnet and lasso multiple targets better input checks using validation py with some additions use lasso multitarget in dict learning contains commits from pr 913 that will close if vene is ok >>>enhancement
wip isotonic regression here is pr for new isotonic regression replacing the one in the manifold mds implementation it has now proper sklearn interface with fit method the isotonic regression code now implements weights and couple of extra options fabian and alex actually implemented this version of the code so it is necessarily perfect the mds code has been updated to use this new version there still the documentation to work on and small example >>>new_feature
rank normalization of features was talking about this feature with ogrisel and he asked me to place an issue for it this is technique suggested by yoshua bengio to handle features with unknown scale convert the features to rank scale so the lowest rank is and the highest rank is this is superior to transform zero mean unit variance because if you have one huge outlier feature it can mess things up but rank transform is robust you can see description here of python code to do this http stackoverflow com questions 3071415 efficient method to calculate the rank vector of list in python scipy stats rankdata does it they convert to ranks but don normalize by the number of features one thing to be careful of if you have lot of zeros and do rank transform using scipy stats rankdata and then normalize by the number of features they will end up have rank so you lose sparsity would recommend to preserve sparsity that you scale the range of the ranks to and clip any feature from the test set that exceeds the range >>>new_feature
implement roc svm linear pairwise ranking loss with sgd to address highly imbalanced data see http www eecs tufts edu dsculley papers detecting adversarial advertisements pdf >>>new_feature
bug in gmm py referencing best params before assignment dear all there appears to be bug in gmm py where under certain circumstances specifically log likelihood max log prob never true during the em iterations best params doesn get assigned but is referenced later on am using version scikit learn 11 py2 win32 egg here is an ipython session that shows what going on in im out array 16 13 11 10 12 10 10 dtype uint8 in 10 from sklearn mixture import gmm in 11 classif gmm components in 12 classif fit im reshape im size unboundlocalerror traceback most recent call last documents and settings administrator my documents dropbox readstacks python in python27 lib site packages scikit learn 11 py2 win32 egg sklearn mixture gmm pyc in fit self kwargs 519 covars self covars 520 if self iter 521 self covars best params covars 522 self means best params means 523 self weights best params weights unboundlocalerror local variable best params referenced before assignment in 13 in 14 debug python27 lib site packages scikit learn 11 py2 win32 egg sklearn mixtur gmm py 521 fit 520 if self iter 521 self covars best params covars 522 self means best params means ipdb best params nameerror name best params is not defined ipdb self iter 100 ipdb log likelihood 20135 341019560929 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan ipdb >>>bug
problems doing cross validation with svr and gridsearchcv am using sklearn 11 and trying to do gridsearch using svr range np array 11 13 15 17 gamma range np array 15 13 11 param grid gamma gamma range range clf gridsearchcv svr param grid param grid jobs cv 10 clf fit train train the code runs in less than second and outputs svr 03125 cache size 200 coef0 degree epsilon gamma 0625 kernel rbf probability false shrinking true tol 001 verbose false but those numbers are garbage and it clear that there is no cross validation being done for the sake of comparison switched to svc and also defined target variable and the code ran properly and took fair amount of time am doing something wrong or is there bug thanks vishal>>>bug easy
parallel random forest runs very slowly trying to use the extratreesregressor to perform feature selection on somewhat large dataset which has 37241 rows 9492 and columns my machine has 32 cores so trying to take advantage of that by setting jobs to be high however this seems to run very slowly and it does not utilize all of the cores although 20 python processes are created most of time are idle most of the time sometimes few are active sometimes none of them are active here how you can re create my problem download and extract that data in question here http dl dropbox com 1800572 problem data2 tar gz in python run from scipy import io from sklearn ensemble import extratreesregressor matlab dict io loadmat act1 competition training mat data matlab dict data data data toarray labels data train features data forest extratreesregressor estimators 1000 compute importances true jobs 20 forest fit train features labels can anyone else confirm the problem anyone have any possible explanations could something be blocking or could it be due to the large amount of memory taken up by the data note that my system has plenty of ram free ve tried this both with the latest dev version and with the stable 11 version >>>enhancement
positive lasso path is there reason not to add the positive option to lasso path and enet path >>>new_feature
mrg set all in consistent manner have set off to address issue 940 and to bring the discussion to line comment environment >>>enhancement
basegradientboosting should use decisiontreeregressor instead of tree ``basegradientboosting`` should use ``decisiontreeregressor`` instead of ``tree`` in order to stay consistent with other ensemble classes this will lead to some redundant input checks so before making any changes we should run some benchmarks the issue came up in 1046 >>>easy enhancement
gradient boosting feature request adding more estimators this post is to follow up discussion on the mailing list with pprett this issue is not about general monitoring api just about the ability to add trees the motivation for this feature request is monitoring see below but let avoid discussion of general monitoring api here which should be the same api as used for monitoring other estimators it might take long time for us to all agree on monitoring api but in the meantime if someone implements way to add more trees or use `warm start` option in the fit method then we ll have made some progress in the right direction motivation monitoring and early termination two of the most important parameters for the boosting estimators are learn rate and estimators in this document http cran project org web packages gbm vignettes gbm pdf greg ridgeway provides advice for settings these my rule of thumb is to set shrinkage as small as possible while still being able to fit the model in reasonable amount of time and storage usually aim for 000 to 10 000 iterations with shrinkage rates between 01 and 001 often such large number of iterations will be an overkill and this will be clear if one monitors the accuracy on the out of bag estimate in this situation which is perhaps the usual situation one should set the learning rate to be small add some number of trees check to see if the accuracy is still improving and if so keep adding trees this requires the ability to add more estimators perhaps using warm start option in the fit function or more method pprett mentioned the original pull request supported an additional parameter ``monitor`` which was called after each iteration using the current state of the model and allowed proper early stopping however we removed the parameter because we could not agree on the api >>>new_feature
wip orthogonalmatchingpursuitcv as discussed in issue 1930 todo narratives coverage >>>new_feature
lassocv docs alpha underscore the lassocv docs http scikit learn org dev modules generated sklearn linear model lassocv html sklearn linear model lassocv say that the attribute giving the best alpha has an underscore in the end ``alpha `` but it doesn maybe it should deprecate etc this is actually in the ``linearmodelcv`` class btw so guess other estimators are also affected >>>documentation easy enhancement
mrg fix percentile tiebreaking add warning fixes the remainders of issue 994 admit to being lazy and not do the masks indices refactoring >>>enhancement
adding ``classes `` to svm makes my head hurt couldn figure out to add support for arbitrary class labels to the svms and add ``classes `` attribute moving to other stuff for the moment it would be great if someone found some time for this the trouble comes with ``class weight`` and regression think it would be good to add ``labelencoder`` somewhere to take care of the encoding of the ``class weights`` but apparently the implementation also requires class weights on the python side in the regression case and the ``labelencoder`` should obviously not be used in the svr this is doable but couldn make it pretty so just left it >>>enhancement moderate
wip gbrt with built in cross validation two new classes ``gradientboostingclassifiercv`` and ``gradientboostingregressorcv`` which pick ``n estimators`` based on cross validation ``gradientboostingclassifiercv`` fits ``gradientboostingclassifier`` with ``max estimators`` for each fold it picks ``n estimators`` based on the min deviance averaged over all test sets finally it trains the model on the whole training set using the found ``n estimators`` ``gradientboostingclassifiercv`` is implemented as ``gradientboostingclassifier`` decorator it soley implements ``fit`` otherwise it delegates to ``gradientboostingclassifier`` see `` getattr `` and `` setattr `` the current implementation might pose some problems if the client uses ``isinstance`` rather than duck typing ``gradientboostingclassifiercv`` instance is not an instance of ``gradientboostingclassifier`` would really appreciate any remarks feedback to this issue tried to adhere the interface of ``ridgecv`` additionally refactored the prediction routines in order to remove code duplication ``staged predict`` and ``staged predict proba`` has been added to ``gradientboostingclassifier`` limitations it is currently hard wired to pick ``n estimtors`` based on deviance no support for custom loss function yet is this needed no joblib support yet only cross validation support should we add held out and oob estimation too >>>new_feature
wip grid search convenience class this aims at closing 1020 it introduces new class to handle the output of gridsearchcv don like complexity but haven found nice way to do this otherwise if you have less complex solutions please let me know basically this transforms the dicts that are usually in ``gridsearchcv grid scores `` remember this is in general list of dictionaries to list of parameters which is ``sorted param grid keys `` and an array where each axis corresponds to one parameter and the last corresponds to folds think this is already an improvement the reason why added the class is that also want to marginalize parameters want to look at it even if have parameters to adjust maximizing over multiple axis is ugly so wanted to class to handle this as always any comments welcome ll make an example to illustrate the usefulness now going back to wip as think this should be designed with having non grid evaluations of estimators in mind >>>new_feature
testing issue in joblib get exception attributeerror attributeerror nonetype object has no attribute tell in ignored and warning file tmp tmpxxafga test pkl934 appears to be zip ignoring mmap mode flag passed gaelvaroquaux do you know where this comes from and is it easy to fix >>>enhancement
rfe doesn clone the estimator it gets rfe gets an estimator as constructor argument it stores this estimator not clone and then fits this estimator this is not how we do this in other places right it this desired behavior feel this is weird side effect todo clone the estimator in the beginning or rfe and rfecv add test that ensures that rfe doesn modify the estimator it gets >>>easy enhancement
calling fit on decision tree can cause infinite loops clf decisiontreeclassifier min samples split 20 min samples leaf max features none shape 3220 3375 shape 3220 calling clf fit exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored exception valueerror valueerror attempting to find split with an empty sample mask in sklearn tree tree tree recursive partition ignored tested this with the current git version using cython 16 the problem goes away broken sudo make clean sudo python2 setup py install fixed sudo make clean make cython sudo python2 setup py install >>>bug
better access visualization of grid search results the ``gridsearchcv grid scores `` are stored in not very user friendly way it would be great to have nd arrays and set of labels things that should be easily possible plot in the case of parameter matshow in the case parameters look at slices and marginals mean over rest of parameters when looking at more parameters>>>new_feature
pipeline can not be used with multiclass or the other way around tldr is it good to check if classifier supports ``decision function`` using ``hasattr`` the plan use the following in the multi class to get decision function python try clf predict proba except attributeerror notimplementederror clf decision function optionally put the ``decision function`` and ``predict proba`` in place on the fly as in ``gridsearchcv`` hey everybody just noticed that pipeline can not be used with the multiclass module in some cases the multiclass module checks whether classifier has ``decision function`` and tries to use that otherwise it uses ``predict proba`` ``pipeline`` by default has the whole zoo of methods and tries to call them on the last estimator so if the last estimator has no ``decision function`` but ``predict proba`` like the trees this fails the main reason this annoys me is because wanted to use the same ``decision function`` ``predict proba`` pattern for auc cross validation see 1014 so this also fails with pipelines two ways to fix this set the methods of pipeline on the fly and only if the last estimator has them it is done this way in ``gridsearchcv`` instead of using ``hasattr clf decision function `` we could use ``try except attributeerror`` block from pretty coding standpoint prefer but the attributeerror might be caused by something else and shadow some other bug if there was an ``nodecisionfunctionerror`` go for that but we don want custom exceptions do we glad didn start counting the api annoyances that found this weekend >>>easy enhancement
stratifiedkfold input validation too restrictive stratifiedkfold input validation checks that the least populated class in has only members which is too few the minimum number of labels for any class cannot be less than is there any strong reason for this restriction expect the following case to be handled from sklearn cross validation import stratifiedkfold python for train test in stratifiedkfold print train test >>>easy enhancement
mrg speedups in covariance with this simple change get speedup on running mincovdet for 100x100 matrix have also turned the `pinv` calls to new `symmetric pinv` function based on `linalg eigh` for considerable speedup all tests pass timings for mincovdet on 100x100 symmetric euclidean distance matrix before 24s without final inversion 76s 6x faster with lapack calls 28 4x faster but alas wrong with symmetric pinv 37 3x faster with vectorized symmetric pinv 34>>>enhancement
wip auc grid search this enables grid search with auc score what do you think about doing it like this cc ogrisel>>>new_feature
spectral clustering consistently creates one sample cluster code to reproduce the issue python import numpy as np def generate blobs 3d np random seed 27 x1 np random randn 200 np array 22 x2 np random randn 100 np array x3 np random randn 400 np array 100 100 100 blobs np vstack x1 x2 x3 return blobs blobs generate blobs 3d np corrcoef blobs from sklearn import cluster algorithm cluster spectralclustering mode arpack algorithm fit pred algorithm labels astype np int the one sample cluster consistently occurs for the first sample >>>bug
mrg speed up euclidean distances with cython `euclidean distances` usually pops up near the top as cumulative time in every profiler output that uses it talking about our new toy in http jenkins scikit learn github com scikit learn speed so optimizing it sounds like good idea here is my first go new at writing cython so feedback is highly appreciated have sinking feeling that copying around memory when don want that here is hackish benchmark script https gist github com 3305769 have intentionally not included the file in this pr so the commits will be lighter until this is done todo fast csr dot product turns out almost impossible be gentle typing with broken finger >>>new_feature
program segfaults with multinomialnb and cross validation am trying to create naive bayes classifier but if cross validate with folds it segfaults have finally succeeded in creating example that also segfaults the problem is that program segfaults if change cv to in here scores cross val score classifier train train cv jobs primer py http dl dropbox com 25828692 example1 primer py all pickle http dl dropbox com 25828692 example1 all pickle pickle http dl dropbox com 25828692 example1 pickle valgrind dump 32594 warning set address range perms large range 0x18851018 0x28851038 noaccess 32594 warning set address range perms large range 0x8c4b028 0x1c3252a0 undefined 32594 warning set address range perms large range 0x1c326028 0x2fa002b1 undefined 32594 warning set address range perms large range 0x1c326018 0x2fa002c1 noaccess 32594 warning set address range perms large range 0x8c4b018 0x1c3252b0 noaccess 32594 warning set address range perms large range 0x8c4b028 0x2726235c undefined 32594 warning set address range perms large range 0x76b9f028 0x951b636d undefined 32594 warning set address range perms large range 0x76b9f018 0x951b637d noaccess 32594 warning set address range perms large range 0x8c4b018 0x2726236c noaccess 32594 warning set address range perms large range 0x38d41018 0x58d41038 noaccess loaded loaded split 32594 warning set address range perms large range 0x7389b028 0x8eed5318 undefined 32594 invalid read of size 32594 at 0x4f3960b trivial three operand loop in home mabu kaggle zascikit lib python2 site packages numpy core umath so 32594 by 0x4f4eef7 pyufunc genericfunction in home mabu kaggle zascikit lib python2 site packages numpy core umath so 32594 by 0x4f4f1ba ufunc generic call in home mabu kaggle zascikit lib python2 site packages numpy core umath so 32594 by 0x409025f pyobject call in usr lib libpython2 so 32594 by 0x4090347 call function tail in usr lib libpython2 so 32594 by 0x409045f pyobject callfunction sizet in usr lib libpython2 so 32594 by 0x4e67b80 pyarray genericbinaryfunction in home mabu kaggle zascikit lib python2 site packages numpy core multiarray so 32594 by 0x408be25 binary op1 in usr lib libpython2 so 32594 by 0x408dc35 pynumber add in usr lib libpython2 so 32594 by 0x4125781 pyeval evalframeex in usr lib libpython2 so 32594 by 0x412a03c pyeval evalcodeex in usr lib libpython2 so 32594 by 0x4128233 pyeval evalframeex in usr lib libpython2 so 32594 address 0x1c is not stack malloc or recently free 32594 32594 32594 process terminating with default action of signal 11 sigsegv 32594 access not within mapped region at address 0x1c 32594 at 0x4f3960b trivial three operand loop in home mabu kaggle zascikit lib python2 site packages numpy core umath so 32594 by 0x4f4eef7 pyufunc genericfunction in home mabu kaggle zascikit lib python2 site packages numpy core umath so 32594 by 0x4f4f1ba ufunc generic call in home mabu kaggle zascikit lib python2 site packages numpy core umath so 32594 by 0x409025f pyobject call in usr lib libpython2 so 32594 by 0x4090347 call function tail in usr lib libpython2 so 32594 by 0x409045f pyobject callfunction sizet in usr lib libpython2 so 32594 by 0x4e67b80 pyarray genericbinaryfunction in home mabu kaggle zascikit lib python2 site packages numpy core multiarray so 32594 by 0x408be25 binary op1 in usr lib libpython2 so 32594 by 0x408dc35 pynumber add in usr lib libpython2 so 32594 by 0x4125781 pyeval evalframeex in usr lib libpython2 so 32594 by 0x412a03c pyeval evalcodeex in usr lib libpython2 so 32594 by 0x4128233 pyeval evalframeex in usr lib libpython2 so this is on yesterday master scikit scipy numpy >>>bug
selectkbest selectpercentile feature selection is broken for certain inputs test case fails for ``score func classif`` as well python fixed already had an old 11 git release import numpy as np from sklearn feature selection import np array 35407973 73858161 21871862 01362241 3565459 92151461 64259241 43849487 01860028 84427892 83171833 0852727 89007728 31564981 1420426 62100712 86350539 49176233 51831504 98832398 2643767 33973403 82126126 08305002 4985046 np array 17966557 19387233 77140599 78315866 40862817 transformer selectkbest score func chi2 transformer fit transformer transform shape assert transformer transform shape python import numpy as np from sklearn feature selection import np array 35407973 73858161 21871862 01362241 3565459 92151461 64259241 43849487 01860028 84427892 83171833 0852727 89007728 31564981 1420426 62100712 86350539 49176233 51831504 98832398 2643767 33973403 82126126 08305002 4985046 np array 17966557 19387233 77140599 78315866 40862817 transformer selectpercentile score func chi2 percentile 60 transformer fit transformer transform shape assert transformer transform shape >>>bug moderate
wip enet strong rules this pr aims to extend the current ``coordinate descent enet path`` to uses an active set of features and strong rule filtering 20 prototype is available here https gist github com 3188143 suggest to integrate the prototype the following way add two options to enet coordinate descent done possibility to skip the dual gap calculation ``calc dual gap`` do the iterations only over provided subset of features ``iter set`` make these options accessible though ``enet fit`` replace the loop over the range of alphas in ``coordinate descent enet path`` line 106 122 with the loop in enet path from the gist in the loop from the gist replace the ``shrinkage `` calls by calls to ``enet fit`` tibshirani bien friedman hastie simon taylor and tibshirani strong rules for discarding predictors in lasso type problems journal of the royal statistical society series statistical methodology 2011 >>>new_feature
raise warning if only one class presented to classifier if only one class is presented to classifier in non multi label setup it should raise an error give warning this should be tested for in the common testing framework >>>enhancement moderate
mds in the example the reconstruction may sometimes be inversed compared to the real solution mds yields solution which is rotation and symmetric invariant the example code realigns the structure rotation wise but doesn check whether it is mirror version of the true positions to facilitate the visualisation of the results it should >>>documentation easy
wip added scale fiasco example while back you may remember the great `scale fiasco` of 2012 after much discussion it was decided that we drop the use of the `scale c` parameter the following example is based on the initial plots that amueller did you may recognize the plots from the mailing list discussions regarding the issue the example will hopefully serve as reference tool that can be used to explain to the next person that sends `serious bug` titled message to the mailing list how it works wouldn say the example is entirely ready for merging would really first like some feedback on it from you all regarding readability making sense getting the point across and mistakes the plots are shown below thanks in advance svc l1 case http oi45 tinypic com 2nar59h jpg svc l2 case http oi47 tinypic com mi1d29 jpg >>>new_feature
gbclassifier multinomialdeviance added logsumexp and nan to num to avoid underflows and nans following my recent 20120723 email on the mailing list here is the pr to address the issue of numerical underflows and nans when using gradientboostingclassifier and multinomialdeviance with large number of classes and large dataset the issue boils down to computing log exp array sum which generates well known underflows when the array has values of different order of magnitude the solution uses sklearn utils extmath logsumexp as suggested by gael instead of numpy logaddexp reduce divisions are protected with nan to num to avoid nans in the results at the moment there is no toy example to test this issue easily ll try to work on it help is warmly welcome anyway this changes solve the problem observed on my dataset >>>enhancement
enh use bayesian priors in nearest neighbors classifier issue 399 the nearest neighbors and radius neighbors classifiers now make explicit use of the bayesian prior probabilities of the classes `self class prior by default each of these prior probabilities for given class is set to the proportion of sample points which are in the given class but they can also be set to other values by the class user this is my first submission so be grateful for any and all advices thank you >>>new_feature
gbrt 32bit issue the ``gradient boosting`` module has stability issues on 32bit arch the source of the instability seems to lie in the fitting procedure it may even lie in `` tree pyx`` >>>bug
tree better algorithm for find split this is follow up of 946 we came to the conclusion that the algorithm behind `find split` should be redesigned in order to decrease one step further the training time in decision trees below is summary of the strategies we discussed total number of training samples number of training samples at node features let assume for now that max features building argsort is log on master at each node find split is to build fully developed tree find split has to be called times which results in cumulative complexity for find split of in total the complexity of building single tree is then log if trees are built the complexity is log since argsort is shared for all trees strategy assume that we remove sample mask and that at each node we rather reorder argsorted in divide and conquer fashion in that case at each node find split is to build fully developped tree find split has to be called times which results if we further assume that the tree is balanced in cumulative complexity for find split of log in total the complexity of building single tree is then log log if trees are built the complexity is log log but requires extra memory of jobs strategy assume that we remove argsort and sample mask and that each node we sort the node samples along the considered features in that case at each node find split is log don exactly know the cumulative complexity in that case but my intuition is that it sould be should something like log anyway far less that in total the complexity of building single tree should be around log if trees are built then complexity should be log overall think strategy is the best of all but the extra memory required is significant disadvatange regarding strategy theory says that asymptotically it is better than master even for building ensemble of trees however agree that we should account for the constant factors behind this analysis remain convinced however that we should at least try and see can work on that >>>enhancement
silhouette score returning nan hello the following code makes silhoutte score return nan that looks like bug to me if it impossible to generate score then expected silhouette score to raise meaningful exception instead of returning nan the following code prints nan python import numpy as np from sklearn import metrics from sklearn cluster import kmeans data np array dtype np float kmeans kmeans init means kmeans fit data print metrics silhouette score data kmeans labels metric euclidean the first matrix ve tried came from bigger sample of 14k items and many more features for each sample reduced the number of samples to and to so that it easier to test in the original sample silhoutte score would fail if was greater than 80 on that test it would print nan instead of nan >>>bug
exposing some internals of ridgecv would you be interested in exposing the `m` matrix https github com npinto scikit learn blob master sklearn linear model ridge py l514 for example one may like to use this matrix to get access to looe for each alpha tested what do you think >>>new_feature
plscanonical fails on boston not so familiar but thought this was regression method that could use on boston but it runs in numerical problems even if standardize ``x`` and ``y`` btw shouldn pls be in ``linear models`` >>>documentation easy enhancement
wip implementation of group lasso model hi all this is my implementation of the group lasso using block coordinate descent contrary to the lasso implementation the cython code is maintained to minimum and only the coordinate descent innermost loop is compiled code the duality gap computation is maintained outside the loop it should be reasonably fast for small group sizes for large groups some time could be won by translating into blas the innermost loop from the cython code however recent developments suggest that this innermost loop could be substituted with more efficient alternatives something am currently looking into think the code as it is here might already be useful for others feedback is welcome http www stat stanford edu nsimon sglpaper pdf todo example implement without precomputed gram >>>new_feature
adding pruning method to the tree have added pruning method to the decision trees method the idea with decision tree is to build huge one prune it via weakest link algorithm until it reaches size that is reasonable neither overfitting nor under fitting also have build helper function cv scores vs leaves that computes the cross validated scores for different sizes of the tree this can be plotted with function such as python def plot cross validated scores scores plots the cross validated scores versus the number of leaves of trees import matplotlib pyplot as plt means np array np mean for in scores stds np array np std for in scores range len scores plt plot means plt plot means stds lw plt plot means stds lw plt xlabel number of leaves plt ylabel cross validated score then we choose which size is the best for the data just couple of notes need to add some tests am not sure how to make them this also needs to be documented before doing that work would gladly have some feedback on these modifications>>>new_feature
top level modules should define all at least for the purpose of more helpful tab completion in ipython but could also be used for automatically gathering of estimators or whatever at the moment for example python in 34 naive bayes naive bayes abcmeta naive bayes gaussiannb naive bayes binarize naive bayes basediscretenb naive bayes labelbinarizer naive bayes deprecated naive bayes baseestimator naive bayes multinomialnb naive bayes issparse naive bayes basenb naive bayes abstractmethod naive bayes logsumexp naive bayes bernoullinb naive bayes array2d naive bayes np naive bayes classifiermixin naive bayes atleast2d or csr naive bayes safe sparse dot in perfect world this would be python in 34 naive bayes naive bayes gaussiannb naive bayes basediscretenb naive bayes multinomialnb naive bayes basenb naive bayes bernoullinb or something similar simple fix just wanted to see if on the same page as you on this >>>enhancement
massive memory usage by parallel randomforestclassifier think this will be hard to fix without swapping out joblib or maybe even the gil but basically the amount of memory used by randomforestclassifier is exorbitant for jobs in my case have dataset of about 1gb 300 000 samples by 415 features by 64 bit float but doing fit on randomforestclassifier having jobs 16 results in 45gb of memory being used does anyone have any ideas or is this hopeless without moving everything to >>>enhancement large_scale
mrg svmlight chunk loader hi all am working on an incremental data loader for the svmlight format that reads chunks of big file that is not expected to all fit in memory in smaller csr matrix to be dumped as set of memmapable files in folders to be later reconcatenated into single large csr memmaped matrix the goal being to be able to load big svmlight files multiple tens of gb into an efficient memmaped csr in an out of core manner possible using several workers in the first step is to augment the existing parser to be able to load chunks of svmlight using seeks to bytes offsets >>>needs_review new_feature
sgd regressor in sklearn hi all get the following error when run my regressor any help would be appreciated ve pulled the latest code and seen the other bug fix but this does not seem to fix it best silk>>>new_feature
orthogonalmatchingpursuitcv omp has parameter `n nonzero coefs` since omp isa greedy algorithm it is very natural to compute all the solutions from `n nonzero coefs 1` to ``n nonzero coefs max nonzero coefs` >>>new_feature
implement density based threshold sampling for extra trees just learned trick for feature sampling from extra trees that we might want to implement instead of sampling threshold uniformly it is often better to sample training sample and use its value as threshold this means the thresholds are sampled from the actual feature distribution and thresholds probably lie in dense regions >>>new_feature
unexpected nosetest results random things when run ``nosetests sklearn`` everything looks fine if do ``nosetests sklearn svm tests `` get an error in ``test sparse py`` but when do ``nosetests sklearn svm tests test sparse py`` get no error guess this has something to do with the shuffling of the dataset or other random things thought the way it is written the shuffling is done once and for all for all the tests so don really understand how this can happen any ideas >>>bug
sparse svm won handle callable kernel when the feature matrix `x` passed to an `svc` is sparse and the kernel is callable it never gets called instead the svm seems to just go ahead and make abysmally bad predictions without an error or warning not exactly sure how to fix this right now tired and getting bit lost in the code what would like is for `svc` to store my sparse input matrix and call my kernel function with two sparse matrices >>>bug
wip covariance updates this very much work in process for issue 910 the idea is to get first python version of the covariant updates to work and turn it then step by step into cython code reference friedman hastie and tibshirani regularization paths for generalized linear models via coordinate descent journal of statistical software 33 no 2010 >>>new_feature
wip speedup coordinate descent for lasso and enet the goal is to implement tricks and speedups mentioned in in the current implementation of the elastic net and lasso ``cd fast pyx`` main steps covariance updates 911 modifications on path wise cd active set of features friedman hastie and tibshirani regularization paths for generalized linear models via coordinate descent journal of statistical software 33 no 2010 >>>new_feature
mrg feature hashing transformer this pr implements feature hasher for large scale learning or memory restricted prediction it implements weinberger et al http alex smola org papers 2009 weinbergeretal09 pdf algorithm except that it cuts one corner instead of running two hash functions on the input it runs single one taking its lowest bit to determine the sign and the rest to determine the column index that should be ok with 32 bit hash function as `scipy sparse` matrices cannot hold more than 31 elements anyway todo support multiple hash functions in particular ogrisel implementation of murmurhash do we want to support the same style of input as `dictvectorizer` have gut feeling that that going to slow things down if we don we should explicitly document this needs optimization needs more tests more documentation needed should this thing be called `hashingvectorizer` instead that means more typing than `featurehasher` but it is vectorizer >>>new_feature
add support for multi armed bandits as advertised already on the mailing list here is contribution integrating support for multi armed bandits to sklearn basically ve set up basic api for bandits and implemented one of the simplest bandit algorithms this comes along with almost clean code no pyflakes warning few pep8 warnings only pyling 71 10 documentation see sklearn bandits context free bandits py example see examples bandits simple bandit py unit tests 90 coverage see sklearn tests test bandits py basic perf tests see sklearn tests test bandits py next steps would be after this first commit is accepted add other bandits algorithms have algos implemented but not submitted add more tests and documentation can also be reached through irc if needed see http en wikipedia org wiki multi armed bandit for an introduction>>>new_feature
add predict to randomized lasso predict is missing from the randomized lasso objects need to add `classifiermixin` and `regressor mixin` too >>>enhancement
fast nmf algorithm for dense and sparse data here an algorithm which think would be good candidate for inclusion in scikit learn http www cs utexas edu cjhsieh nmf >>>new_feature
come up with api for input validation larsmans suggested this while ago but no one has tackled it yet for example classifiers should check whether there is at least one class present see also issue 886 this is also related to issue 864 all estimator should check whether the input dimensions for ``predict`` or ``transform`` are the same as in ``fit`` also see this discussion https github com scikit learn scikit learn issues 253 issuecomment 1615044 see three possible ways to do this implement `` check input fit`` and `` check input predict`` in the ``estimatormixins`` and call them in each estimator pretty but ugly use decorators that perform the checks prettyier but uglier define the checks in the mixins inject the code for the checks using some crazy introspection would keep the estimator implementations clean the third one could be implemented for example by creating `` new `` functions in the mixins and changing the ``fit`` and ``predict`` functions of the created instance so as to do the checks not sure how much like that though >>>enhancement
numerical issues and possible bug in mutual information score there are numerical issues in computing the mutual information also the score should agree with certain form of normalized mutual information but it does not see details at 776 >>>bug moderate
wip calibration plot ve started to play with calibration plots added an example `examples plot calibration py` would like to get feedback from people who are familiar with the subject especially alextp and maybe paolo losi on small and even not so small datasets often getting empty bins meaning that some ranges of probabilities are never predicted by the classifier to get smoother plots was thinking could use polynomial regression but there risk of overfitting since the number of bins is small this is work in progress won have time to add tests and documentation anytime soon >>>new_feature
lassolars stability hi here is reduced test case where lassolars and lasso give very different output with sklearn 11 txt http pastebin com nmwc4hde shape 70 txt http pastebin com ymxdgjsg shape import numpy as np from sklearn import linear model np loadtxt txt np loadtxt txt clf1 linear model lassolars alpha 1e clf2 linear model lasso alpha 1e clf1 fit clf2 fit print clf1 coef sum clf2 coef sum on my computer osx lion 10 sklearn 11 numpy accelerate framework the output is 39586972817e 17 00001508374 but if one changes the input by small factor like 10000 then the output is 00011778066 00011508525 >>>new_feature
multinomial hmm fit errors when fitting data with the multinomial hmm first the number of symbols is undefined second it crashes when unpacking shape on the first line of the forward pass here is how to reproduce the bug import numpy from sklearn import hmm components symbols 5000 generator multinomial hidden markov model transmat numpy array 25 75 emissionprob numpy array 85 15 startprob numpy array emitter hmm multinomialhmm components startprob transmat emitter emissionprob emissionprob observations true states emitter sample learner hmm multinomialhmm components learner symbols symbols learner fit observations the second bug is enlighten by uncommenting the second last line thanks for this great library franois michel de rainville>>>bug
forward pass of hmm creates nan when transition matrix contains zeros tried to train hmm with the codebelow the call to fit threw an exception and complained that the transition probabilities probabilities didn summed to one after some debuging saw that the call to hmmc forward resulted in nans in the forward lattice which where think caused by the zeros in the initial transmat temporarily solved the problem by setting the zeros to 1e and renormalized transmat before calling fit guess check for nans would help here import numpy as np from sklearn hmm import gaussianhmm startprob np array transmat np array hmm gaussianhmm components covariance type full startprob startprob transmat transmat hmm means np zeros 10 hmm covars np tile np identity 10 obs hmm sample 10 for in range 10 hmm fit obs obs iter 100 init params st >>>bug
merge dense and sparse coordinate descent the estimators based on coordinate descent are the last ones that need to merge the dense and sparse estimators maybe nice first task for ibayer still to go linearmodelcv lasso path and enet path>>>enhancement
missing cblas dependency for utils arrayfuncs so on freebsd `pip install` installs ok but there missing runtime dependency on cblas python default may 2012 05 58 58 gcc 20070831 patched freebsd on freebsd9 type help copyright credits or license for more information from sklearn decomposition import nmf traceback most recent call last file line in file usr local lib python2 site packages sklearn decomposition init py line 10 in from sparse pca import sparsepca minibatchsparsepca file usr local lib python2 site packages sklearn decomposition sparse pca py line in from linear model import ridge regression file usr local lib python2 site packages sklearn linear model init py line 15 in from least angle import lars lassolars lars path lars lassolars file usr local lib python2 site packages sklearn linear model least angle py line 20 in from utils import array2d arrayfuncs deprecated importerror usr local lib python2 site packages sklearn utils arrayfuncs so undefined symbol cblas srotg `cblas srotg` is in root nm usr local lib libcblas so grep cblas srotg 0000000000005480 cblas srotg but `arrayfuncs so` doesn have libcblas as dependency root ldd usr local lib python2 site packages sklearn utils arrayfuncs so usr local lib python2 site packages sklearn utils arrayfuncs so liblapack so usr local lib liblapack so 0x801208000 libblas so usr local lib libblas so 0x801a0d000 libm so lib libm so 0x801c60000 libthr so lib libthr so 0x801e81000 libc so lib libc so 0x80084a000 libgfortran so usr local lib gcc46 libgfortran so 0x8020a4000 libgcc so usr local lib gcc46 libgcc so 0x8023b8000 libquadmath so usr local lib gcc46 libquadmath so 0x8025cd000 `freebsd release freebsd release tue jan 07 46 30 utc 2012 root farrell cse buffalo edu usr obj usr src sys generic amd64` >>>bug
reduce example plot time building the docs including figures takes for ever >>>easy enhancement
non numerical labels with labelbinarizer `labelbinarizer` may support non numerical labels just like the recently added `labelencoder` but this is currently not tested things to test binary case multi class case multi label case array like input>>>enhancement
feature request probabilistic matrix factorization don believe there are implementations for many algorithms behind recommendation engines would like to start with probabilistic matrix factorization http www cs utoronto ca amnih papers pmf pdf thoughts >>>new_feature
wip multinomial logistic regression via sgd this is an early pr for multinomial logistic regression via stochastic gradient descent ``sgdclassifier`` now has new parameter ``multi class`` similar to ``linearsvc`` if ``loss log `` and ``multi class multinomial `` sgdclassifier trains multinomial lr model instead ``n classes`` binary lr models refactorings sgd fast pyx lossfunctions now have new method ``weight update`` see multinomiallogloss for the new weight update ve also added multi class perceptron new learning rate schedule exponential decay according to lingpipe bob carpenter this works fine for multinomial lr buttou style learning rate calibration is bit tricky and ve had mixed results in the past comments remarks much appreciated >>>new_feature
add kmeans parameter for pruning small clusters in kmeans often some clusters have only very little data this might happen for all random initializations for this case would like to have an option to set minimum cluster size after which cluster is dropped and new one is created >>>moderate new_feature
feature request implement mars because why not also according to elements of statistical learning it seems to perform quite well also see http www salford systems com doc mars pdf from http news ycombinator com item id 3947653>>>new_feature
test setup py does not actually prevent multiprocessing ok so thought had fixed this but had not https github com scikit learn scikit learn commit 2b287c3bce451133ea477d28403eeeb2c01af7b7 this has no effect got fooled by having manually set the environment variable as well since this is windows only hack would be to do something like system set var name instead and see if it works >>>bug
import all useful assertions in sklearn utils testing when writing tests am bit tired of always having to figure out where the assertions need are some are in numpy others are in nose so would like to import all useful assertions that we commonly use in `sklearn utils testing` this way we should be able to do `from sklearn utils testing import in consistent fashion also would like to move `fake mldata` and `mock urllib2` in another module any opinion >>>enhancement
hmm objects do not follow the scikit learn estimator api amongst other things they have logic in their init jaquesgrobler do you think that you can put this on your todo list >>>enhancement
graph laplacian difference trying to refactor similarity matrices and graph and related manifold learning components and noticed that what scikits currently calls normed graph laplacian assuming normed means normalized is very different in output from the equations from von luxburg http www kyb mpg de fileadmin user upload files publications attachments luxburg07 tutorial 4488 5b0 5d pdf any thoughts on what normed means in this context the reason this is important is because the normed version is used in spectral clustering and that different from any of the approaches in the paper current output proposed changes based on von luxburg see commit in satra scikit learn 2d289ec >>>enhancement
wip estimator summary here pull request to add summary of the estimator capabilities to the doc this is work in progress and need your help to do add more columns time complexity space complexity add more estimators>>>new_feature
association rule learning feature request hi association rule learning would be useful feature http en wikipedia org wiki apriori algorithm http en wikipedia org wiki association rule learning in particular the apriori algorithm as in the package arules http cran project org web packages arules vignettes arules pdf>>>new_feature
segfault in minibatchkmeans with large dataset have problem with segfault in minibatchkmeans have ``k 5000 shape 1000000 128 `` if make any of the two much smaller the problem disappears interestingly the segfault is after convergence in the final call to `` labels inertia`` inside the distance computation if ``tracer`` doesn lie to me it inside ``np dot`` this seems bit weird guess it has something to do with the dataset being that big before the function was always just called for batch can avoid the problem by using ``compute labels false`` still somewhat unsatisfactory >>>bug
token pattern in countvectorizer etc hey guess this just may be problem with the documentation on the website class sklearn feature extraction text countvectorizer input content charset utf charset error strict strip accents none lowercase true preprocessor none tokenizer none stop words none token pattern min max analyzer word max df max features none vocabulary none binary false dtype my intuition is that need to write token pattern guess the intern implementation is correct but when try to pass the standard token pattern as written in the documentation get an error the same for the other text feature extraction methods regards philipp>>>documentation
factor laplacian eigenmaps out of spectral clustering laplacian eigenmaps is one of the few standard manifold embedding methods that is still missing from sklearn it should be pretty easy to implement as it is quite similar to the spectral clustering algorithm if understand it correctly todo move the ``spectra embedding`` into the ``decomposition`` module create an estimator object around it write documentation add to the references>>>easy new_feature
fetch data py fails erg ommegang scikit learn tutorial data languages master python2 fetch data py traceback most recent call last file fetch data py line 59 in html content open html filename read decode utf file usr lib python2 encodings utf py line 16 in decode return codecs utf decode input errors true unicodedecodeerror utf8 codec can decode byte 0x8b in position invalid start byte erg ommegang scikit learn tutorial data languages master uname linux ommegang arch smp preempt sat apr 14 09 48 37 cest 2012 x86 64 intel core tm i7 3960x cpu 30ghz genuineintel gnu linux python2 version python 3>>>bug
randomized lasso causes error with run on data with very few examples in test run of classification system ve set up run the whole thing through on test dataset that has only 20 examples when do feature selection using the randomized lasso get an error the traceback is here http pastebin com hygbysdx any ideas what might be causing this problem it doesn seem to occur if run the randomized lasso with more data >>>bug
scale params for linear models as discussed on the mailing list the way the regularization parameter is scaled in linear models can be fragile to some simple variations of the data such as when the number of training samples vary this is the case of libsvm for which we tried to come up with rescaling of the parameter that ends up being burden as the resulting api no longer matches closely the libsvm api the problem is more general than libsvm and propose that an optional scale params parameter be added to some linear models to put the regularization parameter in more adimensional form in the future it can be added to other estimators for l1 penalized models the way should be scaled is fairly natural and given by the kkt conditions as implemented in svm l1 min note that to convert the parameter of svms logreg to alpha in lasso and enet you have to take something like alpha samples for l2 penalized model there is no such abrupt change and suggest to investigate using the l2 norm of xy instead of the inf max in svm l1 min here is the battle plan transform amueller gist into scikit learn example https gist github com 2354823 implement scale params for l1 models logistic regression and lasso add these models to the example check that scale params works factor out the logic of l1 min into penalty min heuristic function that works for l1 and l2 and use it to implement l1 minc and l2 min implement scale params for l2 models svm ridge add these models to the example check that the scaling does work add warning in gridsearchcv that check if an estimator has scale params attribute and that raises warning if it is set to false remove the scale parameter from svms this should be it and heard that jaquesgrobler was volunteered to do this >>>enhancement
add non negative garotte module to sklearn still working on this and there lot to still do but thought leave it open to reviewing so long seeing as still finding my feet with lot of this stuff the code still has lots of comments that will removed later and cleaned up the `` main `` function currently houses little script that ll turn into an example later all the documentation still needs to be done appreciate any inputs and suggestions with this here some exerts from the discussion which lead to this from the scikit learn mailing list from alexandre gramfort hi as soon as we have immanuel branch with positive lasso merged we could have non negative garotte in the scikit quick gist hopefully not too buggy https gist github com 2351057 feed back welcome and if someone is willing to cleanly merge this alex from jaques grobler here wee summary on the non negative garrote ng pieced together the original non negative garrote from breiman 1995 is basically scaled version of the least square estimate basically take ols estimator and then shrink that estimator to obtain more sparse representation the shrinkage is done by multiplying the ols estimator by some shrinkage factor say `d` which is found by minimising the sum of square residuals under the restriction that the `d` are positive and that some are bound by certain shrinkage parameter the algorithm proposed in this paper is rather similar to that of the lars lasso but with complicating factor being non negative constraint on the shrinkage factor see eq in this paper once you ve computed your shrinkage factor you basically have your regression coefficients seeing as your `ng coefficient` `shrinkage factor` `regression coefficient` he showed it to be stable selection method and often outperforms it competitors like subset regression and ridge regression the solution path of the ng is piece wise linear and it whole path can be computed quickly it is also path consistent solution that contains at least one desirable estimate given an appropriate initial estimate the path consistency of the ng is highlighted to be in contrast to the fact that the `lasso` is not always path consistent peng zhao hui zou personal communication it is argued that the ng has the ability to turn consistent estimate into an estimate that is both consistent in terms of estimation and in terms of variable selection drawback is the ng explicit reliance on the full least square estimate as small sample size may cause it to perform poorly however ridge regression is suggested as an initial estimate for defining the ng estimate instead of the least square estimate from jaques grobler appart from trying it ourselves to see how it fares here re some findings the simulations that are done in the last mentioned paper by ming yuan and yi lin http www2 isye gatech edu statistics papers 05 25 pdf they find that the ng seems to do generally better than the lasso figure their second simulations they consider the different models used in the original lasso paper tibshirani 1996 which they use to compare the ng with several other popular methods inluding the lasso the results are shown in table of the above mentioned paper from which the ng does very well often outperforming the other models and being the most successful in variable selection they also include one real example using the prostate cancer dataset from stamey 1989 the results of which they use to confirm the theory that the path consistency of lasso depends on the correlationo of the design matrix whilst that of the ng is always path consistent thought it may be of interest from alexandre gramfort if you can reproduce this figure using my gist it would be sufficient argument for adding this estimator to the scikit >>>new_feature
rfe py added proper support of warm start to rfe as discussed on the mailing list and as listed on issue 769 >>>enhancement
use warm start where possible in recursive feature elimination recursive feature elimination rfe fits an estimator removes the least important features and then re fits the estimator on the remaining features this process could be sped up if information from the first fit could be used in the re fit some estimators supported by rfe have `warm start` option in their constructors this allows information from previous runs to be used in the current fit currently rfe does not perform the refitting of models in such way that the `warm start` option can be exploited this ticket based on discussion in the mailing list proposes change to rfe so that it exploits the `warm start` option where possible to speed up the iterative model fitting at the heart of rfe >>>enhancement
iterative solvers for ridge and warm start iterative solvers for `ridge` would allow to support the `warm start` constructor option relevant links http docs scipy org doc scipy reference generated scipy sparse linalg cg html scipy sparse linalg cg http docs scipy org doc scipy reference generated scipy optimize fmin cg html scipy optimize fmin cg>>>enhancement
probabilisticpca minor things just noticed some things in probabilisticpca it uses non stanard dim attribute the score function has an unnecessary loop think there is sign error and or factor error in the score function >>>easy enhancement
refactor class weight logic it duplicated in svm and sgd code and somewhat in the other linear models >>>enhancement moderate
average utility in pairwise module we should add an `average` utility function which would work as below `average metric euclidean return mean` `average metric mahattan return median` this will be useful in nearest centroid or in means as the averaging operator used in these algorithms depends on the metric used means with manhattan distance is called medians >>>new_feature
more agglomerative divisive clustering at the moment ward is the only criterion for agglomerative clustering think it should be fairly straight forward to add other criteria >>>new_feature
fixup naive bayes the ``naive bayes`` needs some love the current implementation of ``basediscretenb`` requires that the inputs are positive because otherwise the log computation in line 275 will fail if ``basediscretenb`` is only applicable to non negative inputs we should enforce that ``gaussiannb`` what if the variance of feature is zero did quick fix and add small constant epsilon 1e ``gaussiannb`` and ``basediscretenb`` should provide similar functionality ``gaussiannb`` lacks fit parameter ``class prior`` and ``class weight`` ``gaussiannb`` has performance regression on ``bench covtype`` error rate used to be 23 now 46 this needs to be investigated ``gaussiannb`` has poor test time performance should be similar to ``sgdclassifier`` use fortran style for model parameters >>>enhancement
wip diffusion map embedding this is very early pr for diffusion map embedding into scikits learn started incorporating the basic matrix functions would really like some advice as to where this should go it seems it could go with affinity propagation as pure matrix based method or it could go with the manifold learning which is where it is now >>>new_feature
cosine distance for sparse matrices the `metrics pairwise` module has euclidean distance that works with sparse matrices we should have version of cosine distance that does as well >>>new_feature
speed up means step todays topic why is kmeans in sklearn to slow answer fancy indexing in `` centers`` according to my new friend runsnakerun http www vrplumber com programming runsnakerun and my old friend kernprof http packages python org line profiler about 60 of the time of kmeans is spent doing fancy indexing to find out which data point belongs to which cluster while the 60 is derived just from mnist and `digits` with 10 clusters and probably doesn hold in general think there should be quite some speedup that can be achieved here >>>enhancement moderate
irrational huge pickle file with sparse linearsvc found that the pickle file of sparse linearsvc became irrational larger after shifting the index of features had trained series of models using window of tokens in natural language processing the pickle files are less than 10m with 20 000 50 000 dense features in order to create flexible approach shifted the index of features to left by bits and all the new pickle files have the same size 582m it seems that all the void feature weights were saved can we just save the useful data >>>bug
wip factor analysis implements factor analysis following bishops book todo less naive optimization better stopping criterion narrative doc example tests>>>new_feature
clean up sparse linear model examples the linear model examples all generate their own datasets this should be simplified by using the dataset generators in ``sklearn datasets`` >>>easy enhancement
dontknow rename chunk size to batch size in sparse pca and dictionary learning see discussion at 2c496e7765f44547738f034cd458562ea68bb407>>>enhancement
document classification example is broken python examples document classification 20newsgroups py loading 20 newsgroups dataset for categories alt atheism talk religion misc comp graphics sci space data loaded 2034 documents training set 1353 documents testing set categories extracting features from the training dataset using sparse vectorizer traceback most recent call last file examples document classification 20newsgroups py line 110 in train vectorizer fit transform data train data file home mathieu desktop projects scikit learn sklearn feature extraction text py line 637 in fit transform self tc fit transform raw documents file home mathieu desktop projects scikit learn sklearn feature extraction text py line 401 in fit transform term count current counter self analyzer analyze doc file home mathieu desktop projects scikit learn sklearn feature extraction text py line 191 in analyze self charset error file usr lib python2 encodings utf py line 16 in decode return codecs utf decode input errors true unicodedecodeerror utf8 codec can decode byte 0xda in position 537 invalid continuation byte >>>documentation
the ensembles like random forest classifier need to support sparse matrix currently rfc only support array like input thus it can not apply to huge dataset if the sparse matrix could be supported in the near future would be greatly appreciated >>>new_feature
old version warning on docs the old docs need to be rebuild with the old version warning that jake made also the docs seem to be unavailable atm >>>documentation
intercept sign in svm needs love made an ugly hack in 634 to fix regression introduced earlier would prefer prettier solution >>>enhancement
parallel means hangs on mac os lion first noticed this when running make test hanged tried with stable and bleeding edge scipy initially thought it was something arpack related the test `sklearn cluster tests test means test means plus plus init jobs` hangs the process running in ipython something like `kmeans init means jobs fit np random randn 100 100 hangs as well thought maybe there was something wrong with my setup but `cross val score` works ok with `n jobs 2` >>>bug
what would be the best way to add precomputed kernel support in ridgecv like to be able to use precomputed kernels with ridgecv would you be interested in this if so like to hear your thoughts on how to do this well so that can contribute pr related question when `n samples features` there is more efficient way to get ridgecv looe for free with an svd of `x` again would you be interested in this how should factor the code to contribute and thanks again for such great package n>>>new_feature
linear model sgdregressor buffer has wrong number of dimensions expected got hello using sgdregressor to fit data set of 74k entries and 11 features when call the fit method get the error from below ve tried to understand the problem but cannot say what shall do differently the entries from are equal with the entries in the error traceback most recent call last file work python heritageprize heritageprize program py line 45 in error sgd train file work python heritageprize heritageprize mypredictors py line 103 in train self predictor fit data traindata data traintarget file python27 lib site packages sklearn linear model base py line 506 in fit self fit regressor file python27 lib site packages sklearn linear model stochastic gradient py line 330 in fit regressor self eta0 self power file sgd fast pyx line 214 in sklearn linear model sgd fast plain sgd sklearn linear model sgd fast 4954 valueerror buffer has wrong number of dimensions expected got >>>bug
ardregression array is too big error hello when run the ardregression algorithm get the array is too big error the data is indeed large about 113k records or 11 integer columns is there work around for this issue are there methods for the learner to load the data progressively if divide the data into chunks and train the algorithm sequentially what is the effect know this sounds really stupid but how can divide the work in smaller pieces traceback most recent call last file program py line 58 in clf fit input target file python27 lib site packages sklearn linear model bayes py line 401 in fit sigma linalg pinv np eye samples alpha file python27 lib site packages numpy lib twodim base py line 210 in eye zeros dtype dtype valueerror array is too big >>>bug
fibonacci heaps for ball tree the ball tree neighbor search could potentially be sped up greatly especially for large `n neighbors` and `n features` by using fibonacci heaps instead of the binary heap priority queue structures used currently there is fast cython fibonacci heap in `sklearn utils graph nearest neighbor pyx` this should be factored out so that it can also be used in the ball tree >>>new_feature
nmf inititialization does not work for samples components it raises an index error nmf works with random init if there is an easy fix for still using svd that would be best if not we could check if samples components and then use random init >>>bug
ridge path this would be nice addition to the ridge module http fseoane net blog 2011 ridge regression path >>>new_feature
implement factor analysis or maybe get it from mdp they have it but haven looked at their code this should really be included in sklearn >>>new_feature
move benchmarks into ml benchmarks repository some are already there and can just be removed in the scikit learn repo other have to be ported and made consistent with the ml benchmarks interface >>>enhancement
evaluation metrics for multi label classifiers as far as can tell these are completely missing feel this makes the multi label classifiers much less useful am not sure what common measure there are but two that seem natural to me would be hamming loss how many classes per example were correct and loss for how many examples were all classes correct at least these are two losses that are commonly used in structured prediction afaik >>>new_feature
accept arbitrary object as class labels update think most people agree now the estimators should call ``unique`` from the utilities which is backport of ``numpy unique`` and save the results in ``classes `` attribute you can look at qda and lda for the pattern to find classes that not yet support this use the ``test common py`` just comment out this line https github com scikit learn scikit learn blob master sklearn tests test common py l385 in ``test classifiers classes`` once that works we can use the text of the classes as labels and see where it breaks next if anyone decides to work on this have look at my branch here https github com amueller scikit learn tree arbitrary labels where started work >>>easy enhancement
implement adaptive lasso reweighted l1 here is proof of concept implementation by agramfort https gist github com 1610922 implementing this in the scikit would require conversion to the scikit learn api naming conventions example comparing with classic lasso narrative doc what motivated agramfort gist was http books nips cc papers files nips24 nips2011 1135 pdf see references therein for the original contributions >>>new_feature
categories in vectorized 20newsgroup loader it not possible yet to specify categories in the 20newsgroup loader once this is done we can migrate examples to this loader except for the one that illustrates feature extraction note that due to joblib memoization the categories must be filtered after the entire dataset have been loaded >>>new_feature
implement average sgd average sgd is an old computational trick namely polyak rupert averaging applied to sgd that was recently rediscovered and theoretically studied by wei xu arxiv link http arxiv org abs 1107 2490 and francis bach eric moulines hal link http hal archives ouvertes fr hal 00608041 en and further empirically validated in the public implementation of sgd by leon bottou sgd project page http leon bottou org projects sgd this trick makes the sgd algorithm converge much faster with very small modification of the original sgd code it would be great to have it implemented in the scikit along with some examples that reproduce leon bottou experiments on the rcv1 and alpha datasets that would require new dataset loaders npinto also has pure numpy implementation https github com npinto asgd that could also serve as reference for additional comparison benchmark pprett the original author of the scikit learn sgd module does not plan to work on this in the short term so anyone motivated enough please feel free to embark just send an email on the mailing to avoid implementation efforts edit see also this thread http thread gmane org gmane comp python scikit learn 327 on the mailing list >>>new_feature
mrg adaboost for regression and multi class classification this pr adds new ensemble weight boosting module with adaboostregressor using adaboost r2 and adaboostclassifier using the multi class samme algorithm new gaussian quantiles dataset in datasets samples generator as used in examples are provided hastie https cloud github com assets 202816 74736 07057cd0 60a3 11e2 87e3 dd8572078d11 png twoclass https cloud github com assets 202816 121925 d7a0c70c 6e11 11e2 8927 e0471292262f png multiclass https cloud github com assets 202816 121927 dceefd78 6e11 11e2 8959 60c051ef6118 png regression https cloud github com assets 202816 121928 e1155136 6e11 11e2 9cf2 1d51cae3969a png http citeseerx ist psu edu viewdoc summary doi 10 31 314 http www stanford edu hastie papers samme pdf>>>new_feature
shape problems building pipeline containing patchextractor and minibatchdictionarylearning as part of learning project was trying to adapt the image denoising example http scikit learn org stable auto examples decomposition plot image denoising html example decomposition plot image denoising py to use pipeline containing `patchextractor` instead of manipulating the image data using `extract patches 2d` the attempt can be found here https gist github com 1525765 for either value of `reshape` the code throws `valueerror` expected result no exceptions thrown perhaps with the introduction of `reshape` preprocessor or `flatten` or `shape` parameter to `patchextractor` as far as can tell the issue is due to shape incompatibilities between `patchextractor` and `minibatchdictionarylearning` `patchextractor` expects and yields 3d tensor of images images image height image width however `minibatchdictionarylearning` wants the `image height` and `image width` flattened images image height image width the original example code explicitly reshapes the output of `extract patches 2d` that not currently easily available in the middle of pipeline >>>enhancement
sparse sparse and sparse dense dot product with dense output `safe sparse dot` has an option `dense output` which allows to specify that the dot product between two sparse matrices or between sparse matrix and numpy array should be output to numpy array however scipy currently always return sparse matrix therefore `safe sparse dot` converts it afterwards with `toarray it would be better if we had cython utilities that can directly output to numpy array thus avoiding needless memory allocation and copying those utilities are fairly low level and should probably be contributed to scipy too but feel we should have them in scikit learn until the version of scipy that implements them becomes mainstream used in euclidean distances linear kernel ridge regression features samples case nmf necessary functions for sparse dense dot csr out dot csr fortran out necessary functions for sparse sparse dot csr csc out other situations can be handled by using dot dot t>>>new_feature
wip approximate nearest neighbor search in kmeans this is an early pr for adding random projection based nearest neighbor search in kmeans the for loop in labels inertia random projection` cannot be done efficiently in pure python as far as see it >>>new_feature
precision issue in least angle py on line 192 198 of least angle py there is this code least squares solution least squares info potrs active active sign active active lower true is this really needed aa np sqrt np sum least squares sign active active least squares aa when there are correlated predictors instability in the least squares solution can cause the sum np sum least squares sign active active to be negative causing bunch of nans to hit the rest of the code ultimately causing the function to raise the following exception calculator fit independentvalues dependentvalues file swcontrol sfw python lib python2 site packages scikit learn py2 solaris 10 i86pc egg sklearn linear model least angle py line 427 in fit max iter max iter eps self eps file swcontrol sfw python lib python2 site packages scikit learn py2 solaris 10 i86pc egg sklearn linear model least angle py line 158 in lars path sign active active np sign valueerror cannot convert float nan to integer it looks like can get around my particular issue by increasing the eps parameter passed to the constructor but thought this was worth bringing up >>>enhancement
implement gaussian process based hyper parameter optimizer following bergstra nips 2011 jaberg for the intimates it would be great to have gridsearch like object implementing gaussian process based hyper parameter optimization to keep things simple we would optimize only on continuous parameter in hyper cube the api would specify an initial bounding box and also whether each parameter should be varied in the log domain or in the linear domain some notes from discussion with james bergstra the algorithm goes mostly as compute the score on set of random points in the specified hyper cube for in budget fit gaussian process to the pairs parameters scores find the parameters that optimizes the expectation of getting lower score then the best currently available for this optimize it using black box scipy optimizer such as the simulated annealing lot of the gain comes from sequentially choosing the points so as we don have queue mechanism we should do this sequentially for now parallel can be done in internal cross validations or to compute initial points remark to computing the expectancy of with gaussian process we should overide score to use something more clever than the standard linearregression score >>>new_feature
logisticregression and linearsvc should have read write coef and intercept attributes as reported on this stackoverflow question http stackoverflow com questions 8539141 sklearn scikit learn logistic regression package set trained coefficients 8551193 8551193 the current implementation of liblinear models is using special memory layout for the coefficient currently stored in the `raw coef array those coefficients are made read only accessible to the user by means of the python properties `coef and `intercept however this solution prevents the user to change some of the coefficient values or to reassign complete `coef array on the fitted estimator it would be much nicer to have `coef `intercept as traditional array attributes instead options store parameters fitted by liblinear using the traditional `coef `intercept layout and copy those parameters at prediction time to temporary array suitable for prediction using liblinear implement `predict` and `predict proba` in numpy instead of using `liblinear` at prediction time hence we could use standard numpy arrays with the usual layout for `coef and `intercept >>>enhancement
wip first draft of random search in gridsearchcv hi so far no tests so this is just to get feedback on the api and goals of an extension to sklearn gridsearchcv that does random search when given budget >>>new_feature
mclust for gmm mclust http www stat washington edu mclust is the standard package for mixture modeling in the stats world essentially it is doing model based clustering as described in fraley and raftery 2002 www stat washington edu raftery research pdf fraley2002 pdf this means gaussian mixture modeling essentially it has number of choices for regularizing the covariance matrix it then uses bic to choose the current implementation of gmm in sklearn has several of these options full diag tied spherical but that is only about half the options in mclust and then while see bic is implemented for lassolars it seems to be tied to that so wonder whether there are plans to update gmm py to include other versions of covariance regularization update model selection to include bic generally couldn find the src for the bic implementation so can tell how bic is implemented now if no plans exist might fork pymix has some model selection using bic http pymix org docu mixture pysrc html modelselection so some of that code could be borrowed thanks all for building such useful stuff >>>enhancement
enabling grid search using auc grid search is currently not possible with auc score since fit grid point calls predict on the classifier >>>new_feature
add gaussian kernel to mean shift clustering motivation currently the mean shift clustering uses flat kernel while this is quick and simple there are some disadvantages there is no guarantee that the center will be the densest part flat kernel it might be that the center is sparse and that single kernel covers the centers of two or more clusters at its periphery if you mess around bit with the test case by changing the bandwidth or seeding method this disturbing behavior comes out the center of the found clusters are in fact between the true cluster centers propose that we should also implement gaussian kernel because such kernel would prefer to have dense regions near the center and this is common kernel in the literature the bandwidth parameter would act as the standard deviation for the gaussian kernel propose that we use the same standard deviation in all dimensions just as we used the same radius in all dimensions for the flat kernel efficiency considerations the flat kernel is efficient because only points with certain radius specified by the bandwidth parameter are relevant for the mean shift calculation these points can be efficiently looked up from the larger dataset using the balltree in theory each time we update gaussian kernel we should also consider all points in the dataset but in practice the method may work well if we ignore all points beyond some distance let call this the cutoff distance given that we expect over 99 of points to fall within three standard deviations of the center of gaussian distribution perhaps we could set this cutoff to 3x the bandwidth >>>new_feature
wip semisupervised naive bayes using expectation maximization here the em algorithm for semisupervised naive bayes the implementation checks for convergence based on the coefficients following the advice of bishop 2006 so it could be used more generally for linear classifier self training but only implemented the necessary machinery fitting on of vector on the discrete nb estimators and we might want to switch to log likelihood based convergence checking later narrative documentation follows if there interest in this pull request ve adapted the document classification example script into new semisupervised example we might also merge these scripts >>>new_feature
reorthogonalize we were discussing reorthogonalization on the mailing list since tried it out here trivial patch on top of my other pull request https github com scikit learn scikit learn pull 423 so there some noise in the commits submitting this to contribute to the discussion don think this patch should be accepted as is my observations how much the power iteration helps apparently depends on how quickly the singular spectrum decays the matrices was playing with had slowly decaying spectra found 10 got acceptable results judging by whether the singular values matched the non randomized results didn find that the orthonormalization step helped much for my case and the qr did slow things down significantly so didn pursue this patch further perhaps orthonormalizing every few iterations would be good balance >>>new_feature
wip improve ridge conjugate gradient descent reorder terms in the algorithm so that is not explicitly computed and add linearoperator as accepted types this improves existing code in two ways speed get speedups ranging from 5x to more than 10x here are some experimental benchmarks speed plotted as function of matrix density for three types of design matrix square tall and flat code lives here https gist github com 1322711 square https lh3 googleusercontent com 2ppuonxc bs tq5sae2ayyi aaaaaaaaais obaogkb6st4 s640 cg1 png flat https lh3 googleusercontent com xdmwymdllow tq5sae9dngi aaaaaaaaaiw jppez16m9hm s640 cg2 png tall https lh4 googleusercontent com xgx2oflqww0 tq5saok1h6i aaaaaaaaai0 jk fglpvgde s640 cg3 png interface accepting the linearoperator type enables the use of custom matrix vector products effectively enabling to use dense matrices with special structure pytables etc have tried using memmap and while it works it is exhasperately slow probably pytables is much better but haven tried >>>enhancement
factorize common tests easy in test common check that the valueerror raise has useful error message see sparse test for an example put as many of the specific tests in test clustering test transformers into test non meta estimators not so easy calling `fit` forgets the previous model if any check how classifiers handle only one class being present test how models handle non float input does uint8 cause overflows things done we should factorize common tests in new file `test common py` or maybe `test input py` things to check can pickle the object raise an exception when data contains nans raise an exception for invalid input `np matrix` or `sp csr matrix` if dense only implementation raise an exception if `n features` is not the same in `fit` and `predict` or `transform` repr and `clone` work check that we can pickle and unpickle estimators check that all classifiers have ``classes `` attribute needs some fixes edit by amueller edit by gaelvaroquaux on aug 13th 2014 to reflect progress in the codebase >>>easy enhancement
bayesian priors in nearest neighbors classification regression currently the classification and regression algorithms in the `neighbors` module use flat prior they should be modified to compute prior based on training data and to optionally accept user defined prior >>>new_feature
dpgmm and vbgmm clustering weights not updating when trying to cluster the old faithful data set from and the data set from both the dpgmm and vbgmm are unable to find suitable fit it looks as if the component weights are not updating properly as they remain at after fitting the model ve attached an example script which contains example data sets where this problem is displayed tar file including script data and an example figure http www sendspace com file vyecbg old faithful dataset http research microsoft com en us um people cmbishop prml webdatasets datasets htm figueiredo and jain unsupervised learning of finite mixture models pami 2002 thanks martin>>>bug
implement predict scores proposal `predict scores` is method to unify predict methods which output score such as `decision function` `predict proba` etc it should return samples classes array containing scores the bigger the more likely to choose the corresponding class the method signature should be `predict scores self score margin proba log proba or maybe `predict scores self score func margin proba log proba todo list please comment add `predictormixin` which implements `predict scores` just calling the underlying `decision function` `predict proba` etc if present and raising `notimplementederror` if not add `predictormixin` to objects which have `decision function` or `predict proba` method currently `decision function` returns an array of shape samples in the binary case break api to return samples or handle `decision function` separately in `predictormixin predict scores` suggest we create new method `predict margin` which is basically the same as `decision function` but with the array shape fixed and deprecate `decision function` keep it for two releases override `predict scores` in `kmeans` and other clustering modules to return the opposite of the distances to the clusters implement `predict log proba` as the log of `predict proba` in `predictormixin` change `multiclass` module to internally use `predict scores` currently it looks for `decision function` and `predict proba` add `predict scores` to the multiclass estimators `onevsoneclassifier` and `outputcodeclassifier` will need to override `predict scores` probably good candidate for the next sprint >>>api new_feature
implement linear svc predict and decision function in pure python `linearsvc` and `svc` `predict` and `decision function` could easily be implemented in pure python advantages reduce binding size avoid the creation of liblinear and libsvm internal models from numpy arrays sparse matrices at each call disadvantage less memory efficient if `predict` is implemented as the argmax of `decision function` this should also solve the problem that `decision function` is not implemented in `sparse svc` in any case we should probably do little benchmark to make sure we don loose too much in runtime speed >>>enhancement moderate
enhancements to the tree module add sample weights to trees for boosting dts support loss matrix ala rpart support multivariate regression ala mvpart support randomized trees>>>enhancement
wip sparse random projections early pull requests for sparse random projection main paper used as reference for this pr li hastie and church kdd 2006 very sparse random projections http www stanford edu hastie papers ping kdd06 rp pdf http cseweb ucsd edu akmenon verysparserptalk pdf slides todo before merge write narrative doc empirical checks for johnson lindenstrauss in test suite example explaining johnson lindenstrauss embedding update manifold example to use rp module instead of random unitary example on dim reduction ann search on faces data with ball tree >>>new_feature
wip pu learning the dnf method early pull request the dnf method for binary classifier learning from positive and unlabeled data only pu learning issues this works more or less on the dataset currently working on but that not public yet huge and xml encoded tried to come up with an example based on 20news my `pu learning example` branch but that performs very poorly the implementation is transformer that takes `x` and `y` and returns `y transformed` rather than `x transformed` this is different from other transformers ve adopted the convention that 1` means unlabeled if someone can devise an example that makes this work on benchmark dataset be very glad >>>new_feature
minkowski distance in sklearn neighbors once pr 313 is merged it should be fairly straightforward to add keyword `p` to classes in `sklearn neighbors` to specify an arbitrary minkowski metric for nearest neighbors searches `balltree` accepts `p` upon construction `ckdtree` accepts `p` upon querying brute force will be able to make use of the updates in pr 313 the new `sklearn pairwise` module will have functions `manhattan distance` for `p 1` `euclidean distance` for `p 2` and `minkowski distance` for arbitrary `p` these should have output format similar to what is currently used in `sklearn neighbors` with `algorithm brute the code should use these two specialized functions for `p 1` and `p 2` as they are faster than the general routine >>>new_feature
unit test times following discussion on the mailing list about the total build time including testing it was suggested that some of the unit tests are slow the following functions take the most cumulative time in running the tests and give insight into which tests should be addressed first the hmm gmm tests are currently the worst for taking time to run can someone please have look at these tests and work out if its possible to make them faster ve taken some liberty with the following output but its basically the result of running python profile sklearn py grep test for reference profile sklearn py is >>>easy enhancement
argmin and and argmax utilities in pairwise module very often one doesn care about the pairwise distance matrix but just about the argmin or the argmax along an axis it would be nice if all distance functions in the pairwise module had argmin argmax utilities `euclidean distances argmin` this should greatly improve memory consumption to benefit from blas acceleration we can add `chunk size` argument then the original distance function can be called one chunk at time another alternative to be really memory efficient is to use cython but we lose blas acceleration >>>new_feature
fmin cobyla used in gaussian process py does not like np inf the reduced likelihood function in gaussian process gaussian process py returns np inf when the cholesky decomposition of raises an np linalg linalg exception when the objective function of scipy optimize fmin cobyla returns np inf the optimizer passes np nan to the objective function raised this issue on scipy user this np nan causes an exception when trying to do the cholesky decomposition again because this time is full of np nan maybe there are three routes to fixing this issue do something other than return np inf when the cholesky decomposition raises linalg exception have reduced likelihood function treat nan argument better than raising an exception in such way that fmin cobyla can proceed use an optimizer different from fmin cobyla one that handles values of np inf better >>>bug
compile issues with missing ppc assembler howdy just wanted to offer heads up was having an awful go of compiling from source on my machine until eventually figured out the new xcode deletes the ppc assembler from the system link https github com lericson pylibmc issues 35 this ended up being an issue though as python was still trying to support three architectures and since the makefile couldn find one it was throwing broken pipe error in the meantime found that setting the architecture flags in line resolved it even though have this defined in my bash profile >>>enhancement
fastica doesn really take callable argument here snippet from the current `fastica` code https github com scikit learn scikit learn blob 804a280630feeecf54a8a26f111cf749ab753da9 scikits learn decomposition fastica py l209 if isinstance fun str elif callable fun raise valueerror fun argument should be either string one of logcosh exp or cube or function else def fun args return fun fun args def gprime fun args return fun prime fun args haven tried it out but it seems to that `elif callable fun should really be `elif not callable fun love push this change to master but feel it not really useful without test that demonstrates passing arbitrary functions to `fastica` can someone please write such test bthirion agramfort seem to be mostly responsible for the code in this module >>>enhancement
one hot of transformer in preprocessing module this is an early pull request for transformer that builds the sparse one hot of representation of feature space there no example yet the implementation can handle sparse input and haven optimized it what might further have to be done allow the user to mask out some features that must be left as is refactor `labelbinarizer` and `onehottransformer` to factor out the basic operation handle sparse matrices in smarter way without requiring dense intermediate representation want to have this functionality because working on program that has several features that depend on the presence of items from vocabulary using one hot representation for such features is recommended by hsu chang and lin http www csie ntu edu tw cjlin papers guide guide pdf >>>new_feature
wip means coder dictionary learning using means this was here for while but forgot to send the pull request note my three pull requests are incremental the means coder branch includes the dictionary learning sc branch which includes the sparse pca branch best vlad>>>new_feature
memory use of neighborsclassifier on sparse matrices pprett discovered that `neighborsclassifier` working on sparse data takes disproportionately large amount of memory the issue can be reproduced by running the document classification example on all categories then knn takes some 4gb of memory which is 4x the size of its input >>>enhancement
strong rules for discarding predictors in lasso type problems just note to remember that we can arguably still greatly improve the coordinate descent lasso elastic net convergence speed if we implement the following trick http www stat stanford edu tibs ftp strong pdf>>>new_feature
optimize the ica impl for layouted the current ica implementation might be optimized for fortran layouted inputs which is less frequent than layouted data bench to see if it really impacting the performances and if so rewrite the algorithm if possible to work directly on the layouted data instead >>>enhancement
default tolerance for liblinear libsvm wrappers liblinear and libsvm default tolerance parameters are fine tuned for standardized data by upstream authors and give good compromise between accuracy and convergence speed mblondel suggests having an objective function dependent default values for tol we could set tol to none and use dictionary to set the default value >>>enhancement
cython wrapper for crfsuite http www chokkan org software crfsuite crfsuite probably the fastest linear chain crf implementation written in pure with the right license and features sgd optimizer and optional sparse priors this is probably major task to do correct wrapping in addition it will require quite bit of wise thinking to come up with simple yet expressive pythonic api to be able to deal with structured output in efficient and numpy friendly manner >>>new_feature
wip power iteration clustering here is an early pull request far from being ready for merging to master lacks tests docs and class that implements the estimator public api the goal is to let other developers know about some ongoing work to implement power iteration clustering variant of spectral clustering that is supposed to be more scalable according to the authors of the reference paper in practice am not so sure about the tradeoff speed robustness of the results we need to implement better clustering metrics as mentioned in the paper so as to be able to do principled comparison and evaluate the performance of the algorithm edit here is direct link to the reference paper http www cs cmu edu wcohen postscript icml2010 pic final pdf feedback greatly appreciated status todo before merging find way to quantitatively evaluate the quality of the clusters implemented measure and adjusted rand index now in master investigate with the dependency on the value of the `tol` hyperparameter write documentation write tests cleanup the convergence plot code or find non intrusive generic api to deal with such convergence monitoring maybe using callbacks reproduce convergence results of the paper on the 20 newsgroups dataset >>>new_feature
implement logging module was remaining issues in grid search use logger instead of print factorize common parts with libsvm cross val>>>new_feature
command line interface not high priority but would be nice to have command line interface some possible features input in various formats libsvm svmlight sparse format arff raw documents pipeline transformers and estimator model selection evaluation on test set plots model persistence pickle examples skl fit format svmlight model model pickle preprocessing scaling pca pca svm linearsvc input training data txt skl predict format svmlight model model pp input test data txt output predictions txt when input is not provided the input is read from stdin >>>new_feature
common file format support it would be nice to have loaders for common file formats such as libsvm or weka the loaders should have two modes batch and online in the latter case we could have an iterator that spits matrices of given chunk size suitable for partial fit >>>new_feature
use python logging to report on convergence progress it level info for long running tasks this is proposal to use python logging module instead of using stdout and verbose flags in the models api using the logging module would make it easier for the user to control the verbosity of the scikit using single and well documented configuration interface and logging api http docs python org library logging html>>>new_feature
decision function for sparse svc was make sparse svm first class citizens some functions lack in sparse svm probability predict decision function>>>enhancement moderate
add test for multiple drops on lar see comments on commit 269ab1af31d362a7bb2955936646c7478602a68b>>>enhancement
implement generalized cross validation for ridge regression see http en wikipedia org wiki multivariate adaptive regression splines generalized cross validation 28gcv 29 or http www stat nus edu sg staxyc dmchapter0c pdf sec >>>new_feature
implement mallows cp for lar lasso see http en wikipedia org wiki mallows cp it way to select the regularization parameter of the lar lasso without using cross validation implements it>>>new_feature
output of example logistic l1 l2 coef py lacks explanation what does output represent what do different columns represent etc >>>documentation
add docs on how to build with custom lapack>>>build_/_ci documentation
change lasso path output should output an array of coefficients as lars path >>>enhancement
implement warm restarts for logistic regression assigned to me>>>new_feature
return index of support vectors in sparse svm assigned to me>>>enhancement moderate
